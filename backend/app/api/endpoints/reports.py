"""æŠ¥å‘Šç®¡ç†APIç«¯ç‚¹ - v2ç‰ˆæœ¬"""

from fastapi import APIRouter, Depends, HTTPException, status, Query, BackgroundTasks
from fastapi.responses import FileResponse
from sqlalchemy.orm import Session
from typing import List, Optional, Tuple
import uuid
import os
from pathlib import Path
from uuid import UUID
from datetime import datetime
import io
import zipfile
import csv
import re

from app.core.architecture import ApiResponse, PaginatedResponse
from app.core.permissions import require_permission, ResourceType, PermissionLevel
from app.db.session import get_db
from app.core.dependencies import get_current_user
from app.models.user import User
from app.models.report_history import ReportHistory
from app.schemas.report_history import ReportHistoryCreate, ReportHistoryResponse
# ä½¿ç”¨ç»Ÿä¸€æœåŠ¡é—¨é¢æ›¿ä»£ç›´æ¥è·¨å±‚è°ƒç”¨
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/", response_model=ApiResponse)
async def get_reports(
    skip: int = Query(0, ge=0, description="è·³è¿‡çš„è®°å½•æ•°"),
    limit: int = Query(100, ge=1, le=100, description="è¿”å›çš„è®°å½•æ•°"),
    status: Optional[str] = Query(None, description="æŠ¥å‘ŠçŠ¶æ€"),
    template_id: Optional[str] = Query(None, description="æ¨¡æ¿ID"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–æŠ¥å‘Šå†å²åˆ—è¡¨"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    query = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.task.has(owner_id=user_id)
    )
    
    if status:
        query = query.filter(ReportHistory.status == status)
    
    if template_id:
        query = query.filter(ReportHistory.task.has(template_id=template_id))
    
    if search:
        query = query.filter(ReportHistory.task.has(name=search))
    
    # ä¼˜åŒ–ï¼šä¸€æ¬¡æ€§è·å–æ•°æ®å’Œæ€»æ•°ï¼Œé¿å…é‡å¤æŸ¥è¯¢
    reports = query.offset(skip).limit(limit).all()
    
    # å¦‚æœè¿”å›çš„æ•°æ®å°‘äºlimitï¼Œä¸”skipä¸º0ï¼Œåˆ™totalå°±æ˜¯è¿”å›æ•°é‡
    # å¦åˆ™éœ€è¦å•ç‹¬æŸ¥è¯¢æ€»æ•°
    if len(reports) < limit and skip == 0:
        total = len(reports)
    else:
        # é‡æ„æŸ¥è¯¢ä»¥é¿å…JOINçš„countæ€§èƒ½é—®é¢˜
        base_filter = ReportHistory.task.has(owner_id=user_id)
        count_query = db.query(ReportHistory).filter(base_filter)
        
        if status:
            count_query = count_query.filter(ReportHistory.status == status)
        if template_id:
            count_query = count_query.filter(ReportHistory.task.has(template_id=template_id))
        if search:
            count_query = count_query.filter(ReportHistory.task.has(name=search))
            
        total = count_query.count()
    
    # ä½¿ç”¨ç»Ÿä¸€æœåŠ¡é—¨é¢è·å–å¢å¼ºä¿¡æ¯
    try:
        from app.services.application.facades.unified_service_facade import create_unified_service_facade
        facade = create_unified_service_facade(db, str(current_user.id))
        
        enhanced_reports = []
        for report in reports:
            report_data = ReportHistoryResponse.model_validate(report).model_dump()
            
            # æ·»åŠ å¢å¼ºä¿¡æ¯
            report_data.update({
                "name": f"æŠ¥å‘Š #{report.id}",
                "file_size": 0,  # TODO: ä»æ–‡ä»¶å­˜å‚¨æœåŠ¡è·å–å®é™…å¤§å°
                "download_url": f"/api/v1/reports/{report.id}/download",
                "preview_available": report.status == "completed"
            })
            enhanced_reports.append(report_data)
            
    except Exception as e:
        logger.warning(f"è·å–å¢å¼ºä¿¡æ¯å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯: {e}")
        enhanced_reports = [{
            **ReportHistoryResponse.model_validate(report).model_dump(),
            "name": f"æŠ¥å‘Š #{report.id}",
            "file_size": 0,
        } for report in reports]
    
    return ApiResponse(
        success=True,
        data=PaginatedResponse(
            items=enhanced_reports,
            total=total,
            page=skip // limit + 1,
            size=limit,
            pages=(total + limit - 1) // limit,
            has_next=skip + limit < total,
            has_prev=skip > 0
        )
    )


@router.post("/batch/zip", response_model=ApiResponse)
async def download_reports_as_zip(
    request: dict,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ‰¹é‡æ‰“åŒ…ä¸‹è½½æŠ¥å‘Šä¸ºZIPï¼Œå¹¶åŒ…å«æ¸…å•CSVã€‚

    è¯·æ±‚ä½“:
      - report_ids: List[int]
      - filename: Optional[str] è‡ªå®šä¹‰zipæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
      - expires: Optional[int] é¢„ç­¾åé“¾æ¥æœ‰æ•ˆæœŸ(ç§’)ï¼Œé»˜è®¤86400

    è¿”å›:
      ApiResponse: åŒ…å«zipæ–‡ä»¶çš„é¢„ç­¾åä¸‹è½½URLç­‰ä¿¡æ¯
    """
    try:
        report_ids: List[int] = request.get("report_ids", []) or []
        if not isinstance(report_ids, list) or not report_ids:
            raise HTTPException(status_code=400, detail="è¯·æä¾›è¦æ‰“åŒ…çš„æŠ¥å‘ŠIDåˆ—è¡¨")

        # é™åˆ¶å•æ¬¡æ‰¹é‡æ•°é‡ï¼Œé¿å…å†…å­˜å‹åŠ›
        MAX_BUNDLE = 100
        if len(report_ids) > MAX_BUNDLE:
            raise HTTPException(status_code=400, detail=f"å•æ¬¡æœ€å¤šæ”¯æŒ {MAX_BUNDLE} ä¸ªæŠ¥å‘Š")

        expires: int = int(request.get("expires", 86400))
        custom_filename: Optional[str] = request.get("filename")

        # æŸ¥è¯¢ç”¨æˆ·æœ‰æƒé™çš„æŠ¥å‘Š
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)

        reports = db.query(ReportHistory).join(
            ReportHistory.task
        ).filter(
            ReportHistory.id.in_(report_ids),
            ReportHistory.task.has(owner_id=user_id)
        ).all()

        if not reports:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å¯ä¸‹è½½çš„æŠ¥å‘Šæˆ–æ— æƒé™è®¿é—®")

        # å­˜å‚¨æœåŠ¡
        from app.services.infrastructure.storage.hybrid_storage_service import get_hybrid_storage_service
        storage = get_hybrid_storage_service()

        # å‡†å¤‡zipä¸æ¸…å•
        zip_buffer = io.BytesIO()
        manifest_rows: List[Tuple[int, str, str]] = []  # (åºå·, æ—¥æœŸ, æŠ¥å‘Šåç§°)
        included_ids: List[int] = []
        skipped_ids: List[int] = []

        def safe_filename(name: str) -> str:
            # å»é™¤éæ³•å­—ç¬¦ï¼Œä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€-_.å’Œç©ºæ ¼
            return re.sub(r'[^\w\-\.\u4e00-\u9fa5\s]', '_', name).strip()

        with zipfile.ZipFile(zip_buffer, 'w', compression=zipfile.ZIP_DEFLATED) as zf:
            idx = 1
            for rep in reports:
                # ç¡®ä¿æœ‰æ–‡ä»¶å¯ä¸‹è½½ï¼›è‹¥æ— file_pathä½†æœ‰å†…å®¹ï¼Œç”Ÿæˆä¸´æ—¶æŠ¥å‘Šæ–‡ä»¶å¹¶ä¸Šä¼ 
                file_path = rep.file_path
                if not file_path:
                    report_content = rep.result
                    if report_content:
                        filename = f"report_{rep.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                        try:
                            upload_info = storage.upload_file(
                                file_data=io.BytesIO(report_content.encode('utf-8')),
                                original_filename=filename,
                                file_type="reports",
                                content_type="text/markdown"
                            )
                            file_path = upload_info.get("file_path")
                            # æ›´æ–°è®°å½•
                            rep.file_path = file_path
                            db.add(rep)
                            db.commit()
                        except Exception as e:
                            logger.error(f"ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å¤±è´¥: report_id={rep.id}, error={e}")
                            skipped_ids.append(rep.id)
                            continue
                    else:
                        skipped_ids.append(rep.id)
                        continue

                # ä¸‹è½½æ–‡ä»¶æ•°æ®
                try:
                    file_data, backend_type = storage.download_file(file_path)
                except Exception as e:
                    logger.error(f"ä¸‹è½½æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: report_id={rep.id}, path={file_path}, error={e}")
                    skipped_ids.append(rep.id)
                    continue

                # å‹å¥½æ–‡ä»¶å
                base = os.path.basename(file_path)
                # ä¿ç•™åŸå§‹æ‰©å±•å
                if '.' in base:
                    name_wo_ext = base.rsplit('.', 1)[0]
                    ext = '.' + base.rsplit('.', 1)[1]
                else:
                    name_wo_ext = base
                    ext = ''

                # æŠ¥å‘Šç”Ÿæˆæ—¥æœŸï¼ˆyyyy-mm-ddï¼‰
                gen_dt = rep.generated_at or rep.created_at or datetime.utcnow()
                date_str = gen_dt.strftime('%Y-%m-%d')

                # å‹ç¼©å†…çš„æ–‡ä»¶å
                zipped_filename = safe_filename(f"{name_wo_ext}{ext}") or f"report_{rep.id}{ext}"
                # å†™å…¥zipï¼Œæ”¾åœ¨reports/ç›®å½•ä¸‹
                zf.writestr(f"reports/{zipped_filename}", file_data)

                # æ¸…å•è¡Œï¼šåºå·ã€æ—¥æœŸã€æŠ¥å‘Šåç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
                manifest_rows.append((idx, date_str, name_wo_ext))
                included_ids.append(rep.id)
                idx += 1

            # ç”Ÿæˆmanifest.csvï¼ˆUTF-8ï¼‰
            manifest_io = io.StringIO()
            writer = csv.writer(manifest_io)
            writer.writerow(["åºå·", "æ—¥æœŸ", "æŠ¥å‘Šåç§°"])  # è¡¨å¤´
            for row in manifest_rows:
                writer.writerow(list(row))
            zf.writestr("manifest.csv", manifest_io.getvalue().encode('utf-8'))

        # ä¸Šä¼ ZIPåˆ°å­˜å‚¨
        ts = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        zip_name = custom_filename.strip() if isinstance(custom_filename, str) and custom_filename.strip() else f"reports_bundle_{ts}"
        zip_name = safe_filename(zip_name) + ".zip"
        zip_buffer.seek(0)
        upload_info = storage.upload_file(
            file_data=zip_buffer,
            original_filename=zip_name,
            file_type="reports",
            content_type="application/zip"
        )
        zip_path = upload_info.get("file_path")
        download_url = storage.get_download_url(zip_path, expires=expires)

        return ApiResponse(
            success=True,
            data={
                "zip_file_path": zip_path,
                "download_url": download_url,
                "included_count": len(included_ids),
                "included_report_ids": included_ids,
                "skipped_report_ids": skipped_ids,
                "expires": expires,
                "filename": zip_name
            },
            message=f"æ‰“åŒ…å®Œæˆï¼ŒåŒ…å« {len(included_ids)} ä¸ªæŠ¥å‘Š"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡æ‰“åŒ…ä¸‹è½½å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ‰¹é‡æ‰“åŒ…å¤±è´¥")


@router.get("/{task_id}/download-url", response_model=ApiResponse)
async def get_latest_report_download_url(
    task_id: int,
    expires: int = Query(86400, ge=60, le=7*24*3600, description="ä¸‹è½½é“¾æ¥æœ‰æ•ˆæœŸ(ç§’)"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡æœ€è¿‘ä¸€æ¬¡æŠ¥å‘Šçš„é¢„ç­¾åä¸‹è½½URLï¼ˆåŸºäºå­˜å‚¨è·¯å¾„ç”Ÿæˆï¼‰ã€‚"""
    try:
        from app.models.task import Task, TaskExecution, TaskStatus
        from app.services.infrastructure.storage.hybrid_storage_service import get_hybrid_storage_service
        
        # æ ¡éªŒä»»åŠ¡å½’å±
        task = db.query(Task).filter(
            Task.id == task_id,
            Task.owner_id == current_user.id
        ).first()
        if not task:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        # æœ€è¿‘æ‰§è¡Œè®°å½•ï¼ˆå®Œæˆæ€ä¼˜å…ˆï¼‰
        execution = db.query(TaskExecution).filter(
            TaskExecution.task_id == task_id,
            TaskExecution.execution_status == TaskStatus.COMPLETED
        ).order_by(TaskExecution.completed_at.desc().nullslast(), TaskExecution.id.desc()).first()

        if not execution or not execution.execution_result:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="æœªæ‰¾åˆ°å¯ä¸‹è½½çš„æŠ¥å‘Š")

        report_info = (execution.execution_result or {}).get("report") or {}
        storage_path = report_info.get("storage_path")
        if not storage_path:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="æŠ¥å‘ŠæœªåŒ…å«å­˜å‚¨è·¯å¾„")

        storage = get_hybrid_storage_service()
        url = storage.get_download_url(storage_path, expires=expires)

        return ApiResponse(
            success=True,
            data={
                "task_id": task_id,
                "url": url,
                "storage_path": storage_path,
                "expires": expires
            },
            message="è·å–ä¸‹è½½URLæˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æŠ¥å‘Šä¸‹è½½URLå¤±è´¥: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="è·å–ä¸‹è½½URLå¤±è´¥")


from pydantic import BaseModel

class ReportGenerateRequest(BaseModel):
    template_id: str
    data_source_id: str
    name: Optional[str] = None
    description: Optional[str] = None

class IntelligentReportGenerateRequest(BaseModel):
    template_id: str
    data_source_id: str
    optimization_level: Optional[str] = "standard"  # standard, high_performance, memory_optimized
    enable_intelligent_etl: Optional[bool] = True
    batch_size: Optional[int] = 10000
    name: Optional[str] = None
    description: Optional[str] = None

@router.post("/generate", response_model=ApiResponse)
async def generate_report(
    request: ReportGenerateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ç”ŸæˆæŠ¥å‘Š"""
    from app.models.template import Template
    from app.models.data_source import DataSource
    from app.models.task import Task
    from uuid import UUID
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    # å¼ºåˆ¶å‚æ•°è½¬UUID
    try:
        tpl_uuid = UUID(request.template_id)
        ds_uuid = UUID(request.data_source_id)
    except Exception:
        raise HTTPException(status_code=422, detail="æ¨¡æ¿IDæˆ–æ•°æ®æºIDæ ¼å¼é”™è¯¯")
    # éªŒè¯æ¨¡æ¿å’Œæ•°æ®æº
    template = db.query(Template).filter(
        Template.id == tpl_uuid,
        Template.user_id == user_id
    ).first()
    if not template:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ¨¡æ¿ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    data_source = db.query(DataSource).filter(
        DataSource.id == ds_uuid,
        DataSource.user_id == user_id
    ).first()
    if not data_source:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ•°æ®æºä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    # æŸ¥æ‰¾å½“å‰ç”¨æˆ·ä¸‹ä¸æ¨¡æ¿å’Œæ•°æ®æºåŒ¹é…çš„ä»»åŠ¡
    task = db.query(Task).filter(
        Task.owner_id == user_id,
        Task.template_id == tpl_uuid,
        Task.data_source_id == ds_uuid
    ).order_by(Task.id.desc()).first()
    if not task:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æœªæ‰¾åˆ°åŒ¹é…çš„ä»»åŠ¡"
        )
    
    # åœ¨åå°ç”ŸæˆæŠ¥å‘Š
    background_tasks.add_task(
        generate_report_task,
        template_id=str(tpl_uuid),
        data_source_id=str(ds_uuid),
        user_id=str(user_id),
        task_id=task.id
    )
    return ApiResponse(
        success=True,
        data={
            "task_id": task.id,
            "status": "pending",
            "message": "æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤"
        },
        message="æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤"
    )


@router.post("/generate/intelligent", response_model=ApiResponse)
async def generate_intelligent_report(
    request: IntelligentReportGenerateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ - ä½¿ç”¨Agentç®¡é“ç³»ç»Ÿè¿›è¡Œå®Œæ•´çš„æŠ¥å‘Šå¤„ç†"""
    from app.models.template import Template
    from app.models.data_source import DataSource
    from app.models.task import Task
    from uuid import UUID
    
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
        
    # å¼ºåˆ¶å‚æ•°è½¬UUID
    try:
        tpl_uuid = UUID(request.template_id)
        ds_uuid = UUID(request.data_source_id)
    except Exception:
        raise HTTPException(status_code=422, detail="æ¨¡æ¿IDæˆ–æ•°æ®æºIDæ ¼å¼é”™è¯¯")
        
    # éªŒè¯æ¨¡æ¿å’Œæ•°æ®æº
    template = db.query(Template).filter(
        Template.id == tpl_uuid,
        Template.user_id == user_id
    ).first()
    if not template:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ¨¡æ¿ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
        
    data_source = db.query(DataSource).filter(
        DataSource.id == ds_uuid,
        DataSource.user_id == user_id
    ).first()
    if not data_source:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ•°æ®æºä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
        
    # æŸ¥æ‰¾æˆ–åˆ›å»ºä»»åŠ¡
    task = db.query(Task).filter(
        Task.owner_id == user_id,
        Task.template_id == tpl_uuid,
        Task.data_source_id == ds_uuid
    ).order_by(Task.id.desc()).first()
    
    if not task:
        # åˆ›å»ºæ–°ä»»åŠ¡
        from app.schemas.task import TaskCreate
        task_data = TaskCreate(
            name=request.name or f"æ™ºèƒ½æŠ¥å‘Šä»»åŠ¡-{template.name}",
            description=request.description or f"åŸºäºæ¨¡æ¿{template.name}çš„Agenté©±åŠ¨æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ",
            template_id=tpl_uuid,
            data_source_id=ds_uuid,
            schedule_type="once"
        )
        from app.crud.crud_task import crud_task
        task = crud_task.create_with_owner(db=db, obj_in=task_data, owner_id=user_id)
        
    # åˆ›å»ºæŠ¥å‘Šå†å²è®°å½•
    report_data = ReportHistoryCreate(
        task_id=task.id,
        user_id=user_id,
        status="pending"
    )
    
    # åœ¨åå°ä½¿ç”¨Agentç®¡é“ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š
    background_tasks.add_task(
        generate_agent_based_intelligent_report_task,
        template_id=str(tpl_uuid),
        data_source_id=str(ds_uuid),
        user_id=str(user_id),
        task_id=task.id,
        optimization_level=request.optimization_level,
        enable_intelligent_etl=request.enable_intelligent_etl,
        batch_size=request.batch_size
    )
    
    return ApiResponse(
        success=True,
        data={
            "task_id": task.id,
            "status": "pending",
            "optimization_level": request.optimization_level,
            "batch_size": request.batch_size,
            "agent_pipeline": "enabled",
            "message": "Agenté©±åŠ¨çš„æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤"
        },
        message="Agenté©±åŠ¨çš„æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼Œæ”¯æŒå®Œæ•´çš„æ•°æ®åˆ†æç®¡é“"
    )


@router.get("/{report_id}", response_model=ApiResponse)
async def get_report(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ç‰¹å®šæŠ¥å‘Š"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    report = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.id == report_id,
        ReportHistory.task.has(owner_id=user_id)
    ).first()
    
    if not report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    return ApiResponse(
        success=True,
        data={
            **ReportHistoryResponse.model_validate(report).model_dump(),
            "name": f"æŠ¥å‘Š #{report.id}",
            "file_size": 0,
            "content": report.result if report.status == "completed" else None,
        },
        message="è·å–æŠ¥å‘ŠæˆåŠŸ"
    )


@router.delete("/batch", response_model=ApiResponse)
async def batch_delete_reports(
    request: dict,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ‰¹é‡åˆ é™¤æŠ¥å‘Š"""
    try:
        report_ids = request.get("report_ids", [])
        if not report_ids:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="è¯·æä¾›è¦åˆ é™¤çš„æŠ¥å‘ŠIDåˆ—è¡¨"
            )
        
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)
        
        # æŸ¥æ‰¾ç”¨æˆ·æœ‰æƒé™åˆ é™¤çš„æŠ¥å‘Š
        reports_to_delete = db.query(ReportHistory).join(
            ReportHistory.task
        ).filter(
            ReportHistory.id.in_(report_ids),
            ReportHistory.task.has(owner_id=user_id)
        ).all()
        
        if not reports_to_delete:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æœªæ‰¾åˆ°å¯åˆ é™¤çš„æŠ¥å‘Šæˆ–æ— æƒé™è®¿é—®"
            )
        
        # æ‰§è¡Œæ‰¹é‡åˆ é™¤
        deleted_count = 0
        deleted_ids = []
        for report in reports_to_delete:
            db.delete(report)
            deleted_ids.append(report.id)
            deleted_count += 1
        
        db.commit()
        
        return ApiResponse(
            success=True,
            data={
                "deleted_count": deleted_count,
                "deleted_ids": deleted_ids,
                "requested_count": len(report_ids)
            },
            message=f"æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªæŠ¥å‘Š"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ é™¤æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‰¹é‡åˆ é™¤å¤±è´¥: {str(e)}"
        )


@router.delete("/{report_id}", response_model=ApiResponse)
async def delete_report(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ é™¤æŠ¥å‘Š"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    report = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.id == report_id,
        ReportHistory.task.has(owner_id=user_id)
    ).first()
    
    if not report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    db.delete(report)
    db.commit()
    
    return ApiResponse(
        success=True,
        data={"report_id": report_id},
        message="æŠ¥å‘Šåˆ é™¤æˆåŠŸ"
    )


@router.post("/{report_id}/regenerate", response_model=ApiResponse)
async def regenerate_report(
    report_id: int,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """é‡æ–°ç”ŸæˆæŠ¥å‘Š"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    report = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.id == report_id,
        ReportHistory.task.has(owner_id=user_id)
    ).first()
    
    if not report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    # æ›´æ–°çŠ¶æ€ä¸ºé‡æ–°ç”Ÿæˆ
    report.status = "regenerating"
    db.commit()
    
    # åœ¨åå°é‡æ–°ç”Ÿæˆ
    background_tasks.add_task(
        regenerate_report_task,
        report_id=report_id
    )
    
    return ApiResponse(
        success=True,
        data={
            "report_id": report_id,
            "status": "regenerating",
            "message": "æŠ¥å‘Šé‡æ–°ç”Ÿæˆä»»åŠ¡å·²æäº¤"
        },
        message="æŠ¥å‘Šé‡æ–°ç”Ÿæˆä»»åŠ¡å·²æäº¤"
    )


@router.get("/{report_id}/content", response_model=ApiResponse)
async def get_report_content(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–æŠ¥å‘Šå†…å®¹"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    report = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.id == report_id,
        ReportHistory.task.has(owner_id=user_id)
    ).first()
    
    if not report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    if report.status != "completed":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æŠ¥å‘Šå°šæœªå®Œæˆç”Ÿæˆ"
        )
    
    return ApiResponse(
        success=True,
        data={
            "content": report.result or "æŠ¥å‘Šå†…å®¹ä¸ºç©º",
            "status": report.status,
            "generated_at": report.generated_at.isoformat() if report.generated_at else None
        },
        message="è·å–æŠ¥å‘Šå†…å®¹æˆåŠŸ"
    )


@router.get("/{report_id}/download-info")
async def get_report_download_info(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–æŠ¥å‘Šä¸‹è½½ä¿¡æ¯"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    report = db.query(ReportHistory).join(
        ReportHistory.task
    ).filter(
        ReportHistory.id == report_id,
        ReportHistory.task.has(owner_id=user_id)
    ).first()
    
    if not report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    if report.status != "completed":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æŠ¥å‘Šå°šæœªå®Œæˆç”Ÿæˆ"
        )
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶è·¯å¾„å­˜å‚¨
    if not report.file_path:
        # å¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„å†…å®¹æ–‡ä»¶
        try:
            from app.services.infrastructure.storage.hybrid_storage_service import get_hybrid_storage_service
            from io import BytesIO
            import tempfile
            import os
            
            storage_service = get_hybrid_storage_service()
            
            # åˆ›å»ºæŠ¥å‘Šå†…å®¹æ–‡ä»¶
            report_content = report.result or "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
            filename = f"report_{report_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            # ä¸Šä¼ åˆ°å­˜å‚¨ç³»ç»Ÿ
            file_info = storage_service.upload_file(
                file_data=BytesIO(report_content.encode('utf-8')),
                original_filename=filename,
                file_type="reports",
                content_type="text/plain"
            )
            
            # æ›´æ–°æŠ¥å‘Šè®°å½•
            report.file_path = file_info["file_path"]
            db.commit()
            
            logger.info(f"ä¸ºæŠ¥å‘Š {report_id} åˆ›å»ºäº†ä¸´æ—¶æ–‡ä»¶: {file_info['file_path']}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="æ— æ³•å‡†å¤‡æŠ¥å‘Šä¸‹è½½"
            )
    
    return ApiResponse(
        success=True,
        data={
            "report_id": report_id,
            "download_url": f"/api/v1/reports/{report_id}/download",
            "filename": f"report_{report_id}.txt",
            "file_size": len(report.result.encode('utf-8')) if report.result else 0,
            "has_file": bool(report.file_path)
        },
        message="æŠ¥å‘Šä¸‹è½½ä¿¡æ¯å·²å‡†å¤‡"
    )


async def generate_report_task(
    template_id: str,
    data_source_id: str,
    user_id: str,
    task_id: int
):
    """åå°ç”ŸæˆæŠ¥å‘Šä»»åŠ¡ - ä½¿ç”¨ç»Ÿä¸€æœåŠ¡é—¨é¢"""
    try:
        from app.db.session import get_db_session
        from app.services.application.facades.unified_service_facade import create_unified_service_facade
        from app.schemas.report_history import ReportHistoryCreate
        from app.crud.crud_report_history import report_history
        from uuid import UUID
        
        # åˆ›å»ºæŠ¥å‘Šå†å²è®°å½•
        with get_db_session() as db:
            report_data = ReportHistoryCreate(
                task_id=task_id,
                user_id=UUID(user_id),
                status="pending"
            )
            report_record = report_history.create(db=db, obj_in=report_data)
            db.commit()
            report_id = report_record.id
        
        # ä½¿ç”¨ç»Ÿä¸€æœåŠ¡é—¨é¢ç”ŸæˆæŠ¥å‘Š
        with get_db_session() as db:
            facade = create_unified_service_facade(db, user_id)
            
            # è·å–æ¨¡æ¿å†…å®¹
            from app.crud import template as crud_template
            template = crud_template.get(db, id=template_id)
            if not template:
                raise Exception(f"æ¨¡æ¿ {template_id} ä¸å­˜åœ¨")
            
            # ç”Ÿæˆå›¾è¡¨æ•°æ®
            chart_result = await facade.generate_charts(
                data_source=f"SELECT * FROM data_source_{data_source_id}",
                requirements="ç”ŸæˆåŸºç¡€æŠ¥å‘Šå›¾è¡¨",
                output_format="json"
            )
            
            # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆç»“æœ
            filled_template = f"""
            # æŠ¥å‘Šæ ‡é¢˜: {template.name}
            
            ## æ•°æ®åˆ†æç»“æœ
            æ¨¡æ¿ ID: {template_id}
            æ•°æ®æº ID: {data_source_id}
            ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
            
            ## å›¾è¡¨æ•°æ®
            {chart_result.get('generated_charts', [])}
            
            ## ç»“è®º
            æŠ¥å‘Šç”Ÿæˆå®Œæˆã€‚
            """
            
            # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€
            report = db.query(ReportHistory).filter(ReportHistory.id == report_id).first()
            if report:
                report.status = "completed"
                report.result = filled_template
                report.processing_metadata = {
                    "chart_generation": chart_result,
                    "processing_time": datetime.now().isoformat(),
                    "template_name": template.name
                }
                db.commit()
            
            return {
                "success": True,
                "filled_template": filled_template,
                "processing_metadata": report.processing_metadata
            }
        
    except Exception as e:
        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€ä¸ºå¤±è´¥
        with get_db_session() as db:
            report = db.query(ReportHistory).filter(
                ReportHistory.task_id == task_id
            ).order_by(ReportHistory.id.desc()).first()
            
            if report:
                report.status = "failed"
                report.error_message = str(e)
                db.commit()
        
        logger.error(f"æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
        raise e


async def generate_intelligent_report_task(
    template_id: str,
    data_source_id: str,
    user_id: str,
    task_id: int,
    optimization_config: dict
):
    """åå°æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆä»»åŠ¡"""
    try:
        # åˆå§‹åŒ–Agentç¼–æ’å™¨ï¼Œæ”¯æŒä¼˜åŒ–å‚æ•°
        agent_orchestrator = AgentOrchestrator()
        
        # æ ¹æ®ä¼˜åŒ–çº§åˆ«é…ç½®å‚æ•°
        config = {
            "optimization_level": optimization_level,
            "enable_intelligent_etl": enable_intelligent_etl,
            "batch_size": batch_size
        }
        
        if optimization_level == "high_performance":
            config["batch_size"] = min(batch_size, 5000)  # å°æ‰¹æ¬¡å¤„ç†
            config["enable_caching"] = True
            config["parallel_processing"] = True
        elif optimization_level == "memory_optimized":
            config["batch_size"] = min(batch_size, 1000)  # æå°æ‰¹æ¬¡
            config["streaming_mode"] = True
            config["memory_threshold"] = 0.8
        
        # ä½¿ç”¨Agentç³»ç»Ÿç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š
        placeholder_input = {
            "template_id": template_id,
            "data_source_id": data_source_id,
            "user_id": user_id,
            "placeholder_type": "comprehensive",
            "config": config
        }
        
        agent_result = await agent_orchestrator.execute(placeholder_input)
        result = {
            "filled_template": agent_result.data if agent_result.success else "",
            "processing_metadata": agent_result.metadata or {},
            "success": agent_result.success,
            "error_message": agent_result.error_message if not agent_result.success else None
        }
        
        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€
        from app.db.session import get_db_session
        with get_db_session() as db:
            from app.models.task import Task
            from uuid import UUID
            
            task = db.query(Task).filter(
                Task.owner_id == UUID(user_id),
                Task.template_id == UUID(template_id),
                Task.data_source_id == UUID(data_source_id)
            ).order_by(Task.id.desc()).first()
            
            if task:
                report = db.query(ReportHistory).filter(
                    ReportHistory.task_id == task.id
                ).order_by(ReportHistory.id.desc()).first()
                
                if report:
                    report.status = "completed"
                    report.result = result.get("filled_template", "")
                    report.processing_metadata = {
                        **result.get("processing_metadata", {}),
                        "optimization_level": optimization_level,
                        "batch_size": batch_size,
                        "intelligent_etl_enabled": enable_intelligent_etl
                    }
                    db.commit()
        
        return result
        
    except Exception as e:
        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€ä¸ºå¤±è´¥
        from app.db.session import get_db_session
        with get_db_session() as db:
            from app.models.task import Task
            from uuid import UUID
            
            task = db.query(Task).filter(
                Task.owner_id == UUID(user_id),
                Task.template_id == UUID(template_id),
                Task.data_source_id == UUID(data_source_id)
            ).order_by(Task.id.desc()).first()
            
            if task:
                report = db.query(ReportHistory).filter(
                    ReportHistory.task_id == task.id
                ).order_by(ReportHistory.id.desc()).first()
                
                if report:
                    report.status = "failed"
                    report.error_message = str(e)
                    report.processing_metadata = {
                        "optimization_level": optimization_level,
                        "batch_size": batch_size,
                        "error_type": type(e).__name__
                    }
                    db.commit()
        
        raise e


async def generate_agent_based_intelligent_report_task(
    template_id: str,
    data_source_id: str,
    user_id: str,
    task_id: int,
    optimization_level: str = "standard",
    enable_intelligent_etl: bool = True,
    batch_size: int = 10000
):
    """Agenté©±åŠ¨çš„åå°æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆä»»åŠ¡"""
    try:
        # åˆ›å»ºæŠ¥å‘Šå†å²è®°å½•
        from app.db.session import get_db_session
        report_record_id = None
        
        with get_db_session() as db:
            from app.schemas.report_history import ReportHistoryCreate
            from uuid import UUID
            from app.crud.crud_report_history import report_history
            
            report_data = ReportHistoryCreate(
                task_id=task_id,
                user_id=UUID(user_id),
                status="processing"
            )
            report_record = report_history.create(db=db, obj_in=report_data)
            report_record_id = report_record.id
            db.commit()
            
            # è·å–æ¨¡æ¿å’Œæ•°æ®æºä¿¡æ¯
            from app.models.template import Template
            from app.models.data_source import DataSource
            template = db.query(Template).filter(Template.id == UUID(template_id)).first()
            data_source = db.query(DataSource).filter(DataSource.id == UUID(data_source_id)).first()
        
        # ä½¿ç”¨æ–°çš„agentsç³»ç»Ÿç”Ÿæˆæ™ºèƒ½æŠ¥å‘Šå†…å®¹
        try:
            from app.api.utils.agent_context_helpers import create_report_generation_context
            # Updated to use new Agent system
            from app.services.infrastructure.agents import AgentFacade, AgentInput, PlaceholderSpec, SchemaInfo, TaskContext, AgentConstraints
            from app.core.container import Container
            
            # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆä¸Šä¸‹æ–‡
            data_source_info = {
                "name": data_source.name if data_source else 'æœªçŸ¥æ•°æ®æº',
                "type": data_source.source_type.value if data_source and hasattr(data_source.source_type, 'value') else 'unknown',
                "schema": {
                    "table_name": getattr(data_source, 'doris_database', 'main_table') if data_source else 'main_table',
                    "columns": [],  # Could be populated from actual schema
                    "relationships": []
                }
            }
            
            user_requirements = {
                "optimization_level": optimization_level,
                "batch_size": batch_size,
                "enable_intelligent_etl": enable_intelligent_etl,
                "report_sections": [
                    "æ‰§è¡Œæ‘˜è¦", "æ•°æ®æ¦‚è§ˆ", "å…³é”®æŒ‡æ ‡", "è¶‹åŠ¿åˆ†æ", "æ´å¯Ÿå»ºè®®", "ç»“è®º"
                ]
            }
            
            template_info = {
                "id": template_id,
                "name": template.name if template else 'æœªçŸ¥æ¨¡æ¿',
                "content": template.content if template else "",
                "metadata": {
                    "template_type": template.template_type if template else 'docx',
                    "original_filename": getattr(template, 'original_filename', None)
                }
            } if template else None
            
            context = create_report_generation_context(
                report_type="business_intelligence",
                data_source_info=data_source_info,
                user_requirements=user_requirements,
                template_info=template_info
            )
            
            # æ„å»ºæŠ¥å‘Šç”Ÿæˆå†…å®¹
            report_content = f"""
            ä¸šåŠ¡åˆ†ææŠ¥å‘Šç”Ÿæˆè¯·æ±‚ - æŠ¥å‘ŠID: {report_record_id}
            
            æ¨¡æ¿ä¿¡æ¯:
            - æ¨¡æ¿åç§°: {template.name if template else 'æœªçŸ¥æ¨¡æ¿'}
            - æ¨¡æ¿ç±»å‹: {template.template_type if template else 'docx'}
            - æ¨¡æ¿ID: {template_id}
            
            æ•°æ®æºä¿¡æ¯:
            - æ•°æ®æºåç§°: {data_source.name if data_source else 'æœªçŸ¥æ•°æ®æº'}
            - æ•°æ®æºç±»å‹: {data_source.source_type if data_source else 'unknown'}
            - ä¸»æœºåœ°å€: {data_source.doris_fe_hosts[0] if data_source and data_source.doris_fe_hosts else '192.168.31.160'}
            - æ•°æ®æºID: {data_source_id}
            
            ä¼˜åŒ–é…ç½®:
            - ä¼˜åŒ–çº§åˆ«: {optimization_level}
            - æ‰¹å¤„ç†å¤§å°: {batch_size}
            - æ™ºèƒ½ETL: {enable_intelligent_etl}
            
            ç”Ÿæˆè¦æ±‚ï¼š
            1. æ‰§è¡Œæ‘˜è¦
            2. æ•°æ®æ¦‚è§ˆå’Œç»Ÿè®¡
            3. å…³é”®ä¸šåŠ¡æŒ‡æ ‡åˆ†æ
            4. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«å›¾è¡¨æè¿°ï¼‰
            5. ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®
            6. ç»“è®º
            
            æŠ¥å‘Šåº”è¯¥ä¸“ä¸šã€è¯¦ç»†ï¼ŒåŒ…å«æ•°æ®é©±åŠ¨çš„æ´å¯Ÿå’Œå¯è§†åŒ–å›¾è¡¨çš„æè¿°ã€‚
            ä½¿ç”¨Markdownæ ¼å¼ç”ŸæˆæŠ¥å‘Šå†…å®¹ã€‚
            
            ç”¨æˆ·ID: {user_id}
            ç”Ÿæˆæ—¶é—´: {datetime.utcnow().isoformat()}
            """
            
            agent_result = await execute_agent_task(
                task_name="intelligent_report_generation",
                task_description=f"ç”ŸæˆåŸºäºæ¨¡æ¿ {template.name if template else 'æœªçŸ¥'} çš„æ™ºèƒ½ä¸šåŠ¡åˆ†ææŠ¥å‘Š",
                context_data=context,
                additional_data={
                    "template_content": report_content,
                    "data_source_info": {
                        "type": data_source.source_type.value if data_source and hasattr(data_source.source_type, 'value') else 'unknown',
                        "database": getattr(data_source, 'doris_database', 'unknown') if data_source else 'unknown',
                        "name": data_source.name if data_source else 'unknown',
                        "optimization_level": optimization_level,
                        "task_type": "report_generation",
                        "data_source_id": data_source_id
                    }
                }
            )
            
            # æå–å®é™…çš„å“åº”å†…å®¹
            raw_response = agent_result.get('response', str(agent_result))
            # å¦‚æœå“åº”æ˜¯ç‰¹æ®Šæ ¼å¼ï¼Œæå–çœŸå®å†…å®¹
            if isinstance(raw_response, str) and 'åŸºäºclaude-3-5-sonnet-20241022çš„å›ç­”:' in raw_response:
                # å°è¯•ä»å“åº”ä¸­æå–å®é™…å†…å®¹ï¼ˆè·³è¿‡å‰ç¼€ï¼‰
                try:
                    parts = raw_response.split('åŸºäºclaude-3-5-sonnet-20241022çš„å›ç­”:')
                    if len(parts) > 1:
                        # è·å–å®é™…å›ç­”éƒ¨åˆ†
                        actual_content = parts[1].strip()
                        # è¿›ä¸€æ­¥å¤„ç†ï¼Œç§»é™¤ä¸Šä¸‹æ–‡ä¿¡æ¯éƒ¨åˆ†
                        if 'task_type:' in actual_content:
                            content_lines = actual_content.split('\n')
                            # æ‰¾åˆ°å®é™…å†…å®¹å¼€å§‹çš„åœ°æ–¹ï¼ˆè·³è¿‡ä¸Šä¸‹æ–‡è¡Œï¼‰
                            content_start = 0
                            for i, line in enumerate(content_lines):
                                if not line.strip().startswith(('task_type:', 'template_id:', 'data_source_id:', 'optimization_level:')):
                                    content_start = i
                                    break
                            actual_content = '\n'.join(content_lines[content_start:]).strip()
                        
                        report_content = actual_content if actual_content else "æŠ¥å‘Šå†…å®¹ç”Ÿæˆä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹å®Œæ•´ç‰ˆæœ¬ã€‚"
                    else:
                        report_content = raw_response
                except:
                    report_content = raw_response
            else:
                report_content = raw_response
            
            # ç”Ÿæˆå›¾è¡¨æ•°æ®æè¿°
            chart_prompt = f"""
            ä¸ºä¸Šé¢çš„æŠ¥å‘Šç”Ÿæˆç›¸åº”çš„å›¾è¡¨é…ç½®å’Œæ•°æ®æè¿°ï¼š
            
            è¯·ä¸ºæŠ¥å‘Šç”Ÿæˆä»¥ä¸‹ç±»å‹çš„å›¾è¡¨æè¿°ï¼š
            1. æŸ±çŠ¶å›¾ï¼šæ˜¾ç¤ºå…³é”®æŒ‡æ ‡å¯¹æ¯”
            2. æŠ˜çº¿å›¾ï¼šå±•ç¤ºè¶‹åŠ¿å˜åŒ–
            3. é¥¼å›¾ï¼šæ˜¾ç¤ºæ„æˆåˆ†æ
            4. é¢ç§¯å›¾ï¼šæ˜¾ç¤ºç´¯è®¡æ•ˆæœ
            
            æ¯ä¸ªå›¾è¡¨è¯·æä¾›ï¼š
            - å›¾è¡¨æ ‡é¢˜
            - æ•°æ®ç³»åˆ—æè¿°
            - å»ºè®®çš„é¢œè‰²ä¸»é¢˜
            - äº¤äº’æ€§é…ç½®
            
            æ ¼å¼ï¼šJSONé…ç½® + å›¾è¡¨è¯´æ˜
            """
            
            # ä½¿ç”¨agentsç³»ç»Ÿç”Ÿæˆå›¾è¡¨æè¿°
            from app.api.utils.agent_context_helpers import create_data_analysis_context
            
            chart_context = create_data_analysis_context(
                analysis_type="chart_generation",
                data_info=data_source_info,
                analysis_parameters={
                    "chart_types": ["bar", "line", "pie", "area"],
                    "optimization_level": optimization_level,
                    "report_content": report_content[:1000]  # First 1000 chars for context
                }
            )
            
            chart_result = await execute_agent_task(
                task_name="chart_generation",
                task_description="ä¸ºæŠ¥å‘Šç”Ÿæˆç›¸åº”çš„å›¾è¡¨é…ç½®å’Œæ•°æ®æè¿°",
                context_data=chart_context
            )
            
            # æå–å›¾è¡¨å“åº”å†…å®¹
            raw_chart_response = chart_result.get('response', str(chart_result))
            # åŒæ ·å¤„ç†å›¾è¡¨å“åº”çš„ç‰¹æ®Šæ ¼å¼
            if isinstance(raw_chart_response, str) and 'åŸºäºclaude-3-5-sonnet-20241022çš„å›ç­”:' in raw_chart_response:
                try:
                    parts = raw_chart_response.split('åŸºäºclaude-3-5-sonnet-20241022çš„å›ç­”:')
                    if len(parts) > 1:
                        actual_content = parts[1].strip()
                        if 'task_type:' in actual_content:
                            content_lines = actual_content.split('\n')
                            content_start = 0
                            for i, line in enumerate(content_lines):
                                if not line.strip().startswith(('task_type:', 'chart_types:')):
                                    content_start = i
                                    break
                            actual_content = '\n'.join(content_lines[content_start:]).strip()
                        
                        chart_content = actual_content if actual_content else "å›¾è¡¨é…ç½®ç”Ÿæˆä¸­ï¼Œè¯·ç¨åæŸ¥çœ‹å®Œæ•´ç‰ˆæœ¬ã€‚"
                    else:
                        chart_content = raw_chart_response
                except:
                    chart_content = raw_chart_response
            else:
                chart_content = raw_chart_response
            
            # ç»„åˆæœ€ç»ˆæŠ¥å‘Šå†…å®¹
            final_content = f"""
# æ™ºèƒ½ä¸šåŠ¡åˆ†ææŠ¥å‘Š

{report_content}

---

## ğŸ“Š å›¾è¡¨é…ç½®å’Œå¯è§†åŒ–

{chart_content}

---

## ğŸ“‹ æŠ¥å‘Šå…ƒæ•°æ®

- **ç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}
- **æ•°æ®æº**: {data_source.name if data_source else 'æœªçŸ¥'} ({data_source.source_type if data_source else 'unknown'})
- **æ¨¡æ¿**: {template.name if template else 'æœªçŸ¥æ¨¡æ¿'}
- **ä¼˜åŒ–çº§åˆ«**: {optimization_level}
- **Agentç³»ç»Ÿ**: React Agent (claude-3-5-sonnet-20241022)
- **ç”Ÿæˆæ¨¡å¼**: æ™ºèƒ½åˆ†æ + å›¾è¡¨ç”Ÿæˆ
- **AIå“åº”ç»Ÿè®¡**: åˆ†æè€—æ—¶{agent_result.get('conversation_time', 0)*1000:.2f}ms, å›¾è¡¨è€—æ—¶{chart_result.get('conversation_time', 0)*1000:.2f}ms

---

*æœ¬æŠ¥å‘Šç”±AutoReportAIç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œé‡‡ç”¨React Agentæ™ºèƒ½åˆ†ææŠ€æœ¯*
            """.strip()
            
        except Exception as agent_error:
            logger.error(f"AgentæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {agent_error}")
            # ç”Ÿæˆä¸€ä¸ªç®€åŒ–çš„æŠ¥å‘Šä½œä¸ºé™çº§æ–¹æ¡ˆ
            final_content = f"""
# ä¸šåŠ¡åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
åŸºäº{data_source.name if data_source else 'æ•°æ®æº'}çš„ä¸šåŠ¡åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆã€‚

## æ•°æ®æºä¿¡æ¯
- æ•°æ®æº: {data_source.name if data_source else 'æœªçŸ¥æ•°æ®æº'}
- ç±»å‹: {data_source.source_type if data_source else 'unknown'}
- çŠ¶æ€: {'æ´»è·ƒ' if data_source and data_source.is_active else 'æœªçŸ¥'}

## æ¨¡æ¿ä¿¡æ¯
- æ¨¡æ¿åç§°: {template.name if template else 'æœªçŸ¥æ¨¡æ¿'}
- æ¨¡æ¿ç±»å‹: {template.template_type if template else 'docx'}

## åˆ†æé…ç½®
- ä¼˜åŒ–çº§åˆ«: {optimization_level}
- æ‰¹å¤„ç†å¤§å°: {batch_size}
- æ™ºèƒ½ETLå¯ç”¨: {enable_intelligent_etl}

## ç³»ç»Ÿä¿¡æ¯
- ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
- ä»»åŠ¡ID: {task_id}
- Agenté”™è¯¯: {str(agent_error)}

æœ¬æŠ¥å‘Šä½¿ç”¨ç®€åŒ–æ¨¡å¼ç”Ÿæˆã€‚å¦‚éœ€å®Œæ•´åˆ†æï¼Œè¯·æ£€æŸ¥Agentç³»ç»Ÿé…ç½®ã€‚
            """.strip()
        
        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€
        with get_db_session() as db:
            report = db.query(ReportHistory).filter(
                ReportHistory.id == report_record_id
            ).first()
            
            if report:
                report.status = "completed"
                report.result = final_content
                report.processing_metadata = {
                    "agent_pipeline": True,
                    "optimization_level": optimization_level,
                    "batch_size": batch_size,
                    "intelligent_etl_enabled": enable_intelligent_etl,
                    "generation_method": "react_agent",
                    "template_name": template.name if template else "unknown",
                    "data_source_name": data_source.name if data_source else "unknown",
                    "content_length": len(final_content),
                    "generated_at": datetime.now().isoformat()
                }
                db.commit()
        
        return final_content
        
    except Exception as e:
        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€ä¸ºå¤±è´¥
        try:
            from app.db.session import get_db_session
            with get_db_session() as db:
                report = db.query(ReportHistory).filter(
                    ReportHistory.task_id == task_id
                ).order_by(ReportHistory.id.desc()).first()
                
                if report:
                    report.status = "failed"
                    report.error_message = str(e)
                    report.processing_metadata = {
                        "agent_pipeline": True,
                        "optimization_level": optimization_level,
                        "batch_size": batch_size,
                        "error_type": type(e).__name__
                    }
                    db.commit()
        except Exception as db_error:
            logger.error(f"Failed to update report status: {db_error}")
        
        logger.error(f"Agent-based report generation failed: {e}")
        raise e


async def regenerate_report_task(report_id: int):
    """åå°é‡æ–°ç”ŸæˆæŠ¥å‘Šä»»åŠ¡"""
    try:
        # è·å–åŸå§‹æŠ¥å‘Šé…ç½®å¹¶é‡æ–°ä½¿ç”¨Agentç®¡é“ç”Ÿæˆ
        from app.db.session import get_db_session
        with get_db_session() as db:
            report = db.query(ReportHistory).filter(ReportHistory.id == report_id).first()
            
            if not report or not report.task:
                logger.error(f"Report {report_id} not found for regeneration")
                return
            
            task = report.task
            metadata = report.processing_metadata or {}
            
            # ä½¿ç”¨Agentç®¡é“é‡æ–°ç”Ÿæˆ
            await generate_agent_based_intelligent_report_task(
                template_id=str(task.template_id),
                data_source_id=str(task.data_source_id),
                user_id=str(task.owner_id),
                task_id=task.id,
                optimization_level=metadata.get("optimization_level", "standard"),
                enable_intelligent_etl=metadata.get("intelligent_etl_enabled", True),
                batch_size=metadata.get("batch_size", 10000)
            )
            
    except Exception as e:
        logger.error(f"Report regeneration failed: {e}")


@router.get("/{report_id}/download")
async def download_report(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ä¸‹è½½æŠ¥å‘Šæ–‡ä»¶"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)
        
        # æŸ¥æ‰¾æŠ¥å‘Šè®°å½•
        report = db.query(ReportHistory).join(
            ReportHistory.task
        ).filter(
            ReportHistory.id == report_id,
            ReportHistory.task.has(owner_id=user_id)
        ).first()
        
        if not report:
            raise HTTPException(
                status_code=404,
                detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ²¡æœ‰è®¿é—®æƒé™"
            )
        
        if report.status != "completed":
            raise HTTPException(
                status_code=400,
                detail=f"æŠ¥å‘Šå°šæœªç”Ÿæˆå®Œæˆï¼Œå½“å‰çŠ¶æ€: {report.status}"
            )
        
        # å¦‚æœæ²¡æœ‰æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•ä»å­˜å‚¨æœåŠ¡è·å–
        if not report.file_path:
            # å…ˆå°è¯•å‡†å¤‡æ–‡ä»¶
            try:
                from app.services.infrastructure.storage.hybrid_storage_service import get_hybrid_storage_service
                from io import BytesIO
                
                storage_service = get_hybrid_storage_service()
                
                # åˆ›å»ºæŠ¥å‘Šå†…å®¹æ–‡ä»¶
                report_content = report.result or "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
                filename = f"report_{report_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                
                # ä¸Šä¼ åˆ°å­˜å‚¨ç³»ç»Ÿ
                file_info = storage_service.upload_file(
                    file_data=BytesIO(report_content.encode('utf-8')),
                    original_filename=filename,
                    file_type="reports",
                    content_type="text/markdown"
                )
                
                # æ›´æ–°æŠ¥å‘Šè®°å½•
                report.file_path = file_info["file_path"]
                db.commit()
                
            except Exception as prep_error:
                logger.error(f"å‡†å¤‡æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {prep_error}")
                raise HTTPException(
                    status_code=500,
                    detail="æŠ¥å‘Šæ–‡ä»¶å‡†å¤‡å¤±è´¥"
                )
        
        # ä»å­˜å‚¨ç³»ç»Ÿä¸‹è½½æ–‡ä»¶
        try:
            from app.services.infrastructure.storage.hybrid_storage_service import get_hybrid_storage_service
            from fastapi.responses import StreamingResponse
            import io
            
            storage_service = get_hybrid_storage_service()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not storage_service.file_exists(report.file_path):
                raise HTTPException(
                    status_code=404,
                    detail="æŠ¥å‘Šæ–‡ä»¶åœ¨å­˜å‚¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨"
                )
            
            # ä¸‹è½½æ–‡ä»¶
            file_data, backend_type = storage_service.download_file(report.file_path)
            
            # ç”Ÿæˆå‹å¥½çš„æ–‡ä»¶å
            task_name = report.task.name if report.task else f"æŠ¥å‘Š_{report_id}"
            timestamp = report.generated_at.strftime("%Y%m%d_%H%M%S") if report.generated_at else "unknown"
            
            # æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šæ‰©å±•å
            file_ext = report.file_path.split('.')[-1] if '.' in report.file_path else 'txt'
            filename = f"{task_name}_{timestamp}.{file_ext}"
            
            # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
            import re
            filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
            
            # ç¡®å®šContent-Type
            content_type = "application/octet-stream"
            if file_ext == 'md':
                content_type = "text/markdown"
            elif file_ext == 'txt':
                content_type = "text/plain"
            elif file_ext == 'html':
                content_type = "text/html"
            elif file_ext == 'docx':
                content_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            elif file_ext == 'pdf':
                content_type = "application/pdf"
            
            # åˆ›å»ºå“åº”
            file_stream = io.BytesIO(file_data)
            
            logger.info(f"ç”¨æˆ· {user_id} ä¸‹è½½æŠ¥å‘Š: {report_id}, æ–‡ä»¶: {report.file_path}")
            
            return StreamingResponse(
                file_stream,
                media_type=content_type,
                headers={
                    "Content-Disposition": f'attachment; filename="{filename}"',
                    "X-Storage-Backend": backend_type,
                    "X-Report-ID": str(report_id)
                }
            )
            
        except Exception as download_error:
            logger.error(f"ä»å­˜å‚¨ç³»ç»Ÿä¸‹è½½æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {download_error}")
            raise HTTPException(
                status_code=500,
                detail="æŠ¥å‘Šæ–‡ä»¶ä¸‹è½½å¤±è´¥"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹è½½æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail="æ–‡ä»¶ä¸‹è½½å¤±è´¥"
        )


@router.get("/{report_id}/info", response_model=ApiResponse)
async def get_report_info(
    report_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–æŠ¥å‘Šè¯¦ç»†ä¿¡æ¯"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)
        
        report = db.query(ReportHistory).join(
            ReportHistory.task
        ).filter(
            ReportHistory.id == report_id,
            ReportHistory.task.has(owner_id=user_id)
        ).first()
        
        if not report:
            raise HTTPException(
                status_code=404,
                detail="æŠ¥å‘Šä¸å­˜åœ¨æˆ–æ²¡æœ‰è®¿é—®æƒé™"
            )
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = 0
        if report.file_path and Path(report.file_path).exists():
            file_size = Path(report.file_path).stat().st_size
        
        return ApiResponse(
            success=True,
            data={
                "id": report.id,
                "task_id": report.task_id,
                "task_name": report.task.name if report.task else f"ä»»åŠ¡_{report.task_id}",
                "status": report.status,
                "file_path": report.file_path,
                "file_size": file_size,
                "file_size_mb": round(file_size / (1024 * 1024), 2) if file_size > 0 else 0,
                "generated_at": report.generated_at.isoformat() if report.generated_at else None,
                "error_message": report.error_message,
                "processing_metadata": report.processing_metadata,
                "can_download": report.status == "completed" and report.file_path and Path(report.file_path).exists(),
                "download_url": f"/api/v1/reports/{report_id}/download" if report.status == "completed" else None
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æŠ¥å‘Šä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail="è·å–æŠ¥å‘Šä¿¡æ¯å¤±è´¥"
        )
