from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import logging

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from uuid import UUID

from app.api.base_api_controller import CRUDAPIController, APIResponse, PaginatedAPIResponse
from app.db.session import get_db
from app.core.dependencies import get_current_user
from app.models.user import User
from app.models.task import Task
from app.schemas.task import TaskCreate, TaskUpdate, TaskResponse
from app.services.application.tasks.task_application_service import TaskApplicationService
from app.services.infrastructure.task_queue.celery_config import celery_app
from app.services.application.factories import create_placeholder_validation_service
from app.services.data.query.query_executor_service import query_executor_service
from app.services.infrastructure.document.word_export_service import create_word_export_service
from app.services.data.persistence.etl_persistence_service import ETLPersistenceService
from app.schemas.placeholder_value import PlaceholderValueCreate
from app.utils.time_context import TimeContextManager
from app import crud
import time as _time
import os as _os
from decimal import Decimal

logger = logging.getLogger(__name__)
router = APIRouter()

# åˆ›å»ºä»»åŠ¡æ§åˆ¶å™¨å®ä¾‹
task_controller = CRUDAPIController("ä»»åŠ¡", "TaskController")


@router.get("/", response_model=PaginatedAPIResponse)
async def get_tasks(
    skip: int = Query(0, ge=0, description="è·³è¿‡çš„è®°å½•æ•°"),
    limit: int = Query(100, ge=1, le=100, description="è¿”å›çš„è®°å½•æ•°"),
    is_active: Optional[bool] = Query(None, description="æ˜¯å¦æ¿€æ´»"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    
    # æ„å»ºæŸ¥è¯¢
    query = db.query(Task).filter(Task.owner_id == user_id)

    
    # åº”ç”¨è¿‡æ»¤å™¨
    if is_active is not None:
        query = query.filter(Task.is_active == is_active)
    
    if search:
        query = query.filter(
            Task.name.contains(search) |
            Task.description.contains(search)
        )
    
    # è·å–æ€»æ•°
    total = query.count()
    
    # åº”ç”¨åˆ†é¡µå¹¶è·å–ç»“æœ
    tasks = query.offset(skip).limit(limit).all()
    
    # è½¬æ¢ä¸ºTaskResponseæ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹ï¼Œå¹¶åŒ…å«æ‰§è¡ŒçŠ¶æ€
    task_dicts = []
    for task in tasks:
        # è·å–æœ€æ–°çš„æ‰§è¡Œè®°å½•
        from app.models.task import TaskExecution
        latest_execution = db.query(TaskExecution).filter(
            TaskExecution.task_id == task.id
        ).order_by(TaskExecution.created_at.desc()).first()

        # ç¡®å®šå½“å‰æ‰§è¡ŒçŠ¶æ€
        current_execution_status = None
        current_progress = 0
        current_step = None
        execution_id = None
        celery_task_id = None

        if latest_execution:
            current_execution_status = latest_execution.execution_status.value
            current_progress = latest_execution.progress_percentage or 0
            current_step = latest_execution.current_step
            execution_id = str(latest_execution.execution_id)
            celery_task_id = latest_execution.celery_task_id

        # æ„å»ºå…¼å®¹çš„ä»»åŠ¡æ•°æ®ï¼ŒåŒ…å«æ–°å­—æ®µä½†æœ‰é»˜è®¤å€¼
        task_dict = {
            # åŸæœ‰å­—æ®µ
            "id": task.id,
            "name": task.name,
            "description": task.description,
            "template_id": str(task.template_id) if task.template_id else None,
            "data_source_id": str(task.data_source_id) if task.data_source_id else None,
            "schedule": task.schedule,
            "report_period": task.report_period.value if task.report_period else "monthly",
            "recipients": task.recipients or [],
            "owner_id": str(task.owner_id) if task.owner_id else None,
            "is_active": task.is_active,
            "created_at": task.created_at.isoformat() if task.created_at else None,
            "updated_at": task.updated_at.isoformat() if task.updated_at else None,
            "unique_id": str(task.id),

            # ä»»åŠ¡çŠ¶æ€å­—æ®µ
            "status": task.status.value if hasattr(task, 'status') and task.status else "pending",

            # å½“å‰æ‰§è¡ŒçŠ¶æ€ï¼ˆé‡è¦ï¼šå‰ç«¯éœ€è¦è¿™äº›ä¿¡æ¯æ¥åˆ¤æ–­ä»»åŠ¡æ˜¯å¦åœ¨æ‰§è¡Œï¼‰
            "current_execution_status": current_execution_status,
            "current_execution_progress": current_progress,
            "current_execution_step": current_step,
            "current_execution_id": execution_id,
            "current_celery_task_id": celery_task_id,
            "is_executing": current_execution_status in ["processing", "pending"] if current_execution_status else False,

            # å…¶ä»–æ–°å¢å­—æ®µ
            "processing_mode": task.processing_mode.value if hasattr(task, 'processing_mode') and task.processing_mode else "intelligent",
            "workflow_type": task.workflow_type.value if hasattr(task, 'workflow_type') and task.workflow_type else "simple_report",
            "execution_count": getattr(task, 'execution_count', 0),
            "success_count": getattr(task, 'success_count', 0),
            "failure_count": getattr(task, 'failure_count', 0),
            "success_rate": task.success_rate if hasattr(task, 'success_rate') else 0.0,
            "last_execution_at": task.last_execution_at.isoformat() if hasattr(task, 'last_execution_at') and task.last_execution_at else None,
            "average_execution_time": getattr(task, 'average_execution_time', 0.0),
            "max_context_tokens": getattr(task, 'max_context_tokens', 32000),
            "enable_compression": getattr(task, 'enable_compression', True)
        }
        task_dicts.append(task_dict)
    
    # ç›´æ¥è¿”å›åˆ†é¡µå“åº”ï¼Œé¿å…åŒé‡åŒ…è£…
    return PaginatedAPIResponse.create(
        items=task_dicts,
        total=total,
        page=skip // limit + 1,
        size=limit,
        message="è·å–ä»»åŠ¡åˆ—è¡¨æˆåŠŸ"
    )


@router.post("/", response_model=APIResponse[TaskResponse])
async def create_task(
    task_in: TaskCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ›å»ºä»»åŠ¡"""
    task_controller.log_api_request("create_task", user_id=str(current_user.id))
    
    task_service = TaskApplicationService()

    # è°ƒç”¨åº”ç”¨æœåŠ¡
    app_result = task_service.create_task(
        db=db,
        user_id=str(current_user.id),
        name=task_in.name,
        template_id=str(task_in.template_id),
        data_source_id=str(task_in.data_source_id),
        description=task_in.description,
        schedule=task_in.schedule,
        recipients=task_in.recipients,
        is_active=task_in.is_active,
        processing_mode=task_in.processing_mode,
        workflow_type=task_in.workflow_type,
        max_context_tokens=task_in.max_context_tokens,
        enable_compression=task_in.enable_compression
    )
    
    # ä½¿ç”¨æ§åˆ¶å™¨å¤„ç†ç»“æœ
    return task_controller.handle_application_result(app_result)


@router.put("/{task_id}", response_model=APIResponse[TaskResponse])
async def update_task(
    task_id: int,
    task_in: TaskUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°ä»»åŠ¡"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        # è·å–æ›´æ–°æ•°æ®
        update_data = task_in.model_dump(exclude_unset=True)
        
        task = task_service.update_task(
            db=db,
            task_id=task_id,
            user_id=user_id,
            **update_data
        )
        
        task_schema = TaskResponse.model_validate(task)
        task_dict = task_schema.model_dump()
        return APIResponse(
            success=True,
            data=task_dict,
            message="ä»»åŠ¡æ›´æ–°æˆåŠŸ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="ä»»åŠ¡æ›´æ–°å¤±è´¥"
        )


@router.get("/{task_id}", response_model=APIResponse[TaskResponse])
async def get_task(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–å•ä¸ªä»»åŠ¡"""
    user_id = current_user.id
    if isinstance(user_id, str):
        user_id = UUID(user_id)
    
    task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    task_schema = TaskResponse.model_validate(task)
    task_dict = task_schema.model_dump()
    return APIResponse(
        success=True,
        data=task_dict,
        message="è·å–ä»»åŠ¡æˆåŠŸ"
    )


@router.delete("/{task_id}", response_model=APIResponse[Dict[str, Any]])
async def delete_task(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """åˆ é™¤ä»»åŠ¡"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)

        success = task_service.delete_task(
            db=db,
            task_id=task_id,
            user_id=user_id
        )

        return APIResponse(
            success=True,
            data={"task_id": task_id, "deleted": success},
            message="ä»»åŠ¡åˆ é™¤æˆåŠŸ"
        )

    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            message="ä»»åŠ¡åˆ é™¤å¤±è´¥"
        )


@router.post("/{task_id}/execute", response_model=APIResponse[Dict[str, Any]])
async def execute_task(
    task_id: int,
    execution_time: Optional[str] = Query(None, description="ä»»åŠ¡æ‰§è¡Œæ—¶é—´ (YYYY-MM-DD HH:MM:SSï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´)"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ‰§è¡Œä»»åŠ¡ - ä½¿ç”¨æ–°çš„TaskApplicationService"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        execution_context = {}
        if execution_time:
            try:
                parsed_execution_time = datetime.fromisoformat(execution_time.replace('Z', '+00:00'))
                execution_context["execution_time"] = parsed_execution_time.isoformat()
            except ValueError as e:
                raise HTTPException(status_code=422, detail=f"æ— æ•ˆçš„æ—¶é—´æ ¼å¼: {str(e)}")
        
        # æ‰§è¡Œä»»åŠ¡
        result = task_service.execute_task_immediately(
            db=db,
            task_id=task_id,
            user_id=user_id,
            execution_context=execution_context
        )
        
        return APIResponse(
            success=True,
            data=result,
            message="ä»»åŠ¡æ‰§è¡Œè¯·æ±‚å·²æäº¤"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
        )


@router.post("/{task_id}/pause", response_model=APIResponse[Dict[str, Any]])
async def pause_task(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æš‚åœä»»åŠ¡ï¼ˆå°† is_active ç½®ä¸º False å¹¶ä»è°ƒåº¦å™¨ç§»é™¤ï¼‰"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)

        task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        if task.is_active is False:
            return APIResponse(success=True, data={"task_id": task_id, "is_active": task.is_active}, message="ä»»åŠ¡å·²å¤„äºæš‚åœçŠ¶æ€")

        # 1. æ›´æ–°æ•°æ®åº“çŠ¶æ€
        task.is_active = False
        task.updated_at = datetime.utcnow()
        db.add(task)
        db.commit()
        db.refresh(task)

        # 2. ä»è°ƒåº¦å™¨ç§»é™¤ï¼ˆå¦‚æœæœ‰è°ƒåº¦ï¼‰
        scheduler_result = {"scheduler_removed": False, "message": ""}
        if task.schedule:
            try:
                from app.core.unified_scheduler import get_scheduler
                scheduler = await get_scheduler()
                await scheduler.remove_task(task_id)
                scheduler_result = {
                    "scheduler_removed": True,
                    "message": f"å·²ä»è°ƒåº¦å™¨ç§»é™¤ä»»åŠ¡ {task_id}"
                }
                logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²ä»è°ƒåº¦å™¨ç§»é™¤")
            except Exception as scheduler_error:
                logger.warning(f"âš ï¸ ä»è°ƒåº¦å™¨ç§»é™¤ä»»åŠ¡ {task_id} å¤±è´¥: {scheduler_error}")
                scheduler_result = {
                    "scheduler_removed": False,
                    "message": f"è°ƒåº¦å™¨æ“ä½œå¤±è´¥: {str(scheduler_error)}"
                }

        # 3. å¯é€‰ï¼šå–æ¶ˆæ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
        cancelled_execution = None
        try:
            from app.models.task import TaskExecution, TaskStatus
            ongoing_execution = db.query(TaskExecution).filter(
                TaskExecution.task_id == task_id,
                TaskExecution.execution_status.in_([TaskStatus.PENDING, TaskStatus.PROCESSING])
            ).first()

            if ongoing_execution and ongoing_execution.celery_task_id:
                from app.services.infrastructure.task_queue.celery_config import celery_app
                celery_app.control.revoke(ongoing_execution.celery_task_id, terminate=True)
                ongoing_execution.execution_status = TaskStatus.CANCELLED
                ongoing_execution.current_step = "ä»»åŠ¡å·²è¢«æš‚åœæ“ä½œå–æ¶ˆ"
                ongoing_execution.completed_at = datetime.utcnow()
                db.commit()
                cancelled_execution = str(ongoing_execution.execution_id)
                logger.info(f"âœ… å–æ¶ˆäº†æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡: {ongoing_execution.celery_task_id}")
        except Exception as cancel_error:
            logger.warning(f"âš ï¸ å–æ¶ˆæ‰§è¡Œä»»åŠ¡å¤±è´¥: {cancel_error}")

        return APIResponse(
            success=True,
            data={
                "task_id": task_id,
                "is_active": task.is_active,
                "scheduler_status": scheduler_result,
                "cancelled_execution_id": cancelled_execution
            },
            message="ä»»åŠ¡å·²æš‚åœ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æš‚åœä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()
        return APIResponse(success=False, data=None, errors=[str(e)], message="æš‚åœä»»åŠ¡å¤±è´¥")


@router.post("/{task_id}/resume", response_model=APIResponse[Dict[str, Any]])
async def resume_task(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ¢å¤ä»»åŠ¡ï¼ˆå°† is_active ç½®ä¸º True å¹¶é‡æ–°æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼‰"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)

        task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        if task.is_active is True:
            return APIResponse(success=True, data={"task_id": task_id, "is_active": task.is_active}, message="ä»»åŠ¡å·²å¤„äºå¯ç”¨çŠ¶æ€")

        # 1. æ›´æ–°æ•°æ®åº“çŠ¶æ€
        task.is_active = True
        task.updated_at = datetime.utcnow()
        db.add(task)
        db.commit()
        db.refresh(task)

        # 2. æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼ˆå¦‚æœæœ‰è°ƒåº¦ï¼‰
        scheduler_result = {"scheduler_added": False, "message": ""}
        if task.schedule:
            try:
                from app.core.unified_scheduler import get_scheduler
                scheduler = await get_scheduler()
                await scheduler.add_or_update_task(task_id, task.schedule)

                # è·å–ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                task_status = await scheduler.get_task_status(task_id)
                next_run_time = task_status.get("next_run_time")

                scheduler_result = {
                    "scheduler_added": True,
                    "message": f"å·²æ·»åŠ åˆ°è°ƒåº¦å™¨",
                    "next_run_time": next_run_time
                }
                logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼Œä¸‹æ¬¡æ‰§è¡Œ: {next_run_time}")
            except Exception as scheduler_error:
                logger.warning(f"âš ï¸ æ·»åŠ ä»»åŠ¡ {task_id} åˆ°è°ƒåº¦å™¨å¤±è´¥: {scheduler_error}")
                scheduler_result = {
                    "scheduler_added": False,
                    "message": f"è°ƒåº¦å™¨æ“ä½œå¤±è´¥: {str(scheduler_error)}"
                }
        else:
            scheduler_result = {
                "scheduler_added": False,
                "message": "ä»»åŠ¡æœªè®¾ç½®è°ƒåº¦è¡¨è¾¾å¼ï¼Œæ— éœ€æ·»åŠ åˆ°è°ƒåº¦å™¨"
            }

        return APIResponse(
            success=True,
            data={
                "task_id": task_id,
                "is_active": task.is_active,
                "scheduler_status": scheduler_result
            },
            message="ä»»åŠ¡å·²æ¢å¤"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()
        return APIResponse(success=False, data=None, errors=[str(e)], message="æ¢å¤ä»»åŠ¡å¤±è´¥")


@router.post("/{task_id}/run", response_model=APIResponse[Dict[str, Any]])
async def run_task(
    task_id: int,
    execution_time: Optional[str] = Query(None, description="ä»»åŠ¡æ‰§è¡Œæ—¶é—´ (YYYY-MM-DD HH:MM:SSï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´)"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è¿è¡Œä»»åŠ¡ - /execute æ¥å£çš„åˆ«åï¼Œæä¾›æ›´ç›´è§‚çš„æ¥å£"""
    # ç›´æ¥è°ƒç”¨ execute_task å‡½æ•°ï¼Œå¤ç”¨ç›¸åŒçš„é€»è¾‘
    return await execute_task(task_id, execution_time, db, current_user)


@router.get("/{task_id}/executions", response_model=APIResponse)
async def get_task_executions(
    task_id: int,
    limit: int = Query(50, ge=1, le=100, description="è¿”å›è®°å½•æ•°é‡é™åˆ¶"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡æ‰§è¡Œå†å²"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        executions = task_service.get_task_executions(
            db=db,
            task_id=task_id,
            user_id=user_id,
            limit=limit
        )
        
        return APIResponse(
            success=True,
            data={
                "task_id": task_id,
                "executions": executions
            },
            message="è·å–æ‰§è¡Œå†å²æˆåŠŸ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="è·å–æ‰§è¡Œå†å²å¤±è´¥"
        )


@router.post("/{task_id}/validate", response_model=APIResponse)
async def validate_task_configuration(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """éªŒè¯ä»»åŠ¡é…ç½®ï¼ˆåŒ…æ‹¬å ä½ç¬¦éªŒè¯ï¼‰"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        validation_result = task_service.validate_task_configuration(
            db=db,
            task_id=task_id,
            user_id=user_id
        )
        
        return APIResponse(
            success=True,
            data=validation_result,
            message="ä»»åŠ¡é…ç½®éªŒè¯å·²å¯åŠ¨"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="ä»»åŠ¡é…ç½®éªŒè¯å¤±è´¥"
        )


@router.post("/{task_id}/schedule", response_model=APIResponse)
async def schedule_task(
    task_id: int,
    schedule: str = Query(..., description="Cronè¡¨è¾¾å¼"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è®¾ç½®ä»»åŠ¡è°ƒåº¦"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        result = task_service.schedule_task(
            db=db,
            task_id=task_id,
            schedule=schedule,
            user_id=user_id
        )
        
        return APIResponse(
            success=True,
            data=result,
            message="ä»»åŠ¡è°ƒåº¦è®¾ç½®æˆåŠŸ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="ä»»åŠ¡è°ƒåº¦è®¾ç½®å¤±è´¥"
        )


@router.get("/{task_id}/status", response_model=APIResponse)
async def get_task_status(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)

        status_data = task_service.get_task_status(
            db=db,
            task_id=task_id,
            user_id=user_id
        )

        return APIResponse(
            success=True,
            data=status_data,
            message="è·å–ä»»åŠ¡çŠ¶æ€æˆåŠŸ"
        )

    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥"
        )


@router.get("/{task_id}/progress", response_model=APIResponse)
async def get_task_progress(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """è·å–ä»»åŠ¡æ‰§è¡Œè¿›åº¦"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)

        # è·å–ä»»åŠ¡æƒé™éªŒè¯
        task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        # è·å–æœ€æ–°çš„æ‰§è¡Œè®°å½•
        from app.models.task import TaskExecution
        latest_execution = db.query(TaskExecution).filter(
            TaskExecution.task_id == task_id
        ).order_by(TaskExecution.created_at.desc()).first()

        if not latest_execution:
            return APIResponse(
                success=True,
                data={
                    "task_id": task_id,
                    "progress_percentage": 0,
                    "current_step": "æœªå¼€å§‹æ‰§è¡Œ",
                    "execution_status": "pending",
                    "started_at": None,
                    "estimated_completion": None
                },
                message="è·å–ä»»åŠ¡è¿›åº¦æˆåŠŸ"
            )

        # ä¼°ç®—å®Œæˆæ—¶é—´
        estimated_completion = None
        if latest_execution.started_at and latest_execution.progress_percentage > 0:
            elapsed_seconds = (datetime.utcnow() - latest_execution.started_at).total_seconds()
            if latest_execution.progress_percentage > 0:
                estimated_total_seconds = (elapsed_seconds / latest_execution.progress_percentage) * 100
                estimated_remaining_seconds = estimated_total_seconds - elapsed_seconds
                if estimated_remaining_seconds > 0:
                    estimated_completion = (datetime.utcnow() + timedelta(seconds=estimated_remaining_seconds)).isoformat()

        progress_data = {
            "task_id": task_id,
            "execution_id": str(latest_execution.execution_id),
            "progress_percentage": latest_execution.progress_percentage,
            "current_step": latest_execution.current_step or "æ‰§è¡Œä¸­...",
            "execution_status": latest_execution.execution_status.value,
            "started_at": latest_execution.started_at.isoformat() if latest_execution.started_at else None,
            "completed_at": latest_execution.completed_at.isoformat() if latest_execution.completed_at else None,
            "estimated_completion": estimated_completion,
            "celery_task_id": latest_execution.celery_task_id,
            "error_details": latest_execution.error_details
        }

        return APIResponse(
            success=True,
            data=progress_data,
            message="è·å–ä»»åŠ¡è¿›åº¦æˆåŠŸ"
        )

    except HTTPException:
        raise
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="è·å–ä»»åŠ¡è¿›åº¦å¤±è´¥"
        )


@router.post("/{task_id}/cancel", response_model=APIResponse)
async def cancel_task_execution(
    task_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """å–æ¶ˆ/æš‚åœä»»åŠ¡æ‰§è¡Œ"""
    try:
        user_id = current_user.id
        if isinstance(user_id, str):
            user_id = UUID(user_id)

        # è·å–ä»»åŠ¡æƒé™éªŒè¯
        task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        # è·å–æœ€æ–°çš„æ‰§è¡Œè®°å½•
        from app.models.task import TaskExecution
        latest_execution = db.query(TaskExecution).filter(
            TaskExecution.task_id == task_id,
            TaskExecution.execution_status.in_(['processing', 'pending'])
        ).order_by(TaskExecution.created_at.desc()).first()

        if not latest_execution:
            return APIResponse(
                success=False,
                data=None,
                message="æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡å¯ä»¥å–æ¶ˆ"
            )

        # å°è¯•å–æ¶ˆCeleryä»»åŠ¡
        if latest_execution.celery_task_id:
            try:
                from app.services.infrastructure.task_queue.celery_config import celery_app
                celery_app.control.revoke(latest_execution.celery_task_id, terminate=True)
                logger.info(f"Cancelled Celery task {latest_execution.celery_task_id}")
            except Exception as e:
                logger.warning(f"Failed to cancel Celery task: {e}")

        # æ›´æ–°æ‰§è¡ŒçŠ¶æ€
        from app.models.task import TaskStatus
        latest_execution.execution_status = TaskStatus.CANCELLED
        latest_execution.current_step = "ä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"
        latest_execution.completed_at = datetime.utcnow()
        latest_execution.total_duration = int(
            (latest_execution.completed_at - latest_execution.started_at).total_seconds()
        ) if latest_execution.started_at else 0

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.status = TaskStatus.CANCELLED

        db.commit()

        return APIResponse(
            success=True,
            data={
                "task_id": task_id,
                "execution_id": str(latest_execution.execution_id),
                "status": "cancelled",
                "message": "ä»»åŠ¡å·²æˆåŠŸå–æ¶ˆ"
            },
            message="ä»»åŠ¡æ‰§è¡Œå·²å–æ¶ˆ"
        )

    except HTTPException:
        raise
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="å–æ¶ˆä»»åŠ¡å¤±è´¥"
        )


@router.post("/{task_id}/execute-claude-code", response_model=APIResponse)
async def execute_task_with_claude_code(
    task_id: int,
    execution_context: Optional[Dict[str, Any]] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """ä½¿ç”¨Claude Codeæ¶æ„æ‰§è¡Œä»»åŠ¡"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        # ä½¿ç”¨æ–°çš„Claude Codeæ¶æ„æ‰§è¡Œä»»åŠ¡
        result = await task_service.execute_task_with_claude_code(
            db=db,
            task_id=task_id,
            user_id=user_id,
            execution_context=execution_context or {}
        )
        
        return APIResponse(
            success=True,
            data=result,
            message="Claude Codeä»»åŠ¡æ‰§è¡Œå®Œæˆ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="Claude Codeä»»åŠ¡æ‰§è¡Œå¤±è´¥"
        )


@router.post("/sql/generate", response_model=APIResponse)
async def generate_sql_with_claude_code(
    query_description: str,
    table_info: Optional[Dict[str, Any]] = None,
    current_user: User = Depends(get_current_user)
):
    """ä½¿ç”¨Claude Codeæ¶æ„ç”ŸæˆSQL"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        result = await task_service.generate_sql_with_claude_code(
            user_id=user_id,
            query_description=query_description,
            table_info=table_info or {}
        )
        
        return APIResponse(
            success=True,
            data=result,
            message="SQLç”Ÿæˆå®Œæˆ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="SQLç”Ÿæˆå¤±è´¥"
        )


@router.post("/data/analyze", response_model=APIResponse)
async def analyze_data_with_claude_code(
    dataset: Dict[str, Any],
    analysis_type: str = "exploratory",
    current_user: User = Depends(get_current_user)
):
    """ä½¿ç”¨Claude Codeæ¶æ„åˆ†ææ•°æ®"""
    try:
        task_service = TaskApplicationService()
        user_id = str(current_user.id)
        
        result = await task_service.analyze_data_with_claude_code(
            user_id=user_id,
            dataset=dataset,
            analysis_type=analysis_type
        )
        
        return APIResponse(
            success=True,
            data=result,
            message="æ•°æ®åˆ†æå®Œæˆ"
        )
        
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="æ•°æ®åˆ†æå¤±è´¥"
        )




@router.post("/{task_id}/run-report", response_model=APIResponse[Dict[str, Any]])
async def run_task_report_pipeline(
    task_id: int,
    request: Dict[str, Any] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """æ‰§è¡Œä»»åŠ¡æŠ¥å‘Šæµæ°´çº¿ï¼šå ä½ç¬¦æ ¡éªŒ/ä¿®å¤ -> ETL -> ç»„è£…å¹¶ç”ŸæˆDOCXã€‚

    è¯·æ±‚ä½“ï¼ˆå¯é€‰ï¼‰:
    - execution_time: ISOæ—¶é—´ï¼Œç”¨ä½œæ—¶é—´çª—å£å‚è€ƒ
    - cron_expression: Cronè¡¨è¾¾å¼ï¼Œä¸ä¼ åˆ™ä½¿ç”¨ä»»åŠ¡ä¸Šçš„ schedule
    - force_repair: æ˜¯å¦å¼ºåˆ¶é‡ä¿®å¤ï¼ˆé»˜è®¤Falseï¼‰
    - preview_only: ä»…è¿”å›æ ¡éªŒå’ŒETL JSONï¼Œä¸ç”Ÿæˆdocxï¼ˆé»˜è®¤Falseï¼‰
    - output_format: é»˜è®¤ docx
    """
    try:
        req = request or {}
        force_repair = bool(req.get("force_repair", False))
        preview_only = bool(req.get("preview_only", False))
        output_format = str(req.get("output_format", "docx")).lower()
        exec_time_str = req.get("execution_time")
        cron_expression = req.get("cron_expression")

        # 1) åŠ è½½ä»»åŠ¡/æ¨¡æ¿/æ•°æ®æºï¼Œæ ¡éªŒæƒé™
        user_id = current_user.id
        task = db.query(Task).filter(Task.id == task_id, Task.owner_id == user_id).first()
        if not task:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æƒé™")

        from app.models.template import Template
        from app.models.data_source import DataSource
        template = db.query(Template).filter(Template.id == task.template_id).first()
        if not template:
            raise HTTPException(status_code=404, detail="æ¨¡æ¿ä¸å­˜åœ¨")

        data_source = db.query(DataSource).filter(DataSource.id == task.data_source_id).first()
        if not data_source:
            raise HTTPException(status_code=404, detail="æ•°æ®æºä¸å­˜åœ¨")

        # 2) æ„å»ºæ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆåŸºäºä»»åŠ¡cron+æ‰§è¡Œæ—¶é—´ï¼‰
        tcm = TimeContextManager()
        if not cron_expression:
            cron_expression = task.schedule
        exec_dt = None
        if exec_time_str:
            try:
                exec_dt = datetime.fromisoformat(exec_time_str.replace('Z', '+00:00'))
            except Exception:
                exec_dt = None
        time_ctx: Dict[str, Any] = {}
        if cron_expression:
            tc = tcm.build_task_time_context(cron_expression, exec_dt)
            time_ctx = {
                "cron_expression": cron_expression,
                "execution_time": (exec_dt.isoformat() if exec_dt else tc.get("execution_time")),
                "start_date": tc.get("data_start_time"),
                "end_date": tc.get("data_end_time"),
                "period_description": tc.get("period_description"),
            }
        else:
            # æ— cronæ—¶ï¼Œä½¿ç”¨è¿‘7å¤©çª—å£
            from datetime import timedelta as _td
            end = datetime.utcnow().date().isoformat()
            start = (datetime.utcnow().date() - _td(days=7)).isoformat()
            time_ctx = {"start_date": start, "end_date": end, "execution_time": (datetime.utcnow().isoformat())}

        # 3) å ä½ç¬¦æ ¡éªŒ/ä¿®å¤
        validation_service = create_placeholder_validation_service(str(user_id))
        ds_info = {"data_source_id": str(task.data_source_id), "name": data_source.name}
        validation_summary = await validation_service.batch_repair_template_placeholders(
            template_id=str(task.template_id),
            data_source_info=ds_info,
            time_context=time_ctx,
            force_repair=force_repair,
        )

        # è¯»å–DBä¸­å½“å‰å ä½ç¬¦é…ç½®ï¼Œä»¥ä¾¿ETL
        from app import crud as _crud
        placeholders = _crud.template_placeholder.get_by_template(db, template_id=str(task.template_id))

        # æ‰€æœ‰å ä½ç¬¦è‹¥å‡æ— æ•ˆï¼Œåˆ™å¼ºåˆ¶é‡ä¿®å¤/é‡æ–°ç”ŸæˆSQL
        total_ph = len(placeholders)
        if total_ph == 0:
            raise HTTPException(status_code=400, detail="æ¨¡æ¿æœªåŒ…å«ä»»ä½•å ä½ç¬¦")
        all_invalid = all((not p.generated_sql) or (not p.sql_validated) for p in placeholders)
        if all_invalid:
            validation_summary = await validation_service.batch_repair_template_placeholders(
                template_id=str(task.template_id),
                data_source_info=ds_info,
                time_context=time_ctx,
                force_repair=True,
            )
            # é‡æ–°åŠ è½½å ä½ç¬¦
            placeholders = _crud.template_placeholder.get_by_template(db, template_id=str(task.template_id))

        # 4) ETLï¼šé€å ä½ç¬¦æ‰§è¡ŒSQL
        etl_results: Dict[str, Any] = {}
        etl_start = _time.time()
        for p in placeholders:
            if not getattr(p, 'is_active', True) or not p.generated_sql:
                continue
            q_start = _time.time()
            # ä½¿ç”¨å¸¦å ä½ç¬¦æ›¿æ¢çš„æ‰§è¡Œæ–¹æ³•ï¼Œç¡®ä¿æ—¶é—´çª—å£è¢«æ­£ç¡®æ›¿æ¢
            qres = await query_executor_service.execute_query_with_placeholders(
                p.generated_sql,
                time_ctx or {},
                {"data_source_id": str(task.data_source_id)}
            )
            etl_results[p.placeholder_name] = {
                "success": bool(qres.get("success")),
                "data": qres.get("data", []),
                "metadata": qres.get("metadata", {}),
                "execution_time_ms": int((qres.get("execution_time") or 0) * 1000),
                "columns": (qres.get("metadata", {}) or {}).get("columns", []),
                "row_count": (qres.get("metadata", {}) or {}).get("row_count", len(qres.get("data", []) or [])),
                "placeholder": {
                    "name": p.placeholder_name,
                    "type": p.placeholder_type,
                    "content_type": p.content_type,
                },
                "started_at": datetime.fromtimestamp(q_start).isoformat(),
                "finished_at": datetime.utcnow().isoformat(),
            }
        etl_duration_ms = int((_time.time() - etl_start) * 1000)

        # 5) å›¾è¡¨ç”Ÿæˆï¼ˆç®€åŒ–ï¼šä¸ºcontent_type=chartç”ŸæˆåŸºç¡€æŸ±çŠ¶å›¾ï¼‰
        chart_results: List[Dict[str, Any]] = []
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            _os.makedirs(f"/tmp/charts/{user_id}", exist_ok=True)

            def _is_numeric_value(v):
                if isinstance(v, (int, float, Decimal)):
                    return True
                if isinstance(v, str):
                    try:
                        float(v.strip())
                        return True
                    except Exception:
                        return False
                return False

            def _sanitize_filename(name: str) -> str:
                safe = ''.join(ch if ch.isalnum() or ch in ('_', '-', '.') else '_' for ch in str(name))
                return safe[:100] if len(safe) > 100 else safe

            for p in placeholders:
                if str(getattr(p, 'content_type', '')).lower() != 'chart':
                    continue
                pres = etl_results.get(p.placeholder_name)
                if not pres or not pres.get("data"):
                    chart_results.append({
                        "success": False,
                        "chart_type": "bar",
                        "file_path": None,
                        "metadata": {"title": p.description or p.placeholder_name},
                        "error": "no_data"
                    })
                    continue
                rows = pres["data"]
                # æ¨æ–­åˆ—
                columns = pres.get("columns") or (list(rows[0].keys()) if isinstance(rows[0], dict) else None)
                if not columns:
                    chart_results.append({
                        "success": False,
                        "chart_type": "bar",
                        "file_path": None,
                        "metadata": {"title": p.description or p.placeholder_name},
                        "error": "no_columns"
                    })
                    continue
                x_col = columns[0]
                y_col = None
                for c in columns[1:]:
                    try:
                        if any(_is_numeric_value(r.get(c)) for r in rows if isinstance(r, dict)):
                            y_col = c
                            break
                    except Exception:
                        continue
                if not y_col:
                    chart_results.append({
                        "success": False,
                        "chart_type": "bar",
                        "file_path": None,
                        "metadata": {"title": p.description or p.placeholder_name},
                        "error": "no_numeric_column"
                    })
                    continue

                # æ„é€ ç»˜å›¾æ•°æ®
                x_vals = [r.get(x_col) for r in rows if isinstance(r, dict)]
                y_vals = [r.get(y_col) for r in rows if isinstance(r, dict)]

                # æ¸…æ´—ä¸è½¬æ¢æ•°å€¼
                cleaned_y = []
                for v in y_vals:
                    if isinstance(v, (int, float, Decimal)):
                        cleaned_y.append(float(v))
                    elif isinstance(v, str):
                        try:
                            cleaned_y.append(float(v.strip()))
                        except Exception:
                            cleaned_y.append(float('nan'))
                    else:
                        cleaned_y.append(float('nan'))

                # å¤„ç†è¿‡å¤šç±»ç›®ï¼šä¿ç•™å‰Nï¼ˆæŒ‰å€¼é™åºï¼‰ï¼Œé»˜è®¤N=20
                N = 20
                try:
                    pairs = list(zip(x_vals, cleaned_y))
                    pairs = [p2 for p2 in pairs if p2[0] is not None]
                    pairs.sort(key=lambda t: (t[1] if t[1] == t[1] else float('-inf')), reverse=True)
                    if len(pairs) > N:
                        pairs = pairs[:N]
                    x_vals_plot, y_vals_plot = zip(*pairs) if pairs else ([], [])
                except Exception:
                    x_vals_plot, y_vals_plot = x_vals[:N], cleaned_y[:N]

                # è‹¥ç±»ç›®è¾ƒå¤šï¼Œåˆ‡æ¢ä¸ºæ°´å¹³æ¡å½¢å›¾
                use_barh = len(x_vals_plot) > 10

                plt.figure(figsize=(10, 6))
                try:
                    if use_barh:
                        plt.barh(list(map(lambda s: str(s)[:50], x_vals_plot)), y_vals_plot)
                    else:
                        plt.bar(list(map(lambda s: str(s)[:50], x_vals_plot)), y_vals_plot)
                    plt.title(p.description or p.placeholder_name)
                    if not use_barh:
                        plt.xticks(rotation=30, ha='right')
                    plt.tight_layout()
                    safe_name = _sanitize_filename(p.placeholder_name)
                    fname = f"/tmp/charts/{user_id}/chart_{safe_name}_{int(_time.time())}.png"
                    plt.savefig(fname, dpi=150)
                    chart_results.append({
                        "success": True,
                        "chart_type": "barh" if use_barh else "bar",
                        "file_path": fname,
                        "metadata": {
                            "title": p.description or p.placeholder_name,
                            "x_col": x_col,
                            "y_col": y_col,
                            "top_n": len(x_vals_plot)
                        }
                    })
                except Exception as _plot_err:
                    chart_results.append({
                        "success": False,
                        "chart_type": "bar",
                        "file_path": None,
                        "metadata": {"title": p.description or p.placeholder_name},
                        "error": str(_plot_err)
                    })
                finally:
                    plt.close()
        except Exception as _chart_block_err:
            # ä¸æ¸…ç©ºå·²æœ‰ç»“æœï¼Œä»…è®°å½•å—çº§é”™è¯¯
            chart_results.append({
                "success": False,
                "chart_type": "bar",
                "file_path": None,
                "metadata": {"title": "chart_block"},
                "error": str(_chart_block_err)
            })

        # 6) ç”Ÿæˆç”¨äºæ–‡æœ¬å ä½ç¬¦çš„ç›´æ¥æ›¿æ¢å€¼ï¼ˆä¼˜å…ˆåŸå€¼ï¼Œå…¶æ¬¡å•å¥æ”¹å†™ï¼‰
        direct_values: Dict[str, str] = {}
        end_for_sentence = time_ctx.get("end_date") or time_ctx.get("execution_time") or "æœ¬æœŸ"

        def _format_scalar(value: Any) -> str:
            try:
                # æ•°å€¼æ ¼å¼ï¼šåƒåˆ†ä½ï¼Œæœ€å¤šä¿ç•™2ä½å°æ•°
                if isinstance(value, (int, float, Decimal)):
                    num = float(value)
                    if abs(num) >= 1000:
                        return f"{num:,.2f}".rstrip('0').rstrip('.')
                    return f"{num:.2f}".rstrip('0').rstrip('.')
                # æ—¥æœŸ/æ—¶é—´æ ¼å¼
                if hasattr(value, 'isoformat'):
                    try:
                        return value.strftime('%Y-%m-%d')
                    except Exception:
                        return str(value)
                # å­—ç¬¦ä¸²ï¼šå»é™¤é¦–å°¾ç©ºç™½å¹¶é™åˆ¶é•¿åº¦
                if isinstance(value, str):
                    s = value.strip()
                    return s if len(s) <= 120 else (s[:117] + '...')
                # å…¶å®ƒå¯åºåˆ—åŒ–ç±»å‹
                return str(value)
            except Exception:
                return str(value)

        for p in placeholders:
            # è·³è¿‡å›¾è¡¨ç±»å ä½ç¬¦ï¼ˆç”±chart_resultså¤„ç†ï¼‰
            if str(getattr(p, 'content_type', '')).lower() == 'chart':
                continue
            name = p.placeholder_name
            pres = etl_results.get(name)
            if not pres:
                # æ— ETLç»“æœï¼Œå•å¥æ”¹å†™ä¸ºæç¤º
                direct_values[name] = f"{p.description or name}æš‚æ— å¯ç”¨æ•°æ®"
                continue

            rows = pres.get("data") or []
            cols = pres.get("columns") or []
            # ä¼˜å…ˆåŸå§‹æ ‡é‡å€¼
            scalar_value = None
            try:
                if rows:
                    first = rows[0]
                    if isinstance(first, dict):
                        # è‹¥ä»…ä¸€åˆ—ï¼Œç›´æ¥å–è¯¥åˆ—
                        if len(cols) == 1 and cols[0] in first:
                            scalar_value = first.get(cols[0])
                        else:
                            # æ‰¾ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—ï¼Œå¦åˆ™ç¬¬ä¸€ä¸ªéç©ºå€¼
                            preferred = None
                            for c in cols:
                                v = first.get(c)
                                if isinstance(v, (int, float, Decimal)):
                                    preferred = v
                                    break
                            if preferred is not None:
                                scalar_value = preferred
                            else:
                                for c in cols:
                                    v = first.get(c)
                                    if v not in (None, ""):
                                        scalar_value = v
                                        break
                    elif isinstance(first, list) and first:
                        scalar_value = first[0]
            except Exception:
                scalar_value = None

            if scalar_value is not None:
                direct_values[name] = _format_scalar(scalar_value)
            else:
                # å•å¥æ”¹å†™ï¼ˆæç®€ï¼‰ï¼š
                if not rows:
                    direct_values[name] = f"{p.description or name}åœ¨{end_for_sentence}æ— æ•°æ®"
                else:
                    # å¤šè¡Œ/æ— æ³•æå–æ ‡é‡æ—¶ï¼Œå–Top1æ‘˜è¦
                    if isinstance(rows[0], dict) and cols:
                        x = rows[0].get(cols[0])
                        y = None
                        for c in cols[1:]:
                            v = rows[0].get(c)
                            if isinstance(v, (int, float, Decimal)) or (isinstance(v, str) and v.strip()):
                                y = v
                                break
                        if y is not None:
                            direct_values[name] = f"{p.description or name}ï¼ˆ{_format_scalar(x)}ï¼‰ï¼š{_format_scalar(y)}"
                        else:
                            direct_values[name] = f"{p.description or name}ï¼ˆç¤ºä¾‹ï¼š{_format_scalar(x)}ï¼‰"
                    else:
                        direct_values[name] = f"{p.description or name}æ•°æ®å·²æ›´æ–°"

        # 7) é¢„è§ˆæˆ–ç”Ÿæˆæ–‡æ¡£
        payload = {
            "task": {"id": task.id, "name": task.name},
            "template": {"id": str(task.template_id), "name": getattr(template, 'name', 'æ¨¡æ¿')},
            "time_context": time_ctx,
            "validation": validation_summary,
            "etl": {
                "placeholders": list(etl_results.keys()),
                "results": etl_results,
                "duration_ms": etl_duration_ms,
            },
            "charts": chart_results,
        }

        if preview_only:
            return APIResponse(success=True, data=payload, message="é¢„è§ˆæˆåŠŸï¼ˆæœªç”Ÿæˆæ–‡æ¡£ï¼‰")

        word_service = create_word_export_service(str(user_id))
        export_res = await word_service.export_report_document(
            template_id=str(task.template_id),
            placeholder_data={
                **(validation_summary if isinstance(validation_summary, dict) else {"validation_results": []}),
                "direct_values": direct_values,
            },
            etl_data={str(task.data_source_id): {"transform": {"success": True, "data": [v for v in etl_results.values()]}}},
            chart_data={"data": chart_results},
        )

        # 7.5) ğŸ’¾ æŒä¹…åŒ– direct_values å’Œå›¾è¡¨æ•°æ®åˆ° placeholder_values è¡¨
        # ä»…åœ¨æ–‡æ¡£ç”ŸæˆæˆåŠŸåæŒä¹…åŒ–
        if export_res.success:
            try:
                batch_id = ETLPersistenceService.generate_batch_id()
                values_to_save = []

                # è§£ææ—¶é—´ä¸Šä¸‹æ–‡
                execution_time = None
                period_start = None
                period_end = None
                try:
                    if time_ctx.get("execution_time"):
                        execution_time = datetime.fromisoformat(str(time_ctx["execution_time"]).replace("Z", "+00:00"))
                    if time_ctx.get("start_date"):
                        period_start = datetime.fromisoformat(str(time_ctx["start_date"]).replace("Z", "+00:00"))
                    if time_ctx.get("end_date"):
                        period_end = datetime.fromisoformat(str(time_ctx["end_date"]).replace("Z", "+00:00"))
                except Exception as time_parse_err:
                    logger.warning(f"âš ï¸ è§£ææ—¶é—´ä¸Šä¸‹æ–‡å¤±è´¥: {time_parse_err}")
                    execution_time = datetime.utcnow()

                # æŒä¹…åŒ–æ–‡æœ¬å ä½ç¬¦ï¼ˆdirect_valuesï¼‰
                for p in placeholders:
                    name = p.placeholder_name

                    # è·³è¿‡å›¾è¡¨å ä½ç¬¦ï¼Œç¨åå•ç‹¬å¤„ç†
                    if str(getattr(p, 'content_type', '')).lower() == 'chart':
                        continue

                    # åªä¿å­˜æœ‰ direct_values çš„å ä½ç¬¦
                    if name not in direct_values:
                        continue

                    etl_result = etl_results.get(name, {})

                    values_to_save.append(PlaceholderValueCreate(
                        placeholder_id=p.id,
                        data_source_id=task.data_source_id,
                        # ğŸ”‘ æ ¸å¿ƒï¼šä½¿ç”¨ç²¾ç»†æ ¼å¼åŒ–çš„ formatted_text
                        formatted_text=direct_values[name],
                        raw_query_result=etl_result.get("data"),
                        processed_value={
                            "columns": etl_result.get("columns", []),
                            "row_count": len(etl_result.get("data", [])),
                            "metadata": etl_result.get("metadata", {})
                        },
                        execution_sql=p.generated_sql,
                        row_count=len(etl_result.get("data", [])),
                        success=True,
                        source="run_report",
                        confidence_score=1.0,
                        analysis_metadata={
                            "content_type": str(getattr(p, 'content_type', 'text')),
                            "placeholder_type": str(getattr(p, 'placeholder_type', 'unknown')),
                            "formatting_applied": "åƒåˆ†ä½,å°æ•°ç²¾åº¦,æ™ºèƒ½æ”¹å†™"
                        },
                        execution_time=execution_time or datetime.utcnow(),
                        period_start=period_start,
                        period_end=period_end,
                        report_period=time_ctx.get("report_period"),
                        sql_parameters_snapshot=time_ctx,
                        execution_batch_id=batch_id,
                        is_latest_version=True,
                        cache_key=f"ph_{p.id}_{time_ctx.get('start_date', 'default')}",
                        expires_at=datetime.utcnow() + timedelta(hours=getattr(p, 'cache_ttl_hours', 24))
                    ))

                # æŒä¹…åŒ–å›¾è¡¨å ä½ç¬¦
                for chart_result in chart_results:
                    if not chart_result.get("success"):
                        continue

                    chart_name = chart_result.get("placeholder_name")
                    if not chart_name:
                        continue

                    # æ‰¾åˆ°å¯¹åº”çš„å ä½ç¬¦
                    chart_placeholder = next((p for p in placeholders if p.placeholder_name == chart_name), None)
                    if not chart_placeholder:
                        continue

                    etl_result = etl_results.get(chart_name, {})
                    chart_metadata = chart_result.get("metadata", {})

                    values_to_save.append(PlaceholderValueCreate(
                        placeholder_id=chart_placeholder.id,
                        data_source_id=task.data_source_id,
                        # å›¾è¡¨çš„ formatted_text è®°å½•å…³é”®ä¿¡æ¯
                        formatted_text=f"å›¾è¡¨ï¼š{chart_metadata.get('title', chart_name)} | "
                                      f"Xè½´ï¼š{chart_metadata.get('x_column')} | "
                                      f"Yè½´ï¼š{chart_metadata.get('y_column')} | "
                                      f"Top-{chart_metadata.get('top_n', 'All')}",
                        raw_query_result=etl_result.get("data"),
                        processed_value={
                            "chart_type": chart_metadata.get("chart_type"),
                            "file_path": chart_result.get("file_path"),
                            "columns": etl_result.get("columns", []),
                            "row_count": len(etl_result.get("data", [])),
                            "chart_metadata": chart_metadata
                        },
                        execution_sql=chart_placeholder.generated_sql,
                        row_count=len(etl_result.get("data", [])),
                        success=True,
                        source="run_report_chart",
                        confidence_score=1.0,
                        analysis_metadata={
                            "content_type": "chart",
                            "chart_generated": True,
                            "chart_path": chart_result.get("file_path"),
                            **chart_metadata
                        },
                        execution_time=execution_time or datetime.utcnow(),
                        period_start=period_start,
                        period_end=period_end,
                        report_period=time_ctx.get("report_period"),
                        sql_parameters_snapshot=time_ctx,
                        execution_batch_id=batch_id,
                        is_latest_version=True,
                        cache_key=f"ph_{chart_placeholder.id}_{time_ctx.get('start_date', 'default')}",
                        expires_at=datetime.utcnow() + timedelta(hours=getattr(chart_placeholder, 'cache_ttl_hours', 24))
                    ))

                # ğŸ”‘ æ‰¹é‡æ’å…¥æ•°æ®åº“
                if values_to_save:
                    crud.placeholder_value.create_batch(db, values=values_to_save)
                    db.commit()
                    logger.info(f"âœ… å·²æŒä¹…åŒ– {len(values_to_save)} ä¸ªå ä½ç¬¦å€¼åˆ°æ•°æ®åº“ (batch_id={batch_id})")
                else:
                    logger.warning("âš ï¸ æ²¡æœ‰éœ€è¦æŒä¹…åŒ–çš„å ä½ç¬¦å€¼")

            except Exception as persist_err:
                logger.error(f"âŒ æŒä¹…åŒ–å ä½ç¬¦å€¼å¤±è´¥: {persist_err}")
                logger.exception(persist_err)
                # æŒä¹…åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
                db.rollback()

        payload["document"] = {
            "success": export_res.success,
            "document_path": export_res.document_path,
            "file_size_bytes": export_res.file_size_bytes,
            "page_count": export_res.page_count,
            "export_time_seconds": export_res.export_time_seconds,
            "error": export_res.error,
            "meta": export_res.metadata,
        }

        return APIResponse(
            success=bool(export_res.success),
            data=payload,
            message=("æŠ¥å‘Šç”ŸæˆæˆåŠŸ" if export_res.success else (export_res.error or "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"))
        )

    except HTTPException:
        raise
    except Exception as e:
        return APIResponse(
            success=False,
            data=None,
            errors=[str(e)],
            message="è¿è¡ŒæŠ¥å‘Šæµæ°´çº¿å¤±è´¥"
        )
