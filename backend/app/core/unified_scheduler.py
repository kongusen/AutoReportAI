"""
ç»Ÿä¸€ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
ä½¿ç”¨ APScheduler æ›¿ä»£ Celery Beatï¼Œæä¾›æ•°æ®åº“æŒä¹…åŒ–çš„è°ƒåº¦åŠŸèƒ½
"""
import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
import threading

import redis.asyncio as redis
from app.core.time_utils import now, format_iso
from sqlalchemy.orm import Session

from app import crud
from app.core.config import settings
from app.db.session import get_db_session, SessionLocal
from app.models.task import Task
from app.services.infrastructure.notification.notification_service import NotificationService

logger = logging.getLogger(__name__)


class UnifiedTaskScheduler:
    """ç»Ÿä¸€ä»»åŠ¡è°ƒåº¦å™¨ - ä½¿ç”¨ APScheduler ç®¡ç†æ‰€æœ‰ä»»åŠ¡è°ƒåº¦"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return

        self._initialized = True
        self.active_tasks: Dict[int, Dict[str, Any]] = {}
        self.redis_client = None
        self.apscheduler_manager = None
        self._running = False

    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        try:
            self.redis_client = redis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=True
            )

            # ä½¿ç”¨ APScheduler
            from app.core.apscheduler_config import apscheduler_manager
            self.apscheduler_manager = apscheduler_manager

            logger.info("âœ… ç»Ÿä¸€è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ APScheduler")

        except Exception as e:
            logger.error(f"âŒ ç»Ÿä¸€è°ƒåº¦å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def add_or_update_task(self, task_id: int, cron_expression: str):
        """
        æ·»åŠ æˆ–æ›´æ–°ä»»åŠ¡è°ƒåº¦

        Args:
            task_id: ä»»åŠ¡ID
            cron_expression: Cronè¡¨è¾¾å¼
        """
        try:
            next_run = self.apscheduler_manager.add_task(task_id, cron_expression)
            logger.info(f"âœ… ä»»åŠ¡ {task_id} è°ƒåº¦å·²æ›´æ–°ï¼Œä¸‹æ¬¡æ‰§è¡Œ: {next_run}")
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä»»åŠ¡è°ƒåº¦å¤±è´¥ {task_id}: {e}")
            raise

    async def remove_task(self, task_id: int):
        """
        ç§»é™¤ä»»åŠ¡è°ƒåº¦

        Args:
            task_id: ä»»åŠ¡ID
        """
        try:
            self.apscheduler_manager.remove_task(task_id)

            # æ¸…ç†æ´»è·ƒä»»åŠ¡è®°å½•
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]

            logger.info(f"âœ… ä»»åŠ¡ {task_id} è°ƒåº¦å·²ç§»é™¤")

        except Exception as e:
            logger.error(f"âŒ ç§»é™¤ä»»åŠ¡è°ƒåº¦å¤±è´¥ {task_id}: {e}")

    async def execute_task_immediately(self, task_id: int, user_id: str) -> Dict[str, Any]:
        """
        ç«‹å³æ‰§è¡Œä»»åŠ¡ - ä¼˜å…ˆçº§æ¨¡å¼

        Args:
            task_id: ä»»åŠ¡ID
            user_id: ç”¨æˆ·ID

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        try:
            if task_id in self.active_tasks and self.active_tasks[task_id].get("status") == "running":
                return {"status": "error", "message": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­"}

            with get_db_session() as db:
                task = crud.task.get(db, id=task_id)
                if not task:
                    return {"status": "error", "message": "ä»»åŠ¡ä¸å­˜åœ¨"}

                # å­˜å‚¨ä»»åŠ¡æ‰€æœ‰è€…ä¿¡æ¯åˆ°Redisï¼Œä¾›WebSocketé€šçŸ¥ä½¿ç”¨
                await self._store_task_owner(task_id, user_id)

                # å‘é€å¼€å§‹é€šçŸ¥
                await self._send_start_notification(db, task, user_id)

                # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²workerï¼Œå¦‚æœæœ‰å°±ä½¿ç”¨é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ç«‹å³æ‰§è¡Œ
                celery_result = await self._execute_with_priority(task_id, user_id)

                # è®°å½•æ´»è·ƒä»»åŠ¡
                self.active_tasks[task_id] = {
                    "status": "queued" if celery_result.get("queued") else "running",
                    "start_time": now(),
                    "user_id": user_id,
                    "celery_task_id": celery_result["celery_task_id"],
                    "triggered_by": "manual",
                    "processing_mode": celery_result.get("processing_mode", "intelligent")
                }

                return {
                    "status": "queued" if celery_result.get("queued") else "running",
                    "task_id": task_id,
                    "celery_task_id": celery_result["celery_task_id"],
                    "processing_mode": celery_result.get("processing_mode", "intelligent"),
                    "message": "æ™ºèƒ½å ä½ç¬¦æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—" if celery_result.get("queued") else "ä»»åŠ¡å·²ç«‹å³å¼€å§‹æ‰§è¡Œ"
                }

        except Exception as e:
            logger.error(f"âŒ ç«‹å³æ‰§è¡Œä»»åŠ¡å¤±è´¥ {task_id}: {e}")
            return {"status": "error", "message": f"ä»»åŠ¡å¯åŠ¨å¤±è´¥: {str(e)}"}

    async def _store_task_owner(self, task_id: int, user_id: str):
        """å­˜å‚¨ä»»åŠ¡æ‰€æœ‰è€…ä¿¡æ¯åˆ°Redisä¾›WebSocketé€šçŸ¥ä½¿ç”¨"""
        try:
            if self.redis_client:
                await self.redis_client.set(
                    f"report_task:{task_id}:owner",
                    user_id,
                    ex=86400  # 24å°æ—¶è¿‡æœŸ
                )
                logger.debug(f"âœ… å·²å­˜å‚¨ä»»åŠ¡ {task_id} çš„æ‰€æœ‰è€…ä¿¡æ¯: {user_id}")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨ä»»åŠ¡æ‰€æœ‰è€…ä¿¡æ¯å¤±è´¥ {task_id}: {e}")

    async def _execute_with_priority(self, task_id: int, user_id: str) -> Dict[str, Any]:
        """æ™ºèƒ½ä¼˜å…ˆçº§æ‰§è¡Œ - æ£€æŸ¥workerçŠ¶æ€å¹¶ä¼˜åŒ–æ‰§è¡Œ"""
        try:
            from app.services.application.tasks.workflow_tasks import generate_report_workflow
            from app.services.infrastructure.task_queue.celery_config import celery_app

            # æ£€æŸ¥å½“å‰æ´»è·ƒçš„workeræ•°é‡
            active_workers = celery_app.control.inspect().active_queues()
            worker_count = len(active_workers) if active_workers else 0

            # æ£€æŸ¥å½“å‰é˜Ÿåˆ—ä¸­ç­‰å¾…çš„ä»»åŠ¡æ•°é‡
            queue_stats = celery_app.control.inspect().active()
            pending_tasks = sum(len(tasks) for tasks in queue_stats.values()) if queue_stats else 0

            logger.info(f"ğŸ“Š å½“å‰æ´»è·ƒworkeræ•°é‡: {worker_count}, é˜Ÿåˆ—ä¸­ä»»åŠ¡æ•°é‡: {pending_tasks}")

            # è·å–ä»»åŠ¡ä¿¡æ¯
            with get_db_session() as db:
                task_obj = crud.task.get(db, id=task_id)
                if not task_obj:
                    raise Exception(f"Task {task_id} not found")

                # æ™ºèƒ½è°ƒåº¦å†³ç­–
                if worker_count > 0 and pending_tasks < worker_count:
                    # æœ‰ç©ºé—²workerï¼Œä½¿ç”¨é«˜ä¼˜å…ˆçº§ç«‹å³æ‰§è¡Œ
                    celery_result = generate_report_workflow.apply_async(
                        args=[
                            str(task_obj.template_id) if task_obj.template_id else '',
                            [str(task_obj.data_source_id)] if task_obj.data_source_id else [],
                            {'user_id': user_id, 'task_id': str(task_id), 'priority': 'high'}
                        ],
                        priority=9,  # é«˜ä¼˜å…ˆçº§
                        queue='application_queue'
                    )
                    return {
                        "celery_task_id": celery_result.id,
                        "queued": False,
                        "processing_mode": "intelligent",
                        "message": "ä»»åŠ¡å·²ç«‹å³å¼€å§‹æ‰§è¡Œ"
                    }
                else:
                    # workerç¹å¿™ï¼Œæ­£å¸¸åŠ å…¥é˜Ÿåˆ—
                    celery_result = generate_report_workflow.delay(
                        str(task_obj.template_id) if task_obj.template_id else '',
                        [str(task_obj.data_source_id)] if task_obj.data_source_id else [],
                        {'user_id': user_id, 'task_id': str(task_id)}
                    )
                    return {
                        "celery_task_id": celery_result.id,
                        "queued": True,
                        "processing_mode": "intelligent",
                        "message": "æ™ºèƒ½å ä½ç¬¦æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—"
                    }

        except Exception as e:
            logger.error(f"âš ï¸ ä¼˜å…ˆçº§æ‰§è¡Œæ£€æŸ¥å¤±è´¥: {e}, ä½¿ç”¨æ™®é€šæ‰§è¡Œ")
            # å›é€€åˆ°æ™®é€šæ‰§è¡Œ
            from app.services.application.tasks.workflow_tasks import generate_report_workflow

            with get_db_session() as db:
                task_obj = crud.task.get(db, id=task_id)
                if not task_obj:
                    raise Exception(f"Task {task_id} not found")

                celery_result = generate_report_workflow.delay(
                    str(task_obj.template_id) if task_obj.template_id else '',
                    [str(task_obj.data_source_id)] if task_obj.data_source_id else [],
                    {'user_id': user_id, 'task_id': str(task_id)}
                )

            return {
                "celery_task_id": celery_result.id,
                "queued": True,
                "processing_mode": "intelligent",
                "message": "æ™ºèƒ½å ä½ç¬¦æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—"
            }

    async def get_task_status(self, task_id: int) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            ä»»åŠ¡çŠ¶æ€å­—å…¸
        """
        try:
            # å…ˆä»Redisè·å–å®æ—¶çŠ¶æ€
            if self.redis_client:
                redis_status = await self.redis_client.hgetall(f"report_task:{task_id}:status")
                if redis_status:
                    return redis_status

            # æ£€æŸ¥æ´»è·ƒä»»åŠ¡
            if task_id in self.active_tasks:
                return self.active_tasks[task_id]

            # ä» APScheduler è·å–è°ƒåº¦çŠ¶æ€
            task_info = self.apscheduler_manager.get_task_info(task_id)
            if task_info:
                return {
                    "status": "scheduled",
                    "progress": 0,
                    "current_step": "ç­‰å¾…è°ƒåº¦æ‰§è¡Œ",
                    "next_run_time": task_info.get("next_run_time")
                }

            return {"status": "not_found", "message": "æœªæ‰¾åˆ°ä»»åŠ¡çŠ¶æ€"}

        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥ {task_id}: {e}")
            return {"status": "error", "message": str(e)}

    async def _send_start_notification(self, db: Session, task: Task, user_id: str):
        """å‘é€å¼€å§‹é€šçŸ¥"""
        try:
            notification_service = NotificationService()
            await notification_service.send_task_progress_update(
                task_id=task.id,
                progress_data={
                    "status": "starting",
                    "progress": 5,
                    "message": "ä»»åŠ¡å·²å¯åŠ¨..."
                }
            )
        except Exception as e:
            logger.error(f"âš ï¸ å‘é€å¼€å§‹é€šçŸ¥å¤±è´¥: {e}")

    async def get_scheduler_info(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨ä¿¡æ¯"""
        scheduler_state = self.apscheduler_manager.get_scheduler_state()
        all_jobs = self.apscheduler_manager.list_all_jobs()

        return {
            "scheduler_type": "apscheduler",
            "scheduler_state": scheduler_state,
            "active_tasks_count": len(self.active_tasks),
            "active_tasks": list(self.active_tasks.keys()),
            "scheduled_jobs": all_jobs
        }

    async def reload_all_tasks(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰ä»»åŠ¡"""
        try:
            result = self.apscheduler_manager.load_tasks_from_database()
            logger.info(f"âœ… æ‰€æœ‰ä»»åŠ¡è°ƒåº¦å·²é‡æ–°åŠ è½½: {result}")
            return result
        except Exception as e:
            logger.error(f"âŒ é‡æ–°åŠ è½½ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        try:
            if self.apscheduler_manager:
                self.apscheduler_manager.shutdown(wait=True)

            if self.redis_client:
                await self.redis_client.close()

            self.active_tasks.clear()
            logger.info("âœ… ç»Ÿä¸€è°ƒåº¦å™¨å·²å…³é—­")

        except Exception as e:
            logger.error(f"âŒ å…³é—­è°ƒåº¦å™¨å¤±è´¥: {e}")


# å…¨å±€å•ä¾‹å®ä¾‹
scheduler = UnifiedTaskScheduler()


async def get_scheduler() -> UnifiedTaskScheduler:
    """è·å–ç»Ÿä¸€è°ƒåº¦å™¨å®ä¾‹"""
    if not hasattr(scheduler, '_initialized') or not scheduler._initialized:
        await scheduler.initialize()
    return scheduler


# ä¾¿æ·å‡½æ•°
async def add_task_schedule(task_id: int, cron_expression: str):
    """æ·»åŠ ä»»åŠ¡è°ƒåº¦"""
    scheduler_instance = await get_scheduler()
    return await scheduler_instance.add_or_update_task(task_id, cron_expression)


async def remove_task_schedule(task_id: int):
    """ç§»é™¤ä»»åŠ¡è°ƒåº¦"""
    scheduler_instance = await get_scheduler()
    return await scheduler_instance.remove_task(task_id)


async def execute_task(task_id: int, user_id: str):
    """ç«‹å³æ‰§è¡Œä»»åŠ¡"""
    scheduler_instance = await get_scheduler()
    return await scheduler_instance.execute_task_immediately(task_id, user_id)


async def get_task_status(task_id: int):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    scheduler_instance = await get_scheduler()
    return await scheduler_instance.get_task_status(task_id)
