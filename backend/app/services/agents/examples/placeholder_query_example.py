"""
åŸºäºå ä½ç¬¦æ„å»ºæ•°æ®æŸ¥è¯¢çš„æ ¸å¿ƒç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä»å ä½ç¬¦å’Œæç¤ºè¯æ„å»ºæ­£ç¡®çš„æ•°æ®æŸ¥è¯¢ï¼Œç„¶åä½¿ç”¨å·¥å…·åˆ†æè·å¾—å‡†ç¡®æ•°æ®ã€‚

æ ¸å¿ƒæµç¨‹ï¼š
1. è§£æå ä½ç¬¦ä¸­çš„æç¤ºè¯
2. æ„å»ºè¯­ä¹‰åŒ–çš„æ•°æ®æŸ¥è¯¢
3. æ‰§è¡ŒæŸ¥è¯¢è·å–æ•°æ®
4. éªŒè¯å’Œä¼˜åŒ–æŸ¥è¯¢ç»“æœ
"""

import asyncio
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

from ..enhanced.enhanced_data_query_agent import (
    EnhancedDataQueryAgent, 
    SemanticQueryRequest,
    QueryIntent,
    MetadataInfo
)
from ..tools.data_processing_tools import (
    DataValidationTool,
    DataTransformationTool, 
    SchemaDetectionTool
)
from ..knowledge import KnowledgeContext


class PlaceholderQueryBuilder:
    """å ä½ç¬¦æŸ¥è¯¢æ„å»ºå™¨"""
    
    def __init__(self):
        self.data_agent = EnhancedDataQueryAgent()
        self.validation_tool = DataValidationTool()
        self.transform_tool = DataTransformationTool()
        self.schema_tool = SchemaDetectionTool()
    
    async def parse_placeholder_prompt(self, placeholder_content: str) -> Dict[str, Any]:
        """è§£æå ä½ç¬¦ä¸­çš„æç¤ºè¯"""
        try:
            # ç¤ºä¾‹å ä½ç¬¦å†…å®¹è§£æ
            # {{é”€å”®æ•°æ®åˆ†æ:æŸ¥è¯¢æœ€è¿‘3ä¸ªæœˆçš„é”€å”®é¢,æŒ‰åœ°åŒºåˆ†ç»„,åŒ…å«åŒæ¯”å¢é•¿ç‡}}
            
            parsed_info = {
                "analysis_type": None,
                "time_range": None,
                "groupby_fields": [],
                "metrics": [],
                "filters": [],
                "calculations": []
            }
            
            # æå–åˆ†æç±»å‹
            if "é”€å”®æ•°æ®åˆ†æ" in placeholder_content:
                parsed_info["analysis_type"] = "sales_analysis"
            elif "ç”¨æˆ·è¡Œä¸ºåˆ†æ" in placeholder_content:
                parsed_info["analysis_type"] = "user_behavior_analysis"
            elif "è´¢åŠ¡åˆ†æ" in placeholder_content:
                parsed_info["analysis_type"] = "financial_analysis"
            
            # æå–æ—¶é—´èŒƒå›´
            if "æœ€è¿‘3ä¸ªæœˆ" in placeholder_content:
                parsed_info["time_range"] = "3_months"
            elif "æœ€è¿‘1å¹´" in placeholder_content:
                parsed_info["time_range"] = "1_year"
            elif "æœ¬å­£åº¦" in placeholder_content:
                parsed_info["time_range"] = "current_quarter"
            
            # æå–åˆ†ç»„å­—æ®µ
            if "æŒ‰åœ°åŒºåˆ†ç»„" in placeholder_content:
                parsed_info["groupby_fields"].append("region")
            if "æŒ‰äº§å“åˆ†ç»„" in placeholder_content:
                parsed_info["groupby_fields"].append("product")
            if "æŒ‰æœˆä»½åˆ†ç»„" in placeholder_content:
                parsed_info["groupby_fields"].append("month")
            
            # æå–æŒ‡æ ‡
            if "é”€å”®é¢" in placeholder_content:
                parsed_info["metrics"].append("sales_amount")
            if "è®¢å•æ•°" in placeholder_content:
                parsed_info["metrics"].append("order_count")
            if "å®¢æˆ·æ•°" in placeholder_content:
                parsed_info["metrics"].append("customer_count")
            
            # æå–è®¡ç®—è¦æ±‚
            if "åŒæ¯”å¢é•¿ç‡" in placeholder_content:
                parsed_info["calculations"].append("year_over_year_growth")
            if "ç¯æ¯”å¢é•¿ç‡" in placeholder_content:
                parsed_info["calculations"].append("month_over_month_growth")
            if "å¹³å‡å€¼" in placeholder_content:
                parsed_info["calculations"].append("average")
            
            print(f"ğŸ“ å ä½ç¬¦è§£æç»“æœ: {json.dumps(parsed_info, ensure_ascii=False, indent=2)}")
            return parsed_info
            
        except Exception as e:
            print(f"âŒ å ä½ç¬¦è§£æå¤±è´¥: {e}")
            return {}
    
    async def build_semantic_query(self, parsed_info: Dict[str, Any]) -> SemanticQueryRequest:
        """æ„å»ºè¯­ä¹‰åŒ–æŸ¥è¯¢è¯·æ±‚"""
        try:
            # æ„å»ºè‡ªç„¶è¯­è¨€æŸ¥è¯¢
            natural_query_parts = []
            
            # æ·»åŠ æŸ¥è¯¢ç›®æ ‡
            if parsed_info.get("analysis_type") == "sales_analysis":
                natural_query_parts.append("æŸ¥è¯¢é”€å”®æ•°æ®")
            
            # æ·»åŠ æ—¶é—´èŒƒå›´
            if parsed_info.get("time_range") == "3_months":
                natural_query_parts.append("æœ€è¿‘3ä¸ªæœˆ")
            elif parsed_info.get("time_range") == "1_year":
                natural_query_parts.append("æœ€è¿‘1å¹´")
            
            # æ·»åŠ æŒ‡æ ‡
            if parsed_info.get("metrics"):
                metrics_text = "ã€".join(parsed_info["metrics"])
                natural_query_parts.append(f"åŒ…å«{metrics_text}")
            
            # æ·»åŠ åˆ†ç»„
            if parsed_info.get("groupby_fields"):
                groupby_text = "ã€".join(parsed_info["groupby_fields"])
                natural_query_parts.append(f"æŒ‰{groupby_text}åˆ†ç»„")
            
            # æ·»åŠ è®¡ç®—
            if parsed_info.get("calculations"):
                calc_text = "ã€".join(parsed_info["calculations"])
                natural_query_parts.append(f"è®¡ç®—{calc_text}")
            
            natural_query = "ï¼Œ".join(natural_query_parts)
            
            # æ„å»ºæŸ¥è¯¢è¯·æ±‚
            query_request = SemanticQueryRequest(
                query=natural_query,
                data_source="main_database",  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
                natural_language=True,
                semantic_enhancement=True,
                intent_analysis=True,
                query_optimization=True,
                context={
                    "analysis_type": parsed_info.get("analysis_type"),
                    "time_range": parsed_info.get("time_range"),
                    "required_fields": parsed_info.get("metrics", []) + parsed_info.get("groupby_fields", [])
                }
            )
            
            print(f"ğŸ” æ„å»ºçš„è¯­ä¹‰æŸ¥è¯¢: {natural_query}")
            return query_request
            
        except Exception as e:
            print(f"âŒ è¯­ä¹‰æŸ¥è¯¢æ„å»ºå¤±è´¥: {e}")
            raise
    
    async def execute_data_query(self, query_request: SemanticQueryRequest) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®æŸ¥è¯¢"""
        try:
            print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®æŸ¥è¯¢...")
            
            # åˆ›å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
            knowledge_context = KnowledgeContext(
                agent_id="enhanced_data_query_agent",
                task_type="semantic_query",
                data_characteristics=query_request.context
            )
            
            # æ‰§è¡Œè¯­ä¹‰æŸ¥è¯¢
            result = await self.data_agent.execute_semantic_query(query_request)
            
            if result.success:
                print(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸ")
                query_result = result.data
                
                # æ˜¾ç¤ºæŸ¥è¯¢ç»“æœä¿¡æ¯
                if hasattr(query_result, 'results') and query_result.results:
                    print(f"ğŸ“Š è·å¾— {len(query_result.results)} æ¡æ•°æ®è®°å½•")
                    
                    # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•ä½œä¸ºç¤ºä¾‹
                    sample_records = query_result.results[:3]
                    for i, record in enumerate(sample_records, 1):
                        print(f"   è®°å½•{i}: {record}")
                
                # æ˜¾ç¤ºå…ƒæ•°æ®ä¿¡æ¯
                if hasattr(query_result, 'metadata'):
                    metadata = query_result.metadata
                    print(f"ğŸ”§ æŸ¥è¯¢å…ƒæ•°æ®:")
                    print(f"   - æ‰§è¡Œæ—¶é—´: {metadata.get('execution_time', 'N/A')}ms")
                    print(f"   - ä¼˜åŒ–åº”ç”¨: {metadata.get('optimizations_applied', [])}")
                    print(f"   - å­—æ®µæ˜ å°„: {metadata.get('field_mappings', {})}")
                
                return {
                    "success": True,
                    "data": query_result.results if hasattr(query_result, 'results') else [],
                    "metadata": query_result.metadata if hasattr(query_result, 'metadata') else {},
                    "query_info": {
                        "original_query": query_request.query,
                        "optimized_query": getattr(query_result, 'optimized_query', None),
                        "execution_plan": getattr(query_result, 'execution_plan', None)
                    }
                }
            else:
                print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {result.error_message}")
                return {
                    "success": False,
                    "error": result.error_message,
                    "data": []
                }
                
        except Exception as e:
            print(f"âŒ æ•°æ®æŸ¥è¯¢å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": []
            }
    
    async def validate_and_process_data(self, query_result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œå¤„ç†æŸ¥è¯¢ç»“æœæ•°æ®"""
        try:
            if not query_result.get("success") or not query_result.get("data"):
                return query_result
            
            raw_data = query_result["data"]
            print(f"ğŸ” å¼€å§‹æ•°æ®éªŒè¯å’Œå¤„ç†...")
            
            # 1. æ•°æ®éªŒè¯
            validation_result = await self.validation_tool.execute(
                raw_data,
                context={"validation_rules": ["not_empty", "type_consistency", "range_check"]}
            )
            
            if validation_result.success:
                validation_info = validation_result.data
                print(f"âœ… æ•°æ®éªŒè¯é€šè¿‡:")
                print(f"   - æ€»è®°å½•æ•°: {validation_info.get('total_records', 0)}")
                print(f"   - æœ‰æ•ˆè®°å½•: {validation_info.get('valid_records', 0)}")
                print(f"   - æ•°æ®è´¨é‡åˆ†æ•°: {validation_info.get('quality_score', 0):.2f}")
            else:
                print(f"âš ï¸  æ•°æ®éªŒè¯å‘ç°é—®é¢˜: {validation_result.error_message}")
            
            # 2. æ¨¡å¼æ£€æµ‹
            schema_result = await self.schema_tool.execute(
                raw_data,
                context={"detect_types": True, "suggest_improvements": True}
            )
            
            if schema_result.success:
                schema_info = schema_result.data
                print(f"ğŸ“‹ æ•°æ®æ¨¡å¼åˆ†æ:")
                detected_schema = schema_info.get('detected_schema', {})
                for field, field_info in detected_schema.items():
                    print(f"   - {field}: {field_info.get('type')} (ç¼ºå¤±ç‡: {field_info.get('null_rate', 0):.1%})")
            
            # 3. æ•°æ®è½¬æ¢å’Œæ¸…ç†
            transform_result = await self.transform_tool.execute(
                raw_data,
                context={
                    "operations": ["clean_nulls", "standardize_formats", "detect_outliers"],
                    "schema": schema_result.data.get('detected_schema', {}) if schema_result.success else {}
                }
            )
            
            processed_data = raw_data
            if transform_result.success:
                processed_data = transform_result.data.get('transformed_data', raw_data)
                transform_info = transform_result.data
                print(f"ğŸ”§ æ•°æ®å¤„ç†å®Œæˆ:")
                print(f"   - æ¸…ç†çš„ç©ºå€¼: {transform_info.get('nulls_cleaned', 0)}")
                print(f"   - æ ‡å‡†åŒ–å­—æ®µ: {len(transform_info.get('standardized_fields', []))}")
                print(f"   - æ£€æµ‹åˆ°çš„å¼‚å¸¸å€¼: {transform_info.get('outliers_detected', 0)}")
            
            # 4. æ„å»ºæœ€ç»ˆç»“æœ
            final_result = {
                "success": True,
                "data": processed_data,
                "metadata": {
                    **query_result.get("metadata", {}),
                    "validation": validation_result.data if validation_result.success else {},
                    "schema": schema_result.data if schema_result.success else {},
                    "transformation": transform_result.data if transform_result.success else {}
                },
                "query_info": query_result.get("query_info", {}),
                "data_quality": {
                    "total_records": len(processed_data),
                    "quality_score": validation_info.get('quality_score', 0) if validation_result.success else 0,
                    "processing_applied": transform_result.success
                }
            }
            
            return final_result
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å’Œå¤„ç†å¤±è´¥: {e}")
            return {
                **query_result,
                "processing_error": str(e)
            }
    
    async def demonstrate_complete_flow(self, placeholder_examples: List[str]):
        """æ¼”ç¤ºå®Œæ•´çš„å ä½ç¬¦->æŸ¥è¯¢->æ•°æ®æµç¨‹"""
        print("ğŸ¯ æ¼”ç¤ºï¼šä»å ä½ç¬¦åˆ°å‡†ç¡®æ•°æ®çš„å®Œæ•´æµç¨‹")
        print("=" * 60)
        
        for i, placeholder in enumerate(placeholder_examples, 1):
            print(f"\nã€ç¤ºä¾‹ {i}ã€‘å¤„ç†å ä½ç¬¦: {placeholder}")
            print("-" * 40)
            
            try:
                # æ­¥éª¤1: è§£æå ä½ç¬¦
                parsed_info = await self.parse_placeholder_prompt(placeholder)
                if not parsed_info:
                    print("âŒ å ä½ç¬¦è§£æå¤±è´¥ï¼Œè·³è¿‡æ­¤ç¤ºä¾‹")
                    continue
                
                # æ­¥éª¤2: æ„å»ºè¯­ä¹‰æŸ¥è¯¢
                query_request = await self.build_semantic_query(parsed_info)
                
                # æ­¥éª¤3: æ‰§è¡ŒæŸ¥è¯¢
                query_result = await self.execute_data_query(query_request)
                
                # æ­¥éª¤4: éªŒè¯å’Œå¤„ç†æ•°æ®
                final_result = await self.validate_and_process_data(query_result)
                
                # æ­¥éª¤5: æ€»ç»“ç»“æœ
                if final_result.get("success"):
                    data_quality = final_result.get("data_quality", {})
                    print(f"\nâœ… å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸ!")
                    print(f"   ğŸ“Š æœ€ç»ˆæ•°æ®é‡: {data_quality.get('total_records', 0)} æ¡è®°å½•")
                    print(f"   ğŸ¯ æ•°æ®è´¨é‡åˆ†æ•°: {data_quality.get('quality_score', 0):.2f}/1.0")
                    print(f"   ğŸ”§ å·²åº”ç”¨æ•°æ®å¤„ç†: {'æ˜¯' if data_quality.get('processing_applied') else 'å¦'}")
                    
                    # æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
                    sample_data = final_result.get("data", [])[:2]
                    if sample_data:
                        print(f"   ğŸ“‹ æ•°æ®æ ·ä¾‹:")
                        for j, record in enumerate(sample_data, 1):
                            print(f"      è®°å½•{j}: {record}")
                else:
                    print(f"âŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {final_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                print(f"âŒ ç¤ºä¾‹ {i} æ‰§è¡Œå¼‚å¸¸: {e}")
        
        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ! å±•ç¤ºäº†ä»å ä½ç¬¦åˆ°å‡†ç¡®æ•°æ®çš„å®Œæ•´æ™ºèƒ½åŒ–æµç¨‹")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    builder = PlaceholderQueryBuilder()
    
    # å‡†å¤‡å ä½ç¬¦ç¤ºä¾‹
    placeholder_examples = [
        "{{é”€å”®æ•°æ®åˆ†æ:æŸ¥è¯¢æœ€è¿‘3ä¸ªæœˆçš„é”€å”®é¢,æŒ‰åœ°åŒºåˆ†ç»„,åŒ…å«åŒæ¯”å¢é•¿ç‡}}",
        "{{ç”¨æˆ·è¡Œä¸ºåˆ†æ:ç»Ÿè®¡æœ€è¿‘1å¹´çš„ç”¨æˆ·æ´»è·ƒåº¦,æŒ‰æœˆä»½åˆ†ç»„,è®¡ç®—å¹³å‡å€¼}}",
        "{{è´¢åŠ¡åˆ†æ:è·å–æœ¬å­£åº¦çš„æ”¶å…¥å’Œæˆæœ¬æ•°æ®,æŒ‰äº§å“åˆ†ç»„,åŒ…å«ç¯æ¯”å¢é•¿ç‡}}",
        "{{è®¢å•åˆ†æ:æŸ¥è¯¢æœ€è¿‘6ä¸ªæœˆçš„è®¢å•æ•°æ®,æŒ‰çŠ¶æ€åˆ†ç»„,è®¡ç®—å®Œæˆç‡}}"
    ]
    
    # æ‰§è¡Œå®Œæ•´æ¼”ç¤º
    await builder.demonstrate_complete_flow(placeholder_examples)
    
    print(f"\n" + "="*60)
    print("ğŸ’¡ æ ¸å¿ƒä»·å€¼æ€»ç»“:")
    print("âœ… å ä½ç¬¦æ™ºèƒ½è§£æ - è‡ªåŠ¨ç†è§£ç”¨æˆ·æ„å›¾")
    print("âœ… è¯­ä¹‰æŸ¥è¯¢æ„å»º - å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç²¾ç¡®æŸ¥è¯¢")
    print("âœ… æ™ºèƒ½æ•°æ®è·å– - ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½å’Œå‡†ç¡®æ€§") 
    print("âœ… æ•°æ®è´¨é‡ä¿è¯ - è‡ªåŠ¨éªŒè¯ã€æ¸…ç†å’Œå¤„ç†æ•°æ®")
    print("âœ… ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ– - ä»éœ€æ±‚åˆ°æ•°æ®çš„å®Œå…¨è‡ªåŠ¨åŒ–")


if __name__ == "__main__":
    asyncio.run(main())