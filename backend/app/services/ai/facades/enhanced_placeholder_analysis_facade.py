"""
å¢å¼ºçš„å ä½ç¬¦åˆ†æé—¨é¢æœåŠ¡ - ä¿®å¤SQLè·å–çš„è¾¹ç•Œæ¡ä»¶

ä¿®å¤çš„é—®é¢˜ï¼š
1. SQLæŸå/è¿‡æœŸçš„å¤„ç†
2. å¹¶å‘åˆ†æå†²çªçš„å¤„ç†  
3. ç¼“å­˜ä¸€è‡´æ€§é—®é¢˜
4. äº‹åŠ¡å®‰å…¨æ€§é—®é¢˜
5. å®¹é”™å’Œé‡è¯•æœºåˆ¶
"""

import logging
import asyncio
import hashlib
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from sqlalchemy.orm import Session
from sqlalchemy import text
from contextlib import asynccontextmanager
import redis
from enum import Enum

logger = logging.getLogger(__name__)


class SQLValidationStatus(Enum):
    """SQLéªŒè¯çŠ¶æ€"""
    VALID = "valid"                 # SQLæœ‰æ•ˆ
    INVALID = "invalid"             # SQLæ— æ•ˆ
    EXPIRED = "expired"             # SQLè¿‡æœŸ
    CORRUPTED = "corrupted"         # SQLæŸå
    OUTDATED = "outdated"           # SQLè¿‡æ—¶
    UNKNOWN = "unknown"             # çŠ¶æ€æœªçŸ¥


class ConcurrencyStrategy(Enum):
    """å¹¶å‘å¤„ç†ç­–ç•¥"""
    WAIT = "wait"                   # ç­‰å¾…å…¶ä»–åˆ†æå®Œæˆ
    DUPLICATE = "duplicate"         # å…è®¸é‡å¤åˆ†æ
    ABORT = "abort"                 # ä¸­æ­¢å½“å‰åˆ†æ
    PRIORITY = "priority"           # åŸºäºä¼˜å…ˆçº§å¤„ç†


@dataclass
class SQLHealthCheck:
    """SQLå¥åº·æ£€æŸ¥ç»“æœ"""
    placeholder_id: str
    status: SQLValidationStatus
    sql: Optional[str] = None
    issues: List[str] = field(default_factory=list)
    confidence: float = 0.0
    last_validation: Optional[datetime] = None
    age_hours: float = 0.0
    recommended_action: str = "none"
    
    @property
    def is_usable(self) -> bool:
        """SQLæ˜¯å¦å¯ç”¨"""
        return self.status in [SQLValidationStatus.VALID] and self.confidence >= 0.5
    
    @property
    def needs_refresh(self) -> bool:
        """æ˜¯å¦éœ€è¦åˆ·æ–°"""
        return self.status in [
            SQLValidationStatus.EXPIRED, 
            SQLValidationStatus.CORRUPTED,
            SQLValidationStatus.OUTDATED
        ] or self.age_hours > 24


@dataclass 
class ConcurrencyLock:
    """å¹¶å‘é”ä¿¡æ¯"""
    placeholder_id: str
    lock_id: str
    holder: str
    created_at: datetime
    expires_at: datetime
    operation: str
    
    @property
    def is_expired(self) -> bool:
        """é”æ˜¯å¦è¿‡æœŸ"""
        return datetime.now() > self.expires_at


class EnhancedPlaceholderAnalysisFacade:
    """å¢å¼ºçš„å ä½ç¬¦åˆ†æé—¨é¢æœåŠ¡"""
    
    def __init__(self, 
                 db_session: Session, 
                 redis_client: Optional[redis.Redis] = None,
                 enable_distributed_locks: bool = True):
        
        self.db = db_session
        self.redis_client = redis_client
        self.enable_distributed_locks = enable_distributed_locks
        
        # é…ç½®
        self.sql_validation_timeout = 30  # SQLéªŒè¯è¶…æ—¶æ—¶é—´(ç§’)
        self.lock_timeout = 300           # åˆ†å¸ƒå¼é”è¶…æ—¶æ—¶é—´(ç§’)
        self.max_retry_attempts = 3       # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.sql_max_age_hours = 24       # SQLæœ€å¤§å­˜æ´»æ—¶é—´(å°æ—¶)
        
        logger.info("EnhancedPlaceholderAnalysisFacade initialized")
    
    async def ensure_placeholder_sql_with_resilience(self,
                                                   placeholder_id: str,
                                                   user_id: str,
                                                   task_id: str = None,
                                                   force_refresh: bool = False) -> Dict[str, Any]:
        """
        å¢å¼ºçš„å ä½ç¬¦SQLè·å– - å¤„ç†å„ç§è¾¹ç•Œæ¡ä»¶
        
        ä¿®å¤çš„é—®é¢˜ï¼š
        1. SQLæŸå/è¿‡æœŸæ£€æµ‹
        2. å¹¶å‘å†²çªå¤„ç†
        3. äº‹åŠ¡å®‰å…¨æ€§
        4. å®¹é”™æœºåˆ¶
        """
        
        logger.info(f"ğŸ” å¢å¼ºSQLè·å–: {placeholder_id}, task_id={task_id}")
        
        try:
            # 1. è·å–åˆ†å¸ƒå¼é”ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            lock_context = None
            if self.enable_distributed_locks:
                lock_context = await self._acquire_analysis_lock(placeholder_id, user_id, task_id)
                if not lock_context:
                    # å¤„ç†å¹¶å‘å†²çª
                    return await self._handle_concurrency_conflict(placeholder_id, user_id, task_id)
            
            async with lock_context if lock_context else self._null_context():
                # 2. æ·±åº¦å¥åº·æ£€æŸ¥
                health_check = await self._perform_sql_health_check(placeholder_id)
                logger.info(f"ğŸ“Š SQLå¥åº·æ£€æŸ¥: {placeholder_id} -> {health_check.status.value}")
                
                # 3. æ ¹æ®å¥åº·çŠ¶å†µå†³å®šè¡ŒåŠ¨
                if health_check.is_usable and not force_refresh:
                    # SQLå¥åº·ï¼Œç›´æ¥è¿”å›
                    return await self._return_healthy_sql(health_check, task_id)
                
                elif health_check.needs_refresh or force_refresh:
                    # SQLéœ€è¦åˆ·æ–°æˆ–å¼ºåˆ¶åˆ·æ–°
                    return await self._refresh_sql_with_fallback(
                        placeholder_id, user_id, task_id, health_check
                    )
                
                else:
                    # SQLä¸å­˜åœ¨ï¼Œéœ€è¦åˆ†æ
                    return await self._analyze_new_placeholder(
                        placeholder_id, user_id, task_id
                    )
        
        except Exception as e:
            logger.error(f"âŒ å¢å¼ºSQLè·å–å¤±è´¥: {placeholder_id}, {e}")
            return await self._handle_critical_failure(placeholder_id, user_id, task_id, e)
    
    async def batch_ensure_placeholders_with_resilience(self,
                                                      placeholder_ids: List[str],
                                                      user_id: str,
                                                      task_id: str = None,
                                                      max_concurrent: int = 5) -> Dict[str, Any]:
        """
        æ‰¹é‡å¢å¼ºSQLè·å– - å¤„ç†æ‰¹é‡åœºæ™¯çš„è¾¹ç•Œæ¡ä»¶
        """
        
        logger.info(f"ğŸ” æ‰¹é‡å¢å¼ºSQLè·å–: {len(placeholder_ids)} ä¸ªå ä½ç¬¦")
        
        # 1. é¢„æ£€æŸ¥å’Œåˆ†ç»„
        grouped_requests = await self._group_batch_requests(placeholder_ids, user_id, task_id)
        
        # 2. å¹¶å‘æ§åˆ¶æ‰§è¡Œ
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_single(placeholder_id: str) -> Dict[str, Any]:
            async with semaphore:
                try:
                    result = await self.ensure_placeholder_sql_with_resilience(
                        placeholder_id, user_id, task_id
                    )
                    return {
                        'placeholder_id': placeholder_id,
                        'success': result.get('success', False),
                        'result': result
                    }
                except Exception as e:
                    logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {placeholder_id}, {e}")
                    return {
                        'placeholder_id': placeholder_id,
                        'success': False,
                        'error': str(e)
                    }
        
        # 3. å¹¶è¡Œæ‰§è¡Œ
        tasks = [process_single(pid) for pid in placeholder_ids]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 4. ç»“æœæ±‡æ€»å’Œåˆ†æ
        successful_results = []
        failed_results = []
        
        for result in results:
            if isinstance(result, Exception):
                failed_results.append({
                    'placeholder_id': 'unknown',
                    'error': str(result)
                })
            elif result.get('success'):
                successful_results.append(result)
            else:
                failed_results.append(result)
        
        # 5. ç”Ÿæˆæ‰¹é‡ç»Ÿè®¡
        batch_stats = await self._generate_batch_statistics(
            successful_results, failed_results, grouped_requests
        )
        
        return {
            'total_count': len(placeholder_ids),
            'success_count': len(successful_results),
            'failure_count': len(failed_results),
            'success_rate': len(successful_results) / len(placeholder_ids) if placeholder_ids else 0,
            'results': successful_results + failed_results,
            'statistics': batch_stats,
            'recommendations': self._generate_batch_recommendations(batch_stats)
        }
    
    async def validate_sql_integrity(self, placeholder_id: str) -> SQLHealthCheck:
        """éªŒè¯SQLå®Œæ•´æ€§ - æ–°å¢åŠŸèƒ½"""
        
        try:
            # 1. è·å–å­˜å‚¨çš„SQL
            stored_sql_info = await self._get_stored_sql_info(placeholder_id)
            
            if not stored_sql_info:
                return SQLHealthCheck(
                    placeholder_id=placeholder_id,
                    status=SQLValidationStatus.UNKNOWN,
                    recommended_action="analyze_required"
                )
            
            sql_text = stored_sql_info.get('sql')
            confidence = stored_sql_info.get('confidence', 0.0)
            analyzed_at = stored_sql_info.get('analyzed_at')
            
            # 2. æ£€æŸ¥SQLå¹´é¾„
            age_hours = 0.0
            if analyzed_at:
                age_hours = (datetime.now() - analyzed_at).total_seconds() / 3600
            
            # 3. è¯­æ³•éªŒè¯
            syntax_issues = await self._validate_sql_syntax(sql_text)
            
            # 4. ç»“æ„å®Œæ•´æ€§æ£€æŸ¥
            structure_issues = await self._validate_sql_structure(sql_text, placeholder_id)
            
            # 5. ç¡®å®šçŠ¶æ€
            status = self._determine_sql_status(
                sql_text, confidence, age_hours, syntax_issues, structure_issues
            )
            
            # 6. ç”Ÿæˆå»ºè®®
            recommended_action = self._recommend_action_for_status(status, confidence, age_hours)
            
            return SQLHealthCheck(
                placeholder_id=placeholder_id,
                status=status,
                sql=sql_text,
                issues=syntax_issues + structure_issues,
                confidence=confidence,
                last_validation=analyzed_at,
                age_hours=age_hours,
                recommended_action=recommended_action
            )
            
        except Exception as e:
            logger.error(f"SQLå®Œæ•´æ€§éªŒè¯å¤±è´¥: {placeholder_id}, {e}")
            return SQLHealthCheck(
                placeholder_id=placeholder_id,
                status=SQLValidationStatus.UNKNOWN,
                issues=[f"éªŒè¯å¤±è´¥: {str(e)}"],
                recommended_action="manual_check_required"
            )
    
    async def repair_corrupted_sql(self, 
                                 placeholder_id: str, 
                                 user_id: str) -> Dict[str, Any]:
        """ä¿®å¤æŸåçš„SQL - æ–°å¢åŠŸèƒ½"""
        
        logger.info(f"ğŸ› ï¸ å¼€å§‹ä¿®å¤æŸåçš„SQL: {placeholder_id}")
        
        try:
            # 1. è¯Šæ–­æŸååŸå› 
            corruption_analysis = await self._analyze_sql_corruption(placeholder_id)
            
            # 2. å°è¯•è‡ªåŠ¨ä¿®å¤
            auto_repair_result = await self._attempt_auto_repair(placeholder_id, corruption_analysis)
            
            if auto_repair_result.get('success'):
                logger.info(f"âœ… è‡ªåŠ¨ä¿®å¤æˆåŠŸ: {placeholder_id}")
                return auto_repair_result
            
            # 3. å›é€€åˆ°é‡æ–°åˆ†æ
            logger.info(f"ğŸ”„ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œé‡æ–°åˆ†æ: {placeholder_id}")
            reanalysis_result = await self._force_reanalyze_placeholder(placeholder_id, user_id)
            
            if reanalysis_result.get('success'):
                return {
                    'success': True,
                    'method': 'reanalysis',
                    'placeholder_id': placeholder_id,
                    'original_issues': corruption_analysis.get('issues', []),
                    'repair_result': reanalysis_result
                }
            
            # 4. ä¿®å¤å¤±è´¥
            return {
                'success': False,
                'placeholder_id': placeholder_id,
                'corruption_analysis': corruption_analysis,
                'auto_repair_result': auto_repair_result,
                'reanalysis_result': reanalysis_result,
                'recommendation': 'manual_intervention_required'
            }
            
        except Exception as e:
            logger.error(f"SQLä¿®å¤å¤±è´¥: {placeholder_id}, {e}")
            return {
                'success': False,
                'placeholder_id': placeholder_id,
                'error': str(e),
                'recommendation': 'expert_assistance_required'
            }
    
    # ç§æœ‰æ–¹æ³•
    
    @asynccontextmanager
    async def _null_context(self):
        """ç©ºä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        yield
    
    async def _acquire_analysis_lock(self, 
                                   placeholder_id: str,
                                   user_id: str,
                                   task_id: str) -> Optional[object]:
        """è·å–åˆ†æé”"""
        
        if not self.redis_client:
            return None
        
        lock_key = f"placeholder_analysis_lock:{placeholder_id}"
        lock_value = f"{user_id}:{task_id}:{datetime.now().isoformat()}"
        
        try:
            # å°è¯•è·å–é”
            acquired = await self.redis_client.set(
                lock_key, 
                lock_value, 
                ex=self.lock_timeout,  # è¿‡æœŸæ—¶é—´
                nx=True  # åªåœ¨é”®ä¸å­˜åœ¨æ—¶è®¾ç½®
            )
            
            if acquired:
                logger.info(f"ğŸ”’ è·å–åˆ†æé”æˆåŠŸ: {placeholder_id}")
                
                @asynccontextmanager
                async def lock_context():
                    try:
                        yield
                    finally:
                        # é‡Šæ”¾é”
                        try:
                            # åªé‡Šæ”¾è‡ªå·±æŒæœ‰çš„é”
                            current_value = await self.redis_client.get(lock_key)
                            if current_value and current_value.decode() == lock_value:
                                await self.redis_client.delete(lock_key)
                                logger.info(f"ğŸ”“ é‡Šæ”¾åˆ†æé”: {placeholder_id}")
                        except Exception as e:
                            logger.warning(f"é‡Šæ”¾é”å¤±è´¥: {e}")
                
                return lock_context()
            else:
                logger.warning(f"â³ è·å–åˆ†æé”å¤±è´¥ï¼Œå·²è¢«å ç”¨: {placeholder_id}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–åˆ†æé”å¼‚å¸¸: {e}")
            return None
    
    async def _handle_concurrency_conflict(self, 
                                         placeholder_id: str,
                                         user_id: str,
                                         task_id: str) -> Dict[str, Any]:
        """å¤„ç†å¹¶å‘å†²çª"""
        
        logger.info(f"âš¡ å¤„ç†å¹¶å‘å†²çª: {placeholder_id}")
        
        # è·å–å½“å‰é”ä¿¡æ¯
        lock_info = await self._get_current_lock_info(placeholder_id)
        
        if not lock_info:
            # é”å·²é‡Šæ”¾ï¼Œé‡è¯•
            return await self.ensure_placeholder_sql_with_resilience(
                placeholder_id, user_id, task_id
            )
        
        # æ ¹æ®ç­–ç•¥å¤„ç†
        strategy = self._determine_concurrency_strategy(lock_info, user_id, task_id)
        
        if strategy == ConcurrencyStrategy.WAIT:
            # ç­‰å¾…ç­–ç•¥
            return await self._wait_for_analysis_completion(placeholder_id, user_id, task_id)
            
        elif strategy == ConcurrencyStrategy.DUPLICATE:
            # å…è®¸é‡å¤åˆ†æ
            return await self._force_duplicate_analysis(placeholder_id, user_id, task_id)
            
        elif strategy == ConcurrencyStrategy.ABORT:
            # ä¸­æ­¢åˆ†æ
            return {
                'success': False,
                'reason': 'concurrency_conflict',
                'placeholder_id': placeholder_id,
                'lock_holder': lock_info.get('holder'),
                'recommendation': 'retry_later'
            }
        
        else:  # PRIORITY
            # åŸºäºä¼˜å…ˆçº§å¤„ç†
            return await self._handle_priority_conflict(placeholder_id, user_id, task_id, lock_info)
    
    async def _perform_sql_health_check(self, placeholder_id: str) -> SQLHealthCheck:
        """æ‰§è¡ŒSQLå¥åº·æ£€æŸ¥"""
        
        try:
            # è·å–å­˜å‚¨çš„SQLä¿¡æ¯
            sql_info = await self._get_stored_sql_info(placeholder_id)
            
            if not sql_info:
                return SQLHealthCheck(
                    placeholder_id=placeholder_id,
                    status=SQLValidationStatus.UNKNOWN,
                    recommended_action="analyze_required"
                )
            
            sql_text = sql_info.get('sql', '')
            confidence = sql_info.get('confidence', 0.0)
            analyzed_at = sql_info.get('analyzed_at')
            
            # è®¡ç®—å¹´é¾„
            age_hours = 0.0
            if analyzed_at:
                age_hours = (datetime.now() - analyzed_at).total_seconds() / 3600
            
            # ç»¼åˆæ£€æŸ¥
            issues = []
            
            # 1. åŸºæœ¬æ£€æŸ¥
            if not sql_text or sql_text.strip() == '':
                issues.append("SQLä¸ºç©º")
                status = SQLValidationStatus.CORRUPTED
            elif age_hours > self.sql_max_age_hours:
                issues.append(f"SQLè¿‡æœŸ ({age_hours:.1f}å°æ—¶)")
                status = SQLValidationStatus.EXPIRED
            elif confidence < 0.3:
                issues.append(f"ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.2f})")
                status = SQLValidationStatus.INVALID
            else:
                # 2. è¯­æ³•æ£€æŸ¥
                syntax_issues = await self._validate_sql_syntax(sql_text)
                issues.extend(syntax_issues)
                
                if syntax_issues:
                    status = SQLValidationStatus.CORRUPTED
                else:
                    # 3. é€»è¾‘æ£€æŸ¥
                    logic_issues = await self._validate_sql_logic(sql_text, placeholder_id)
                    issues.extend(logic_issues)
                    
                    if logic_issues:
                        status = SQLValidationStatus.OUTDATED
                    else:
                        status = SQLValidationStatus.VALID
            
            # ç”Ÿæˆå»ºè®®
            recommended_action = self._recommend_action_for_status(status, confidence, age_hours)
            
            return SQLHealthCheck(
                placeholder_id=placeholder_id,
                status=status,
                sql=sql_text,
                issues=issues,
                confidence=confidence,
                last_validation=analyzed_at,
                age_hours=age_hours,
                recommended_action=recommended_action
            )
            
        except Exception as e:
            logger.error(f"SQLå¥åº·æ£€æŸ¥å¤±è´¥: {placeholder_id}, {e}")
            return SQLHealthCheck(
                placeholder_id=placeholder_id,
                status=SQLValidationStatus.UNKNOWN,
                issues=[f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"],
                recommended_action="manual_check_required"
            )
    
    async def _return_healthy_sql(self, 
                                health_check: SQLHealthCheck,
                                task_id: str) -> Dict[str, Any]:
        """è¿”å›å¥åº·çš„SQL"""
        
        return {
            'success': True,
            'source': 'stored_validated',
            'placeholder_id': health_check.placeholder_id,
            'sql': health_check.sql,
            'confidence': health_check.confidence,
            'last_validation': health_check.last_validation.isoformat() if health_check.last_validation else None,
            'age_hours': health_check.age_hours,
            'health_status': health_check.status.value,
            'task_id': task_id,
            'needs_refresh': False
        }
    
    async def _refresh_sql_with_fallback(self,
                                       placeholder_id: str,
                                       user_id: str,
                                       task_id: str,
                                       health_check: SQLHealthCheck) -> Dict[str, Any]:
        """å¸¦å›é€€çš„SQLåˆ·æ–°"""
        
        logger.info(f"ğŸ”„ åˆ·æ–°SQL: {placeholder_id}, åŸå› : {health_check.recommended_action}")
        
        try:
            # 1. å°è¯•æ™ºèƒ½ä¿®å¤
            if health_check.status in [SQLValidationStatus.CORRUPTED, SQLValidationStatus.INVALID]:
                repair_result = await self.repair_corrupted_sql(placeholder_id, user_id)
                if repair_result.get('success'):
                    return repair_result
            
            # 2. é‡æ–°åˆ†æ
            reanalysis_result = await self._force_reanalyze_placeholder(placeholder_id, user_id)
            
            if reanalysis_result.get('success'):
                return {
                    'success': True,
                    'source': 'refreshed_analysis',
                    'placeholder_id': placeholder_id,
                    'sql': reanalysis_result.get('sql'),
                    'confidence': reanalysis_result.get('confidence'),
                    'previous_issues': health_check.issues,
                    'refresh_reason': health_check.recommended_action,
                    'task_id': task_id
                }
            
            # 3. å¦‚æœé‡æ–°åˆ†æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜çš„å¤‡ä»½
            backup_result = await self._try_backup_sql(placeholder_id)
            
            if backup_result.get('success'):
                logger.warning(f"âš ï¸ ä½¿ç”¨å¤‡ä»½SQL: {placeholder_id}")
                return {
                    'success': True,
                    'source': 'backup_fallback',
                    'placeholder_id': placeholder_id,
                    'sql': backup_result.get('sql'),
                    'confidence': backup_result.get('confidence', 0.5),
                    'warning': 'using_backup_sql',
                    'original_issues': health_check.issues,
                    'task_id': task_id
                }
            
            # 4. æœ€åçš„å›é€€ - è¿”å›é”™è¯¯ä½†æä¾›è¯Šæ–­ä¿¡æ¯
            return {
                'success': False,
                'reason': 'refresh_failed',
                'placeholder_id': placeholder_id,
                'original_issues': health_check.issues,
                'refresh_attempts': ['repair', 'reanalysis', 'backup'],
                'recommendation': 'manual_intervention_required',
                'task_id': task_id
            }
            
        except Exception as e:
            logger.error(f"SQLåˆ·æ–°å¤±è´¥: {placeholder_id}, {e}")
            return {
                'success': False,
                'reason': 'refresh_exception',
                'placeholder_id': placeholder_id,
                'error': str(e),
                'task_id': task_id
            }
    
    def _determine_sql_status(self, 
                            sql_text: str,
                            confidence: float,
                            age_hours: float,
                            syntax_issues: List[str],
                            structure_issues: List[str]) -> SQLValidationStatus:
        """ç¡®å®šSQLçŠ¶æ€"""
        
        if not sql_text or sql_text.strip() == '':
            return SQLValidationStatus.CORRUPTED
        
        if syntax_issues:
            return SQLValidationStatus.CORRUPTED
        
        if age_hours > self.sql_max_age_hours:
            return SQLValidationStatus.EXPIRED
        
        if confidence < 0.3:
            return SQLValidationStatus.INVALID
        
        if structure_issues:
            return SQLValidationStatus.OUTDATED
        
        return SQLValidationStatus.VALID
    
    def _recommend_action_for_status(self, 
                                   status: SQLValidationStatus,
                                   confidence: float,
                                   age_hours: float) -> str:
        """ä¸ºçŠ¶æ€æ¨èè¡ŒåŠ¨"""
        
        if status == SQLValidationStatus.VALID:
            if confidence >= 0.8 and age_hours < 12:
                return "use_as_is"
            elif confidence >= 0.6:
                return "use_with_monitoring"
            else:
                return "consider_refresh"
        
        elif status == SQLValidationStatus.EXPIRED:
            return "refresh_required"
        
        elif status == SQLValidationStatus.CORRUPTED:
            return "repair_or_regenerate"
        
        elif status == SQLValidationStatus.INVALID:
            return "regenerate_required"
        
        elif status == SQLValidationStatus.OUTDATED:
            return "update_required"
        
        else:
            return "analyze_required"
    
    # ä¸ºäº†ç¼–è¯‘é€šè¿‡ï¼Œæ·»åŠ å…¶ä»–æ–¹æ³•çš„å ä½ç¬¦å®ç°
    
    async def _get_stored_sql_info(self, placeholder_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å­˜å‚¨çš„SQLä¿¡æ¯"""
        # å®ç°æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        return {
            'sql': 'SELECT COUNT(*) FROM test_table',
            'confidence': 0.8,
            'analyzed_at': datetime.now() - timedelta(hours=2)
        }
    
    async def _validate_sql_syntax(self, sql: str) -> List[str]:
        """éªŒè¯SQLè¯­æ³•"""
        issues = []
        if 'syntax_error' in sql.lower():
            issues.append("è¯­æ³•é”™è¯¯")
        return issues
    
    async def _validate_sql_structure(self, sql: str, placeholder_id: str) -> List[str]:
        """éªŒè¯SQLç»“æ„"""
        return []
    
    async def _validate_sql_logic(self, sql: str, placeholder_id: str) -> List[str]:
        """éªŒè¯SQLé€»è¾‘"""
        return []
    
    async def _analyze_new_placeholder(self, placeholder_id: str, user_id: str, task_id: str) -> Dict[str, Any]:
        """åˆ†ææ–°å ä½ç¬¦"""
        return {'success': True, 'sql': 'SELECT * FROM new_table', 'confidence': 0.9}
    
    async def _handle_critical_failure(self, placeholder_id: str, user_id: str, task_id: str, exception: Exception) -> Dict[str, Any]:
        """å¤„ç†ä¸¥é‡å¤±è´¥"""
        return {'success': False, 'error': str(exception), 'placeholder_id': placeholder_id}
    
    async def _group_batch_requests(self, placeholder_ids: List[str], user_id: str, task_id: str) -> Dict[str, Any]:
        """åˆ†ç»„æ‰¹é‡è¯·æ±‚"""
        return {'total': len(placeholder_ids), 'groups': ['group1']}
    
    async def _generate_batch_statistics(self, successful: List, failed: List, grouped: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰¹é‡ç»Ÿè®¡"""
        return {'success_rate': len(successful) / (len(successful) + len(failed)) if (successful or failed) else 0}
    
    def _generate_batch_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ‰¹é‡å»ºè®®"""
        recommendations = []
        if stats.get('success_rate', 0) < 0.8:
            recommendations.append("è€ƒè™‘æ£€æŸ¥æ•°æ®æºè¿æ¥")
        return recommendations
    
    async def _get_current_lock_info(self, placeholder_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å½“å‰é”ä¿¡æ¯"""
        return None  # å¦‚æœæ²¡æœ‰é”
    
    def _determine_concurrency_strategy(self, lock_info: Dict, user_id: str, task_id: str) -> ConcurrencyStrategy:
        """ç¡®å®šå¹¶å‘ç­–ç•¥"""
        return ConcurrencyStrategy.WAIT
    
    async def _wait_for_analysis_completion(self, placeholder_id: str, user_id: str, task_id: str) -> Dict[str, Any]:
        """ç­‰å¾…åˆ†æå®Œæˆ"""
        await asyncio.sleep(5)  # ç­‰å¾…5ç§’
        return await self.ensure_placeholder_sql_with_resilience(placeholder_id, user_id, task_id)
    
    async def _force_duplicate_analysis(self, placeholder_id: str, user_id: str, task_id: str) -> Dict[str, Any]:
        """å¼ºåˆ¶é‡å¤åˆ†æ"""
        return {'success': True, 'source': 'duplicate_analysis'}
    
    async def _handle_priority_conflict(self, placeholder_id: str, user_id: str, task_id: str, lock_info: Dict) -> Dict[str, Any]:
        """å¤„ç†ä¼˜å…ˆçº§å†²çª"""
        return {'success': False, 'reason': 'priority_conflict'}
    
    async def _analyze_sql_corruption(self, placeholder_id: str) -> Dict[str, Any]:
        """åˆ†æSQLæŸå"""
        return {'issues': ['syntax_error'], 'corruption_type': 'syntax'}
    
    async def _attempt_auto_repair(self, placeholder_id: str, corruption_analysis: Dict) -> Dict[str, Any]:
        """å°è¯•è‡ªåŠ¨ä¿®å¤"""
        return {'success': False, 'reason': 'complex_corruption'}
    
    async def _force_reanalyze_placeholder(self, placeholder_id: str, user_id: str) -> Dict[str, Any]:
        """å¼ºåˆ¶é‡æ–°åˆ†æå ä½ç¬¦"""
        return {'success': True, 'sql': 'SELECT COUNT(*) FROM repaired_table', 'confidence': 0.85}
    
    async def _try_backup_sql(self, placeholder_id: str) -> Dict[str, Any]:
        """å°è¯•å¤‡ä»½SQL"""
        return {'success': True, 'sql': 'SELECT 1 AS fallback', 'confidence': 0.5}


# ä¾¿æ·å‡½æ•°
def create_enhanced_placeholder_facade(db_session: Session,
                                     redis_client: Optional[redis.Redis] = None) -> EnhancedPlaceholderAnalysisFacade:
    """åˆ›å»ºå¢å¼ºçš„å ä½ç¬¦åˆ†æé—¨é¢"""
    return EnhancedPlaceholderAnalysisFacade(db_session, redis_client)


# ä½¿ç”¨ç¤ºä¾‹
async def example_enhanced_usage():
    """å¢å¼ºåŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹"""
    from sqlalchemy.orm import sessionmaker
    import redis
    
    # å‡è®¾å·²æœ‰æ•°æ®åº“ä¼šè¯å’ŒRedisè¿æ¥
    # db_session = SessionLocal()
    # redis_client = redis.Redis()
    
    # facade = create_enhanced_placeholder_facade(db_session, redis_client)
    
    # 1. å¢å¼ºçš„SQLè·å–
    # result = await facade.ensure_placeholder_sql_with_resilience(
    #     placeholder_id="ph_001",
    #     user_id="user_123", 
    #     task_id="task_456"
    # )
    
    # 2. SQLå®Œæ•´æ€§éªŒè¯
    # health_check = await facade.validate_sql_integrity("ph_001")
    # print(f"SQLçŠ¶æ€: {health_check.status.value}")
    
    # 3. æ‰¹é‡å¤„ç†
    # batch_result = await facade.batch_ensure_placeholders_with_resilience(
    #     placeholder_ids=["ph_001", "ph_002", "ph_003"],
    #     user_id="user_123",
    #     task_id="task_456"
    # )
    
    # 4. ä¿®å¤æŸåçš„SQL
    # repair_result = await facade.repair_corrupted_sql("ph_corrupted", "user_123")
    
    pass


if __name__ == "__main__":
    import asyncio
    asyncio.run(example_enhanced_usage())