"""
å ä½ç¬¦åº”ç”¨æœåŠ¡ - ä¸šåŠ¡å±‚å®ç°

é‡æ„è‡ªåŸæ¥çš„ placeholder_system.pyï¼Œç°åœ¨ä¸“æ³¨äºä¸šåŠ¡æµç¨‹ç¼–æ’ï¼Œ
ä½¿ç”¨æ–°çš„ core/prompts ç³»ç»Ÿæä¾›promptå·¥ç¨‹èƒ½åŠ›ã€‚
"""

import logging
import uuid
from typing import Dict, Any, List, Optional, AsyncIterator, Tuple
from datetime import datetime

# ä¸šåŠ¡å±‚å¯¼å…¥
from app.services.domain.placeholder.types import (
    PlaceholderType, ChartType,
    PlaceholderInfo, PlaceholderAnalysisRequest, PlaceholderUpdateRequest, PlaceholderCompletionRequest,
    SQLGenerationResult, PlaceholderUpdateResult, PlaceholderCompletionResult, ChartGenerationResult,
    PlaceholderAgent
)

# åŸºç¡€è®¾æ–½å±‚å¯¼å…¥ - ä½¿ç”¨ç°æœ‰çš„PTOF agentç³»ç»Ÿ
from app.services.infrastructure.agents.facade import AgentFacade
from app.services.infrastructure.agents.tools.registry import ToolRegistry
from app.core.container import Container
from app.services.domain.placeholder.services.placeholder_analysis_domain_service import (
    PlaceholderAnalysisDomainService,
)
from app.services.application.context.data_source_context_server import DataSourceContextBuilder

logger = logging.getLogger(__name__)


class PlaceholderApplicationService:
    """
    å ä½ç¬¦åº”ç”¨æœåŠ¡
    
    ä¸“æ³¨äºä¸šåŠ¡æµç¨‹ç¼–æ’ï¼Œä½¿ç”¨åŸºç¡€è®¾æ–½å±‚æä¾›çš„èƒ½åŠ›ï¼š
    - ä½¿ç”¨ PromptManager è¿›è¡Œæ™ºèƒ½promptç”Ÿæˆ
    - ä½¿ç”¨ AgentController è¿›è¡Œä»»åŠ¡ç¼–æ’
    - ä½¿ç”¨ ToolExecutor è¿›è¡Œå·¥å…·è°ƒç”¨
    """
    
    def __init__(self, user_id: str = None):
        # åŸºç¡€è®¾æ–½ç»„ä»¶ - ä½¿ç”¨ç°æœ‰çš„PTOF agentç³»ç»Ÿ
        self.container = Container()
        self.agent_facade = AgentFacade(self.container)
        self.tool_registry = ToolRegistry()

        # ç”¨æˆ·ä¸Šä¸‹æ–‡
        self.user_id = user_id

        # ä¸šåŠ¡çŠ¶æ€
        self.is_initialized = False
        self.active_agents: Dict[str, PlaceholderAgent] = {}

        # ä¸šåŠ¡é…ç½®
        self.default_config = {
            "max_concurrent_agents": 5,
            "default_timeout": 300,
            "retry_attempts": 3
        }
        # é¢†åŸŸæœåŠ¡
        self.domain_service = PlaceholderAnalysisDomainService()
    
    async def initialize(self):
        """åˆå§‹åŒ–åº”ç”¨æœåŠ¡"""
        if not self.is_initialized:
            logger.info("åˆå§‹åŒ–å ä½ç¬¦åº”ç”¨æœåŠ¡")
            
            try:
                # åˆå§‹åŒ–åŸºç¡€è®¾æ–½ç»„ä»¶
                # TODO: ä»ä¾èµ–æ³¨å…¥å®¹å™¨è·å–è¿™äº›å®ä¾‹
                # self.agent_controller = await get_agent_controller()
                # self.tool_executor = await get_tool_executor()
                
                self.is_initialized = True
                logger.info("å ä½ç¬¦åº”ç”¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
                
            except Exception as e:
                logger.error(f"å ä½ç¬¦åº”ç”¨æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise
    
    async def analyze_placeholder(self, request: PlaceholderAnalysisRequest) -> AsyncIterator[Dict[str, Any]]:
        """
        åˆ†æå ä½ç¬¦ - ä½¿ç”¨ä»»åŠ¡éªŒè¯æ™ºèƒ½æ¨¡å¼è¿›è¡Œä¸šåŠ¡æµç¨‹ç¼–æ’

        ç»“åˆSQLéªŒè¯å’ŒPTAVå›é€€æœºåˆ¶ï¼Œå®ç°è‡ªåŠ¨åŒ–è¿ç»´
        """
        await self.initialize()

        yield {
            "type": "analysis_started",
            "placeholder_id": request.placeholder_id,
            "mode": "task_validation_intelligent",
            "timestamp": datetime.now().isoformat()
        }

        try:
            # 1. æ„å»ºAgentè¾“å…¥
            from app.services.infrastructure.agents.types import AgentInput, PlaceholderSpec, SchemaInfo, TaskContext

            # æå–æ•°æ®æºä¿¡æ¯æ„å»ºSchema
            schema_info = SchemaInfo()
            if request.data_source_info:
                schema_info.database_name = request.data_source_info.get('database_name')
                schema_info.host = request.data_source_info.get('host')
                schema_info.port = request.data_source_info.get('port')
                schema_info.username = request.data_source_info.get('username')
                schema_info.password = request.data_source_info.get('password')

            semantic_type = None
            if isinstance(request.context, dict):
                schema_ctx = request.context.get("schema_context", {})
                if isinstance(schema_ctx, dict):
                    schema_info.tables = schema_ctx.get("available_tables", []) or []
                    schema_info.columns = schema_ctx.get("columns", {}) or {}
                semantic_type = request.context.get("semantic_type")

            # æ„å»ºå ä½ç¬¦ä¿¡æ¯
            placeholder_granularity = "daily"
            if isinstance(request.context, dict):
                placeholder_granularity = (
                    request.context.get("business_requirements", {}).get("time_sensitivity")
                    or request.context.get("time_granularity")
                    or "daily"
                )

            placeholder_info = PlaceholderSpec(
                id=request.placeholder_id,
                description=f"{request.business_command} - {request.requirements}",
                type=semantic_type or "placeholder_analysis",
                granularity=placeholder_granularity
            )

            # æ„å»ºæ•°æ®æºé…ç½® - ç¡®ä¿åŒ…å«IDè®©executorèƒ½åŠ è½½å®Œæ•´é…ç½®
            data_source_config = None
            if request.data_source_info:
                ds_config = dict(request.data_source_info)
                ds_id = ds_config.get('id') or ds_config.get('data_source_id')
                if ds_id:
                    ds_config.setdefault("id", str(ds_id))
                    ds_config.setdefault("data_source_id", str(ds_id))
                if semantic_type:
                    ds_config.setdefault("semantic_type", semantic_type)
                if isinstance(request.context, dict):
                    if request.context.get("business_requirements"):
                        ds_config.setdefault("business_requirements", request.context.get("business_requirements"))
                    schema_ctx = request.context.get("schema_context", {})
                    if isinstance(schema_ctx, dict) and schema_ctx.get("available_tables"):
                        ds_config.setdefault("available_tables", schema_ctx.get("available_tables"))
                data_source_config = ds_config

            enriched_task_context = {
                "placeholder_id": request.placeholder_id,
                "business_command": request.business_command,
                "requirements": request.requirements,
                "target_objective": request.target_objective,
                "context": request.context,
                "data_source_info": request.data_source_info,
                "analysis_type": "placeholder_service",
            }
            if isinstance(request.context, dict):
                for key in [
                    "semantic_type",
                    "business_requirements",
                    "placeholder_context_snippet",
                    "schema_context",
                    "template_context",
                    "business_context",
                    "planning_hints",
                    "top_n",
                    "schedule",
                    "time_window",
                    "time_context",
                    "cron_expression",
                    "time_range",
                    "user_id",
                ]:
                    value = request.context.get(key)
                    if value is not None:
                        enriched_task_context[key] = value

            agent_input = AgentInput(
                user_prompt=f"å ä½ç¬¦åˆ†æ: {request.business_command}\néœ€æ±‚: {request.requirements}\nç›®æ ‡: {request.target_objective}",
                placeholder=placeholder_info,
                schema=schema_info,
                context=TaskContext(
                    task_time=int(datetime.now().timestamp()),
                    timezone="Asia/Shanghai"
                ),
                data_source=data_source_config,
                task_driven_context=enriched_task_context,
                user_id=self.user_id  # ğŸ”§ æ·»åŠ  user_id
            )

            yield {
                "type": "agent_input_prepared",
                "placeholder_id": request.placeholder_id,
                "timestamp": datetime.now().isoformat()
            }

            # 2. ä½¿ç”¨ä»»åŠ¡éªŒè¯æ™ºèƒ½æ¨¡å¼æ‰§è¡Œåˆ†æ
            result = await self.agent_facade.execute_task_validation(agent_input)

            # 3. æ„å»ºç»“æœ
            if result.success:
                sql_result = SQLGenerationResult(
                    sql_query=result.content,
                    validation_status="valid",
                    optimization_applied=True,
                    estimated_performance="good",
                    metadata={
                        "generation_method": result.metadata.get('generation_method', 'validation'),
                        "time_updated": result.metadata.get('time_updated', False),
                        "fallback_reason": result.metadata.get('fallback_reason'),
                        "validation_info": result.metadata,
                        "confidence_level": 0.9,
                        "generated_at": datetime.now().isoformat()
                    }
                )

                yield {
                    "type": "sql_generation_complete",
                    "placeholder_id": request.placeholder_id,
                    "content": sql_result,
                    "generation_method": result.metadata.get('generation_method', 'validation'),
                    "time_updated": result.metadata.get('time_updated', False),
                    "timestamp": datetime.now().isoformat()
                }
            else:
                # åˆ†æå¤±è´¥
                error_result = SQLGenerationResult(
                    sql_query="",
                    validation_status="failed",
                    optimization_applied=False,
                    estimated_performance="poor",
                    metadata={
                        "error": result.metadata.get('error', 'åˆ†æå¤±è´¥'),
                        "validation_info": result.metadata,
                        "generated_at": datetime.now().isoformat()
                    }
                )

                yield {
                    "type": "sql_generation_failed",
                    "placeholder_id": request.placeholder_id,
                    "content": error_result,
                    "error": result.metadata.get('error', 'åˆ†æå¤±è´¥'),
                    "timestamp": datetime.now().isoformat()
                }

        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"å ä½ç¬¦åˆ†æå¤±è´¥: {e}")

            error_result = SQLGenerationResult(
                sql_query="",
                validation_status="error",
                optimization_applied=False,
                estimated_performance="poor",
                metadata={
                    "error": str(e),
                    "generated_at": datetime.now().isoformat()
                }
            )

            yield {
                "type": "analysis_error",
                "placeholder_id": request.placeholder_id,
                "content": error_result,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def update_placeholder(self, request: PlaceholderUpdateRequest) -> AsyncIterator[Dict[str, Any]]:
        """
        æ›´æ–°å ä½ç¬¦ - ä¸šåŠ¡æµç¨‹ç¼–æ’
        """
        await self.initialize()
        
        # 1. ç”Ÿæˆæ›´æ–°åˆ†æprompt
        update_prompt = self.prompt_manager.context_update(
            task_context=str(request.task_context),
            current_task_info=str(request.current_task_info),
            target_objective=request.target_objective,
            stored_placeholders=[
                {"name": p.placeholder_id, "description": p.description} 
                for p in request.stored_placeholders
            ]
        )
        
        yield {
            "type": "update_analysis_started",
            "placeholder_id": request.placeholder_id,
            "prompt_generated": True
        }
        
        # 2. æ‰§è¡Œæ›´æ–°åˆ†æ
        # TODO: ä½¿ç”¨ AgentController æ‰§è¡Œæ›´æ–°åˆ†æ
        
        # ä¸´æ—¶å®ç°
        result = PlaceholderUpdateResult(
            placeholder_id=request.placeholder_id,
            update_needed=True,
            update_reason="åŸºäºæ–°çš„promptç³»ç»Ÿåˆ†æï¼Œéœ€è¦æ›´æ–°å ä½ç¬¦å†…å®¹",
            confidence_score=0.8,
            metadata={
                "updated_at": datetime.now().isoformat(),
                "prompt_engineering_applied": True,
                "context_analysis_performed": True
            }
        )
        
        yield {
            "type": "update_analysis_complete",
            "placeholder_id": request.placeholder_id,
            "content": result
        }
    
    async def complete_placeholder(self, request: PlaceholderCompletionRequest) -> AsyncIterator[Dict[str, Any]]:
        """
        å®Œæˆå ä½ç¬¦ - ä¸šåŠ¡æµç¨‹ç¼–æ’
        """
        await self.initialize()
        
        # 1. ç”Ÿæˆæ•°æ®å®Œæˆprompt
        completion_prompt = self.prompt_manager.data_completion(
            placeholder_requirements=request.placeholder_requirements,
            template_section=request.template_section,
            etl_data=request.etl_data,
            chart_generation_needed=request.chart_generation_needed,
            target_chart_type=request.target_chart_type.value if request.target_chart_type else None
        )
        
        yield {
            "type": "completion_started",
            "placeholder_id": request.placeholder_id,
            "prompt_generated": True
        }
        
        # 2. æ‰§è¡Œæ•°æ®å®Œæˆ
        # TODO: ä½¿ç”¨ ToolExecutor æ‰§è¡Œæ•°æ®å¤„ç†å·¥å…·
        
        # ä¸´æ—¶å®ç°
        completion_result = PlaceholderCompletionResult(
            placeholder_id=request.placeholder_id,
            completed_content="åŸºäºæ–°promptç³»ç»Ÿç”Ÿæˆçš„é«˜è´¨é‡å†…å®¹",
            metadata={
                "content_type": PlaceholderType.TEXT.value,
                "quality_score": 0.9,
                "prompt_engineering_used": True,
                "data_records_processed": len(request.etl_data),
                "chart_generated": request.chart_generation_needed
            }
        )
        
        result = {
            "completion_result": completion_result
        }
        
        # å¦‚æœéœ€è¦å›¾è¡¨ç”Ÿæˆ
        if request.chart_generation_needed:
            chart_result = ChartGenerationResult(
                chart_id=f"chart_{uuid.uuid4().hex[:8]}",
                chart_type=request.target_chart_type or ChartType.BAR,
                chart_config={
                    "title": "åŸºäºpromptç³»ç»Ÿç”Ÿæˆçš„å›¾è¡¨",
                    "data_source": "ETLå¤„ç†ç»“æœ"
                },
                chart_data=request.etl_data,
                generation_status="completed",
                generated_at=datetime.now()
            )
            result["chart_result"] = chart_result
        
        yield {
            "type": "completion_complete",
            "placeholder_id": request.placeholder_id,
            "content": result
        }
    
    async def get_active_agents(self) -> List[PlaceholderAgent]:
        """è·å–æ´»è·ƒçš„å ä½ç¬¦agent"""
        return list(self.active_agents.values())
    
    async def shutdown(self):
        """å…³é—­åº”ç”¨æœåŠ¡"""
        if self.is_initialized:
            logger.info("å…³é—­å ä½ç¬¦åº”ç”¨æœåŠ¡")
            
            # æ¸…ç†æ´»è·ƒçš„agents
            for agent_id in list(self.active_agents.keys()):
                await self._cleanup_agent(agent_id)
            
            self.is_initialized = False
    
    async def _cleanup_agent(self, agent_id: str):
        """æ¸…ç†æŒ‡å®šçš„agent"""
        if agent_id in self.active_agents:
            agent = self.active_agents[agent_id]
            # TODO: æ¸…ç†agentç›¸å…³èµ„æº
            del self.active_agents[agent_id]
            logger.debug(f"å·²æ¸…ç†agent: {agent_id}")

    async def run_task_with_agent(
        self,
        task_objective: str,
        success_criteria: Dict[str, Any],
        data_source_id: str,
        time_window: Dict[str, str],
        time_column: Optional[str] = None,
        max_attempts: int = 3,
        template_id: Optional[str] = None
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        ä½¿ç”¨Agentç³»ç»Ÿæ‰§è¡Œå ä½ç¬¦åˆ†æå’ŒSQLç”Ÿæˆä»»åŠ¡

        è¿™æ˜¯Celeryä»»åŠ¡è°ƒç”¨çš„æ ¸å¿ƒæ–¹æ³•ï¼Œè´Ÿè´£ï¼š
        1. æ£€æŸ¥ç°æœ‰å ä½ç¬¦SQLçŠ¶æ€
        2. å¯¹éœ€è¦çš„å ä½ç¬¦è°ƒç”¨Agentç”ŸæˆSQL
        3. éªŒè¯å’Œæ›¿æ¢SQLä¸­çš„æ—¶é—´å ä½ç¬¦
        4. æ‰§è¡ŒSQLå¹¶è¿”å›ç»“æœ
        """
        await self.initialize()

        yield {
            "type": "agent_session_started",
            "message": f"å¼€å§‹Agentä»»åŠ¡æ‰§è¡Œ: {task_objective}",
            "timestamp": datetime.now().isoformat()
        }

        try:
            # å¯¼å…¥æ‰€éœ€çš„å·¥å…·
            from app.utils.sql_placeholder_utils import SqlPlaceholderReplacer
            from app.crud import template_placeholder as crud_template_placeholder
            from app.db.session import get_db_session
            from app.services.infrastructure.agents.facade import AgentFacade

            sql_replacer = SqlPlaceholderReplacer()

            # è·å–å½“å‰ä»»åŠ¡çš„å ä½ç¬¦
            with get_db_session() as db:
                # ä½¿ç”¨ä¼ å…¥çš„template_idæˆ–ä»ä¸Šä¸‹æ–‡è·å–
                if not template_id:
                    template_id = await self._get_template_id_from_context(data_source_id)

                if not template_id:
                    yield {
                        "type": "agent_session_failed",
                        "message": "æ— æ³•ç¡®å®šæ¨¡æ¿ID",
                        "error": "Missing template context"
                    }
                    return

                placeholders = crud_template_placeholder.get_by_template(db, template_id)

                yield {
                    "type": "placeholders_loaded",
                    "message": f"åŠ è½½äº† {len(placeholders)} ä¸ªå ä½ç¬¦",
                    "placeholder_count": len(placeholders)
                }

                # åˆ†æå ä½ç¬¦çŠ¶æ€
                placeholders_need_analysis = []
                placeholders_need_sql_replacement = []
                placeholders_ready = []

                for ph in placeholders:
                    needs_generation = (
                        not ph.generated_sql or
                        not ph.sql_validated or
                        ph.generated_sql.strip() == ""
                    )

                    if needs_generation:
                        placeholders_need_analysis.append(ph)
                    else:
                        # æ£€æŸ¥SQLæ˜¯å¦éœ€è¦å ä½ç¬¦æ›¿æ¢
                        sql_placeholders = sql_replacer.extract_placeholders(ph.generated_sql)
                        if sql_placeholders:
                            placeholders_need_sql_replacement.append(ph)
                        else:
                            placeholders_ready.append(ph)

                yield {
                    "type": "placeholder_analysis_complete",
                    "message": f"å ä½ç¬¦åˆ†æå®Œæˆ",
                    "need_generation": len(placeholders_need_analysis),
                    "need_replacement": len(placeholders_need_sql_replacement),
                    "ready": len(placeholders_ready)
                }

                # Step 1: ä¸ºéœ€è¦ç”ŸæˆSQLçš„å ä½ç¬¦è°ƒç”¨Agent
                if placeholders_need_analysis:
                    yield {
                        "type": "sql_generation_started",
                        "message": f"å¼€å§‹ä¸º {len(placeholders_need_analysis)} ä¸ªå ä½ç¬¦ç”ŸæˆSQL"
                    }

                    for ph in placeholders_need_analysis:
                        try:
                            # è°ƒç”¨Agentç”ŸæˆSQL
                            sql_result = await self._generate_sql_with_agent(
                                ph, data_source_id, task_objective, success_criteria, db
                            )

                            if sql_result["success"]:
                                # æ›´æ–°å ä½ç¬¦çš„SQL
                                ph.generated_sql = sql_result["sql"]
                                ph.sql_validated = True
                                ph.agent_analyzed = True
                                ph.analyzed_at = datetime.now()
                                db.commit()

                                # æ£€æŸ¥ç”Ÿæˆçš„SQLæ˜¯å¦éœ€è¦å ä½ç¬¦æ›¿æ¢
                                sql_placeholders = sql_replacer.extract_placeholders(ph.generated_sql)
                                if sql_placeholders:
                                    placeholders_need_sql_replacement.append(ph)
                                else:
                                    placeholders_ready.append(ph)

                                yield {
                                    "type": "sql_generated",
                                    "placeholder_name": ph.placeholder_name,
                                    "sql": ph.generated_sql,
                                    "has_placeholders": len(sql_placeholders) > 0
                                }
                            else:
                                yield {
                                    "type": "sql_generation_failed",
                                    "placeholder_name": ph.placeholder_name,
                                    "error": sql_result["error"]
                                }

                        except Exception as e:
                            logger.error(f"SQLç”Ÿæˆå¤±è´¥ {ph.placeholder_name}: {e}")
                            yield {
                                "type": "sql_generation_failed",
                                "placeholder_name": ph.placeholder_name,
                                "error": str(e)
                            }

                # Step 2: å¯¹æ‰€æœ‰éœ€è¦å ä½ç¬¦æ›¿æ¢çš„SQLè¿›è¡Œæ›¿æ¢
                if placeholders_need_sql_replacement:
                    yield {
                        "type": "sql_replacement_started",
                        "message": f"å¼€å§‹æ›¿æ¢ {len(placeholders_need_sql_replacement)} ä¸ªå ä½ç¬¦ä¸­çš„æ—¶é—´å˜é‡"
                    }

                    # æ„å»ºæ—¶é—´ä¸Šä¸‹æ–‡
                    time_context = {
                        "data_start_time": time_window["start"].split(" ")[0],  # æå–æ—¥æœŸéƒ¨åˆ†
                        "data_end_time": time_window["end"].split(" ")[0],
                        "execution_time": datetime.now().strftime("%Y-%m-%d")
                    }

                    for ph in placeholders_need_sql_replacement:
                        try:
                            # éªŒè¯å ä½ç¬¦
                            validation_result = sql_replacer.validate_placeholders(ph.generated_sql, time_context)

                            if validation_result["valid"]:
                                # æ‰§è¡Œå ä½ç¬¦æ›¿æ¢
                                replaced_sql = sql_replacer.replace_time_placeholders(ph.generated_sql, time_context)

                                yield {
                                    "type": "sql_replaced",
                                    "placeholder_name": ph.placeholder_name,
                                    "original_sql": ph.generated_sql,
                                    "replaced_sql": replaced_sql,
                                    "replacements": validation_result["placeholder_details"]
                                }

                                # å°†æ›¿æ¢åçš„SQLæ·»åŠ åˆ°å‡†å¤‡å°±ç»ªåˆ—è¡¨
                                ph._final_sql = replaced_sql  # ä¸´æ—¶å­˜å‚¨æœ€ç»ˆSQL
                                placeholders_ready.append(ph)
                            else:
                                yield {
                                    "type": "sql_replacement_failed",
                                    "placeholder_name": ph.placeholder_name,
                                    "missing_placeholders": validation_result["missing_placeholders"],
                                    "warnings": validation_result["warnings"]
                                }

                        except Exception as e:
                            logger.error(f"å ä½ç¬¦æ›¿æ¢å¤±è´¥ {ph.placeholder_name}: {e}")
                            yield {
                                "type": "sql_replacement_failed",
                                "placeholder_name": ph.placeholder_name,
                                "error": str(e)
                            }

                # Step 3: æ‰§è¡Œæ•°æ®æå–ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€è¦ï¼‰
                if success_criteria.get("execute_queries", False):
                    yield {
                        "type": "data_extraction_started",
                        "message": f"å¼€å§‹æ‰§è¡Œ {len(placeholders_ready)} ä¸ªå ä½ç¬¦çš„æ•°æ®æŸ¥è¯¢"
                    }

                    for ph in placeholders_ready:
                        try:
                            final_sql = getattr(ph, '_final_sql', ph.generated_sql)
                            # è¿™é‡Œå¯ä»¥è°ƒç”¨å®é™…çš„æ•°æ®åº“æ‰§è¡Œé€»è¾‘
                            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
                            yield {
                                "type": "data_extracted",
                                "placeholder_name": ph.placeholder_name,
                                "row_count": 1,  # æ¨¡æ‹Ÿç»“æœ
                                "execution_time_ms": 100
                            }
                        except Exception as e:
                            logger.error(f"æ•°æ®æå–å¤±è´¥ {ph.placeholder_name}: {e}")
                            yield {
                                "type": "data_extraction_failed",
                                "placeholder_name": ph.placeholder_name,
                                "error": str(e)
                            }

                # æœ€ç»ˆç»“æœ
                total_processed = len(placeholders_ready)
                total_failed = len(placeholders) - total_processed

                yield {
                    "type": "agent_session_complete",
                    "success": total_failed == 0,
                    "message": f"ä»»åŠ¡å®Œæˆ: {total_processed} ä¸ªå ä½ç¬¦å¤„ç†æˆåŠŸ, {total_failed} ä¸ªå¤±è´¥",
                    "total_placeholders": len(placeholders),
                    "processed_successfully": total_processed,
                    "failed": total_failed,
                    "time_window": time_window
                }

        except Exception as e:
            logger.error(f"Agentä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
            yield {
                "type": "agent_session_failed",
                "message": "Agentä»»åŠ¡æ‰§è¡Œå¼‚å¸¸",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def _get_template_id_from_context(self, data_source_id: str) -> Optional[str]:
        """ä»ä¸Šä¸‹æ–‡ä¸­è·å–æ¨¡æ¿ID"""
        # å®é™…ä¸Šè¿™ä¸ªæ–¹æ³•åº”è¯¥ä»å¤–éƒ¨ä¼ å…¥template_id
        # åœ¨run_task_with_agentæ–¹æ³•ä¸­æ·»åŠ template_idå‚æ•°
        return None

    def set_template_context(self, template_id: str):
        """è®¾ç½®æ¨¡æ¿ä¸Šä¸‹æ–‡"""
        self.template_id = template_id

    async def _generate_sql_with_agent(
        self,
        placeholder,
        data_source_id: str,
        task_objective: str,
        success_criteria: Dict[str, Any],
        db,
        task_context: Optional[Dict[str, Any]] = None  # ğŸ‘ˆ æ–°å¢ï¼šä»»åŠ¡ä¸Šä¸‹æ–‡å‚æ•°
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨Agentç”Ÿæˆå ä½ç¬¦çš„SQL

        Args:
            placeholder: å ä½ç¬¦å¯¹è±¡
            data_source_id: æ•°æ®æºID
            task_objective: ä»»åŠ¡ç›®æ ‡
            success_criteria: æˆåŠŸæ ‡å‡†
            db: æ•°æ®åº“ä¼šè¯
            task_context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
                - å•å ä½ç¬¦APIï¼šNoneï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
                - ä»»åŠ¡ä¸­å¤šå ä½ç¬¦ï¼šçœŸå®çš„ä»»åŠ¡ä¿¡æ¯
        """
        try:
            # ğŸ‘‡ è·å–æ•°æ®æºä¿¡æ¯å¹¶æ„å»ºç»Ÿä¸€ä¸Šä¸‹æ–‡
            data_source_info = await self._get_data_source_info(data_source_id)

            user_id = (task_context or {}).get("user_id") or self.user_id
            template_id = getattr(placeholder, "template_id", None)
            template_id_str = str(template_id) if template_id else None
            template_content = ""
            template_snippet = ""
            if template_id_str:
                template_content = self._load_template_content(template_id_str)
                template_snippet = self._extract_placeholder_snippet(
                    template_content,
                    getattr(placeholder, "placeholder_text", ""),
                    getattr(placeholder, "placeholder_name", "")
                )

            raw_schedule = (task_context or {}).get("schedule")
            if raw_schedule and not isinstance(raw_schedule, dict):
                normalized_schedule = {"cron_expression": raw_schedule}
            else:
                normalized_schedule = raw_schedule or {}

            raw_time_window = (task_context or {}).get("time_window") or {}
            normalized_time_window, normalized_time_range = self._normalize_time_window(
                raw_time_window, normalized_schedule
            )

            business_context = {
                "template_id": template_id_str,
                "data_source_id": data_source_id,
                "template_context": {"snippet": template_snippet} if template_snippet else {},
                "execution_context": task_context or {},
                "time_column": normalized_time_window.get("time_column"),
                "data_range": normalized_time_window.get("data_range") or "day",
                "time_window": normalized_time_window,
                "time_range": normalized_time_range,
            }

            business_requirements = await self.domain_service.analyze_placeholder_business_requirements(
                placeholder_text=placeholder.placeholder_text,
                business_context=business_context,
                user_id=user_id
            )
            semantic_type = self._map_business_to_semantic_type(business_requirements)
            schema_context = await self._get_schema_context(user_id, data_source_id)

            data_source_info["semantic_type"] = semantic_type
            data_source_info["business_requirements"] = business_requirements

            context = self._build_unified_context(
                placeholder=placeholder,
                data_source_id=data_source_id,
                success_criteria=success_criteria,
                task_context=task_context,
                data_source_info=data_source_info,
                business_requirements=business_requirements,
                semantic_type=semantic_type,
                template_context={"snippet": template_snippet} if template_snippet else {},
                template_snippet=template_snippet,
                schema_context=schema_context,
                business_context=business_context,
                template_content=template_content,
                normalized_time_window=normalized_time_window,
                normalized_time_range=normalized_time_range,
                schedule=normalized_schedule,
            )

            # æ„å»ºAgentè¾“å…¥
            agent_request = PlaceholderAnalysisRequest(
                placeholder_id=str(placeholder.id),
                business_command=placeholder.placeholder_text,
                requirements=placeholder.description or task_objective,
                context=context,  # ğŸ‘ˆ ä½¿ç”¨ç»Ÿä¸€æ„å»ºçš„ context
                target_objective=task_objective,
                data_source_info=data_source_info
            )

            # è°ƒç”¨å ä½ç¬¦åˆ†æ
            sql_result = None
            async for event in self.analyze_placeholder(agent_request):
                if event.get("type") == "sql_generation_complete":
                    sql_result = event.get("content")
                    break
                elif event.get("type") == "sql_generation_failed":
                    return {
                        "success": False,
                        "error": event.get("error", "SQLç”Ÿæˆå¤±è´¥")
                    }

            if sql_result and hasattr(sql_result, 'generated_sql'):
                return {
                    "success": True,
                    "sql": sql_result.generated_sql,
                    "confidence": sql_result.confidence_score
                }
            else:
                return {
                    "success": False,
                    "error": "Agentæœªè¿”å›æœ‰æ•ˆçš„SQLç»“æœ"
                }

        except Exception as e:
            logger.error(f"Agent SQLç”Ÿæˆå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def _build_unified_context(
        self,
        placeholder,
        data_source_id: str,
        success_criteria: Dict[str, Any],
        task_context: Optional[Dict[str, Any]] = None,
        data_source_info: Optional[Dict[str, Any]] = None,
        business_requirements: Optional[Dict[str, Any]] = None,
        semantic_type: Optional[str] = None,
        template_context: Optional[Dict[str, Any]] = None,
        template_snippet: Optional[str] = None,
        schema_context: Optional[Dict[str, Any]] = None,
        business_context: Optional[Dict[str, Any]] = None,
        template_content: Optional[str] = None,
        normalized_time_window: Optional[Dict[str, Any]] = None,
        normalized_time_range: Optional[Dict[str, Any]] = None,
        schedule: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        æ„å»ºç»Ÿä¸€çš„ contextï¼ˆåŒºåˆ†çœŸå®å€¼ vs é»˜è®¤å€¼ï¼‰

        Args:
            placeholder: å ä½ç¬¦å¯¹è±¡
            data_source_id: æ•°æ®æºID
            success_criteria: æˆåŠŸæ ‡å‡†
            task_context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
                - Noneï¼šå•å ä½ç¬¦APIåœºæ™¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
                - Dictï¼šä»»åŠ¡åœºæ™¯ï¼Œä½¿ç”¨çœŸå®å€¼

        Returns:
            ç»Ÿä¸€çš„ context å­—å…¸
        """
        # ğŸ”¹ åŸºç¡€å­—æ®µï¼ˆä¸¤ç§åœºæ™¯éƒ½æœ‰ï¼‰
        context = {
            "data_source_id": data_source_id,
            "placeholder_type": getattr(placeholder, "placeholder_type", None),
            "placeholder_name": getattr(placeholder, "placeholder_name", None),
            "content_type": getattr(placeholder, "content_type", None),
            "template_id": str(getattr(placeholder, "template_id", "") or "") or None,
        }

        # ğŸ”¹ ä» success_criteria æå–ä¿¡æ¯
        context["required_fields"] = success_criteria.get("required_fields", [])
        context["quality_threshold"] = success_criteria.get("quality_threshold", 0.6)

        # ğŸ”¹ ä» placeholder å¯¹è±¡æå–æ›´å¤šä¿¡æ¯
        context["execution_order"] = getattr(placeholder, "execution_order", 0)
        context["is_required"] = getattr(placeholder, "is_required", True)
        context["confidence_score"] = getattr(placeholder, "confidence_score", 0.0)

        # æå–è§£æå…ƒæ•°æ®
        parsing_metadata = getattr(placeholder, "parsing_metadata", None)
        if isinstance(parsing_metadata, dict):
            context["parsing_metadata"] = parsing_metadata

        # ğŸ”¹ æ•°æ®æºä¸Šä¸‹æ–‡
        if data_source_info:
            ds_id = data_source_info.get("data_source_id") or data_source_info.get("id") or data_source_id
            normalized_ds = {
                "id": str(ds_id) if ds_id else None,
                "data_source_id": str(ds_id) if ds_id else None,
                "name": data_source_info.get("name"),
                "source_type": data_source_info.get("source_type"),
                "connection_config": data_source_info.get("connection_config") or data_source_info
            }
            context["data_source"] = normalized_ds
            context["data_source_id"] = normalized_ds["data_source_id"]
            context["data_source_info"] = data_source_info
            if data_source_info.get("name"):
                context.setdefault("data_source_name", data_source_info.get("name"))

        # ğŸ”¹ ä»»åŠ¡ä¸Šä¸‹æ–‡å¤„ç†ï¼ˆåŒºåˆ†çœŸå®å€¼ vs é»˜è®¤å€¼ï¼‰
        if task_context:
            # âœ… ä»»åŠ¡åœºæ™¯ï¼šä½¿ç”¨çœŸå®çš„ä»»åŠ¡ä¿¡æ¯
            logger.info(f"ğŸ“¦ ä½¿ç”¨çœŸå®ä»»åŠ¡ä¸Šä¸‹æ–‡: task_id={task_context.get('task_id')}")

            context["task_id"] = task_context.get("task_id")
            context["task_name"] = task_context.get("task_name")
            context["report_period"] = task_context.get("report_period")
            context["user_id"] = task_context.get("user_id")

            raw_schedule = schedule if schedule is not None else task_context.get("schedule")
            if raw_schedule and not isinstance(raw_schedule, dict):
                schedule_dict = {"cron_expression": raw_schedule}
            else:
                schedule_dict = raw_schedule or {}
            context["schedule"] = schedule_dict

            raw_time_window = task_context.get("time_window") or {}
            if normalized_time_window is None or normalized_time_range is None:
                normalized_time_window, normalized_time_range = self._normalize_time_window(
                    raw_time_window,
                    schedule_dict
                )
            context["time_window"] = normalized_time_window
            context["time_range"] = normalized_time_range

            context["time_context"] = task_context.get("time_context")  # å®Œæ•´æ—¶é—´ä¸Šä¸‹æ–‡

            # æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆçœŸå®å€¼ï¼‰
            context["execution_trigger"] = task_context.get("execution_trigger", "scheduled")
            context["execution_id"] = task_context.get("execution_id")

        else:
            # âš ï¸ APIåœºæ™¯ï¼šæ„é€ é»˜è®¤å€¼
            logger.info("ğŸ“¦ ä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡ï¼ˆå•å ä½ç¬¦APIåœºæ™¯ï¼‰")

            context["template_id"] = str(placeholder.template_id) if hasattr(placeholder, "template_id") else None
            context["execution_trigger"] = "manual"  # API æ‰‹åŠ¨è§¦å‘

            # æ—¶é—´ä¿¡æ¯ï¼ˆé»˜è®¤å€¼ï¼‰
            from datetime import datetime
            from app.utils.time_context import TimeContextManager

            # æ„é€ é»˜è®¤çš„æ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆæ¯å¤© 9ç‚¹ï¼ŒæŸ¥è¯¢æ˜¨å¤©çš„æ•°æ®ï¼‰
            default_cron = "0 9 * * *"
            time_manager = TimeContextManager()
            default_time_ctx = time_manager.build_task_time_context(default_cron, datetime.now())

            schedule_dict = {
                "cron_expression": default_cron,
                "timezone": default_time_ctx.get("timezone", "Asia/Shanghai"),
            }
            context["schedule"] = schedule_dict
            default_raw_time_window = {
                "start": default_time_ctx.get("data_start_time") and f"{default_time_ctx.get('data_start_time')} 00:00:00",
                "end": default_time_ctx.get("data_end_time") and f"{default_time_ctx.get('data_end_time')} 23:59:59",
                "time_column": None,
                "timezone": default_time_ctx.get("timezone", "Asia/Shanghai"),
                "data_range": "day",
            }
            normalized_default_window, normalized_default_range = self._normalize_time_window(
                default_raw_time_window,
                schedule_dict
            )
            context["time_window"] = normalized_default_window
            context["time_range"] = normalized_default_range
            context["time_context"] = default_time_ctx
            logger.info(f"ğŸ•’ ä½¿ç”¨é»˜è®¤æ—¶é—´çª—å£: {context['time_window']}")

        # ğŸ”¹ ä¸šåŠ¡ä¸è¯­ä¹‰ä¿¡æ¯
        if business_context:
            context["business_context"] = business_context
        if business_requirements:
            context["business_requirements"] = business_requirements
            if business_requirements.get("top_n") is not None:
                context.setdefault("top_n", business_requirements.get("top_n"))
        if semantic_type:
            context["semantic_type"] = semantic_type
            context["placeholder_type"] = semantic_type

        # ğŸ”¹ æ¨¡æ¿ä¸Šä¸‹æ–‡
        if template_context:
            context["template_context"] = template_context
        if template_snippet:
            context["placeholder_context_snippet"] = template_snippet
        if template_content:
            context["template_content_preview"] = template_content[:500]

        # ğŸ”¹ Schemaä¸Šä¸‹æ–‡
        if schema_context:
            context["schema_context"] = schema_context

        # é»˜è®¤çš„è§„åˆ’æç¤ºå ä½
        context.setdefault("planning_hints", {})

        return context

    def _normalize_time_window(
        self,
        raw_time_window: Optional[Dict[str, Any]],
        schedule: Optional[Dict[str, Any]] = None,
        default_timezone: str = "Asia/Shanghai",
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """è§„èŒƒåŒ–æ—¶é—´çª—å£ä¿¡æ¯ï¼Œç”Ÿæˆç»Ÿä¸€çš„time_windowä¸time_rangeç»“æ„"""
        raw_time_window = raw_time_window or {}
        schedule = schedule or {}
        if isinstance(schedule, str):
            schedule = {"cron_expression": schedule}

        timezone = (
            raw_time_window.get("timezone")
            or schedule.get("timezone")
            or default_timezone
        )
        start_dt = raw_time_window.get("start") or raw_time_window.get("start_datetime")
        end_dt = raw_time_window.get("end") or raw_time_window.get("end_datetime")
        start_date = raw_time_window.get("start_date")
        end_date = raw_time_window.get("end_date")

        if start_dt and not start_date:
            start_date = start_dt.split(" ")[0]
        if end_dt and not end_date:
            end_date = end_dt.split(" ")[0]

        normalized_time_window = {
            "start": start_dt,
            "end": end_dt,
            "start_date": start_date,
            "end_date": end_date,
            "time_column": raw_time_window.get("time_column"),
            "timezone": timezone,
            "data_range": raw_time_window.get("data_range"),
        }

        normalized_time_range = {
            "start_date": start_date,
            "end_date": end_date,
            "time_column": raw_time_window.get("time_column"),
            "timezone": timezone,
        }

        return normalized_time_window, normalized_time_range

    def _map_business_to_semantic_type(self, business_requirements: Optional[Dict[str, Any]]) -> str:
        """å°†ä¸šåŠ¡éœ€æ±‚æ˜ å°„åˆ°Agentå·¥å…·çš„è¯­ä¹‰ç±»å‹"""
        if not business_requirements:
            return "stat"

        business_type = str(business_requirements.get("business_type", "")).lower()
        semantic_intent = str(business_requirements.get("semantic_intent", "")).lower()

        if "ranking" in business_type or "top" in semantic_intent or "æ’è¡Œ" in semantic_intent:
            return "ranking"
        if "compare" in business_type or "å¯¹æ¯”" in semantic_intent or "æ¯”è¾ƒ" in semantic_intent:
            return "compare"
        if "period" in business_type or "å‘¨æœŸ" in semantic_intent or "æ—¶é—´" in semantic_intent:
            return "period"
        if "chart" in business_type or "å›¾è¡¨" in semantic_intent:
            return "chart"
        return "stat"

    def _extract_placeholder_snippet(self, template_text: str, placeholder_text: str, placeholder_name: str) -> str:
        """ä»æ¨¡æ¿ä¸­æå–åŒ…å«å ä½ç¬¦çš„æ®µè½"""
        try:
            if not template_text:
                return ""
            lines = template_text.splitlines()
            keys = [k for k in [placeholder_text, placeholder_name, placeholder_name and f"{{{{{placeholder_name}}}}}"] if k]
            hit_idx = -1
            for i, line in enumerate(lines):
                for key in keys:
                    if key and key in line:
                        hit_idx = i
                        break
                if hit_idx >= 0:
                    break

            if hit_idx < 0:
                preview = template_text[:500]
                return preview + ("â€¦" if len(template_text) > 500 else "")

            start = hit_idx
            while start > 0 and lines[start].strip() != "" and lines[start - 1].strip() != "":
                start -= 1
            end = hit_idx
            while end + 1 < len(lines) and lines[end].strip() != "" and lines[end + 1].strip() != "":
                end += 1
            snippet_lines = lines[start:end + 1]
            if start > 0:
                snippet_lines.insert(0, lines[start - 1])
            if end + 1 < len(lines):
                snippet_lines.append(lines[end + 1])
            return "\n".join(snippet_lines).strip()
        except Exception:
            preview = template_text[:500]
            return preview + ("â€¦" if len(template_text) > 500 else "")

    def _load_template_content(self, template_id: str) -> str:
        """åŠ è½½æ¨¡æ¿å†…å®¹"""
        try:
            from app.db.session import get_db_session
            from app import crud

            with get_db_session() as db_session:
                template_obj = crud.template.get(db_session, id=template_id)
                if template_obj and getattr(template_obj, "content", None):
                    return template_obj.content
        except Exception as e:
            logger.warning(f"åŠ è½½æ¨¡æ¿å†…å®¹å¤±è´¥: {e}")
        return ""

    async def _get_schema_context(self, user_id: Optional[str], data_source_id: str) -> Dict[str, Any]:
        """è·å–æ•°æ®æºSchemaä¿¡æ¯ï¼Œç”¨äºæŒ‡å¯¼Agentç”ŸæˆSQL"""
        if not data_source_id:
            return {"available_tables": [], "table_count": 0}

        try:
            builder = DataSourceContextBuilder(container=self.container)
            context_result = await builder.build_data_source_context(
                user_id=user_id or "system",
                data_source_id=data_source_id,
                required_tables=None,
                force_refresh=False,
                names_only=True
            )
            if context_result and context_result.get("success"):
                tables_payload = context_result.get("tables", [])
                tables: List[str] = []
                for table_info in tables_payload:
                    if isinstance(table_info, dict):
                        name = table_info.get("table_name")
                        if name:
                            tables.append(name)
                return {
                    "available_tables": tables,
                    "table_count": len(tables)
                }
        except Exception as e:
            logger.warning(f"è·å–Schemaä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        return {"available_tables": [], "table_count": 0}

    async def _get_data_source_info(self, data_source_id: str) -> Dict[str, Any]:
        """è·å–æ•°æ®æºä¿¡æ¯"""
        try:
            if not data_source_id:
                return {}

            normalized_id = str(data_source_id)

            # ä¼˜å…ˆä½¿ç”¨å®¹å™¨æä¾›çš„ç”¨æˆ·æ•°æ®æºæœåŠ¡ï¼ˆæ”¯æŒå¯†ç è§£å¯†ï¼‰
            user_id = self.user_id or ""
            user_ds_service = getattr(self.container, "user_data_source_service", None)
            if user_ds_service and user_id:
                try:
                    ds_obj = await user_ds_service.get_user_data_source(user_id, normalized_id)
                    if ds_obj and hasattr(ds_obj, "connection_config"):
                        cfg = dict(ds_obj.connection_config or {})
                        # è¡¥å…¨åŸºç¡€å­—æ®µ
                        source_type = getattr(ds_obj, "source_type", cfg.get("source_type"))
                        if hasattr(source_type, "value"):
                            source_type = source_type.value
                        if isinstance(source_type, str):
                            cfg.setdefault("source_type", source_type.split(".")[-1])
                        cfg.setdefault("name", getattr(ds_obj, "name", ""))
                        cfg.setdefault("id", normalized_id)
                        cfg.setdefault("data_source_id", normalized_id)
                        # å…¼å®¹å¸¸ç”¨å­—æ®µ
                        cfg.setdefault("database_name", cfg.get("database") or cfg.get("schema"))
                        return cfg
                except Exception as svc_error:
                    logger.warning(f"ä½¿ç”¨ç”¨æˆ·æ•°æ®æºæœåŠ¡è·å–é…ç½®å¤±è´¥: {svc_error}")

            # å›é€€ï¼šç›´æ¥è¯»å–æ•°æ®æºè®°å½•
            from app.crud import data_source as crud_data_source
            from app.db.session import get_db_session
            from app.models.data_source import DataSourceType
            from app.core.security_utils import decrypt_data
            from app.core.data_source_utils import DataSourcePasswordManager

            with get_db_session() as db:
                data_source = crud_data_source.get(db, id=normalized_id)
                if not data_source:
                    return {}

                info: Dict[str, Any] = {
                    "id": normalized_id,
                    "data_source_id": normalized_id,
                    "name": data_source.name,
                }

                if data_source.source_type == DataSourceType.doris:
                    info.update({
                        "source_type": "doris",
                        "database": getattr(data_source, "doris_database", "default"),
                        "database_name": getattr(data_source, "doris_database", "default"),
                        "fe_hosts": list(getattr(data_source, "doris_fe_hosts", []) or ["localhost"]),
                        "be_hosts": list(getattr(data_source, "doris_be_hosts", []) or ["localhost"]),
                        "http_port": getattr(data_source, "doris_http_port", 8030),
                        "query_port": getattr(data_source, "doris_query_port", 9030),
                        "username": getattr(data_source, "doris_username", "root"),
                        "password": DataSourcePasswordManager.get_password(data_source.doris_password) if getattr(data_source, "doris_password", None) else "",
                        "timeout": 30
                    })
                elif data_source.source_type == DataSourceType.sql:
                    conn_str = data_source.connection_string
                    try:
                        if conn_str:
                            conn_str = decrypt_data(conn_str)
                    except Exception:
                        pass
                    info.update({
                        "source_type": "sql",
                        "connection_string": conn_str,
                        "database": getattr(data_source, "database_name", None),
                        "database_name": getattr(data_source, "database_name", None),
                        "host": getattr(data_source, "host", None),
                        "port": getattr(data_source, "port", None),
                        "username": getattr(data_source, "username", None),
                        "password": getattr(data_source, "password", None),
                    })
                else:
                    source_type = data_source.source_type.value if hasattr(data_source.source_type, "value") else str(data_source.source_type)
                    info.setdefault("source_type", source_type)

                return info

        except Exception as e:
            logger.error(f"è·å–æ•°æ®æºä¿¡æ¯å¤±è´¥: {e}")
            return {}


# å…¨å±€æœåŠ¡å®ä¾‹ç®¡ç†
_global_service = None


async def get_placeholder_service() -> PlaceholderApplicationService:
    """è·å–å…¨å±€å ä½ç¬¦åº”ç”¨æœåŠ¡å®ä¾‹"""
    global _global_service
    if _global_service is None:
        _global_service = PlaceholderApplicationService()
        await _global_service.initialize()
    return _global_service


async def shutdown_placeholder_service():
    """å…³é—­å…¨å±€å ä½ç¬¦åº”ç”¨æœåŠ¡"""
    global _global_service
    if _global_service:
        await _global_service.shutdown()
        _global_service = None


# å…¼å®¹æ€§å‡½æ•° - ä¿æŒå‘åå…¼å®¹
async def analyze_placeholder_simple(
    placeholder_id: str,
    business_command: str,
    requirements: str,
    context: Optional[Dict[str, Any]] = None,
    target_objective: str = "",
    data_source_info: Optional[Dict[str, Any]] = None,
    existing_sql: Optional[str] = None
) -> SQLGenerationResult:
    """
    ç®€åŒ–çš„å ä½ç¬¦åˆ†ææ¥å£ - ä½¿ç”¨ä»»åŠ¡éªŒè¯æ™ºèƒ½æ¨¡å¼

    Args:
        placeholder_id: å ä½ç¬¦ID
        business_command: ä¸šåŠ¡å‘½ä»¤
        requirements: éœ€æ±‚æè¿°
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        target_objective: ç›®æ ‡è¦æ±‚
        data_source_info: æ•°æ®æºä¿¡æ¯
        existing_sql: ç°æœ‰SQLï¼ˆå¦‚æœå­˜åœ¨ï¼‰

    Returns:
        SQLç”Ÿæˆç»“æœ
    """

    service = await get_placeholder_service()

    # å¦‚æœæä¾›äº†existing_sqlï¼ŒåŠ å…¥åˆ°contextä¸­
    if existing_sql:
        context = context or {}
        context["current_sql"] = existing_sql

    request = PlaceholderAnalysisRequest(
        placeholder_id=placeholder_id,
        business_command=business_command,
        requirements=requirements,
        context=context or {},
        target_objective=target_objective,
        data_source_info=data_source_info
    )

    result = None
    async for response in service.analyze_placeholder(request):
        if response["type"] == "sql_generation_complete":
            result = response["content"]
            break
        elif response["type"] == "sql_generation_failed":
            # è¿”å›å¤±è´¥çš„ç»“æœ
            result = response["content"]
            break

    return result


async def update_placeholder_simple(
    placeholder_id: str,
    task_context: Dict[str, Any],
    current_task_info: Dict[str, Any],
    target_objective: str,
    stored_placeholders: List[PlaceholderInfo]
) -> PlaceholderUpdateResult:
    """ç®€åŒ–çš„å ä½ç¬¦æ›´æ–°æ¥å£ - å…¼å®¹æ€§å‡½æ•°"""
    
    service = await get_placeholder_service()
    
    request = PlaceholderUpdateRequest(
        placeholder_id=placeholder_id,
        task_context=task_context,
        current_task_info=current_task_info,
        target_objective=target_objective,
        stored_placeholders=stored_placeholders
    )
    
    result = None
    async for response in service.update_placeholder(request):
        if response["type"] == "update_analysis_complete":
            result = response["content"]
            break
    
    return result


async def complete_placeholder_simple(
    placeholder_id: str,
    etl_data: List[Dict[str, Any]],
    placeholder_requirements: str,
    template_section: str,
    chart_generation_needed: bool = False,
    target_chart_type: Optional[ChartType] = None
) -> Dict[str, Any]:
    """ç®€åŒ–çš„å ä½ç¬¦å®Œæˆæ¥å£ - å…¼å®¹æ€§å‡½æ•°"""
    
    service = await get_placeholder_service()
    
    request = PlaceholderCompletionRequest(
        placeholder_id=placeholder_id,
        etl_data=etl_data,
        placeholder_requirements=placeholder_requirements,
        template_section=template_section,
        chart_generation_needed=chart_generation_needed,
        target_chart_type=target_chart_type
    )
    
    result = None
    async for response in service.complete_placeholder(request):
        if response["type"] == "completion_complete":
            result = response["content"]
            break
    
    return result


# å…¼å®¹æ€§åˆ«å
analyze_placeholder = analyze_placeholder_simple
update_placeholder = update_placeholder_simple  
complete_placeholder = complete_placeholder_simple
