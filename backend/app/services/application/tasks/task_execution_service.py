"""
ä»»åŠ¡æ‰§è¡ŒæœåŠ¡ - å®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆæµæ°´çº¿

é›†æˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œæµç¨‹ï¼š
1. å ä½ç¬¦éªŒè¯å’Œä¿®å¤
2. ETLæ•°æ®å¤„ç†
3. å›¾è¡¨ç”Ÿæˆ
4. Wordæ–‡æ¡£å¯¼å‡º
5. æ–‡ä»¶å­˜å‚¨å’Œé‚®ä»¶å‘é€
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    VALIDATING = "validating"
    PROCESSING = "processing"
    GENERATING = "generating"
    EXPORTING = "exporting"
    DELIVERING = "delivering"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class TaskExecutionRequest:
    """ä»»åŠ¡æ‰§è¡Œè¯·æ±‚"""
    task_id: str
    template_id: str
    data_source_ids: List[str]
    user_id: str
    execution_context: Dict[str, Any]
    time_context: Optional[Dict[str, Any]] = None
    output_format: str = "docx"
    delivery_config: Optional[Dict[str, Any]] = None
    
    
@dataclass
class TaskExecutionResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    task_id: str
    status: TaskStatus
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    execution_time_seconds: float = 0.0
    artifacts: Optional[Dict[str, str]] = None  # ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„


class TaskExecutionService:
    """
    ä»»åŠ¡æ‰§è¡ŒæœåŠ¡
    
    æä¾›å®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆä»»åŠ¡æ‰§è¡Œæµæ°´çº¿ï¼Œé›†æˆï¼š
    - å ä½ç¬¦éªŒè¯å’Œä¿®å¤æœåŠ¡
    - ETLæ•°æ®å¤„ç†æœåŠ¡
    - å›¾è¡¨ç”ŸæˆæœåŠ¡
    - æ–‡æ¡£å¯¼å‡ºæœåŠ¡
    - æ–‡ä»¶å­˜å‚¨å’Œé‚®ä»¶æœåŠ¡
    """
    
    def __init__(self, user_id: str = None):
        # user_id made optional for compatibility with new architecture
        self.user_id = user_id
        self.active_tasks: Dict[str, Dict[str, Any]] = {}
        # Import TimeContextManager here to avoid circular imports
        from app.utils.time_context import TimeContextManager
        from app.utils.sql_placeholder_utils import SqlPlaceholderReplacer
        self.time_context_manager = TimeContextManager()
        self.sql_replacer = SqlPlaceholderReplacer()
        
    async def execute_task(self, request: TaskExecutionRequest) -> TaskExecutionResult:
        """
        æ‰§è¡Œå®Œæ•´ä»»åŠ¡æµç¨‹
        
        Args:
            request: ä»»åŠ¡æ‰§è¡Œè¯·æ±‚
            
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        start_time = datetime.now()
        task_id = request.task_id
        
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        self.active_tasks[task_id] = {
            "status": TaskStatus.PENDING,
            "start_time": start_time,
            "current_step": "åˆå§‹åŒ–",
            "progress": 0.0
        }
        
        # æ–°ç‰ˆï¼šç›´æ¥å§”æ‰˜ç»™ Agents æµæ°´çº¿ï¼Œä¿æŒæ¥å£ä¸å˜
        return await self._execute_with_agents(request, start_time)

        
        try:
            # Step 1: å ä½ç¬¦éªŒè¯å’Œä¿®å¤
            await self._update_task_status(task_id, TaskStatus.VALIDATING, "éªŒè¯å’Œä¿®å¤å ä½ç¬¦", 10.0)
            placeholder_results = await self._validate_and_repair_placeholders(request)
            
            if not placeholder_results["success"]:
                return self._create_error_result(request, "å ä½ç¬¦éªŒè¯å¤±è´¥", placeholder_results["error"])
            
            # Step 2: ETLæ•°æ®å¤„ç†
            await self._update_task_status(task_id, TaskStatus.PROCESSING, "ETLæ•°æ®å¤„ç†", 30.0)
            etl_results = await self._execute_etl_pipeline(request, placeholder_results["data"])
            
            if not etl_results["success"]:
                return self._create_error_result(request, "ETLå¤„ç†å¤±è´¥", etl_results["error"])
            
            # Step 3: å›¾è¡¨ç”Ÿæˆ
            await self._update_task_status(task_id, TaskStatus.GENERATING, "ç”Ÿæˆå›¾è¡¨", 50.0)
            chart_results = await self._generate_charts(request, etl_results["data"])
            
            if not chart_results["success"]:
                return self._create_error_result(request, "å›¾è¡¨ç”Ÿæˆå¤±è´¥", chart_results["error"])
            
            # Step 4: æ–‡æ¡£å¯¼å‡º
            await self._update_task_status(task_id, TaskStatus.EXPORTING, "å¯¼å‡ºæ–‡æ¡£", 70.0)
            export_results = await self._export_document(request, {
                "placeholder_data": placeholder_results["data"],
                "etl_data": etl_results["data"],
                "chart_data": chart_results["data"]
            })
            
            if not export_results["success"]:
                return self._create_error_result(request, "æ–‡æ¡£å¯¼å‡ºå¤±è´¥", export_results["error"])
            
            # Step 5: æ–‡ä»¶å­˜å‚¨å’Œé‚®ä»¶å‘é€
            await self._update_task_status(task_id, TaskStatus.DELIVERING, "å­˜å‚¨å’Œå‘é€", 90.0)
            delivery_results = await self._deliver_report(request, export_results["data"])
            
            if not delivery_results["success"]:
                return self._create_error_result(request, "æŠ¥å‘ŠæŠ•é€’å¤±è´¥", delivery_results["error"])
            
            # å®Œæˆä»»åŠ¡
            await self._update_task_status(task_id, TaskStatus.COMPLETED, "ä»»åŠ¡å®Œæˆ", 100.0)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # æ¸…ç†ä»»åŠ¡çŠ¶æ€
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]
            
            logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}, è€—æ—¶: {execution_time:.2f}ç§’")
            
            return TaskExecutionResult(
                task_id=task_id,
                status=TaskStatus.COMPLETED,
                success=True,
                message="ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ",
                data={
                    "placeholder_results": placeholder_results["data"],
                    "etl_results": etl_results["data"],
                    "chart_results": chart_results["data"],
                    "export_results": export_results["data"],
                    "delivery_results": delivery_results["data"]
                },
                execution_time_seconds=execution_time,
                artifacts=export_results["data"].get("artifacts", {})
            )
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {task_id}, é”™è¯¯: {e}")
            return self._create_error_result(request, "ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸", str(e))

    async def execute_with_persistence(self, request: TaskExecutionRequest) -> TaskExecutionResult:
        """
        æ‰§è¡Œä»»åŠ¡ï¼ˆåŒ…å«å®Œæ•´çš„ETLæ•°æ®æŒä¹…åŒ–ï¼‰

        æ ¸å¿ƒæµç¨‹ï¼š
        1. å‡†å¤‡å ä½ç¬¦
        2. æ‰§è¡ŒETL
        3. æŒä¹…åŒ–ETLæ•°æ® â† æ–°å¢
        4. ç”ŸæˆæŠ¥å‘Š
        5. ç»Ÿä¸€commit â† å…³é”®

        Args:
            request: ä»»åŠ¡æ‰§è¡Œè¯·æ±‚

        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        from app.db.session import get_db_session
        from app.services.data.persistence.etl_persistence_service import ETLPersistenceService

        start_time = datetime.now()
        task_id = request.task_id

        # ç”Ÿæˆæ‰¹æ¬¡ID
        batch_id = ETLPersistenceService.generate_batch_id()

        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰: {task_id}, batch_id={batch_id}")

        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        self.active_tasks[task_id] = {
            "status": TaskStatus.PENDING,
            "start_time": start_time,
            "current_step": "åˆå§‹åŒ–",
            "progress": 0.0,
            "batch_id": batch_id
        }

        with get_db_session() as db:
            try:
                # Step 1: å‡†å¤‡å ä½ç¬¦æ•°æ®
                await self._update_task_status(task_id, TaskStatus.VALIDATING, "å‡†å¤‡å ä½ç¬¦æ•°æ®", 10.0)
                placeholder_data = await self._prepare_placeholder_data(request)
                logger.info(f"âœ… å ä½ç¬¦å‡†å¤‡å®Œæˆ: {len(placeholder_data.get('placeholder_sql_map', {}))} ä¸ª")

                # Step 2: æ‰§è¡ŒETLæ•°æ®æå–
                await self._update_task_status(task_id, TaskStatus.PROCESSING, "ETLæ•°æ®æå–", 30.0)
                etl_result = await self._execute_etl_pipeline(request, placeholder_data)

                if not etl_result.get("success"):
                    raise Exception(f"ETLæ‰§è¡Œå¤±è´¥: {etl_result.get('error')}")

                etl_data = etl_result.get("data", {})
                logger.info(f"âœ… ETLæ‰§è¡Œå®Œæˆ")

                # ğŸ”‘ Step 3: æŒä¹…åŒ–ETLç»“æœï¼ˆæ–°å¢ï¼‰
                await self._update_task_status(task_id, TaskStatus.PROCESSING, "æŒä¹…åŒ–ETLæ•°æ®", 50.0)
                persistence_service = ETLPersistenceService(db)
                persistence_result = await persistence_service.persist_etl_results(
                    template_id=request.template_id,
                    etl_results=etl_data,
                    batch_id=batch_id,
                    time_context=request.time_context or {}
                )

                logger.info(f"âœ… {persistence_result['message']}")

                # Step 4: ç”ŸæˆæŠ¥å‘Š
                await self._update_task_status(task_id, TaskStatus.GENERATING, "ç”ŸæˆæŠ¥å‘Š", 70.0)
                report_result = await self._generate_report(request, etl_data)

                if not report_result.get("success"):
                    raise Exception(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report_result.get('error')}")

                logger.info(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

                # ğŸ”‘ Step 5: ç»Ÿä¸€æäº¤äº‹åŠ¡
                db.commit()
                await self._update_task_status(task_id, TaskStatus.COMPLETED, "ä»»åŠ¡å®Œæˆ", 100.0)
                logger.info(f"âœ… äº‹åŠ¡æäº¤æˆåŠŸ: batch_id={batch_id}")

                execution_time = (datetime.now() - start_time).total_seconds()

                # æ¸…ç†ä»»åŠ¡çŠ¶æ€
                if task_id in self.active_tasks:
                    del self.active_tasks[task_id]

                logger.info(f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}, è€—æ—¶: {execution_time:.2f}ç§’")

                return TaskExecutionResult(
                    task_id=task_id,
                    status=TaskStatus.COMPLETED,
                    success=True,
                    message="ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ",
                    data={
                        "batch_id": batch_id,
                        "etl_saved_count": persistence_result["saved_count"],
                        "etl_failed_count": persistence_result["failed_count"],
                        "report_result": report_result,
                    },
                    execution_time_seconds=execution_time,
                    artifacts=report_result.get("artifacts", {})
                )

            except Exception as e:
                # ğŸ”‘ ç»Ÿä¸€å›æ»š
                db.rollback()
                await self._update_task_status(task_id, TaskStatus.FAILED, f"ä»»åŠ¡å¤±è´¥: {str(e)}", 0.0)
                logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå·²å›æ»š: {task_id}, {e}")
                logger.exception(e)

                # æ¸…ç†ä»»åŠ¡çŠ¶æ€
                if task_id in self.active_tasks:
                    del self.active_tasks[task_id]

                execution_time = (datetime.now() - start_time).total_seconds()

                return TaskExecutionResult(
                    task_id=task_id,
                    status=TaskStatus.FAILED,
                    success=False,
                    message="ä»»åŠ¡æ‰§è¡Œå¤±è´¥",
                    error=str(e),
                    execution_time_seconds=execution_time,
                    data={"batch_id": batch_id}
                )

    async def execute_task_complete(self, request: TaskExecutionRequest) -> TaskExecutionResult:
        """
        å®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œï¼ˆä¸ä½¿ç”¨Agentæµæ°´çº¿ï¼Œä¿ç•™å®Œæ•´æµç¨‹ï¼‰

        ä¸execute_taskçš„åŒºåˆ«ï¼š
        - execute_task: ä½¿ç”¨æ–°çš„Agentæµæ°´çº¿ï¼ˆ_execute_with_agentsï¼‰
        - execute_task_complete: ä¿ç•™å®Œæ•´çš„æ—§æµç¨‹
        - execute_with_persistence: æ–°æµç¨‹ + ETLæŒä¹…åŒ–
        """
        start_time = datetime.now()
        task_id = request.task_id

        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆå®Œæ•´æµç¨‹ï¼‰: {task_id}")

        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        self.active_tasks[task_id] = {
            "status": TaskStatus.PENDING,
            "start_time": start_time,
            "current_step": "åˆå§‹åŒ–",
            "progress": 0.0
        }


    async def _execute_with_agents(self, request: TaskExecutionRequest, start_time: datetime) -> TaskExecutionResult:
        """ä½¿ç”¨ PlaceholderProcessingSystem çš„ ReAct æµæ°´çº¿æ‰§è¡Œä»»åŠ¡ï¼ˆæ–°æ¶æ„ï¼‰"""
        task_id = request.task_id
        try:
            # æ—¶é—´çª—å£ - ä½¿ç”¨ç®€åŒ–çš„æ—¶é—´ä¸Šä¸‹æ–‡
            if request.time_context and request.time_context.get("data_start_time") and request.time_context.get("data_end_time"):
                # ä½¿ç”¨è¯·æ±‚ä¸­çš„æ—¶é—´ä¸Šä¸‹æ–‡
                period_start_date = request.time_context.get("data_start_time")
                period_end_date = request.time_context.get("data_end_time")
            else:
                # ç”Ÿæˆæ–°çš„æ—¶é—´ä¸Šä¸‹æ–‡
                schedule = request.execution_context.get("schedule") if request.execution_context else None
                if schedule:
                    time_ctx = self.time_context_manager.build_task_time_context(cron_expression=schedule)
                    period_start_date = time_ctx.get("data_start_time")
                    period_end_date = time_ctx.get("data_end_time")
                else:
                    # é»˜è®¤ä½¿ç”¨æ˜¨å¤©
                    yesterday = datetime.now() - timedelta(days=1)
                    period_start_date = yesterday.strftime('%Y-%m-%d')
                    period_end_date = yesterday.strftime('%Y-%m-%d')

            time_window = {"start": f"{period_start_date} 00:00:00", "end": f"{period_end_date} 23:59:59"}

            # æ›´æ–°çŠ¶æ€
            await self._update_task_status(task_id, TaskStatus.PROCESSING, "Agentsæµæ°´çº¿æ‰§è¡Œ", 50.0)

            from app.services.application.placeholder import PlaceholderApplicationService as PlaceholderProcessingSystem
            system = PlaceholderProcessingSystem(user_id=request.user_id)
            await system.initialize()

            success_criteria = {
                "min_rows": 1,
                "max_rows": 100000,
                "required_fields": request.execution_context.get("required_fields", []) if request.execution_context else [],
                "quality_threshold": request.execution_context.get("quality_threshold", 0.6) if request.execution_context else 0.6,
            }
            objective = request.execution_context.get("objective") if request.execution_context else f"ä»»åŠ¡[{task_id}]æ•°æ®å‡†å¤‡ä¸åˆ†æ"

            events: List[Dict[str, Any]] = []
            async for ev in system.run_task_with_agent(
                task_objective=objective,
                success_criteria=success_criteria,
                data_source_id=(request.data_source_ids[0] if request.data_source_ids else None),
                time_window=time_window,
                time_column=request.execution_context.get("time_column") if request.execution_context else None,
                max_attempts=request.execution_context.get("max_attempts", 3) if request.execution_context else 3,
            ):
                events.append(ev)

            final = next((e for e in reversed(events) if e.get("type") == "agent_session_complete"), None)
            success = bool(final and final.get("success"))

            await self._update_task_status(task_id, TaskStatus.COMPLETED if success else TaskStatus.FAILED, "å®Œæˆ", 100.0)
            duration = (datetime.now() - start_time).total_seconds()

            # æ¸…ç†ä»»åŠ¡çŠ¶æ€
            if task_id in self.active_tasks:
                del self.active_tasks[task_id]

            return TaskExecutionResult(
                task_id=task_id,
                status=TaskStatus.COMPLETED if success else TaskStatus.FAILED,
                success=success,
                message="ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ" if success else "ä»»åŠ¡æ‰§è¡Œå¤±è´¥",
                data={"events": events, "final": final, "time_window": time_window},
                execution_time_seconds=duration,
            )
        except Exception as e:
            logger.error(f"Agentsæµæ°´çº¿æ‰§è¡Œå¼‚å¸¸: {e}")
            duration = (datetime.now() - start_time).total_seconds()
            return TaskExecutionResult(
                task_id=task_id,
                status=TaskStatus.FAILED,
                success=False,
                message="ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸",
                error=str(e),
                execution_time_seconds=duration,
            )
    
    async def _validate_and_repair_placeholders(
        self, 
        request: TaskExecutionRequest
    ) -> Dict[str, Any]:
        """éªŒè¯å’Œä¿®å¤å ä½ç¬¦"""
        # æ—§æµç¨‹å·²è¿ç§»ï¼Œç”± Agents æµæ°´çº¿åœ¨æ‰§è¡Œé˜¶æ®µå¤„ç†
        return {"success": True, "data": {}, "message": "migrated_to_agents"}
    
    async def _execute_etl_pipeline(
        self,
        request: TaskExecutionRequest,
        placeholder_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒETLæ•°æ®å¤„ç†"""
        try:
            from app.services.data.processing.etl.etl_service import ETLService

            etl_service = ETLService(user_id=self.user_id)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡æ¿åŒ–SQLæ˜ å°„
            placeholder_sql_map = placeholder_data.get("placeholder_sql_map")

            if placeholder_sql_map:
                # ä½¿ç”¨æ¨¡æ¿åŒ–æ–¹æ³•è¿›è¡Œæ•°æ®æå–
                logger.info("ä½¿ç”¨æ¨¡æ¿åŒ–SQLæ‰§è¡ŒETLæµæ°´çº¿")

                etl_results = {}
                for data_source_id in request.data_source_ids:
                    # ç¡®å®šæ‰§è¡Œæ¨¡å¼
                    execution_mode = request.execution_context.get("execution_mode", "production")
                    if request.execution_context.get("mode") == "validation_only":
                        execution_mode = "test"

                    # æ„å»ºæ—¶é—´ä¸Šä¸‹æ–‡
                    time_context = {
                        "cron_expression": request.execution_context.get("cron_expression", "0 8 * * *"),
                        "execution_time": request.time_context.get("execution_time"),
                        "test_date": request.time_context.get("test_date"),
                        "additional_params": request.execution_context.get("additional_params", {})
                    }

                    # ä½¿ç”¨æ¨¡æ¿åŒ–æå–
                    extract_result = await etl_service.extract_data_with_templates(
                        data_source_id=data_source_id,
                        placeholder_sql_map=placeholder_sql_map,
                        time_context=time_context,
                        execution_mode=execution_mode
                    )

                    if extract_result.get("success"):
                        # æ•°æ®è½¬æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        transform_config = request.execution_context.get("transform_config", {})
                        if transform_config:
                            # ä¸ºæ¯ä¸ªæˆåŠŸæå–çš„å ä½ç¬¦åº”ç”¨è½¬æ¢
                            transformed_extractions = []
                            for extraction in extract_result["data"]["successful_extractions"]:
                                transform_result = await etl_service.transform_data(
                                    raw_data=extraction["data"],
                                    transformation_config=transform_config
                                )
                                extraction["transform_result"] = transform_result
                                transformed_extractions.append(extraction)
                            extract_result["data"]["successful_extractions"] = transformed_extractions

                        etl_results[data_source_id] = {
                            "extract": extract_result,
                            "method": "template_based"
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"æ¨¡æ¿åŒ–æ•°æ®æå–å¤±è´¥: {extract_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                            "data": None
                        }

                return {
                    "success": True,
                    "data": etl_results,
                    "method": "template_based",
                    "message": f"æˆåŠŸå¤„ç† {len(etl_results)} ä¸ªæ•°æ®æºçš„æ¨¡æ¿åŒ–æ•°æ®"
                }
            else:
                # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                logger.info("ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æ‰§è¡ŒETLæµæ°´çº¿")

                etl_results = {}
                for data_source_id in request.data_source_ids:
                    # æ„å»ºæŸ¥è¯¢é…ç½®
                    query_config = {
                        "template_id": request.template_id,
                        "placeholder_data": placeholder_data,
                        "time_context": request.time_context,
                        "execution_context": request.execution_context
                    }

                    # æ‰§è¡Œæ•°æ®æå–
                    extract_result = await etl_service.extract_data(
                        data_source_id=data_source_id,
                        query_config=query_config
                    )

                    if extract_result.get("success"):
                        # æ•°æ®è½¬æ¢
                        transform_result = await etl_service.transform_data(
                            raw_data=extract_result["data"],
                            transformation_config=request.execution_context.get("transform_config", {})
                        )

                        etl_results[data_source_id] = {
                            "extract": extract_result,
                            "transform": transform_result,
                            "method": "traditional"
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"æ•°æ®æå–å¤±è´¥: {extract_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                            "data": None
                        }

                return {
                    "success": True,
                    "data": etl_results,
                    "method": "traditional",
                    "message": f"æˆåŠŸå¤„ç† {len(etl_results)} ä¸ªæ•°æ®æºçš„æ•°æ®"
                }

        except Exception as e:
            logger.error(f"ETLå¤„ç†å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": None
            }
    
    async def _generate_charts(
        self, 
        request: TaskExecutionRequest,
        etl_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨TTé€’å½’ç”Ÿæˆå›¾è¡¨ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰"""
        try:
            from app.services.infrastructure.agents import execute_chart_generation_tt
            
            # 1. åˆ†ææ¨¡æ¿ä¸­çš„å›¾è¡¨å ä½ç¬¦
            chart_placeholders = await self._analyze_chart_placeholders(request.template_id)
            
            if not chart_placeholders:
                return {
                    "success": True,
                    "data": {"charts_generated": 0, "message": "æœªæ‰¾åˆ°å›¾è¡¨å ä½ç¬¦"},
                    "message": "æœªæ‰¾åˆ°å›¾è¡¨å ä½ç¬¦ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ"
                }
            
            # 2. ä½¿ç”¨TTé€’å½’ä¸ºæ•°æ®ç”Ÿæˆå›¾è¡¨
            chart_results = []
            for placeholder in chart_placeholders:
                try:
                    chart_result = await execute_chart_generation_tt(
                        chart_placeholder=placeholder.get('description', ''),
                        etl_data=etl_data,
                        user_id=self.user_id,
                        context={
                            "template_id": request.template_id,
                            "placeholder_id": placeholder.get('id'),
                            "chart_type": placeholder.get('chart_type', 'auto'),
                            "etl_data_summary": self._summarize_etl_data(etl_data)
                        }
                    )
                    
                    chart_results.append({
                        "success": True,
                        "placeholder_id": placeholder.get('id'),
                        "chart_content": chart_result,
                        "generation_method": "tt_recursion"
                    })
                    
                except Exception as e:
                    logger.error(f"TTé€’å½’å›¾è¡¨ç”Ÿæˆå¤±è´¥ - å ä½ç¬¦: {placeholder.get('id')}, é”™è¯¯: {e}")
                    chart_results.append({
                        "success": False,
                        "placeholder_id": placeholder.get('id'),
                        "error": str(e),
                        "generation_method": "tt_recursion"
                    })
            
            # 3. æ•´ç†ç»“æœ
            successful_charts = [r for r in chart_results if r.success]
            failed_charts = [r for r in chart_results if not r.success]
            
            chart_data = {
                "charts_generated": len(successful_charts),
                "failed_charts": len(failed_charts),
                "chart_results": chart_results,
                "chart_placeholders": chart_placeholders,
                "generation_method": "tt_recursion"
            }
            
            return {
                "success": True,
                "data": chart_data,
                "message": f"TTé€’å½’å›¾è¡¨ç”Ÿæˆå®Œæˆ: æˆåŠŸ{len(successful_charts)}ä¸ª, å¤±è´¥{len(failed_charts)}ä¸ª"
            }
            
        except Exception as e:
            logger.error(f"TTé€’å½’å›¾è¡¨ç”Ÿæˆå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": None
            }
    
    async def _analyze_chart_placeholders(self, template_id: str) -> List[Dict[str, Any]]:
        """åˆ†ææ¨¡æ¿ä¸­çš„å›¾è¡¨å ä½ç¬¦"""
        try:
            with get_db_session() as db:
                from app.models.template import Template
                from uuid import UUID
                
                template = db.query(Template).filter(Template.id == UUID(template_id)).first()
                if not template:
                    return []
                
                # ç®€å•çš„å›¾è¡¨å ä½ç¬¦åˆ†æï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
                import re
                chart_patterns = [
                    r'\{chart:([^}]+)\}',
                    r'\{å›¾è¡¨:([^}]+)\}',
                    r'\{chart_([^}]+)\}'
                ]
                
                placeholders = []
                for pattern in chart_patterns:
                    matches = re.findall(pattern, template.content or '')
                    for match in matches:
                        placeholders.append({
                            "id": f"chart_{len(placeholders)}",
                            "description": match,
                            "chart_type": "auto"
                        })
                
                return placeholders
                
        except Exception as e:
            logger.error(f"åˆ†æå›¾è¡¨å ä½ç¬¦å¤±è´¥: {e}")
            return []
    
    def _summarize_etl_data(self, etl_data: Dict[str, Any]) -> str:
        """æ€»ç»“ETLæ•°æ®"""
        try:
            if not etl_data or not etl_data.get('data'):
                return "æ— æ•°æ®"
            
            data = etl_data['data']
            if isinstance(data, list):
                return f"æ•°æ®è¡Œæ•°: {len(data)}, åˆ—æ•°: {len(data[0]) if data else 0}"
            elif isinstance(data, dict):
                return f"æ•°æ®å­—æ®µ: {list(data.keys())}"
            else:
                return f"æ•°æ®ç±»å‹: {type(data)}"
                
        except Exception as e:
            return f"æ•°æ®æ€»ç»“å¤±è´¥: {e}"
    
    async def _export_document(
        self, 
        request: TaskExecutionRequest,
        processed_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å¯¼å‡ºæ–‡æ¡£"""
        try:
            from app.services.infrastructure.document.word_export_service import (
                create_word_export_service, DocumentConfig, DocumentFormat
            )
            
            word_service = create_word_export_service(self.user_id)
            
            # åˆ›å»ºæ–‡æ¡£é…ç½®
            output_format = DocumentFormat.DOCX
            if request.output_format.lower() == "pdf":
                output_format = DocumentFormat.PDF
            elif request.output_format.lower() == "html":
                output_format = DocumentFormat.HTML
                
            doc_config = DocumentConfig(
                template_id=request.template_id,
                output_format=output_format,
                font_name="å®‹ä½“",
                font_size=12,
                line_spacing=1.5
            )
            
            # å¯¼å‡ºæ–‡æ¡£
            export_result = await word_service.export_report_document(
                template_id=request.template_id,
                placeholder_data=processed_data.get("placeholder_data", {}),
                etl_data=processed_data.get("etl_data", {}),
                chart_data=processed_data.get("chart_data", {}),
                config=doc_config
            )
            
            if export_result.success:
                export_data = {
                    "document_path": export_result.document_path,
                    "format": request.output_format,
                    "size_bytes": export_result.file_size_bytes,
                    "page_count": export_result.page_count,
                    "export_time_seconds": export_result.export_time_seconds,
                    "artifacts": {
                        "main_document": export_result.document_path,
                        "charts": processed_data.get("chart_data", {}).get("chart_files", [])
                    },
                    "metadata": export_result.metadata
                }
                
                return {
                    "success": True,
                    "data": export_data,
                    "message": f"æˆåŠŸå¯¼å‡ºæ–‡æ¡£: {export_result.document_path}"
                }
            else:
                return {
                    "success": False,
                    "error": export_result.error,
                    "data": None
                }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£å¯¼å‡ºå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": None
            }
    
    async def _deliver_report(
        self, 
        request: TaskExecutionRequest,
        export_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æŠ•é€’æŠ¥å‘Šï¼ˆå­˜å‚¨å’Œå‘é€é‚®ä»¶ï¼‰"""
        try:
            from app.services.infrastructure.delivery.delivery_service import (
                create_delivery_service, DeliveryRequest, DeliveryMethod,
                StorageConfig, EmailConfig, NotificationConfig
            )
            
            delivery_service = create_delivery_service(self.user_id)
            
            # å‡†å¤‡æ–‡ä»¶åˆ—è¡¨
            files_to_deliver = []
            
            # ä¸»æ–‡æ¡£
            if export_data.get("document_path"):
                files_to_deliver.append(export_data["document_path"])
            
            # å›¾è¡¨æ–‡ä»¶
            chart_files = export_data.get("artifacts", {}).get("charts", [])
            files_to_deliver.extend(chart_files)
            
            if not files_to_deliver:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æ–‡ä»¶å¯æŠ•é€’",
                    "data": None
                }
            
            # æ„å»ºæŠ•é€’é…ç½®
            delivery_config = request.delivery_config or {}
            
            # å­˜å‚¨é…ç½®
            storage_config = StorageConfig(
                bucket_name="reports",
                path_prefix=f"reports/{request.user_id}/",
                public_access=False,
                retention_days=90
            )
            
            # é‚®ä»¶é…ç½®
            email_config = None
            if delivery_config.get("send_email", False):
                recipients = delivery_config.get("email_recipients", [])
                if recipients:
                    email_config = EmailConfig(
                        recipients=recipients,
                        subject=f"æŠ¥å‘Šç”Ÿæˆå®Œæˆ - {request.template_id}",
                        body=delivery_config.get("email_body", ""),
                        attach_files=delivery_config.get("attach_files", True),
                        cc_recipients=delivery_config.get("cc_recipients"),
                        bcc_recipients=delivery_config.get("bcc_recipients")
                    )
            
            # é€šçŸ¥é…ç½®
            notification_config = NotificationConfig(
                channels=["system", "web"],
                message=f"æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼š{request.template_id}",
                priority="normal"
            )
            
            # ç¡®å®šæŠ•é€’æ–¹å¼
            delivery_method = DeliveryMethod.STORAGE_AND_EMAIL
            if email_config is None:
                delivery_method = DeliveryMethod.STORAGE_ONLY
            
            # åˆ›å»ºæŠ•é€’è¯·æ±‚
            delivery_request = DeliveryRequest(
                task_id=request.task_id,
                user_id=request.user_id,
                files=files_to_deliver,
                delivery_method=delivery_method,
                storage_config=storage_config,
                email_config=email_config,
                notification_config=notification_config,
                metadata={
                    "template_id": request.template_id,
                    "execution_context": request.execution_context,
                    "export_metadata": export_data.get("metadata", {})
                }
            )
            
            # æ‰§è¡ŒæŠ•é€’
            delivery_result = await delivery_service.deliver_report(delivery_request)
            
            if delivery_result.success:
                return {
                    "success": True,
                    "data": {
                        "delivery_id": delivery_result.delivery_id,
                        "status": delivery_result.status.value,
                        "storage_result": delivery_result.storage_result,
                        "email_result": delivery_result.email_result,
                        "notification_result": delivery_result.notification_result,
                        "download_urls": delivery_result.download_urls,
                        "delivery_time_seconds": delivery_result.delivery_time_seconds
                    },
                    "message": delivery_result.message
                }
            else:
                return {
                    "success": False,
                    "error": delivery_result.error,
                    "data": {
                        "delivery_id": delivery_result.delivery_id,
                        "status": delivery_result.status.value
                    }
                }
            
        except Exception as e:
            logger.error(f"æŠ¥å‘ŠæŠ•é€’å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": None
            }
    
    async def _get_data_source_info(self, data_source_id: str) -> Dict[str, Any]:
        """è·å–æ•°æ®æºä¿¡æ¯"""
        try:
            from app.crud import data_source as crud_data_source
            from app.db.session import SessionLocal
            
            db = SessionLocal()
            try:
                data_source = crud_data_source.get(db, id=data_source_id)
                if not data_source:
                    raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {data_source_id}")
                
                return {
                    "type": data_source.source_type.value if hasattr(data_source.source_type, 'value') else str(data_source.source_type),
                    "name": data_source.name,
                    "database": getattr(data_source, 'doris_database', 'unknown'),
                    "fe_hosts": getattr(data_source, 'doris_fe_hosts', ['localhost']),
                    "username": getattr(data_source, 'doris_username', 'root'),
                    "password": getattr(data_source, 'doris_password', ''),
                    "query_port": getattr(data_source, 'doris_query_port', 9030)
                }
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"è·å–æ•°æ®æºä¿¡æ¯å¤±è´¥: {e}")
            return {"type": "unknown", "name": "unknown"}
    
    async def _update_task_status(
        self, 
        task_id: str, 
        status: TaskStatus, 
        step: str, 
        progress: float
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id in self.active_tasks:
            self.active_tasks[task_id].update({
                "status": status,
                "current_step": step,
                "progress": progress,
                "updated_at": datetime.now()
            })
        logger.debug(f"ä»»åŠ¡çŠ¶æ€æ›´æ–°: {task_id} -> {status.value} ({progress}%): {step}")
    
    def _create_error_result(
        self, 
        request: TaskExecutionRequest, 
        message: str, 
        error: str
    ) -> TaskExecutionResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        task_id = request.task_id
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        if task_id in self.active_tasks:
            self.active_tasks[task_id]["status"] = TaskStatus.FAILED
            
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task_id}, é”™è¯¯: {error}")
        
        return TaskExecutionResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            success=False,
            message=message,
            error=error
        )
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return self.active_tasks.get(task_id)
    
    def list_active_tasks(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ´»è·ƒä»»åŠ¡"""
        return [
            {
                "task_id": task_id,
                **task_info
            }
            for task_id, task_info in self.active_tasks.items()
        ]
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        if task_id in self.active_tasks:
            self.active_tasks[task_id]["status"] = TaskStatus.CANCELLED
            logger.info(f"ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
            return True
        return False

    def replace_sql_placeholders_in_task(self, sql: str, time_context: Dict[str, Any]) -> str:
        """
        åœ¨ä»»åŠ¡æ‰§è¡Œä¸­æ›¿æ¢SQLå ä½ç¬¦

        Args:
            sql: åŒ…å«å ä½ç¬¦çš„SQL (å¦‚: "WHERE dt BETWEEN {{start_date}} AND {{end_date}}")
            time_context: æ—¶é—´ä¸Šä¸‹æ–‡

        Returns:
            æ›¿æ¢åçš„SQL (å¦‚: "WHERE dt BETWEEN '2025-09-27' AND '2025-09-27'")
        """
        try:
            replaced_sql = self.sql_replacer.replace_time_placeholders(sql, time_context)
            logger.info(f"SQLå ä½ç¬¦æ›¿æ¢å®Œæˆï¼ŒåŸSQLåŒ…å« {len(self.sql_replacer.extract_placeholders(sql))} ä¸ªå ä½ç¬¦")
            return replaced_sql
        except Exception as e:
            logger.error(f"SQLå ä½ç¬¦æ›¿æ¢å¤±è´¥: {e}")
            return sql

    def generate_time_context_for_task(
        self,
        execution_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä¸ºä»»åŠ¡ç”Ÿæˆæ—¶é—´ä¸Šä¸‹æ–‡ - ä½¿ç”¨ç®€åŒ–çš„å ä½ç¬¦æ›¿æ¢é€»è¾‘

        Args:
            execution_params: ä»»åŠ¡æ‰§è¡Œå‚æ•°ï¼ŒåŒ…å«schedule (cronè¡¨è¾¾å¼)

        Returns:
            æ—¶é—´ä¸Šä¸‹æ–‡å­—å…¸ï¼ŒåŒ…å«data_start_timeå’Œdata_end_timeç”¨äºå ä½ç¬¦æ›¿æ¢
        """
        try:
            schedule = execution_params.get("schedule")
            execution_time = None

            # å°è¯•è§£ææ‰§è¡Œæ—¶é—´
            if "execution_time" in execution_params:
                exec_time_str = execution_params["execution_time"]
                if isinstance(exec_time_str, str):
                    try:
                        execution_time = datetime.fromisoformat(exec_time_str.replace('Z', '+00:00'))
                    except ValueError:
                        logger.warning(f"Invalid execution_time format: {exec_time_str}")

            # ä½¿ç”¨ç®€åŒ–çš„æ—¶é—´ä¸Šä¸‹æ–‡ç”Ÿæˆ - ç›´æ¥åŸºäºcronå’Œæ‰§è¡Œæ—¶é—´
            if schedule:
                time_context = self.time_context_manager.build_task_time_context(
                    cron_expression=schedule,
                    execution_time=execution_time
                )
                logger.info(f"Generated simplified time context for cron: {schedule}")
            else:
                # å›é€€åˆ°é»˜è®¤çš„æ¯æ—¥ä¸Šä¸‹æ–‡
                logger.warning("No schedule provided, using default daily context")
                time_context = self.time_context_manager.build_task_time_context(
                    cron_expression="0 0 * * *",  # é»˜è®¤æ¯æ—¥
                    execution_time=execution_time
                )

            return time_context

        except Exception as e:
            logger.error(f"Failed to generate time context: {e}")
            # è¿”å›åŸºç¡€çš„æ—¶é—´ä¸Šä¸‹æ–‡
            yesterday = datetime.now() - timedelta(days=1)
            return {
                "execution_time": datetime.now().isoformat(),
                "data_start_time": yesterday.strftime('%Y-%m-%d'),
                "data_end_time": yesterday.strftime('%Y-%m-%d'),
                "period": "daily",
                "fallback": True
            }
    
    def execute_complete_task_flow(
        self,
        execution_params: Dict[str, Any],
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´ä»»åŠ¡æµç¨‹ - æ–°çš„å…¥å£æ–¹æ³•
        
        Args:
            execution_params: æ‰§è¡Œå‚æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # 1. ç”Ÿæˆæ—¶é—´ä¸Šä¸‹æ–‡
            time_context = self.generate_time_context_for_task(execution_params)
            
            # 2. æ„å»ºTaskExecutionRequest
            request = TaskExecutionRequest(
                task_id=execution_params["task_id"],
                template_id=execution_params["template_id"],
                data_source_ids=[execution_params["data_source_id"]],
                user_id=execution_params["user_id"],
                execution_context=execution_params.get("execution_context", {}),
                time_context=time_context,
                output_format="docx",
                delivery_config={
                    "send_email": bool(execution_params.get("recipients")),
                    "email_recipients": execution_params.get("recipients", []),
                    "storage_path": f"reports/{execution_params['task_id']}"
                }
            )
            
            # 3. è¿è¡Œå¼‚æ­¥æ‰§è¡Œï¼ˆè¿™éœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼‰
            import asyncio
            
            # åˆ›å»ºäº‹ä»¶å¾ªç¯æˆ–ä½¿ç”¨ç°æœ‰çš„
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # å¦‚æœæœ‰è¿›åº¦å›è°ƒï¼Œè®¾ç½®ä¸ºä»»åŠ¡çŠ¶æ€æ›´æ–°å›è°ƒ
            if progress_callback:
                original_update = self._update_task_status
                async def wrapped_update(task_id, status, message, progress):
                    result = await original_update(task_id, status, message, progress)
                    progress_callback(int(progress), message, status.value if hasattr(status, 'value') else str(status))
                    return result
                self._update_task_status = wrapped_update
            
            # æ‰§è¡Œä»»åŠ¡
            if loop.is_running():
                # å¦‚æœå¾ªç¯å·²åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                future = asyncio.create_task(self.execute_task(request))
                # æ³¨æ„ï¼šåœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™éœ€è¦ç‰¹æ®Šå¤„ç†
                logger.warning("Event loop is running, task execution may need adjustment")
                result = {"success": False, "error": "Event loop running - task queued"}
            else:
                result = loop.run_until_complete(self.execute_task(request))
            
            # è½¬æ¢ç»“æœæ ¼å¼
            if hasattr(result, 'success'):
                return {
                    "success": result.success,
                    "status": result.status.value if hasattr(result.status, 'value') else str(result.status),
                    "message": result.message,
                    "data": result.data,
                    "artifacts": result.artifacts,
                    "execution_time": result.execution_time_seconds,
                    "error": result.error
                }
            else:
                return result
            
        except Exception as e:
            logger.error(f"Complete task flow execution failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "status": "failed"
            }
    
    async def validate_all_placeholders(
        self,
        template_id: str,
        data_source_id: str,
        user_id: str,
        report_period: str = "monthly"
    ) -> Dict[str, Any]:
        """
        éªŒè¯æ‰€æœ‰å ä½ç¬¦ - ä¾›å¤–éƒ¨è°ƒç”¨
        
        Args:
            template_id: æ¨¡æ¿ID
            data_source_id: æ•°æ®æºID  
            user_id: ç”¨æˆ·ID
            report_period: æŠ¥å‘Šå‘¨æœŸ
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            # ç”Ÿæˆæ—¶é—´ä¸Šä¸‹æ–‡
            time_context = self.time_context_manager.generate_time_context(report_period)
            
            # æ„å»ºè¯·æ±‚
            request = TaskExecutionRequest(
                task_id=f"validation_{datetime.now().timestamp()}",
                template_id=template_id,
                data_source_ids=[data_source_id],
                user_id=user_id,
                execution_context={"mode": "validation_only"},
                time_context=time_context
            )
            
            # ä»…æ‰§è¡ŒéªŒè¯æ­¥éª¤
            validation_result = await self._validate_and_repair_placeholders(request)
            
            return validation_result
            
        except Exception as e:
            logger.error(f"Placeholder validation failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }


# å·¥å‚å‡½æ•°
def create_task_execution_service(user_id: str) -> TaskExecutionService:
    """åˆ›å»ºä»»åŠ¡æ‰§è¡ŒæœåŠ¡å®ä¾‹"""
    return TaskExecutionService(user_id=user_id)
