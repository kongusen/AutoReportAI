"""
å·¥ä½œæµä»»åŠ¡ - React Agentç³»ç»Ÿ
åŸºäºCeleryçš„å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå™¨
"""

from celery import current_app as celery_app
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


@celery_app.task(bind=True, name='tasks.application.workflow.generate_report_workflow')
def generate_report_workflow(
    self,
    task_id: str,
    data_source_ids: List[str],
    execution_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ¥å‘Šå·¥ä½œæµä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ID
        data_source_ids: æ•°æ®æºIDåˆ—è¡¨
        execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
    
    Returns:
        Dict[str, Any]: æ‰§è¡Œç»“æœ
    """
    try:
        # 1) åŠ è½½ä»»åŠ¡ä¸ä¸Šä¸‹æ–‡
        from app.db.session import get_db_session
        from app import crud
        from app.services.application.facades.unified_service_facade import create_unified_service_facade

        now = datetime.now().isoformat()
        with get_db_session() as db:
            task_obj = crud.task.get(db, id=int(task_id))
            if not task_obj:
                raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

            # ç”¨æˆ·ä¸èµ„æº
            user_id = str(task_obj.owner_id)
            template_id = str(task_obj.template_id)
            ds_id = str(task_obj.data_source_id)
            # è°ƒåº¦å‘¨æœŸ
            cron_expr = task_obj.schedule or (execution_context.get('cron_expression') if execution_context else None)

            logger.info(f"å¼€å§‹æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ - ä»»åŠ¡: {task_id}, ç”¨æˆ·: {user_id}")

            # æ›´æ–°çŠ¶æ€
            self.update_state(state='PROGRESS', meta={'current_step': 'åˆå§‹åŒ–å·¥ä½œæµ', 'progress': 10, 'started_at': now})

            # 2) æ‰§è¡Œç»„è£…ï¼ˆv2 æµæ°´çº¿ï¼ŒæŒ‰è‡ªç„¶æ—¥/å‘¨/æœˆ/å¹´ï¼‰
            facade = create_unified_service_facade(db, user_id)
            import asyncio
            assembled = asyncio.run(
                facade.generate_report_v2(
                    template_id=template_id,
                    data_source_id=ds_id,
                    schedule={'cron_expression': cron_expr} if cron_expr else None,
                    execution_time=now,
                )
            )

            result = {
                'success': True,
                'task_id': task_id,
                'user_id': user_id,
                'template_id': template_id,
                'data_source_ids': data_source_ids or [ds_id],
                'execution_context': execution_context or {},
                'workflow_type': 'generate_report',
                'completed_at': datetime.now().isoformat(),
                'message': 'æŠ¥å‘Šæµæ°´çº¿æ‰§è¡Œå®Œæˆ',
                'assembled': assembled,
            }

            logger.info(f"æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµå®Œæˆ - ä»»åŠ¡: {task_id}")
            return result
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµå¤±è´¥ - ä»»åŠ¡: {task_id}, é”™è¯¯: {e}")
        
        self.update_state(state='FAILURE', meta={'error': str(e), 'task_id': task_id, 'failed_at': datetime.now().isoformat()})
        
        return {
            'success': False,
            'task_id': task_id,
            'error': str(e),
            'failed_at': datetime.now().isoformat()
        }


@celery_app.task(bind=True, name='generate_report_orchestrated')
def generate_report_orchestrated(
    self,
    task_id: str,
    template_id: str,
    data_source_id: str,
    user_id: str,
    schedule: Optional[Dict[str, Any]] = None,
    skip_stages: Optional[List[str]] = None,
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ Orchestrator çš„æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ - å¤šé˜¶æ®µ Agent ç¼–æ’

    Args:
        task_id: ä»»åŠ¡ID
        template_id: æ¨¡æ¿ID
        data_source_id: æ•°æ®æºID
        user_id: ç”¨æˆ·ID
        schedule: è°ƒåº¦ä¿¡æ¯
        skip_stages: è¦è·³è¿‡çš„é˜¶æ®µåˆ—è¡¨

    Returns:
        Dict[str, Any]: æ‰§è¡Œç»“æœ
    """
    try:
        logger.info(f"å¼€å§‹å¤šé˜¶æ®µæŠ¥å‘Šç”Ÿæˆ - ä»»åŠ¡: {task_id}, æ¨¡æ¿: {template_id}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={
                'current_step': 'åˆå§‹åŒ– Orchestrator',
                'progress': 5,
                'started_at': datetime.now().isoformat()
            }
        )

        # åˆ›å»º Orchestrator
        import asyncio
        from app.services.infrastructure.agents import ReportGenerationOrchestrator, OrchestratorContext
        from app.core.container import Container

        async def run_orchestration():
            container = Container()
            orchestrator = ReportGenerationOrchestrator(container=container)

            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            context = OrchestratorContext(
                template_id=template_id,
                data_source_id=data_source_id,
                user_id=user_id,
                schedule=schedule,
                execution_time=datetime.now(),
            )

            # æ‰§è¡Œç¼–æ’æµç¨‹
            all_events = []
            async for event in orchestrator.execute(context, skip_stages=skip_stages):
                all_events.append(event)

                # æ›´æ–° Celery ä»»åŠ¡çŠ¶æ€
                if event.get("type") == "stage_started":
                    progress = (event.get("stage_index", 0) / event.get("total_stages", 6)) * 100
                    self.update_state(
                        state='PROGRESS',
                        meta={
                            'current_step': f"æ‰§è¡Œé˜¶æ®µ: {event.get('stage_name')}",
                            'progress': progress,
                            'stage_index': event.get("stage_index"),
                        }
                    )

                elif event.get("type") == "orchestration_failed":
                    self.update_state(
                        state='FAILURE',
                        meta={
                            'error': event.get("error"),
                            'failed_stage': event.get("failed_stage"),
                        }
                    )

            return {
                "context": context,
                "events": all_events,
            }

        # æ‰§è¡Œå¼‚æ­¥ç¼–æ’
        result_data = asyncio.run(run_orchestration())
        context = result_data["context"]
        events = result_data["events"]

        # æ„å»ºè¿”å›ç»“æœ
        result = {
            'success': True,
            'task_id': task_id,
            'template_id': template_id,
            'data_source_id': data_source_id,
            'user_id': user_id,
            'workflow_type': 'orchestrated_report_generation',
            'completed_at': datetime.now().isoformat(),
            'stage_results': {
                name: stage.to_dict()
                for name, stage in context.stage_results.items()
            },
            'total_events': len(events),
        }

        logger.info(f"å¤šé˜¶æ®µæŠ¥å‘Šç”Ÿæˆå®Œæˆ - ä»»åŠ¡: {task_id}")
        return result

    except Exception as e:
        logger.error(f"å¤šé˜¶æ®µæŠ¥å‘Šç”Ÿæˆå¤±è´¥ - ä»»åŠ¡: {task_id}, é”™è¯¯: {e}", exc_info=True)

        self.update_state(
            state='FAILURE',
            meta={
                'error': str(e),
                'task_id': task_id,
                'failed_at': datetime.now().isoformat()
            }
        )

        return {
            'success': False,
            'task_id': task_id,
            'error': str(e),
            'failed_at': datetime.now().isoformat()
        }


@celery_app.task(bind=True, name='analyze_placeholder_workflow')
def analyze_placeholder_workflow(
    self,
    template_id: str,
    data_source_id: str,
    user_id: str,
    force_reanalyze: bool = False,
    existing_sql: str = None
) -> Dict[str, Any]:
    """
    å ä½ç¬¦åˆ†æå·¥ä½œæµä»»åŠ¡ - ä½¿ç”¨ä»»åŠ¡éªŒè¯æ™ºèƒ½æ¨¡å¼

    Args:
        template_id: æ¨¡æ¿ID
        data_source_id: æ•°æ®æºID
        user_id: ç”¨æˆ·ID
        force_reanalyze: å¼ºåˆ¶é‡æ–°åˆ†æ
        existing_sql: ç°æœ‰SQLï¼ˆå¦‚æœå­˜åœ¨ï¼‰

    Returns:
        Dict[str, Any]: åˆ†æç»“æœ
    """
    try:
        logger.info(f"å¼€å§‹å ä½ç¬¦åˆ†æå·¥ä½œæµ - æ¨¡æ¿: {template_id}, æ•°æ®æº: {data_source_id}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={
                'current_step': 'åˆå§‹åŒ–Agentç³»ç»Ÿ',
                'progress': 10,
                'started_at': datetime.now().isoformat()
            }
        )

        # ä½¿ç”¨Agentç³»ç»Ÿè¿›è¡Œå ä½ç¬¦åˆ†æ
        import asyncio
        from app.services.infrastructure.agents import AgentService
        from app.services.infrastructure.agents.types import AgentInput, PlaceholderSpec, SchemaInfo, TaskContext
        from app.core.container import Container
        from app.db.session import get_db_session

        async def run_analysis():
            # åˆ›å»ºAgenté—¨é¢
            container = Container()
            agent_service = AgentService(container=container)

            # è·å–æ•°æ®æºä¿¡æ¯å’Œæ¨¡æ¿ä¿¡æ¯
            with get_db_session() as db:
                from app.models.data_source import DataSource
                from app.models.template import Template
                from uuid import UUID

                data_source = db.query(DataSource).filter(DataSource.id == UUID(data_source_id)).first()
                template = db.query(Template).filter(Template.id == UUID(template_id)).first()

                if not data_source or not template:
                    raise ValueError(f"æ•°æ®æºæˆ–æ¨¡æ¿ä¸å­˜åœ¨: data_source={data_source_id}, template={template_id}")

            # æ›´æ–°è¿›åº¦
            self.update_state(
                state='PROGRESS',
                meta={
                    'current_step': 'æ„å»ºåˆ†æä¸Šä¸‹æ–‡',
                    'progress': 30,
                    'data_source_name': data_source.name,
                    'template_name': template.name
                }
            )

            # æ„å»ºæ•°æ®æºè¿æ¥é…ç½®
            data_source_config = {
                "id": str(data_source_id),
                "data_source_id": str(data_source_id),
                "source_type": data_source.source_type.value if hasattr(data_source.source_type, 'value') else str(data_source.source_type),
                "database": getattr(data_source, 'doris_database', 'default_db'),
                "host": data_source.doris_fe_hosts[0] if data_source.doris_fe_hosts else None,
                "port": getattr(data_source, 'doris_fe_http_port', 8030),
                "username": getattr(data_source, 'username', None),
                "password": getattr(data_source, 'password', None)
            }

            # æ„å»ºAgentè¾“å…¥
            agent_input = AgentInput(
                user_prompt=f"åˆ†ææ¨¡æ¿ {template.name} çš„å ä½ç¬¦ï¼Œç”Ÿæˆæˆ–éªŒè¯å¯¹åº”çš„æ•°æ®æŸ¥è¯¢SQL",
                placeholder=PlaceholderSpec(
                    description=f"æ¨¡æ¿å ä½ç¬¦åˆ†æ - {template.name}",
                    type="template_analysis"
                ),
                schema=SchemaInfo(
                    database_name=getattr(data_source, 'doris_database', 'default_db'),
                    host=data_source.doris_fe_hosts[0] if data_source.doris_fe_hosts else None,
                    port=getattr(data_source, 'doris_fe_http_port', 8030),
                    username=getattr(data_source, 'username', None),
                    password=getattr(data_source, 'password', None)
                ),
                context=TaskContext(
                    task_time=int(datetime.now().timestamp()),
                    timezone="Asia/Shanghai"
                ),
                data_source=data_source_config,
                task_driven_context={
                    "template_id": template_id,
                    "template_name": template.name,
                    "template_content": template.content[:1000] if template.content else "",
                    "data_source_id": data_source_id,
                    "data_source_name": data_source.name,
                    "data_source_type": data_source.source_type.value if hasattr(data_source.source_type, 'value') else str(data_source.source_type),
                    "current_sql": existing_sql,
                    "force_reanalyze": force_reanalyze,
                    "analysis_type": "placeholder_workflow"
                },
                user_id=user_id
            )

            # æ›´æ–°è¿›åº¦
            self.update_state(
                state='PROGRESS',
                meta={
                    'current_step': 'æ‰§è¡Œæ™ºèƒ½åˆ†æå’ŒéªŒè¯',
                    'progress': 50,
                    'mode': 'task_validation_intelligent'
                }
            )

            # ğŸ¯ ä½¿ç”¨ä»»åŠ¡éªŒè¯æ™ºèƒ½æ¨¡å¼ - æ ¸å¿ƒè°ƒç”¨
            result = await agent_service.execute_task_validation(agent_input)

            return result

        # æ‰§è¡Œå¼‚æ­¥åˆ†æ
        analysis_result = asyncio.run(run_analysis())

        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current_step': 'å¤„ç†åˆ†æç»“æœ',
                'progress': 80,
                'agent_success': analysis_result.success
            }
        )

        # æ„å»ºè¿”å›ç»“æœ
        if analysis_result.success:
            final_result = {
                'success': True,
                'template_id': template_id,
                'data_source_id': data_source_id,
                'user_id': user_id,
                'force_reanalyze': force_reanalyze,
                'analysis_completed_at': datetime.now().isoformat(),
                'sql_content': analysis_result.result,
                'validation_info': analysis_result.metadata,
                'generation_method': analysis_result.metadata.get('generation_method', 'validation'),
                'time_updated': analysis_result.metadata.get('time_updated', False),
                'fallback_reason': analysis_result.metadata.get('fallback_reason'),
                'placeholders_analyzed': True,
                'sql_generated': True,
                'validation_passed': True,
                'message': f'å ä½ç¬¦åˆ†æå®Œæˆ - æ–¹æ³•: {analysis_result.metadata.get("generation_method", "validation")}'
            }
        else:
            final_result = {
                'success': False,
                'template_id': template_id,
                'data_source_id': data_source_id,
                'user_id': user_id,
                'error': analysis_result.metadata.get('error', 'æœªçŸ¥é”™è¯¯'),
                'validation_info': analysis_result.metadata,
                'failed_at': datetime.now().isoformat(),
                'message': 'Agentå ä½ç¬¦åˆ†æå¤±è´¥'
            }

        logger.info(f"å ä½ç¬¦åˆ†æå·¥ä½œæµå®Œæˆ - æ¨¡æ¿: {template_id}, æˆåŠŸ: {analysis_result.success}")

        return final_result

    except Exception as e:
        logger.error(f"å ä½ç¬¦åˆ†æå·¥ä½œæµå¤±è´¥ - æ¨¡æ¿: {template_id}, é”™è¯¯: {e}")

        self.update_state(
            state='FAILURE',
            meta={
                'error': str(e),
                'template_id': template_id,
                'failed_at': datetime.now().isoformat()
            }
        )

        return {
            'success': False,
            'template_id': template_id,
            'error': str(e),
            'failed_at': datetime.now().isoformat()
        }
