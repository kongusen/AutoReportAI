"""
Apache Dorisæ•°æ®ä»“åº“è¿æ¥å™¨
æ”¯æŒé«˜æ€§èƒ½æŸ¥è¯¢ã€Stream Loadå’Œåˆ†å¸ƒå¼è®¡ç®—
ç°åœ¨ä½¿ç”¨MySQLåè®®è¿›è¡Œæ›´ç¨³å®šçš„è¿æ¥
"""

import asyncio
import aiohttp
import pandas as pd
import json
import logging
import pymysql
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from urllib.parse import urljoin
import numpy as np
from contextlib import contextmanager

from app.core.security_utils import decrypt_data
from app.core.data_source_utils import DataSourcePasswordManager
from app.models.data_source import DataSource
from .base_connector import BaseConnector, ConnectorConfig, QueryResult
from .resilience_manager import get_resilience_manager, CircuitBreakerConfig, RetryConfig


@dataclass
class DorisConfig(ConnectorConfig):
    """Dorisé…ç½® - æ”¯æŒMySQLåè®®å’ŒHTTP API"""
    # MySQLåè®®é…ç½®
    mysql_host: str = "localhost"
    mysql_port: int = 9030  # MySQLåè®®ç«¯å£
    mysql_database: str = "default"
    mysql_username: str = "root"
    mysql_password: str = ""
    mysql_charset: str = "utf8mb4"
    
    # HTTP APIé…ç½®ï¼ˆç”¨äºç®¡ç†æ“ä½œï¼‰
    fe_hosts: List[str] = None
    be_hosts: List[str] = None
    http_port: int = 8030
    query_port: int = 9030
    database: str = "default"
    username: str = "root"
    password: str = ""
    load_balance: bool = True
    timeout: int = 30
    
    # è¿æ¥æ¨¡å¼é€‰æ‹©
    use_mysql_protocol: bool = True  # ä¼˜å…ˆä½¿ç”¨MySQLåè®®
    
    def __post_init__(self):
        if self.fe_hosts is None:
            self.fe_hosts = ["localhost"]
        if self.be_hosts is None:
            self.be_hosts = ["localhost"]
        
        # ç»Ÿä¸€é…ç½®é¡¹
        if hasattr(self, 'mysql_host') and self.mysql_host == "localhost" and self.fe_hosts:
            self.mysql_host = self.fe_hosts[0]
        if hasattr(self, 'mysql_username') and self.mysql_username == "root" and self.username:
            self.mysql_username = self.username
        if hasattr(self, 'mysql_password') and self.mysql_password == "" and self.password:
            self.mysql_password = self.password
        if hasattr(self, 'mysql_database') and self.mysql_database == "default" and self.database:
            self.mysql_database = self.database


@dataclass
class DorisQueryResult:
    """DorisæŸ¥è¯¢ç»“æœ"""
    data: pd.DataFrame
    execution_time: float
    rows_scanned: int
    bytes_scanned: int
    is_cached: bool
    query_id: str
    fe_host: str
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸"""
        return {
            "data": self.data.to_dict(orient="records") if not self.data.empty else [],
            "columns": self.data.columns.tolist() if not self.data.empty else [],
            "execution_time": self.execution_time,
            "rows_scanned": self.rows_scanned,
            "bytes_scanned": self.bytes_scanned,
            "is_cached": self.is_cached,
            "query_id": self.query_id,
            "fe_host": self.fe_host,
            "row_count": len(self.data)
        }
    
    def __json__(self):
        """Kombu/Celery JSON serialization support"""
        return self.to_dict()
    
    def __reduce__(self):
        """Pickle serialization support for Celery"""
        return (self.from_dict, (self.to_dict(),))
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'DorisQueryResult':
        """ä»å­—å…¸åˆ›å»ºDorisQueryResultå¯¹è±¡"""
        df_data = data.get("data", [])
        columns = data.get("columns", [])
        
        if df_data and columns:
            df = pd.DataFrame(df_data, columns=columns)
        else:
            df = pd.DataFrame()
        
        return cls(
            data=df,
            execution_time=data.get("execution_time", 0.0),
            rows_scanned=data.get("rows_scanned", 0),
            bytes_scanned=data.get("bytes_scanned", 0),
            is_cached=data.get("is_cached", False),
            query_id=data.get("query_id", ""),
            fe_host=data.get("fe_host", "")
        )


class DorisConnector(BaseConnector):
    """Apache Dorisè¿æ¥å™¨ - æ”¯æŒMySQLåè®®å’ŒHTTP API"""
    
    def __init__(self, config: DorisConfig):
        super().__init__(config)
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # éŸ§æ€§ç®¡ç†å™¨
        self.resilience_manager = get_resilience_manager()
        
        # æ–­è·¯å™¨é…ç½®
        self.connection_circuit_config = CircuitBreakerConfig(
            failure_threshold=3,      # è¿æ¥å¤±è´¥3æ¬¡åå¼€è·¯
            recovery_timeout=30,      # 30ç§’åå°è¯•æ¢å¤
            success_threshold=2,      # æˆåŠŸ2æ¬¡åå…³é—­æ–­è·¯å™¨
            monitor_window=300        # 5åˆ†é’Ÿç›‘æ§çª—å£
        )
        
        self.query_circuit_config = CircuitBreakerConfig(
            failure_threshold=5,      # æŸ¥è¯¢å¤±è´¥5æ¬¡åå¼€è·¯
            recovery_timeout=60,      # 60ç§’åå°è¯•æ¢å¤
            success_threshold=3,      # æˆåŠŸ3æ¬¡åå…³é—­æ–­è·¯å™¨
            monitor_window=600        # 10åˆ†é’Ÿç›‘æ§çª—å£
        )
        
        # é‡è¯•é…ç½®
        self.connection_retry_config = RetryConfig(
            max_attempts=3,
            base_delay=1.0,
            max_delay=10.0,
            exponential_factor=2.0,
            jitter=True
        )
        
        self.query_retry_config = RetryConfig(
            max_attempts=2,
            base_delay=0.5,
            max_delay=5.0,
            exponential_factor=1.5,
            jitter=True
        )
        
        # MySQLè¿æ¥
        self.mysql_connection = None
        
        # HTTPä¼šè¯é…ç½®ï¼ˆç”¨äºç®¡ç†æ“ä½œï¼‰
        self.current_fe_index = 0  # å½“å‰ä½¿ç”¨çš„FEèŠ‚ç‚¹ç´¢å¼•
        self.session = None  # åˆå§‹åŒ–sessionä¸ºNone
        self.timeout = aiohttp.ClientTimeout(total=self.config.timeout)
        self.connector = aiohttp.TCPConnector(
            limit=20,
            limit_per_host=5,
            keepalive_timeout=60
        )
        
    async def connect(self) -> None:
        """å»ºç«‹è¿æ¥ - ä½¿ç”¨éŸ§æ€§ç®¡ç†å™¨ä¿æŠ¤"""
        
        connection_name = f"doris_connect_{self.config.mysql_host}_{self.config.mysql_port}"
        
        async with self.resilience_manager.resilient_operation(
            operation_name=connection_name,
            circuit_breaker_config=self.connection_circuit_config,
            retry_config=self.connection_retry_config
        ) as circuit_breaker:
            
            mysql_connected = False
            
            if self.config.use_mysql_protocol:
                try:
                    await circuit_breaker.async_call(self._connect_mysql)
                    mysql_connected = True
                except Exception as e:
                    self.logger.warning(f"MySQLåè®®è¿æ¥å¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨HTTP API: {e}")
                    # ç¦ç”¨MySQLåè®®ï¼Œå›é€€åˆ°HTTP API
                    self.config.use_mysql_protocol = False
            
            # å»ºç«‹HTTPä¼šè¯ç”¨äºç®¡ç†æ“ä½œï¼ˆæˆ–ä½œä¸ºä¸»è¦è¿æ¥æ–¹å¼ï¼‰
            await circuit_breaker.async_call(self._setup_http_session)
            self._connected = True
            
            if mysql_connected:
                self.logger.info("âœ… å·²å»ºç«‹MySQLåè®®è¿æ¥å’ŒHTTP APIä¼šè¯")
            else:
                self.logger.info("âœ… å·²å»ºç«‹HTTP APIä¼šè¯ï¼ˆMySQLåè®®ä¸å¯ç”¨ï¼‰")
    
    async def _setup_http_session(self):
        """è®¾ç½®HTTPä¼šè¯"""
        self.session = aiohttp.ClientSession(
            connector=self.connector,
            timeout=self.timeout
        )
        
    async def _connect_mysql(self) -> None:
        """å»ºç«‹MySQLåè®®è¿æ¥ï¼Œæ”¯æŒé‡è¯•"""
        max_retries = 3
        base_timeout = self.config.timeout
        
        for attempt in range(max_retries):
            try:
                # é€’å¢è¶…æ—¶æ—¶é—´
                timeout = base_timeout + (attempt * 10)
                
                self.mysql_connection = pymysql.connect(
                    host=self.config.mysql_host,
                    port=self.config.mysql_port,
                    user=self.config.mysql_username,
                    password=self.config.mysql_password,
                    database=self.config.mysql_database,
                    charset=self.config.mysql_charset,
                    connect_timeout=timeout,
                    read_timeout=timeout,
                    write_timeout=timeout,
                    autocommit=True
                )
                self.logger.info(f"âœ… MySQLåè®®è¿æ¥æˆåŠŸ: {self.config.mysql_host}:{self.config.mysql_port} (å°è¯• {attempt + 1})")
                return
            except Exception as e:
                self.logger.warning(f"âŒ MySQLåè®®è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    self.logger.error(f"âŒ MySQLåè®®è¿æ¥æœ€ç»ˆå¤±è´¥: {e}")
                    raise
                # ç­‰å¾…ä¸€ç§’åé‡è¯•
                import asyncio
                await asyncio.sleep(1)
        
    @contextmanager
    def _get_mysql_cursor(self):
        """è·å–MySQLæ¸¸æ ‡çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if not self.mysql_connection:
            raise Exception("MySQLè¿æ¥æœªå»ºç«‹")
        
        cursor = self.mysql_connection.cursor()
        try:
            yield cursor
        finally:
            cursor.close()
        
    async def disconnect(self) -> None:
        """æ–­å¼€è¿æ¥"""
        try:
            # å…³é—­MySQLè¿æ¥
            if hasattr(self, 'mysql_connection') and self.mysql_connection is not None:
                self.mysql_connection.close()
                self.mysql_connection = None
                self.logger.info("âœ… MySQLè¿æ¥å·²å…³é—­")
            
            # å…³é—­HTTPä¼šè¯
            if hasattr(self, 'session') and self.session is not None:
                if not self.session.closed:
                    await self.session.close()
            if hasattr(self, 'connector') and self.connector is not None:
                await self.connector.close()
        except Exception as e:
            self.logger.warning(f"Error during disconnect: {e}")
        finally:
            self._connected = False
            self.session = None
    
    async def close(self) -> None:
        """å…³é—­è¿æ¥ï¼ˆdisconnectçš„åˆ«åï¼‰"""
        await self.disconnect()
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾"""
        if hasattr(self, 'session') and self.session is not None and not self.session.closed:
            # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­æˆ‘ä»¬åªèƒ½è®°å½•è­¦å‘Š
            import warnings
            warnings.warn(
                "DorisConnector session was not properly closed. "
                "Please use 'await connector.disconnect()' or async context manager.",
                ResourceWarning
            )
            # å°è¯•å¼ºåˆ¶å…³é—­ä¼šè¯ï¼ˆåœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼‰
            try:
                import asyncio
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    loop.create_task(self.session.close())
                else:
                    loop.run_until_complete(self.session.close())
            except Exception:
                pass  # å¿½ç•¥æ¸…ç†æ—¶çš„é”™è¯¯
    
    @classmethod
    def from_data_source(cls, data_source: DataSource) -> 'DorisConnector':
        """ä»æ•°æ®æºåˆ›å»ºè¿æ¥å™¨"""
        
        config = DorisConfig(
            source_type="doris",
            name=data_source.name,
            # MySQLåè®®é…ç½®
            mysql_host=(data_source.doris_fe_hosts or ["localhost"])[0],
            mysql_port=data_source.doris_query_port or 9030,
            mysql_database=data_source.doris_database or "default",
            mysql_username=data_source.doris_username or "root",
            mysql_password=DataSourcePasswordManager.get_password(data_source.doris_password),
            mysql_charset="utf8mb4",
            # HTTP APIé…ç½®ï¼ˆä¿æŒå…¼å®¹ï¼‰
            fe_hosts=data_source.doris_fe_hosts or ["localhost"],
            be_hosts=data_source.doris_be_hosts or ["localhost"], 
            http_port=data_source.doris_http_port or 8030,
            query_port=data_source.doris_query_port or 9030,
            database=data_source.doris_database or "default",
            username=data_source.doris_username or "root",
            password=DataSourcePasswordManager.get_password(data_source.doris_password),
            timeout=30,  # è®¾ç½®é»˜è®¤è¶…æ—¶æ—¶é—´ä¸º30ç§’
            use_mysql_protocol=False  # ä¼˜å…ˆä½¿ç”¨HTTP APIï¼Œå› ä¸ºæ›´ç¨³å®š
        )
        
        return cls(config)
    
    @classmethod
    def _get_password(cls, password: Optional[str]) -> str:
        """å®‰å…¨è·å–å¯†ç ï¼Œæ”¯æŒåŠ å¯†å’Œæ˜æ–‡ä¸¤ç§å½¢å¼"""
        if not password:
            return ""
        
        # å¦‚æœå¯†ç çœ‹èµ·æ¥åƒæ˜¯åŠ å¯†çš„ï¼ˆbase64ç¼–ç ï¼‰ï¼Œå°è¯•è§£å¯†
        if len(password) > 10 and password.startswith('gAAAA'):
            try:
                decrypted = decrypt_data(password)
                if decrypted and len(decrypted) > 0:
                    return decrypted
            except Exception as e:
                # è§£å¯†å¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸æŠ›å‡ºå¼‚å¸¸
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"å¯†ç è§£å¯†å¤±è´¥ï¼Œä½¿ç”¨æ˜æ–‡å¤„ç†: {e}")
        
        # ç›´æ¥è¿”å›åŸå¯†ç ï¼ˆå¯èƒ½æ˜¯æ˜æ–‡ï¼‰
        return password
    
    def _clean_sql(self, sql: str) -> str:
        """æ¸…ç†å’ŒéªŒè¯SQLæŸ¥è¯¢"""
        if not sql:
            return sql
            
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
        cleaned = ' '.join(sql.split())
        
        # åªè¿›è¡ŒåŸºæœ¬çš„SQLæ ¼å¼åŒ–ï¼Œé¿å…è¿‡åº¦ä¿®å¤
        import re
        
        # åªä¿®å¤æ˜æ˜¾çš„è¯­æ³•é”™è¯¯ï¼Œä¸è¦è¿‡åº¦å¤„ç†
        basic_fixes = [
            # ç¡®ä¿COUNT(*)è¯­æ³•æ­£ç¡®ï¼ˆé€šç”¨æ¸…ç†ï¼‰
            (r'\bCOUNT\s*\(\s*\*\s*\)', 'COUNT(*)'),
            # ä¿®å¤å¤šä½™çš„ç©ºæ ¼
            (r'\s+', ' '),
            # ç§»é™¤é¦–å°¾ç©ºæ ¼
        ]
        
        for pattern, replacement in basic_fixes:
            cleaned = re.sub(pattern, replacement, cleaned, flags=re.IGNORECASE)
        
        cleaned = cleaned.strip()
        
        # è®°å½•æ¸…ç†ç»“æœï¼ˆä»…åœ¨æœ‰å˜åŒ–æ—¶ï¼‰
        if cleaned != sql:
            self.logger.debug(f"SQLå·²æ¸…ç†: {sql} -> {cleaned}")
        
        return cleaned
    
    async def execute_mysql_query(self, sql: str, params: Optional[tuple] = None) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨MySQLåè®®æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›DataFrame"""
        if not self.config.use_mysql_protocol or not self.mysql_connection:
            self.logger.warning("MySQLåè®®æœªå¯ç”¨æˆ–æœªè¿æ¥ï¼Œå›é€€åˆ°HTTP API")
            return None
            
        # æ¸…ç†å’ŒéªŒè¯SQLæŸ¥è¯¢
        cleaned_sql = self._clean_sql(sql)
        self.logger.debug(f"æ‰§è¡ŒSQLæŸ¥è¯¢: {cleaned_sql}")
        
        try:
            start_time = time.time()
            with self._get_mysql_cursor() as cursor:
                cursor.execute(cleaned_sql, params)
                results = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                execution_time = time.time() - start_time
                
                df = pd.DataFrame(results, columns=columns)
                self.logger.info(f"âœ… MySQLæŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶: {execution_time:.3f}ç§’ï¼Œè¿”å› {len(df)} è¡Œ")
                return df
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"âŒ MySQLæŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥é—®é¢˜
            if any(keyword in error_msg.lower() for keyword in ['connection', 'timeout', 'refused', 'lost']):
                self.logger.error("MySQLè¿æ¥é—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥ç½‘ç»œæˆ–DorisæœåŠ¡çŠ¶æ€")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯Dorisç‰¹å®šçš„SQLè¯­æ³•é”™è¯¯
            elif "can only be used in conjunction with COUNT" in error_msg:
                self.logger.error(f"Doris SQLè¯­æ³•é”™è¯¯")
                self.logger.error(f"åŸå§‹SQL: {sql}")
                self.logger.error(f"æ¸…ç†åSQL: {cleaned_sql}")
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨ä¸å­˜åœ¨é”™è¯¯
            elif "doesn't exist" in error_msg.lower() or "table not found" in error_msg.lower():
                self.logger.error(f"è¡¨ä¸å­˜åœ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¡¨åå’Œæ•°æ®åº“")
                
            return None
    
    async def get_databases_mysql(self) -> List[str]:
        """ä½¿ç”¨MySQLåè®®è·å–æ•°æ®åº“åˆ—è¡¨"""
        try:
            with self._get_mysql_cursor() as cursor:
                cursor.execute("SHOW DATABASES")
                databases = cursor.fetchall()
                db_list = [db[0] for db in databases if db[0] not in ['information_schema', '__internal_schema']]
                self.logger.info(f"âœ… MySQLåè®®è·å–æ•°æ®åº“: {db_list}")
                return db_list
        except Exception as e:
            self.logger.error(f"âŒ MySQLåè®®è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def get_tables_mysql(self, database: str = None) -> List[str]:
        """ä½¿ç”¨MySQLåè®®è·å–è¡¨åˆ—è¡¨"""
        try:
            with self._get_mysql_cursor() as cursor:
                if database:
                    cursor.execute(f"USE {database}")
                cursor.execute("SHOW TABLES")
                tables = cursor.fetchall()
                table_list = [table[0] for table in tables]
                self.logger.info(f"âœ… MySQLåè®®è·å–è¡¨: {table_list}")
                return table_list
        except Exception as e:
            self.logger.error(f"âŒ MySQLåè®®è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def get_table_schema_mysql(self, table_name: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨MySQLåè®®è·å–è¡¨ç»“æ„"""
        try:
            with self._get_mysql_cursor() as cursor:
                cursor.execute(f"DESCRIBE {table_name}")
                columns = cursor.fetchall()
                schema = []
                for col in columns:
                    schema.append({
                        'field': col[0],
                        'type': col[1],
                        'null': col[2],
                        'key': col[3],
                        'default': col[4],
                        'extra': col[5]
                    })
                self.logger.info(f"âœ… MySQLåè®®è·å–è¡¨ {table_name} ç»“æ„: {len(schema)} ä¸ªå­—æ®µ")
                return schema
        except Exception as e:
            self.logger.error(f"âŒ MySQLåè®®è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
            return []

    async def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•è¿æ¥ - ä½¿ç”¨ç®¡ç† API"""
        
        try:
            # ç¡®ä¿è¿æ¥å·²å»ºç«‹
            if not self.session:
                await self.connect()
                
            # ä½¿ç”¨ç®¡ç† API æµ‹è¯•è¿æ¥ï¼Œå› ä¸ºè¿™æ˜¯ Doris 2.1.9 ä¸­å¯ç”¨çš„
            fe_host = await self._get_available_fe_host()
            
            # æµ‹è¯•åŸºæœ¬è¿æ¥å’Œè®¤è¯
            url = f"http://{fe_host}:{self.config.http_port}/api/show_proc"
            params = {'path': '/'}
            auth = aiohttp.BasicAuth(self.config.username, self.config.password)
            
            async with self.session.get(url, params=params, auth=auth) as response:
                response.raise_for_status()
                result = await response.json()
            
            if result.get("code") == 0 and result.get("msg") == "success":
                return {
                    "success": True,
                    "message": "Doris connection successful via management API",
                    "fe_host": fe_host,
                    "database": self.config.database,
                    "version_info": "Doris 2.1.9 connection validated",
                    "method": "management_api"
                }
            else:
                return {
                    "success": False,
                    "error": f"Management API test failed: {result.get('msg', 'Unknown error')}"
                }
                
        except aiohttp.ClientResponseError as e:
            return {
                "success": False,
                "error": f"HTTP error {e.status}: {e.message}"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Connection failed: {str(e)}"
            }
    
    async def get_resilience_health_status(self) -> Dict[str, Any]:
        """è·å–è¿æ¥å™¨çš„éŸ§æ€§å¥åº·çŠ¶æ€"""
        try:
            health_report = self.resilience_manager.get_health_report()
            
            # è·å–ä¸æ­¤è¿æ¥å™¨ç›¸å…³çš„æŒ‡æ ‡
            connection_name = f"doris_connect_{self.config.mysql_host}_{self.config.mysql_port}"
            connection_metrics = health_report.get("connection_metrics", {}).get(connection_name, {})
            
            # è·å–æ–­è·¯å™¨çŠ¶æ€
            circuit_breakers = health_report.get("circuit_breakers", {})
            relevant_breakers = {
                name: status for name, status in circuit_breakers.items()
                if self.config.mysql_host in name or "doris" in name.lower()
            }
            
            # åŸºç¡€è¿æ¥çŠ¶æ€
            basic_status = await self.test_connection()
            
            return {
                "connector_type": "DorisConnector",
                "host": self.config.mysql_host,
                "port": self.config.mysql_port,
                "database": self.config.mysql_database,
                "basic_connection": basic_status,
                "resilience_metrics": {
                    "connection_metrics": connection_metrics,
                    "circuit_breakers": relevant_breakers,
                    "overall_health": health_report.get("overall_health", "unknown")
                },
                "connection_config": {
                    "use_mysql_protocol": self.config.use_mysql_protocol,
                    "has_mysql_connection": self.mysql_connection is not None,
                    "has_http_session": self.session is not None and not self.session.closed,
                    "timeout": self.config.timeout
                },
                "resilience_config": {
                    "connection_circuit": {
                        "failure_threshold": self.connection_circuit_config.failure_threshold,
                        "recovery_timeout": self.connection_circuit_config.recovery_timeout
                    },
                    "query_circuit": {
                        "failure_threshold": self.query_circuit_config.failure_threshold,
                        "recovery_timeout": self.query_circuit_config.recovery_timeout
                    },
                    "connection_retry": {
                        "max_attempts": self.connection_retry_config.max_attempts,
                        "base_delay": self.connection_retry_config.base_delay
                    },
                    "query_retry": {
                        "max_attempts": self.query_retry_config.max_attempts,
                        "base_delay": self.query_retry_config.base_delay
                    }
                },
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {
                "connector_type": "DorisConnector",
                "host": self.config.mysql_host,
                "error": f"Failed to get resilience health status: {str(e)}",
                "timestamp": datetime.utcnow().isoformat()
            }
    
    async def execute_query(
        self, 
        sql: str, 
        parameters: Optional[Dict[str, Any]] = None
    ) -> QueryResult:
        """
        æ‰§è¡ŒSQLæŸ¥è¯¢ - ä¼˜å…ˆä½¿ç”¨MySQLåè®®ï¼Œå›é€€åˆ°HTTP APIï¼Œå¸¦éŸ§æ€§ä¿æŠ¤
        
        Args:
            sql: SQLæŸ¥è¯¢è¯­å¥
            parameters: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        query_name = f"doris_query_{self.config.mysql_host}_{hash(sql) % 10000}"
        
        async with self.resilience_manager.resilient_operation(
            operation_name=query_name,
            circuit_breaker_config=self.query_circuit_config,
            retry_config=self.query_retry_config
        ) as circuit_breaker:
            
            start_time = asyncio.get_event_loop().time()
            
            # ä¼˜å…ˆä½¿ç”¨MySQLåè®®
            if self.config.use_mysql_protocol and self.mysql_connection:
                try:
                    # è½¬æ¢å‚æ•°æ ¼å¼ï¼ˆä»å­—å…¸åˆ°å…ƒç»„ï¼‰
                    params_tuple = None
                    if parameters:
                        # å¯¹äºMySQLåè®®ï¼Œéœ€è¦å°†å­—å…¸å‚æ•°è½¬æ¢ä¸ºä½ç½®å‚æ•°
                        formatted_sql = sql
                        for key, value in parameters.items():
                            formatted_sql = formatted_sql.replace(f"${key}", "%s")
                            if params_tuple is None:
                                params_tuple = (value,)
                            else:
                                params_tuple += (value,)
                        sql = formatted_sql
                    
                    df = await circuit_breaker.async_call(
                        self.execute_mysql_query, sql, params_tuple
                    )
                    execution_time = asyncio.get_event_loop().time() - start_time
                    
                    if df is not None:
                        return DorisQueryResult(
                            data=df,
                            execution_time=execution_time,
                            rows_scanned=len(df),
                            bytes_scanned=len(df.to_string()) if hasattr(df, 'to_string') else 0,
                            is_cached=False,
                            query_id=f"mysql_query_{int(start_time)}",
                            fe_host=self.config.fe_hosts[self.current_fe_index]
                        )
                except Exception as e:
                    self.logger.error(f"MySQLåè®®æŸ¥è¯¢å¤±è´¥: {e}")
                    execution_time = asyncio.get_event_loop().time() - start_time
                    raise Exception(f"MySQL query failed: {str(e)}")
            
            # å¦‚æœæ²¡æœ‰MySQLè¿æ¥ï¼Œå°è¯•HTTP API fallback
            self.logger.warning("MySQL connection not available, attempting HTTP API fallback")
            try:
                # æ¸…ç†SQLç”¨äºHTTP API
                cleaned_sql = self._clean_sql(sql)
                fe_host = await self._get_available_fe_host()
                result = await circuit_breaker.async_call(
                    self._execute_http_query, fe_host, start_time, cleaned_sql, parameters
                )
                return result
            except Exception as http_error:
                execution_time = asyncio.get_event_loop().time() - start_time
                self.logger.error(f"HTTP API fallbackä¹Ÿå¤±è´¥: {http_error}")
                raise Exception(f"Both MySQL and HTTP API failed. MySQL: not available, HTTP: {str(http_error)}")
    
    async def _get_databases(self, fe_host: str, start_time: float) -> QueryResult:
        """é€šè¿‡ç®¡ç†APIè·å–æ•°æ®åº“åˆ—è¡¨"""
        
        url = f"http://{fe_host}:{self.config.http_port}/api/show_proc"
        params = {"path": "/dbs"}
        auth = aiohttp.BasicAuth(self.config.username, self.config.password)
        
        async with self.session.get(url, params=params, auth=auth) as response:
            response.raise_for_status()
            result = await response.json()
            
            if result.get("code") != 0:
                raise Exception(f"API error: {result.get('msg', 'Unknown error')}")
            
            # è§£ææ•°æ®åº“åˆ—è¡¨
            data = result.get("data", [])
            databases = []
            for row in data:
                if len(row) >= 2:
                    db_name = row[1]  # ç¬¬äºŒåˆ—æ˜¯æ•°æ®åº“å
                    # è¿‡æ»¤æ‰ç³»ç»Ÿæ•°æ®åº“
                    if db_name not in ['information_schema', '__internal_schema']:
                        databases.append([db_name])
            
            # åˆ›å»º DataFrame
            df = pd.DataFrame(databases, columns=['Database'])
            
            execution_time = asyncio.get_event_loop().time() - start_time
            
            return DorisQueryResult(
                data=df,
                execution_time=execution_time,
                rows_scanned=len(databases),
                bytes_scanned=0,
                is_cached=False,
                query_id="show_databases",
                fe_host=fe_host
            )
    
    async def _get_tables_info(self, fe_host: str, start_time: float, sql: str) -> DorisQueryResult:
        """é€šè¿‡ç®¡ç†APIè·å–è¡¨ä¿¡æ¯"""
        
        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿”å›è¡¨ä¿¡æ¯ï¼Œå®é™…åº”è¯¥è°ƒç”¨ç›¸åº”çš„API
        # ç›®å‰ Doris çš„ç®¡ç†APIæ²¡æœ‰ç›´æ¥çš„è¡¨åˆ—è¡¨æ¥å£ï¼Œéœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è·å–
        
        execution_time = asyncio.get_event_loop().time() - start_time
        
        # è¿”å›ç©ºç»“æœï¼Œè¡¨ç¤ºæ²¡æœ‰ç”¨æˆ·è¡¨æˆ–æš‚ä¸æ”¯æŒ
        df = pd.DataFrame(columns=['table_schema', 'table_name'])
        
        return DorisQueryResult(
            data=df,
            execution_time=execution_time,
            rows_scanned=0,
            bytes_scanned=0,
            is_cached=False,
            query_id="get_tables",
            fe_host=fe_host
        )
    
    async def _get_table_count(self, fe_host: str, start_time: float) -> DorisQueryResult:
        """é€šè¿‡ç®¡ç†APIè·å–è¡¨ç»Ÿè®¡æ•°é‡"""
        
        url = f"http://{fe_host}:{self.config.http_port}/api/show_proc"
        params = {"path": "/statistic"}
        auth = aiohttp.BasicAuth(self.config.username, self.config.password)
        
        async with self.session.get(url, params=params, auth=auth) as response:
            response.raise_for_status()
            result = await response.json()
            
            if result.get("code") != 0:
                raise Exception(f"API error: {result.get('msg', 'Unknown error')}")
            
            # è§£æç»Ÿè®¡æ•°æ®
            data = result.get("data", [])
            total_tables = 0
            
            for row in data:
                if len(row) >= 3 and row[0] not in ['Total']:
                    db_name = row[1] if len(row) > 1 else ''
                    if db_name not in ['information_schema', '__internal_schema', 'mysql']:
                        table_count = int(row[2]) if row[2].isdigit() else 0
                        total_tables += table_count
            
            # åˆ›å»º DataFrame
            df = pd.DataFrame([[total_tables]], columns=['table_count'])
            
            execution_time = asyncio.get_event_loop().time() - start_time
            
            return DorisQueryResult(
                data=df,
                execution_time=execution_time,
                rows_scanned=1,
                bytes_scanned=0,
                is_cached=False,
                query_id="table_count",
                fe_host=fe_host
            )
    
    async def execute_optimized_query(
        self,
        sql: str, 
        optimization_hints: Optional[List[str]] = None
    ) -> DorisQueryResult:
        """
        æ‰§è¡Œä¼˜åŒ–æŸ¥è¯¢
        
        Args:
            sql: SQLæŸ¥è¯¢è¯­å¥
            optimization_hints: ä¼˜åŒ–æç¤º
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        
        # æ·»åŠ Dorisç‰¹å®šçš„ä¼˜åŒ–æç¤º
        optimized_sql = self._apply_optimization_hints(sql, optimization_hints or [])
        
        return await self.execute_query(optimized_sql)
    
    def _apply_optimization_hints(self, sql: str, hints: List[str]) -> str:
        """åº”ç”¨ä¼˜åŒ–æç¤º"""
        
        hint_comments = []
        
        # åˆ†åŒºè£å‰ªæç¤º
        if "partition_pruning" in hints:
            hint_comments.append("/*+ USE_PARTITION_PRUNE */")
        
        # å‘é‡åŒ–æ‰§è¡Œæç¤º  
        if "vectorization" in hints:
            hint_comments.append("/*+ VECTORIZED_ENGINE */")
        
        # å¹¶è¡Œæ‰§è¡Œæç¤º
        if "parallel_execution" in hints:
            hint_comments.append("/*+ PARALLEL(4) */")
        
        # ç´¢å¼•æç¤º
        if "index_optimization" in hints:
            hint_comments.append("/*+ USE_INDEX */")
        
        # å°†æç¤ºæ·»åŠ åˆ°SQLå¼€å¤´
        if hint_comments:
            hint_str = " ".join(hint_comments)
            return f"{hint_str} {sql}"
        
        return sql
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨ç»“æ„"""
        
        sql = f"DESCRIBE {table_name}"
        
        try:
            result = await self.execute_query(sql)
            
            schema_info = {
                "table_name": table_name,
                "columns": [],
                "total_columns": len(result.data)
            }
            
            for _, row in result.data.iterrows():
                column_info = {
                    "name": row.get("Field", ""),
                    "type": row.get("Type", ""),
                    "nullable": row.get("Null", "") == "YES",
                    "key": row.get("Key", ""),
                    "default": row.get("Default", ""),
                    "extra": row.get("Extra", "")
                }
                schema_info["columns"].append(column_info)
            
            return schema_info
            
        except Exception as e:
            self.logger.error(f"Failed to get table schema: {e}")
            return {"error": str(e)}
    
    async def get_all_tables(self) -> List[str]:
        """è·å–æ‰€æœ‰è¡¨å"""
        try:
            # ä¼˜å…ˆä½¿ç”¨MySQLåè®®è·å–è¡¨åˆ—è¡¨
            if self.config.use_mysql_protocol and self.mysql_connection:
                try:
                    tables = await self.get_tables_mysql(self.config.database)
                    if tables:
                        # è¿‡æ»¤å¼‚å¸¸å ä½å†…å®¹
                        tables = [t for t in tables if t and t.lower() != 'query not supported']
                        self.logger.info(f"âœ… MySQLåè®®è·å–è¡¨åˆ—è¡¨æˆåŠŸ: {len(tables)} ä¸ªè¡¨")
                        return tables
                except Exception as e:
                    self.logger.warning(f"MySQLåè®®è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
            
            # å›é€€åˆ°ä½¿ç”¨SHOW TABLESæŸ¥è¯¢
            try:
                result = await self.execute_query("SHOW TABLES")
                tables = []
                
                if hasattr(result, 'data') and not result.data.empty:
                    # è·å–ç¬¬ä¸€åˆ—çš„æ‰€æœ‰å€¼ä½œä¸ºè¡¨å
                    table_column = result.data.iloc[:, 0]  # ç¬¬ä¸€åˆ—
                    tables = [str(x) for x in table_column.tolist()]
                    
                    # è¿‡æ»¤ç³»ç»Ÿè¡¨å’Œå¼‚å¸¸å ä½è¡Œ
                    tables = [table for table in tables if table and not table.startswith('__') and table.lower() != 'query not supported']
                    
                    self.logger.info(f"âœ… SHOW TABLESè·å–è¡¨åˆ—è¡¨æˆåŠŸ: {len(tables)} ä¸ªè¡¨")
                    return tables
                else:
                    self.logger.warning("SHOW TABLESè¿”å›ç©ºç»“æœ")
                    return []
                    
            except Exception as e:
                self.logger.warning(f"SHOW TABLESæŸ¥è¯¢å¤±è´¥: {e}")
            
            # æœ€åå°è¯•ä½¿ç”¨ç®¡ç†API
            try:
                fe_host = await self._get_available_fe_host()
                url = f"http://{fe_host}:{self.config.http_port}/api/show_proc"
                params = {"path": f"/dbs/{self.config.database}"}
                auth = aiohttp.BasicAuth(self.config.username, self.config.password)
                
                async with self.session.get(url, params=params, auth=auth) as response:
                    response.raise_for_status()
                    result = await response.json()
                    
                    if result.get("code") != 0:
                        self.logger.warning(f"ç®¡ç†APIè·å–è¡¨åˆ—è¡¨å¤±è´¥: {result.get('msg', 'Unknown error')}")
                        return []
                    
                    # ä»ç»“æœä¸­æå–è¡¨å
                    tables = []
                    data = result.get("data", [])
                    for row in data:
                        if len(row) >= 2:
                            table_name = str(row[1])  # è¡¨åé€šå¸¸åœ¨ç¬¬äºŒåˆ—
                            # è¿‡æ»¤ç³»ç»Ÿè¡¨å’Œå¼‚å¸¸å ä½
                            if table_name and not table_name.startswith('__') and table_name.lower() != 'query not supported':
                                tables.append(table_name)
                    
                    self.logger.info(f"âœ… ç®¡ç†APIè·å–è¡¨åˆ—è¡¨æˆåŠŸ: {len(tables)} ä¸ªè¡¨")
                    return tables
                    
            except Exception as e:
                self.logger.error(f"ç®¡ç†APIè·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
                
            return []
                
        except Exception as e:
            self.logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def get_fields(self, table_name: Optional[str] = None) -> List[str]:
        """è·å–å­—æ®µåˆ—è¡¨ - å®ç°BaseConnectoræŠ½è±¡æ–¹æ³•"""
        return await self.get_table_fields(table_name)
    
    async def get_tables(self) -> List[str]:
        """è·å–è¡¨åˆ—è¡¨ - å®ç°BaseConnectoræŠ½è±¡æ–¹æ³•"""
        return await self.get_all_tables()
    
    async def get_databases(self, database_name: Optional[str] = None) -> List[str]:
        """è·å–æ•°æ®åº“åˆ—è¡¨ - ä¼˜å…ˆä½¿ç”¨MySQLåè®®"""
        if self.config.use_mysql_protocol and self.mysql_connection:
            return await self.get_databases_mysql()
        
        # å›é€€åˆ°HTTP API
        try:
            if not self.session:
                await self.connect()
            
            fe_host = await self._get_available_fe_host()
            start_time = asyncio.get_event_loop().time()
            
            result = await self._get_databases(fe_host, start_time)
            
            # ä»DataFrameä¸­æå–æ•°æ®åº“åç§°
            if not result.data.empty:
                return result.data['Database'].tolist()
            else:
                return []
                
        except Exception as e:
            self.logger.error(f"Failed to get databases: {e}")
            return []
    
    async def get_table_fields(self, table_name: str = None) -> List[str]:
        """è·å–è¡¨çš„å­—æ®µåˆ—è¡¨ï¼Œå¦‚æœæœªæŒ‡å®šè¡¨ååˆ™è·å–æ‰€æœ‰è¡¨çš„å­—æ®µ"""
        try:
            if table_name:
                # è·å–æŒ‡å®šè¡¨çš„å­—æ®µ
                schema = await self.get_table_schema(table_name)
                if "error" in schema:
                    return []
                return [col["name"] for col in schema.get("columns", [])]
            else:
                # è·å–æ‰€æœ‰è¡¨çš„å­—æ®µ
                all_fields = set()
                tables = await self.get_all_tables()
                
                for table in tables[:5]:  # é™åˆ¶æ£€æŸ¥å‰5ä¸ªè¡¨ä»¥é¿å…è¿‡å¤šè¯·æ±‚
                    try:
                        schema = await self.get_table_schema(table)
                        if "error" not in schema:
                            for col in schema.get("columns", []):
                                all_fields.add(col["name"])
                    except Exception as e:
                        self.logger.warning(f"Failed to get schema for table {table}: {e}")
                        continue
                
                return list(all_fields)
                
        except Exception as e:
            self.logger.error(f"Failed to get table fields: {e}")
            return []
    
    async def get_table_statistics(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        
        sql = f"SHOW TABLE STATUS LIKE '{table_name}'"
        
        try:
            result = await self.execute_query(sql)
            
            if not result.data.empty:
                row = result.data.iloc[0]
                return {
                    "table_name": table_name,
                    "rows": row.get("Rows", 0),
                    "data_length": row.get("Data_length", 0),
                    "index_length": row.get("Index_length", 0),
                    "create_time": row.get("Create_time", ""),
                    "update_time": row.get("Update_time", ""),
                    "engine": row.get("Engine", "")
                }
            
            return {"error": "Table not found"}
            
        except Exception as e:
            self.logger.error(f"Failed to get table statistics: {e}")
            return {"error": str(e)}
    
    async def bulk_load_data(
        self,
        table_name: str,
        data: pd.DataFrame,
        load_label: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡åŠ è½½æ•°æ®ï¼ˆStream Loadï¼‰
        
        Args:
            table_name: ç›®æ ‡è¡¨å
            data: è¦åŠ è½½çš„æ•°æ®
            load_label: åŠ è½½æ ‡ç­¾
            
        Returns:
            åŠ è½½ç»“æœ
        """
        
        if load_label is None:
            load_label = f"load_{table_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # é€‰æ‹©å¯ç”¨çš„FEèŠ‚ç‚¹
        fe_host = await self._get_available_fe_host()
        
        # æ„å»ºStream Load URL
        load_url = f"http://{fe_host}:{self.config.http_port}/api/{self.config.database}/{table_name}/_stream_load"
        
        # å‡†å¤‡è®¤è¯
        auth = aiohttp.BasicAuth(self.config.username, self.config.password)
        
        # è½¬æ¢æ•°æ®ä¸ºCSVæ ¼å¼
        csv_data = data.to_csv(index=False, header=False)
        
        # è®¾ç½®åŠ è½½å¤´éƒ¨
        headers = {
            "label": load_label,
            "format": "csv",
            "Content-Type": "text/plain"
        }
        
        try:
            async with self.session.put(
                load_url,
                data=csv_data,
                auth=auth,
                headers=headers
            ) as response:
                response.raise_for_status()
                result = await response.json()
            
            return {
                "success": result.get("Status") == "Success",
                "message": result.get("Message", ""),
                "load_label": load_label,
                "rows_loaded": result.get("NumberLoadedRows", 0),
                "rows_filtered": result.get("NumberFilteredRows", 0),
                "load_bytes": result.get("LoadBytes", 0),
                "load_time_ms": result.get("LoadTimeMs", 0)
            }
            
        except Exception as e:
            self.logger.error(f"Bulk load failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "load_label": load_label
            }
    
    async def _get_available_fe_host(self) -> str:
        """è·å–å¯ç”¨çš„FEèŠ‚ç‚¹"""
        
        if not self.config.load_balance:
            return self.config.fe_hosts[0]
        
        # ç®€å•çš„è½®è¯¢è´Ÿè½½å‡è¡¡
        fe_host = self.config.fe_hosts[self.current_fe_index]
        self.current_fe_index = (self.current_fe_index + 1) % len(self.config.fe_hosts)
        
        return fe_host
    
    async def _switch_fe_host(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªFEèŠ‚ç‚¹"""
        self.current_fe_index = (self.current_fe_index + 1) % len(self.config.fe_hosts)
        self.logger.info(f"Switched to FE host: {self.config.fe_hosts[self.current_fe_index]}")
    
    def _parse_query_result(self, result_data: Dict[str, Any]) -> pd.DataFrame:
        """è§£ææŸ¥è¯¢ç»“æœä¸ºDataFrame"""
        
        try:
            # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
            if result_data.get("code") != 0:
                raise Exception(f"Query failed: {result_data.get('msg', 'Unknown error')}")
            
            # è·å–æ•°æ®å’Œå…ƒæ•°æ®
            data = result_data.get("data", [])
            meta = result_data.get("meta", [])
            
            if not data:
                # è¿”å›ç©ºDataFrameä½†ä¿æŒåˆ—ç»“æ„
                columns = [col.get("name", f"col_{i}") for i, col in enumerate(meta)]
                return pd.DataFrame(columns=columns)
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(data)
            
            # è®¾ç½®åˆ—å
            if meta:
                column_names = [col.get("name", f"col_{i}") for i, col in enumerate(meta)]
                if len(column_names) == len(df.columns):
                    df.columns = column_names
            
            # ç±»å‹è½¬æ¢
            if meta:
                for i, col_meta in enumerate(meta):
                    if i < len(df.columns):
                        col_name = df.columns[i]
                        col_type = col_meta.get("type", "").lower()
                        
                        try:
                            if "int" in col_type:
                                df[col_name] = pd.to_numeric(df[col_name], errors='coerce')
                            elif "float" in col_type or "double" in col_type or "decimal" in col_type:
                                df[col_name] = pd.to_numeric(df[col_name], errors='coerce')
                            elif "date" in col_type or "time" in col_type:
                                df[col_name] = pd.to_datetime(df[col_name], errors='coerce')
                            elif "bool" in col_type:
                                df[col_name] = df[col_name].astype(bool)
                        except Exception as e:
                            self.logger.warning(f"Failed to convert column {col_name} to {col_type}: {e}")
            
            return df
            
        except Exception as e:
            self.logger.error(f"Failed to parse query result: {e}")
            return pd.DataFrame()
    
    async def _handle_unknown_table_query(self, fe_host: str, start_time: float, sql: str) -> DorisQueryResult:
        """å¤„ç†UNKNOWN_TABLEæŸ¥è¯¢ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®"""
        execution_time = asyncio.get_event_loop().time() - start_time
        
        # è¿”å›æ¨¡æ‹Ÿçš„è®¡æ•°ç»“æœ
        df = pd.DataFrame([[0]], columns=['COUNT'])
        
        return DorisQueryResult(
            data=df,
            execution_time=execution_time,
            rows_scanned=1,
            bytes_scanned=0,
            is_cached=False,
            query_id="unknown_table_query",
            fe_host=fe_host
        )
    
    async def _process_http_response(self, response, start_time: float, fe_host: str) -> DorisQueryResult:
        """å¤„ç†HTTPå“åº”"""
        if response.status == 200:
            result = await response.json()
            
            # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”ï¼ˆå¯é€‰ï¼‰
            # self.logger.info(f"ğŸ” Doris HTTP å“åº”: {result}")
            
            # å¢å¼ºçš„é”™è¯¯æ—¥å¿—
            if result.get("code") != 0:
                error_info = {
                    "code": result.get("code", "Unknown"),
                    "msg": result.get("msg", ""),
                    "exception": result.get("exception", ""),
                    "data": result.get("data", ""),
                    "full_response": result
                }
                self.logger.error(f"Doris HTTP API è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_info}")
                
                # æ„å»ºæ›´è¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯
                error_details = []
                if result.get("msg"):
                    error_details.append(f"æ¶ˆæ¯: {result.get('msg')}")
                if result.get("exception"):
                    error_details.append(f"å¼‚å¸¸: {result.get('exception')}")
                if result.get("code"):
                    error_details.append(f"ä»£ç : {result.get('code')}")
                
                error_message = "; ".join(error_details) if error_details else "Unknown error"
                raise Exception(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {error_message}")
            
            # è§£æDoris HTTPæŸ¥è¯¢APIå“åº”
            # Doris APIè¿”å›ç»“æ„: {"data": {"type": "result_set", "meta": [...], "data": [...] }, "msg": "success", "code": 0}
            response_data = result.get("data", {})
            data = response_data.get("data", [])
            columns = response_data.get("meta", [])
            
            # æ„å»ºDataFrame
            if data and columns:
                column_names = [col.get("name", f"col_{i}") for i, col in enumerate(columns)]
                df = pd.DataFrame(data, columns=column_names)
            else:
                df = pd.DataFrame()
            
            execution_time = asyncio.get_event_loop().time() - start_time
            
            return DorisQueryResult(
                data=df,
                execution_time=execution_time,
                rows_scanned=len(data),
                bytes_scanned=len(str(data)) if data else 0,
                is_cached=False,
                query_id=result.get("queryId", "http_query"),
                fe_host=fe_host
            )
        else:
            # è·å–å“åº”æ–‡æœ¬ä»¥æä¾›æ›´å¤šä¿¡æ¯
            try:
                response_text = await response.text()
                self.logger.error(f"HTTPå“åº”é”™è¯¯è¯¦æƒ…: Status={response.status}, Body={response_text}")
                raise Exception(f"HTTPæŸ¥è¯¢APIè¿”å›é”™è¯¯çŠ¶æ€: {response.status}, å“åº”: {response_text[:200]}")
            except:
                raise Exception(f"HTTPæŸ¥è¯¢APIè¿”å›é”™è¯¯çŠ¶æ€: {response.status}")
    
    async def _execute_http_query(self, fe_host: str, start_time: float, sql: str, parameters: Optional[Dict] = None) -> DorisQueryResult:
        """ä½¿ç”¨HTTPæŸ¥è¯¢æ¥å£æ‰§è¡Œä¸€èˆ¬SQLæŸ¥è¯¢"""
        try:
            # ç¡®ä¿sessionå·²åˆå§‹åŒ–
            if not self.session:
                await self.connect()
            
            # å¤„ç†å‚æ•°æ›¿æ¢
            formatted_sql = sql
            if parameters:
                for key, value in parameters.items():
                    formatted_sql = formatted_sql.replace(f"${key}", str(value))
            
            # å°è¯•å¤šä¸ªDoris HTTPæŸ¥è¯¢APIç«¯ç‚¹
            endpoints_to_try = [
                # Doris 2.xçš„æŸ¥è¯¢API (å·²éªŒè¯å¯ç”¨)
                f"http://{fe_host}:{self.config.http_port}/api/query/default_cluster/{self.config.database}",
                # ç§»é™¤äº†å…¶ä»–è¿”å›HTMLè€ŒéJSONçš„ç«¯ç‚¹
            ]
            
            auth = aiohttp.BasicAuth(self.config.username, self.config.password)
            
            # å°è¯•ä¸åŒçš„è¯·æ±‚æ–¹å¼
            request_methods = [
                # æ–¹æ³•1: POST with JSON (Doris 2.x uses 'stmt' not 'sql')
                {
                    "method": "post",
                    "headers": {"Content-Type": "application/json"},
                    "data_type": "json",
                    "data": {"stmt": formatted_sql}
                }
            ]
            
            for url in endpoints_to_try:
                for method_config in request_methods:
                    try:
                        self.logger.info(f"å°è¯•HTTPæŸ¥è¯¢: {method_config['method'].upper()} {url}")
                        self.logger.info(f"è¯·æ±‚æ•°æ®: {method_config['data']}")
                        
                        # ç¡®ä¿sessionå¯ç”¨
                        if not self.session or self.session.closed:
                            self.logger.warning("Sessionä¸å¯ç”¨ï¼Œé‡æ–°è¿æ¥")
                            await self.connect()
                        
                        if method_config["data_type"] == "json":
                            async with getattr(self.session, method_config["method"])(
                                url, 
                                json=method_config["data"], 
                                auth=auth, 
                                headers=method_config["headers"]
                            ) as response:
                                self.logger.info(f"HTTPå“åº”çŠ¶æ€: {response.status}")
                                return await self._process_http_response(response, start_time, fe_host)
                                
                        elif method_config["data_type"] == "form":
                            # ç¡®ä¿sessionå¯ç”¨
                            if not self.session or self.session.closed:
                                self.logger.warning("Sessionä¸å¯ç”¨ï¼Œé‡æ–°è¿æ¥")
                                await self.connect()
                            
                            form_data = aiohttp.FormData()
                            for key, value in method_config["data"].items():
                                form_data.add_field(key, value)
                            async with getattr(self.session, method_config["method"])(
                                url, 
                                data=form_data, 
                                auth=auth, 
                                headers=method_config["headers"]
                            ) as response:
                                return await self._process_http_response(response, start_time, fe_host)
                                
                        elif method_config["data_type"] == "params":
                            # ç¡®ä¿sessionå¯ç”¨
                            if not self.session or self.session.closed:
                                self.logger.warning("Sessionä¸å¯ç”¨ï¼Œé‡æ–°è¿æ¥")
                                await self.connect()
                            
                            async with getattr(self.session, method_config["method"])(
                                url, 
                                params=method_config["data"], 
                                auth=auth, 
                                headers=method_config["headers"]
                            ) as response:
                                return await self._process_http_response(response, start_time, fe_host)
                                
                    except Exception as endpoint_error:
                        self.logger.error(f"ç«¯ç‚¹ {url} æ–¹æ³• {method_config['method']} å¤±è´¥: {endpoint_error}")
                        continue
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºè¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯
            self.logger.error(f"æ‰€æœ‰HTTPæŸ¥è¯¢ç«¯ç‚¹å’Œæ–¹æ³•éƒ½å¤±è´¥")
            self.logger.error(f"å°è¯•çš„SQL: {formatted_sql[:200]}...")
            self.logger.error(f"å°è¯•çš„ç«¯ç‚¹: {endpoints_to_try}")
            raise Exception(f"HTTP query failed:æ‰€æœ‰HTTPæŸ¥è¯¢ç«¯ç‚¹å’Œæ–¹æ³•éƒ½å¤±è´¥ã€‚è¯·æ£€æŸ¥DorisæœåŠ¡çŠ¶æ€å’Œç½‘ç»œè¿æ¥ã€‚")
                    
        except Exception as e:
            # HTTPæŸ¥è¯¢å¤±è´¥æ—¶ä¸è¦ä¼ªé€ æ•°æ®ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚æ„ŸçŸ¥é”™è¯¯
            execution_time = asyncio.get_event_loop().time() - start_time
            self.logger.warning(f"HTTPæŸ¥è¯¢å¤±è´¥: {e}, SQL: {formatted_sql[:200] if 'formatted_sql' in locals() else 'SQLæœªçŸ¥'}...")
            raise Exception(f"HTTP query failed: {e}")

    async def get_table_columns(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        try:
            # ä½¿ç”¨ DESCRIBE å‘½ä»¤è·å–è¡¨ç»“æ„
            sql = f"DESCRIBE {table_name}"
            result = await self.execute_query(sql)
            
            if hasattr(result, 'to_dict'):
                result_dict = result.to_dict()
                data = result_dict.get("data", [])
                
                # è½¬æ¢æ ¼å¼
                table_columns = []
                for row in data:
                    if len(row) >= 4:  # Field, Type, Null, Key, Default, Extra
                        column_info = {
                            "name": row[0] if len(row) > 0 else "",
                            "type": row[1] if len(row) > 1 else "",
                            "nullable": row[2] if len(row) > 2 else "",
                            "key": row[3] if len(row) > 3 else "",
                            "default": row[4] if len(row) > 4 else None,
                            "extra": row[5] if len(row) > 5 else ""
                        }
                        table_columns.append(column_info)
                
                if table_columns:
                    return table_columns
                else:
                    # å¦‚æœæ²¡æœ‰è·å–åˆ°åˆ—ä¿¡æ¯ï¼Œè¿”å›é»˜è®¤ç»“æ„
                    return [{"name": "id", "type": "varchar", "nullable": "YES", "key": "", "default": None, "extra": ""}]
            else:
                # å¦‚æœç»“æœæ ¼å¼ä¸æ ‡å‡†ï¼Œè¿”å›åŸºæœ¬ç»“æ„
                return [{"name": "id", "type": "varchar", "nullable": "YES", "key": "", "default": None, "extra": ""}]
                
        except Exception as e:
            self.logger.warning(f"è·å–è¡¨ {table_name} ç»“æ„å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æ„
            return [{"name": "id", "type": "varchar", "nullable": "YES", "key": "", "default": None, "extra": ""}]


# å·¥å‚å‡½æ•°
def create_doris_connector(data_source: DataSource) -> DorisConnector:
    """åˆ›å»ºDorisè¿æ¥å™¨"""
    return DorisConnector.from_data_source(data_source)