"""
ETL Data Persistence Service

ETLæ•°æ®æŒä¹…åŒ–æœåŠ¡ - ç²¾ç®€ç‰ˆï¼ˆé’ˆå¯¹100å ä½ç¬¦åœºæ™¯ä¼˜åŒ–ï¼‰

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å°†ETLæå–çš„æ•°æ®æ‰¹é‡ä¿å­˜åˆ°placeholder_valuesè¡¨
2. æ”¯æŒæ‰¹æ¬¡ç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶
3. æä¾›ç¼“å­˜é”®ç”Ÿæˆï¼ˆä¸ºåç»­ç¼“å­˜ä¼˜åŒ–é¢„ç•™ï¼‰
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List
from uuid import UUID
from sqlalchemy.orm import Session

from app import crud
from app.schemas.placeholder_value import PlaceholderValueCreate

logger = logging.getLogger(__name__)


class ETLPersistenceService:
    """ETLæ•°æ®æŒä¹…åŒ–æœåŠ¡"""

    def __init__(self, db: Session):
        """
        åˆå§‹åŒ–æŒä¹…åŒ–æœåŠ¡

        Args:
            db: æ•°æ®åº“ä¼šè¯ï¼ˆç”±è°ƒç”¨æ–¹ç»Ÿä¸€ç®¡ç†äº‹åŠ¡ï¼‰
        """
        self.db = db
        self.logger = logger

    @staticmethod
    def generate_batch_id() -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„æ‰¹æ¬¡ID

        Returns:
            æ ¼å¼: batch_YYYYMMDDHHMMSS_<uuid8ä½>
        """
        import uuid
        timestamp = datetime.utcnow().strftime("%Y%m%d%H%M%S")
        return f"batch_{timestamp}_{str(uuid.uuid4())[:8]}"

    async def persist_etl_results(
        self,
        template_id: str,
        etl_results: Dict[str, Any],
        batch_id: str,
        time_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æŒä¹…åŒ–ETLç»“æœåˆ°placeholder_valuesè¡¨ï¼ˆç²¾ç®€ç‰ˆ - 100å ä½ç¬¦ä¼˜åŒ–ï¼‰

        æ ¸å¿ƒé€»è¾‘ï¼š
        1. éå†æ‰€æœ‰æˆåŠŸæå–çš„æ•°æ®
        2. æ‰¹é‡æ„å»ºPlaceholderValueå¯¹è±¡
        3. ä¸€æ¬¡æ€§æ‰¹é‡æ’å…¥
        4. ä¸åœ¨æ­¤commitï¼ˆç”±è°ƒç”¨æ–¹ç»Ÿä¸€ç®¡ç†äº‹åŠ¡ï¼‰

        Args:
            template_id: æ¨¡æ¿ID
            etl_results: ETLæ‰§è¡Œç»“æœï¼ˆæ¥è‡ª_execute_etl_pipelineï¼‰
            batch_id: æ‰¹æ¬¡ID
            time_context: æ—¶é—´ä¸Šä¸‹æ–‡

        Returns:
            æŒä¹…åŒ–ç»“æœç»Ÿè®¡
            {
                "success": True/False,
                "batch_id": "batch_xxx",
                "saved_count": 100,
                "failed_count": 0,
                "message": "æŒä¹…åŒ–å®Œæˆ: æˆåŠŸ100, å¤±è´¥0"
            }
        """
        try:
            saved_count = 0
            failed_count = 0
            values_to_create = []  # æ”¶é›†æ‰€æœ‰è¦æ’å…¥çš„æ•°æ®

            execution_time = time_context.get("execution_time") or datetime.utcnow()
            period_start = time_context.get("period_start")
            period_end = time_context.get("period_end")

            self.logger.info(f"ğŸ“¦ å¼€å§‹æŒä¹…åŒ–ETLç»“æœ, batch_id={batch_id}")

            # éå†æ¯ä¸ªæ•°æ®æºçš„ç»“æœ
            for data_source_id, source_result in etl_results.items():
                extract_data = source_result.get("extract", {}).get("data", {})
                successful_extractions = extract_data.get("successful_extractions", [])

                self.logger.info(f"   æ•°æ®æº {data_source_id}: {len(successful_extractions)} ä¸ªå ä½ç¬¦")

                for extraction in successful_extractions:
                    try:
                        placeholder_name = extraction["placeholder"]

                        # æŸ¥æ‰¾å ä½ç¬¦é…ç½®
                        placeholder = crud.template_placeholder.get_by_template_and_name(
                            db=self.db,
                            template_id=template_id,
                            name=placeholder_name
                        )

                        if not placeholder:
                            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å ä½ç¬¦é…ç½®: {placeholder_name}")
                            failed_count += 1
                            continue

                        # æ„å»ºæ•°æ®ï¼ˆç®€åŒ–ç‰ˆ - åªä¿ç•™æ ¸å¿ƒå­—æ®µï¼‰
                        value_data = PlaceholderValueCreate(
                            placeholder_id=placeholder.id,
                            data_source_id=UUID(data_source_id),
                            raw_query_result=extraction["data"],
                            processed_value=extraction["data"],
                            formatted_text=self._format_data(extraction["data"]),
                            execution_sql=placeholder.generated_sql,
                            row_count=extraction.get("row_count", 0),
                            success=True,
                            source="etl",
                            confidence_score=1.0,
                            analysis_metadata={
                                "extraction_mode": extract_data.get("extraction_mode"),
                                "execution_mode": extract_data.get("execution_mode"),
                                "base_date": str(extract_data.get("base_date", ""))
                            },
                            # æ—¶é—´ä¿¡æ¯
                            execution_time=execution_time,
                            period_start=period_start,
                            period_end=period_end,
                            sql_parameters_snapshot=time_context.get("additional_params", {}),
                            # ç‰ˆæœ¬æ§åˆ¶
                            execution_batch_id=batch_id,
                            is_latest_version=True,
                            # ç¼“å­˜ä¿¡æ¯ï¼ˆé¢„ç•™ï¼Œå¯é€‰ï¼‰
                            cache_key=self._generate_cache_key(
                                str(placeholder.id),
                                data_source_id,
                                period_start,
                                period_end
                            ) if period_start else None,
                            expires_at=datetime.utcnow() + timedelta(hours=placeholder.cache_ttl_hours or 24)
                        )

                        values_to_create.append(value_data)
                        saved_count += 1

                    except Exception as e:
                        self.logger.error(f"âŒ å¤„ç†å ä½ç¬¦å¤±è´¥: {extraction.get('placeholder')}, {e}")
                        failed_count += 1

            # ğŸ”‘ æ‰¹é‡æ’å…¥ï¼ˆä¸€æ¬¡æ€§æ’å…¥100æ¡ï¼‰
            if values_to_create:
                crud.placeholder_value.create_batch(self.db, values=values_to_create)
                self.logger.info(f"âœ… æ‰¹é‡æ’å…¥ {len(values_to_create)} æ¡è®°å½•åˆ°placeholder_valuesè¡¨")

            # ğŸ”‘ æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œcommitï¼Œç”±è°ƒç”¨æ–¹ï¼ˆtask_execution_serviceï¼‰ç»Ÿä¸€ç®¡ç†äº‹åŠ¡

            result = {
                "success": True,
                "batch_id": batch_id,
                "saved_count": saved_count,
                "failed_count": failed_count,
                "message": f"æŒä¹…åŒ–å®Œæˆ: æˆåŠŸ{saved_count}, å¤±è´¥{failed_count}"
            }

            self.logger.info(f"âœ… {result['message']}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ ETLæ•°æ®æŒä¹…åŒ–å¤±è´¥: {e}")
            self.logger.exception(e)
            raise

    async def persist_failed_extractions(
        self,
        template_id: str,
        failed_extractions: List[Dict[str, Any]],
        batch_id: str,
        data_source_id: str
    ) -> int:
        """
        æŒä¹…åŒ–å¤±è´¥çš„æå–è®°å½•ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

        Args:
            template_id: æ¨¡æ¿ID
            failed_extractions: å¤±è´¥çš„æå–åˆ—è¡¨
            batch_id: æ‰¹æ¬¡ID
            data_source_id: æ•°æ®æºID

        Returns:
            ä¿å­˜çš„å¤±è´¥è®°å½•æ•°
        """
        saved_count = 0

        for extraction in failed_extractions:
            try:
                placeholder_name = extraction["placeholder"]

                placeholder = crud.template_placeholder.get_by_template_and_name(
                    db=self.db,
                    template_id=template_id,
                    name=placeholder_name
                )

                if not placeholder:
                    continue

                value_data = PlaceholderValueCreate(
                    placeholder_id=placeholder.id,
                    data_source_id=UUID(data_source_id),
                    success=False,
                    error_message=extraction.get("error", "Unknown error"),
                    execution_batch_id=batch_id,
                    source="etl",
                    execution_time=datetime.utcnow()
                )

                crud.placeholder_value.create(self.db, obj_in=value_data)
                saved_count += 1

            except Exception as e:
                self.logger.error(f"âŒ æŒä¹…åŒ–å¤±è´¥è®°å½•å¼‚å¸¸: {extraction.get('placeholder')}, {e}")

        if saved_count > 0:
            self.logger.info(f"âœ… è®°å½•äº† {saved_count} ä¸ªå¤±è´¥çš„æå–")

        return saved_count

    @staticmethod
    def _format_data(data: Any) -> str:
        """
        ç®€å•æ ¼å¼åŒ–æ•°æ®ä¸ºæ–‡æœ¬æ˜¾ç¤º

        Args:
            data: åŸå§‹æ•°æ®

        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if isinstance(data, (int, float)):
            return str(data)
        elif isinstance(data, dict):
            if len(data) == 1:
                return str(list(data.values())[0])
            return str(data)
        elif isinstance(data, list):
            if len(data) == 0:
                return "0"
            elif len(data) == 1 and isinstance(data[0], dict):
                if len(data[0]) == 1:
                    return str(list(data[0].values())[0])
            return f"{len(data)} æ¡è®°å½•"
        else:
            return str(data)

    @staticmethod
    def _generate_cache_key(
        placeholder_id: str,
        data_source_id: str,
        period_start: Any,
        period_end: Any
    ) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®ï¼ˆé¢„ç•™åŠŸèƒ½ï¼Œç”¨äºåç»­ç¼“å­˜ä¼˜åŒ–ï¼‰

        Args:
            placeholder_id: å ä½ç¬¦ID
            data_source_id: æ•°æ®æºID
            period_start: å‘¨æœŸå¼€å§‹æ—¶é—´
            period_end: å‘¨æœŸç»“æŸæ—¶é—´

        Returns:
            ç¼“å­˜é”®
        """
        import hashlib

        key_parts = [
            str(placeholder_id),
            str(data_source_id),
            str(period_start) if period_start else "none",
            str(period_end) if period_end else "none"
        ]
        key_string = "_".join(key_parts)
        return hashlib.md5(key_string.encode()).hexdigest()
