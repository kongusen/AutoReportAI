"""
Wordæ–‡æ¡£ç”Ÿæˆæµæ°´çº¿ç³»ç»Ÿ

åŸºäºæ¨¡æ¿çš„ç¨³å®šæ–‡æ¡£ç”Ÿæˆæµæ°´çº¿ï¼Œæ”¯æŒï¼š
1. æ¨¡æ¿è§£æå’ŒéªŒè¯
2. å ä½ç¬¦æ›¿æ¢
3. æ ¼å¼åŒ–å’Œæ ·å¼åº”ç”¨
4. Wordæ–‡æ¡£ç”Ÿæˆå’Œå¯¼å‡º
5. æ–‡æ¡£è´¨é‡æ£€æŸ¥
"""

import asyncio
import json
import logging
import os
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Union
from datetime import datetime
import uuid
import base64

# å°è¯•å¯¼å…¥python-docxï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ¨¡æ‹Ÿ
try:
    from docx import Document
    from docx.shared import Inches, Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.oxml.ns import qn
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

logger = logging.getLogger(__name__)


class DocumentFormat(Enum):
    """æ–‡æ¡£æ ¼å¼æšä¸¾"""
    DOCX = "docx"
    PDF = "pdf"
    HTML = "html"
    MARKDOWN = "md"


class ContentType(Enum):
    """å†…å®¹ç±»å‹æšä¸¾"""
    TEXT = "text"
    TABLE = "table"
    CHART = "chart"
    IMAGE = "image"
    LIST = "list"
    PARAGRAPH = "paragraph"


@dataclass
class PlaceholderInfo:
    """å ä½ç¬¦ä¿¡æ¯"""
    name: str
    type: str
    description: str
    content_type: ContentType
    required: bool = True
    default_value: str = ""
    format_rules: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DocumentTemplate:
    """æ–‡æ¡£æ¨¡æ¿"""
    template_id: str
    name: str
    content: str
    placeholders: List[PlaceholderInfo]
    styles: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ProcessedContent:
    """å¤„ç†åçš„å†…å®¹"""
    placeholder_name: str
    content_type: ContentType
    raw_content: Any
    formatted_content: str
    style_info: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DocumentGenerationResult:
    """æ–‡æ¡£ç”Ÿæˆç»“æœ"""
    success: bool
    document_path: str
    document_format: DocumentFormat
    generation_time: float
    placeholder_count: int
    processed_placeholders: int
    failed_placeholders: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class TemplateParser:
    """æ¨¡æ¿è§£æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        # æ”¯æŒå•èŠ±æ‹¬å·å’ŒåŒèŠ±æ‹¬å·æ ¼å¼çš„å ä½ç¬¦
        self.placeholder_pattern = r'\{\{([^}]+)\}\}|\{([^}]+)\}'
    
    def parse_template(self, template_content: str) -> DocumentTemplate:
        """è§£ææ¨¡æ¿å†…å®¹"""
        template_id = str(uuid.uuid4())
        
        # æå–å ä½ç¬¦
        placeholders = self._extract_placeholders(template_content)
        
        # åˆ†ææ¨¡æ¿ç»“æ„
        styles = self._analyze_template_styles(template_content)
        
        return DocumentTemplate(
            template_id=template_id,
            name="Parsed Template",
            content=template_content,
            placeholders=placeholders,
            styles=styles,
            metadata={
                "parsed_at": datetime.now().isoformat(),
                "placeholder_count": len(placeholders)
            }
        )
    
    def extract_placeholders(self, content: str) -> List[Dict[str, Any]]:
        """æå–å ä½ç¬¦ï¼ˆå…¬å…±æ–¹æ³•ï¼‰"""
        # é¦–å…ˆå°è¯•æ£€æµ‹æ˜¯å¦ä¸ºäºŒè¿›åˆ¶Wordæ–‡æ¡£
        text_content = self._extract_text_from_content(content)
        placeholders_info = self._extract_placeholders(text_content)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥å…¼å®¹ç°æœ‰ä»£ç 
        result = []
        for placeholder in placeholders_info:
            result.append({
                "name": placeholder.name,
                "type": placeholder.type,
                "description": placeholder.description,
                "content_type": placeholder.content_type.value if hasattr(placeholder.content_type, 'value') else str(placeholder.content_type),
                "required": placeholder.required
            })
        
        return result
    
    def _extract_text_from_content(self, content: str) -> str:
        """ä»å†…å®¹ä¸­æå–æ–‡æœ¬ï¼ˆæ”¯æŒäºŒè¿›åˆ¶Wordæ–‡æ¡£ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ•°æ®ï¼ˆWordæ–‡æ¡£çš„åå…­è¿›åˆ¶è¡¨ç¤ºï¼‰
        if self._is_binary_content(content):
            self.logger.info("æ£€æµ‹åˆ°äºŒè¿›åˆ¶Wordæ–‡æ¡£ï¼Œå°è¯•è§£æ...")
            try:
                # å°è¯•å°†åå…­è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ•°æ®
                binary_data = bytes.fromhex(content)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºWordæ–‡æ¡£ï¼ˆZIPæ ¼å¼ï¼‰
                if binary_data.startswith(b'PK'):
                    return self._extract_text_from_word_doc(binary_data)
                else:
                    self.logger.warning("æ— æ³•è¯†åˆ«çš„äºŒè¿›åˆ¶æ ¼å¼")
                    return content
            except Exception as e:
                self.logger.error(f"è§£æäºŒè¿›åˆ¶æ–‡æ¡£å¤±è´¥: {e}")
                return content
        else:
            # çº¯æ–‡æœ¬å†…å®¹ï¼Œç›´æ¥è¿”å›
            return content
    
    def _is_binary_content(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ•°æ®çš„åå…­è¿›åˆ¶è¡¨ç¤º"""
        if len(content) > 20 and all(c in '0123456789abcdef' for c in content.lower()):
            # æ£€æŸ¥æ˜¯å¦ä»¥å¸¸è§çš„æ–‡æ¡£æ ¼å¼é­”æœ¯å­—èŠ‚å¼€å¤´
            hex_prefix = content[:20].lower()
            # PKï¼ˆZIP/Wordæ–‡æ¡£ï¼‰= 504b
            # PDF = 255044462d
            if hex_prefix.startswith('504b') or hex_prefix.startswith('255044462d'):
                return True
        return False
    
    def _extract_text_from_word_doc(self, binary_data: bytes) -> str:
        """ä»Wordæ–‡æ¡£äºŒè¿›åˆ¶æ•°æ®ä¸­æå–æ–‡æœ¬"""
        try:
            import tempfile
            import os
            
            # ä¿å­˜äºŒè¿›åˆ¶æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_file:
                temp_file.write(binary_data)
                temp_file_path = temp_file.name
            
            try:
                if HAS_DOCX:
                    # ä½¿ç”¨python-docxè§£æ
                    from docx import Document
                    doc = Document(temp_file_path)
                    
                    # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
                    text_parts = []
                    for paragraph in doc.paragraphs:
                        if paragraph.text.strip():
                            text_parts.append(paragraph.text)
                    
                    # æå–è¡¨æ ¼æ–‡æœ¬
                    for table in doc.tables:
                        for row in table.rows:
                            for cell in row.cells:
                                if cell.text.strip():
                                    text_parts.append(cell.text)
                    
                    extracted_text = '\n'.join(text_parts)
                    self.logger.info(f"æˆåŠŸä»Wordæ–‡æ¡£æå–æ–‡æœ¬ï¼Œé•¿åº¦: {len(extracted_text)}")
                    return extracted_text
                else:
                    self.logger.warning("python-docxä¸å¯ç”¨ï¼Œæ— æ³•è§£æWordæ–‡æ¡£")
                    return ""
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
                    
        except Exception as e:
            self.logger.error(f"è§£æWordæ–‡æ¡£å¤±è´¥: {e}")
            return ""
    
    def _extract_placeholders(self, content: str) -> List[PlaceholderInfo]:
        """æå–å ä½ç¬¦ï¼ˆç§æœ‰æ–¹æ³•ï¼‰"""
        placeholders = []
        matches = re.findall(self.placeholder_pattern, content)
        
        for match in matches:
            # matchæ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä¸¤ä¸ªç»„ï¼š(åŒèŠ±æ‹¬å·åŒ¹é…, å•èŠ±æ‹¬å·åŒ¹é…)
            # å–éç©ºçš„é‚£ä¸ª
            placeholder_name = (match[0] or match[1]).strip()
            
            if not placeholder_name:
                continue
            
            # åˆ†æå ä½ç¬¦ç±»å‹
            content_type = self._infer_content_type(placeholder_name)
            
            placeholder = PlaceholderInfo(
                name=placeholder_name,
                type=self._infer_placeholder_type(placeholder_name),
                description=f"å ä½ç¬¦: {placeholder_name}",
                content_type=content_type,
                required=True
            )
            
            placeholders.append(placeholder)
        
        # å»é‡
        unique_placeholders = []
        seen_names = set()
        
        for placeholder in placeholders:
            if placeholder.name not in seen_names:
                unique_placeholders.append(placeholder)
                seen_names.add(placeholder.name)
        
        return unique_placeholders
    
    def _infer_content_type(self, placeholder_name: str) -> ContentType:
        """æ¨æ–­å†…å®¹ç±»å‹"""
        name_lower = placeholder_name.lower()
        
        if any(keyword in name_lower for keyword in ['å›¾è¡¨', 'chart', 'å›¾', 'å¯è§†åŒ–']):
            return ContentType.CHART
        elif any(keyword in name_lower for keyword in ['è¡¨æ ¼', 'table', 'åˆ—è¡¨', 'list']):
            return ContentType.TABLE
        elif any(keyword in name_lower for keyword in ['å›¾ç‰‡', 'image', 'ç…§ç‰‡']):
            return ContentType.IMAGE
        elif any(keyword in name_lower for keyword in ['æ¸…å•', 'é¡¹ç›®', 'item']):
            return ContentType.LIST
        else:
            return ContentType.TEXT
    
    def _infer_placeholder_type(self, placeholder_name: str) -> str:
        """æ¨æ–­å ä½ç¬¦ç±»å‹"""
        name_lower = placeholder_name.lower()
        
        if any(keyword in name_lower for keyword in ['ç»Ÿè®¡', 'æ•°é‡', 'æ€»æ•°', 'è®¡ç®—']):
            return "statistic"
        elif any(keyword in name_lower for keyword in ['åˆ†æ', 'æ´å¯Ÿ', 'è¶‹åŠ¿']):
            return "analysis"
        elif any(keyword in name_lower for keyword in ['å›¾è¡¨', 'chart']):
            return "chart"
        else:
            return "text"
    
    def _analyze_template_styles(self, content: str) -> Dict[str, Any]:
        """åˆ†ææ¨¡æ¿æ ·å¼"""
        styles = {
            "default_font": "Arial",
            "default_size": 12,
            "heading_styles": {},
            "paragraph_styles": {},
            "table_styles": {}
        }
        
        # åˆ†ææ ‡é¢˜æ ·å¼
        heading_pattern = r'^(#{1,6})\s+(.+)$'
        headings = re.findall(heading_pattern, content, re.MULTILINE)
        
        for heading_level, heading_text in headings:
            level = len(heading_level)
            styles["heading_styles"][f"heading_{level}"] = {
                "font_size": max(16 - level, 10),
                "bold": True,
                "color": "black"
            }
        
        return styles
    
    def parse_doc_placeholders(self, doc_path: str) -> Dict[str, Any]:
        """è§£æDOCæ–‡æ¡£ä¸­çš„å ä½ç¬¦ï¼ˆAPIå…¼å®¹æ–¹æ³•ï¼‰"""
        try:
            # è¯»å–æ–‡æ¡£å†…å®¹
            if HAS_DOCX:
                try:
                    doc = Document(doc_path)
                    text_content = ""
                    for paragraph in doc.paragraphs:
                        text_content += paragraph.text + "\n"
                except Exception as docx_error:
                    self.logger.warning(f"python-docxè§£æå¤±è´¥ï¼Œä½¿ç”¨äºŒè¿›åˆ¶æ–¹å¼: {docx_error}")
                    # é™çº§åˆ°äºŒè¿›åˆ¶è¯»å–
                    with open(doc_path, 'rb') as f:
                        binary_data = f.read()
                    text_content = self._extract_text_from_word_doc(binary_data)
            else:
                # å¦‚æœæ²¡æœ‰python-docxï¼Œå°è¯•äºŒè¿›åˆ¶è¯»å–
                with open(doc_path, 'rb') as f:
                    binary_data = f.read()
                text_content = self._extract_text_from_word_doc(binary_data)
            
            # æå–å ä½ç¬¦
            placeholders_info = self._extract_placeholders(text_content)
            
            # åˆ†ç±»å ä½ç¬¦
            stats_placeholders = []
            chart_placeholders = []
            
            for placeholder in placeholders_info:
                placeholder_dict = {
                    "description": placeholder.description,
                    "placeholder_text": f"{{{{{placeholder.name}}}}}",
                    "placeholder_name": placeholder.name,
                    "placeholder_type": placeholder.type,
                    "content_type": placeholder.content_type.value if hasattr(placeholder.content_type, 'value') else str(placeholder.content_type)
                }
                
                # æ ¹æ®ç±»å‹åˆ†ç±»
                if placeholder.type in ["ç»Ÿè®¡", "statistic", "count", "sum", "average"]:
                    placeholder_dict["analysis_requirements"] = {
                        "data_operation": self._infer_data_operation(placeholder.name),
                        "aggregation_type": self._infer_aggregation_type(placeholder.name),
                        "time_dimension": "æ—¶é—´" in placeholder.name or "å¹´" in placeholder.name or "æœˆ" in placeholder.name,
                        "geographic_dimension": "åœ°åŒº" in placeholder.name or "åŒºåŸŸ" in placeholder.name,
                        "requires_grouping": "åˆ†ç»„" in placeholder.name or "æŒ‰" in placeholder.name
                    }
                    stats_placeholders.append(placeholder_dict)
                elif placeholder.type in ["å›¾è¡¨", "chart", "graph"]:
                    placeholder_dict["chart_requirements"] = {
                        "chart_type": self._infer_chart_type(placeholder.name),
                        "data_series": 1,
                        "x_axis": "category",
                        "y_axis": "value",
                        "show_legend": True
                    }
                    chart_placeholders.append(placeholder_dict)
                else:
                    # é»˜è®¤å½’ç±»ä¸ºç»Ÿè®¡
                    placeholder_dict["analysis_requirements"] = {
                        "data_operation": "unknown",
                        "aggregation_type": None,
                        "time_dimension": False,
                        "geographic_dimension": False,
                        "requires_grouping": False
                    }
                    stats_placeholders.append(placeholder_dict)
            
            return {
                "success": True,
                "stats_placeholders": stats_placeholders,
                "chart_placeholders": chart_placeholders,
                "total_placeholders": len(placeholders_info),
                "document_path": doc_path
            }
            
        except Exception as e:
            self.logger.error(f"è§£æDOCå ä½ç¬¦å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "stats_placeholders": [],
                "chart_placeholders": [],
                "total_placeholders": 0,
                "document_path": doc_path
            }
    
    def _infer_data_operation(self, placeholder_name: str) -> str:
        """æ¨æ–­æ•°æ®æ“ä½œç±»å‹"""
        name_lower = placeholder_name.lower()
        if any(keyword in name_lower for keyword in ['æ€»æ•°', 'æ•°é‡', 'count', 'ä¸ªæ•°']):
            return 'count'
        elif any(keyword in name_lower for keyword in ['æ€»å’Œ', 'åˆè®¡', 'sum', 'æ€»è®¡']):
            return 'sum'
        elif any(keyword in name_lower for keyword in ['å¹³å‡', 'avg', 'average', 'å‡å€¼']):
            return 'average'
        elif any(keyword in name_lower for keyword in ['æœ€å¤§', 'max', 'æœ€é«˜']):
            return 'max'
        elif any(keyword in name_lower for keyword in ['æœ€å°', 'min', 'æœ€ä½']):
            return 'min'
        else:
            return 'unknown'
    
    def _infer_aggregation_type(self, placeholder_name: str) -> Optional[str]:
        """æ¨æ–­èšåˆç±»å‹"""
        name_lower = placeholder_name.lower()
        if any(keyword in name_lower for keyword in ['æŒ‰æœˆ', 'æœˆåº¦', 'monthly']):
            return 'monthly'
        elif any(keyword in name_lower for keyword in ['æŒ‰å¹´', 'å¹´åº¦', 'yearly']):
            return 'yearly'
        elif any(keyword in name_lower for keyword in ['æŒ‰æ—¥', 'æ—¥åº¦', 'daily']):
            return 'daily'
        elif any(keyword in name_lower for keyword in ['æŒ‰åŒºåŸŸ', 'åœ°åŒº', 'region']):
            return 'regional'
        else:
            return None
    
    def _infer_chart_type(self, placeholder_name: str) -> str:
        """æ¨æ–­å›¾è¡¨ç±»å‹"""
        name_lower = placeholder_name.lower()
        if any(keyword in name_lower for keyword in ['æŸ±çŠ¶å›¾', 'bar', 'æ¡å½¢å›¾']):
            return 'bar'
        elif any(keyword in name_lower for keyword in ['æŠ˜çº¿å›¾', 'line', 'è¶‹åŠ¿å›¾']):
            return 'line'
        elif any(keyword in name_lower for keyword in ['é¥¼å›¾', 'pie', 'é¥¼çŠ¶å›¾']):
            return 'pie'
        elif any(keyword in name_lower for keyword in ['æ•£ç‚¹å›¾', 'scatter']):
            return 'scatter'
        else:
            return 'bar'  # é»˜è®¤æŸ±çŠ¶å›¾


class ContentFormatter:
    """å†…å®¹æ ¼å¼åŒ–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    def format_content(self, raw_content: Any, content_type: ContentType, 
                      format_rules: Dict[str, Any] = None) -> ProcessedContent:
        """æ ¼å¼åŒ–å†…å®¹"""
        format_rules = format_rules or {}
        
        if content_type == ContentType.TEXT:
            formatted = self._format_text(raw_content, format_rules)
        elif content_type == ContentType.TABLE:
            formatted = self._format_table(raw_content, format_rules)
        elif content_type == ContentType.CHART:
            formatted = self._format_chart(raw_content, format_rules)
        elif content_type == ContentType.LIST:
            formatted = self._format_list(raw_content, format_rules)
        elif content_type == ContentType.IMAGE:
            formatted = self._format_image(raw_content, format_rules)
        else:
            formatted = str(raw_content)
        
        return ProcessedContent(
            placeholder_name="",
            content_type=content_type,
            raw_content=raw_content,
            formatted_content=formatted,
            metadata={"formatted_at": datetime.now().isoformat()}
        )
    
    def _format_text(self, content: Any, format_rules: Dict) -> str:
        """æ ¼å¼åŒ–æ–‡æœ¬å†…å®¹"""
        if isinstance(content, (dict, list)):
            # å¦‚æœæ˜¯ç»“æ„åŒ–æ•°æ®ï¼Œè½¬æ¢ä¸ºæ–‡æœ¬
            if isinstance(content, dict):
                if "value" in content:
                    return str(content["value"])
                elif "results" in content:
                    results = content["results"]
                    if isinstance(results, dict):
                        # æå–ä¸»è¦ä¿¡æ¯
                        if "numeric_statistics" in results:
                            stats = results["numeric_statistics"]
                            text_parts = []
                            for field, field_stats in stats.items():
                                mean = field_stats.get("mean", 0)
                                count = field_stats.get("count", 0)
                                text_parts.append(f"{field}: å¹³å‡å€¼ {mean:.2f}ï¼Œå…± {count} é¡¹")
                            return "; ".join(text_parts)
                        else:
                            return json.dumps(results, ensure_ascii=False, indent=2)
                    else:
                        return str(results)
                else:
                    # é€‰æ‹©å…³é”®å­—æ®µ
                    key_fields = ["total", "count", "sum", "average", "result", "value"]
                    for field in key_fields:
                        if field in content:
                            return str(content[field])
                    return json.dumps(content, ensure_ascii=False)
            elif isinstance(content, list) and content:
                if isinstance(content[0], dict):
                    # å¦‚æœæ˜¯å•å€¼ç»“æœ
                    if len(content) == 1:
                        return self._format_text(content[0], format_rules)
                    # å¦‚æœæ˜¯å¤šè¡Œæ•°æ®ï¼Œæ ¼å¼åŒ–ä¸ºæ‘˜è¦
                    return f"å…± {len(content)} é¡¹æ•°æ®"
                else:
                    return ", ".join(str(item) for item in content[:5])
        
        return str(content)
    
    def _format_table(self, content: Any, format_rules: Dict) -> str:
        """æ ¼å¼åŒ–è¡¨æ ¼å†…å®¹"""
        if not isinstance(content, list) or not content:
            return "æ— è¡¨æ ¼æ•°æ®"
        
        # å¦‚æœæ˜¯æŸ¥è¯¢ç»“æœæ ¼å¼
        if isinstance(content, dict) and "data" in content:
            content = content["data"]
        
        if not isinstance(content, list) or not content:
            return "æ— è¡¨æ ¼æ•°æ®"
        
        # è·å–åˆ—å
        if isinstance(content[0], dict):
            columns = list(content[0].keys())
        else:
            return "æ— æ•ˆè¡¨æ ¼æ•°æ®æ ¼å¼"
        
        # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°
        max_rows = format_rules.get("max_rows", 10)
        display_data = content[:max_rows]
        
        # ç”Ÿæˆè¡¨æ ¼å­—ç¬¦ä¸²
        table_lines = []
        
        # è¡¨å¤´
        header = " | ".join(columns)
        table_lines.append(header)
        table_lines.append(" | ".join(["---"] * len(columns)))
        
        # æ•°æ®è¡Œ
        for row in display_data:
            if isinstance(row, dict):
                values = []
                for col in columns:
                    value = row.get(col, "")
                    # æ ¼å¼åŒ–æ•°å€¼
                    if isinstance(value, float):
                        values.append(f"{value:.2f}")
                    else:
                        values.append(str(value))
                table_lines.append(" | ".join(values))
        
        # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ·»åŠ çœç•¥å·
        if len(content) > max_rows:
            table_lines.append(f"... (å…± {len(content)} è¡Œ)")
        
        return "\n".join(table_lines)
    
    def _format_chart(self, content: Any, format_rules: Dict) -> str:
        """æ ¼å¼åŒ–å›¾è¡¨å†…å®¹"""
        if isinstance(content, dict):
            chart_type = content.get("chart_type", "unknown")
            data_points = 0
            
            if "chart_data" in content:
                data_points = len(content["chart_data"])
            elif "data" in content:
                data_points = len(content["data"]) if isinstance(content["data"], list) else 0
            
            return f"[{chart_type}å›¾è¡¨ï¼ŒåŒ…å«{data_points}ä¸ªæ•°æ®ç‚¹]"
        
        return "[å›¾è¡¨å†…å®¹]"
    
    def _format_list(self, content: Any, format_rules: Dict) -> str:
        """æ ¼å¼åŒ–åˆ—è¡¨å†…å®¹"""
        if isinstance(content, list):
            list_items = []
            for i, item in enumerate(content[:10]):  # é™åˆ¶10é¡¹
                if isinstance(item, dict):
                    # æå–ä¸»è¦ä¿¡æ¯
                    if "name" in item and "value" in item:
                        list_items.append(f"{i+1}. {item['name']}: {item['value']}")
                    else:
                        list_items.append(f"{i+1}. {json.dumps(item, ensure_ascii=False)}")
                else:
                    list_items.append(f"{i+1}. {item}")
            
            if len(content) > 10:
                list_items.append(f"... (å…± {len(content)} é¡¹)")
            
            return "\n".join(list_items)
        
        return str(content)
    
    def _format_image(self, content: Any, format_rules: Dict) -> str:
        """æ ¼å¼åŒ–å›¾ç‰‡å†…å®¹"""
        if isinstance(content, dict) and "image_path" in content:
            return f"[å›¾ç‰‡: {content['image_path']}]"
        elif isinstance(content, str) and content.startswith("data:image"):
            return "[Base64å›¾ç‰‡å†…å®¹]"
        else:
            return "[å›¾ç‰‡å†…å®¹]"


class WordDocumentGenerator:
    """Wordæ–‡æ¡£ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    def generate_document(self, template: DocumentTemplate, 
                         processed_contents: List[ProcessedContent],
                         output_path: str = None) -> DocumentGenerationResult:
        """ç”ŸæˆWordæ–‡æ¡£"""
        start_time = time.time()
        
        try:
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            if not output_path:
                timestamp = int(time.time())
                output_path = f"/tmp/report_{timestamp}.docx"
            
            if HAS_DOCX:
                # ä½¿ç”¨python-docxç”ŸæˆçœŸå®æ–‡æ¡£
                result = self._generate_docx_document(template, processed_contents, output_path)
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿç”Ÿæˆ
                result = self._generate_mock_document(template, processed_contents, output_path)
            
            generation_time = time.time() - start_time
            result.generation_time = generation_time
            
            return result
            
        except Exception as e:
            generation_time = time.time() - start_time
            self.logger.error(f"æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
            
            return DocumentGenerationResult(
                success=False,
                document_path="",
                document_format=DocumentFormat.DOCX,
                generation_time=generation_time,
                placeholder_count=len(template.placeholders),
                processed_placeholders=0,
                error_message=str(e)
            )
    
    def _generate_docx_document(self, template: DocumentTemplate,
                               processed_contents: List[ProcessedContent],
                               output_path: str) -> DocumentGenerationResult:
        """ä½¿ç”¨python-docxç”ŸæˆçœŸå®æ–‡æ¡£"""
        doc = Document()
        
        # è®¾ç½®æ–‡æ¡£æ ‡é¢˜
        title = doc.add_heading(template.name, 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # å¤„ç†æ¨¡æ¿å†…å®¹
        content_lines = template.content.split('\n')
        content_map = {pc.placeholder_name: pc for pc in processed_contents}
        
        failed_placeholders = []
        processed_count = 0
        warnings = []
        
        for line in content_lines:
            line = line.strip()
            if not line:
                # æ·»åŠ ç©ºè¡Œ
                doc.add_paragraph()
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å ä½ç¬¦
            placeholders_in_line = re.findall(r'\{([^}]+)\}', line)
            
            if placeholders_in_line:
                # æ›¿æ¢å ä½ç¬¦
                processed_line = line
                
                for placeholder_name in placeholders_in_line:
                    if placeholder_name in content_map:
                        processed_content = content_map[placeholder_name]
                        replacement = processed_content.formatted_content
                        processed_line = processed_line.replace(f"{{{placeholder_name}}}", replacement)
                        processed_count += 1
                    else:
                        processed_line = processed_line.replace(f"{{{placeholder_name}}}", f"[æœªå¤„ç†: {placeholder_name}]")
                        failed_placeholders.append(placeholder_name)
                        warnings.append(f"å ä½ç¬¦ {placeholder_name} æœªæ‰¾åˆ°å¯¹åº”å†…å®¹")
                
                # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ åˆ°æ–‡æ¡£
                if any(pc.content_type == ContentType.TABLE for pc in content_map.values()
                       if pc.placeholder_name in placeholders_in_line):
                    # å¦‚æœåŒ…å«è¡¨æ ¼å†…å®¹ï¼Œæ·»åŠ ä¸ºè¡¨æ ¼
                    self._add_table_to_doc(doc, processed_line, content_map, placeholders_in_line)
                else:
                    # æ·»åŠ ä¸ºæ®µè½
                    self._add_paragraph_to_doc(doc, processed_line, line)
            else:
                # æ™®é€šæ–‡æœ¬è¡Œ
                self._add_paragraph_to_doc(doc, line)
        
        # ä¿å­˜æ–‡æ¡£
        doc.save(output_path)
        
        return DocumentGenerationResult(
            success=True,
            document_path=output_path,
            document_format=DocumentFormat.DOCX,
            generation_time=0,  # ä¼šåœ¨ä¸Šçº§å‡½æ•°ä¸­è®¾ç½®
            placeholder_count=len(template.placeholders),
            processed_placeholders=processed_count,
            failed_placeholders=failed_placeholders,
            warnings=warnings
        )
    
    def _generate_mock_document(self, template: DocumentTemplate,
                               processed_contents: List[ProcessedContent],
                               output_path: str) -> DocumentGenerationResult:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–‡æ¡£ï¼ˆå½“æ²¡æœ‰python-docxæ—¶ï¼‰"""
        content_map = {pc.placeholder_name: pc for pc in processed_contents}
        
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
        final_content = template.content
        processed_count = 0
        failed_placeholders = []
        
        for placeholder in template.placeholders:
            placeholder_pattern = f"{{{placeholder.name}}}"
            
            if placeholder.name in content_map:
                replacement = content_map[placeholder.name].formatted_content
                final_content = final_content.replace(placeholder_pattern, replacement)
                processed_count += 1
            else:
                final_content = final_content.replace(placeholder_pattern, f"[æœªå¤„ç†: {placeholder.name}]")
                failed_placeholders.append(placeholder.name)
        
        # ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
        text_output_path = output_path.replace('.docx', '.txt')
        
        try:
            with open(text_output_path, 'w', encoding='utf-8') as f:
                f.write(f"# {template.name}\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å ä½ç¬¦æ€»æ•°: {len(template.placeholders)}\n")
                f.write(f"å·²å¤„ç†: {processed_count}\n")
                f.write(f"æœªå¤„ç†: {len(failed_placeholders)}\n\n")
                f.write("=" * 50 + "\n\n")
                f.write(final_content)
            
            self.logger.info(f"æ¨¡æ‹Ÿæ–‡æ¡£å·²ä¿å­˜: {text_output_path}")
            
        except Exception as e:
            self.logger.warning(f"ä¿å­˜æ¨¡æ‹Ÿæ–‡æ¡£å¤±è´¥: {e}")
            text_output_path = output_path
        
        return DocumentGenerationResult(
            success=True,
            document_path=text_output_path,
            document_format=DocumentFormat.DOCX,
            generation_time=0,
            placeholder_count=len(template.placeholders),
            processed_placeholders=processed_count,
            failed_placeholders=failed_placeholders,
            warnings=["ä½¿ç”¨æ¨¡æ‹Ÿæ–‡æ¡£ç”Ÿæˆå™¨ï¼ˆæœªå®‰è£…python-docxï¼‰"] if not HAS_DOCX else [],
            metadata={"mock_generation": not HAS_DOCX}
        )
    
    def _add_paragraph_to_doc(self, doc, content: str, original_line: str = None):
        """æ·»åŠ æ®µè½åˆ°æ–‡æ¡£"""
        if content.startswith('#'):
            # æ ‡é¢˜
            level = min(len(content) - len(content.lstrip('#')), 6)
            title_text = content.lstrip('#').strip()
            doc.add_heading(title_text, level)
        else:
            # æ™®é€šæ®µè½
            para = doc.add_paragraph(content)
            
            # å¦‚æœå†…å®¹åŒ…å«æ•°å­—ï¼Œè®¾ç½®ä¸ºå³å¯¹é½
            if re.search(r'\d+\.?\d*', content):
                para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    
    def _add_table_to_doc(self, doc, content: str, content_map: Dict,
                          placeholders_in_line: List[str]):
        """æ·»åŠ è¡¨æ ¼åˆ°æ–‡æ¡£"""
        # ç®€åŒ–å®ç°ï¼šå°†è¡¨æ ¼å†…å®¹ä½œä¸ºæ ¼å¼åŒ–æ–‡æœ¬æ·»åŠ 
        doc.add_paragraph(content)
        
        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºçœŸæ­£çš„è¡¨æ ¼æ’å…¥é€»è¾‘
        for placeholder_name in placeholders_in_line:
            if (placeholder_name in content_map and 
                content_map[placeholder_name].content_type == ContentType.TABLE):
                
                table_content = content_map[placeholder_name].formatted_content
                # ç®€å•æ·»åŠ ä¸ºä»£ç å—æ ·å¼
                para = doc.add_paragraph(table_content)
                para.style = 'Normal'


class DocumentPipeline:
    """æ–‡æ¡£ç”Ÿæˆæµæ°´çº¿"""
    
    def __init__(self):
        self.pipeline_id = str(uuid.uuid4())
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.template_parser = TemplateParser()
        self.content_formatter = ContentFormatter()
        self.document_generator = WordDocumentGenerator()
        
        # æµæ°´çº¿ç»Ÿè®¡
        self.stats = {
            "templates_processed": 0,
            "documents_generated": 0,
            "total_processing_time": 0,
            "success_rate": 0
        }
    
    async def process_template(self, template_content: str, placeholder_data: Dict[str, Any],
                              output_path: str = None, template_name: str = "Generated Report") -> DocumentGenerationResult:
        """å¤„ç†æ¨¡æ¿å¹¶ç”Ÿæˆæ–‡æ¡£"""
        start_time = time.time()
        
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†æ¨¡æ¿: {template_name}")
            
            # 1. è§£ææ¨¡æ¿
            template = self.template_parser.parse_template(template_content)
            template.name = template_name
            
            # 2. å¤„ç†å ä½ç¬¦æ•°æ®
            processed_contents = []
            
            for placeholder in template.placeholders:
                if placeholder.name in placeholder_data:
                    raw_content = placeholder_data[placeholder.name]
                    
                    # æ ¼å¼åŒ–å†…å®¹
                    processed_content = self.content_formatter.format_content(
                        raw_content=raw_content,
                        content_type=placeholder.content_type,
                        format_rules=placeholder.format_rules
                    )
                    processed_content.placeholder_name = placeholder.name
                    
                    processed_contents.append(processed_content)
            
            # 3. ç”Ÿæˆæ–‡æ¡£
            result = self.document_generator.generate_document(
                template=template,
                processed_contents=processed_contents,
                output_path=output_path
            )
            
            # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats["templates_processed"] += 1
            if result.success:
                self.stats["documents_generated"] += 1
            
            total_time = time.time() - start_time
            self.stats["total_processing_time"] += total_time
            self.stats["success_rate"] = self.stats["documents_generated"] / self.stats["templates_processed"]
            
            self.logger.info(f"æ¨¡æ¿å¤„ç†å®Œæˆ: {template_name}, è€—æ—¶: {total_time:.2f}ç§’")
            
            return result
            
        except Exception as e:
            self.logger.error(f"æ¨¡æ¿å¤„ç†å¤±è´¥: {e}")
            return DocumentGenerationResult(
                success=False,
                document_path="",
                document_format=DocumentFormat.DOCX,
                generation_time=time.time() - start_time,
                placeholder_count=0,
                processed_placeholders=0,
                error_message=str(e)
            )
    
    def get_pipeline_stats(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿ç»Ÿè®¡ä¿¡æ¯"""
        avg_processing_time = (
            self.stats["total_processing_time"] / self.stats["templates_processed"]
            if self.stats["templates_processed"] > 0 else 0
        )
        
        return {
            **self.stats,
            "pipeline_id": self.pipeline_id,
            "average_processing_time": avg_processing_time,
            "uptime": datetime.now().isoformat()
        }
    
    async def batch_process_templates(self, template_requests: List[Dict[str, Any]]) -> List[DocumentGenerationResult]:
        """æ‰¹é‡å¤„ç†æ¨¡æ¿"""
        self.logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(template_requests)} ä¸ªæ¨¡æ¿")
        
        results = []
        
        for i, request in enumerate(template_requests):
            self.logger.info(f"å¤„ç†æ¨¡æ¿ {i+1}/{len(template_requests)}")
            
            result = await self.process_template(
                template_content=request.get("template_content", ""),
                placeholder_data=request.get("placeholder_data", {}),
                output_path=request.get("output_path"),
                template_name=request.get("template_name", f"Template_{i+1}")
            )
            
            results.append(result)
        
        self.logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in results if r.success)}/{len(results)}")
        
        return results


# å…¨å±€æµæ°´çº¿å®ä¾‹
document_pipeline = DocumentPipeline()


# ä¾¿æ·å‡½æ•°
async def generate_document_from_template(template_content: str, placeholder_data: Dict[str, Any],
                                        output_path: str = None, template_name: str = "Report") -> DocumentGenerationResult:
    """ä»æ¨¡æ¿ç”Ÿæˆæ–‡æ¡£çš„ä¾¿æ·å‡½æ•°"""
    return await document_pipeline.process_template(
        template_content=template_content,
        placeholder_data=placeholder_data,
        output_path=output_path,
        template_name=template_name
    )


def create_sample_template() -> str:
    """åˆ›å»ºç¤ºä¾‹æ¨¡æ¿"""
    return """
# {æŠ¥å‘Šæ ‡é¢˜}

## æ‰§è¡Œæ‘˜è¦
{æ‰§è¡Œæ‘˜è¦}

## æ•°æ®æ¦‚è§ˆ
åœ¨æœ¬æŠ¥å‘ŠæœŸé—´ï¼Œæˆ‘ä»¬æ”¶é›†å’Œåˆ†æäº†ä»¥ä¸‹æ•°æ®ï¼š

### åŸºç¡€ç»Ÿè®¡
- æ€»è®°å½•æ•°ï¼š{æ€»è®°å½•æ•°}
- å¹³å‡å€¼ï¼š{å¹³å‡å€¼}
- æ•°æ®å®Œæ•´æ€§ï¼š{æ•°æ®å®Œæ•´æ€§}

## è¯¦ç»†åˆ†æ

### åˆ†ç±»ç»Ÿè®¡
{åˆ†ç±»ç»Ÿè®¡è¡¨æ ¼}

### è¶‹åŠ¿åˆ†æ
{è¶‹åŠ¿åˆ†æå›¾è¡¨}

### å…³é”®æ´å¯Ÿ
{å…³é”®æ´å¯Ÿåˆ—è¡¨}

## ç»“è®ºå’Œå»ºè®®
åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

{ç»“è®ºå’Œå»ºè®®}

## é™„å½•
- æ•°æ®æ¥æºï¼š{æ•°æ®æ¥æº}
- ç”Ÿæˆæ—¶é—´ï¼š{ç”Ÿæˆæ—¶é—´}
- æŠ¥å‘Šç‰ˆæœ¬ï¼š{æŠ¥å‘Šç‰ˆæœ¬}
"""


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    async def test_document_pipeline():
        """æµ‹è¯•æ–‡æ¡£ç”Ÿæˆæµæ°´çº¿"""
        print("ğŸ§ª æµ‹è¯•æ–‡æ¡£ç”Ÿæˆæµæ°´çº¿...")
        
        # åˆ›å»ºç¤ºä¾‹æ¨¡æ¿
        template_content = create_sample_template()
        
        # å‡†å¤‡å ä½ç¬¦æ•°æ®
        placeholder_data = {
            "æŠ¥å‘Šæ ‡é¢˜": "æœˆåº¦æ•°æ®åˆ†ææŠ¥å‘Š",
            "æ‰§è¡Œæ‘˜è¦": "æœ¬æŠ¥å‘Šåˆ†æäº†æœ¬æœˆçš„ä¸šåŠ¡æ•°æ®ï¼Œå‘ç°äº†å¤šä¸ªé‡è¦è¶‹åŠ¿å’Œæœºä¼šç‚¹ã€‚",
            "æ€»è®°å½•æ•°": 1234,
            "å¹³å‡å€¼": 89.5,
            "æ•°æ®å®Œæ•´æ€§": "95.2%",
            "åˆ†ç±»ç»Ÿè®¡è¡¨æ ¼": [
                {"ç±»åˆ«": "äº§å“A", "æ•°é‡": 150, "å æ¯”": "30%"},
                {"ç±»åˆ«": "äº§å“B", "æ•°é‡": 120, "å æ¯”": "24%"},
                {"ç±»åˆ«": "äº§å“C", "æ•°é‡": 230, "å æ¯”": "46%"}
            ],
            "è¶‹åŠ¿åˆ†æå›¾è¡¨": {
                "chart_type": "line",
                "data": [{"month": "1æœˆ", "value": 100}, {"month": "2æœˆ", "value": 120}]
            },
            "å…³é”®æ´å¯Ÿåˆ—è¡¨": [
                "äº§å“Cè¡¨ç°æœ€ä½³ï¼Œå æ¯”è¾¾åˆ°46%",
                "æ•´ä½“è¶‹åŠ¿å‘ˆä¸Šå‡æ€åŠ¿",
                "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå®Œæ•´æ€§è¶…è¿‡95%"
            ],
            "ç»“è®ºå’Œå»ºè®®": "å»ºè®®ç»§ç»­å…³æ³¨äº§å“Cçš„å‘å±•ï¼ŒåŒæ—¶æ”¹è¿›äº§å“Aå’ŒBçš„å¸‚åœºç­–ç•¥ã€‚",
            "æ•°æ®æ¥æº": "å†…éƒ¨ä¸šåŠ¡ç³»ç»Ÿ",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æŠ¥å‘Šç‰ˆæœ¬": "v1.0"
        }
        
        # ç”Ÿæˆæ–‡æ¡£
        result = await generate_document_from_template(
            template_content=template_content,
            placeholder_data=placeholder_data,
            template_name="æµ‹è¯•æŠ¥å‘Š"
        )
        
        print(f"âœ… æ–‡æ¡£ç”Ÿæˆå®Œæˆ!")
        print(f"æˆåŠŸ: {result.success}")
        print(f"æ–‡æ¡£è·¯å¾„: {result.document_path}")
        print(f"ç”Ÿæˆæ—¶é—´: {result.generation_time:.2f}ç§’")
        print(f"å ä½ç¬¦å¤„ç†: {result.processed_placeholders}/{result.placeholder_count}")
        
        if result.warnings:
            print("âš ï¸ è­¦å‘Š:")
            for warning in result.warnings:
                print(f"  - {warning}")
        
        if result.failed_placeholders:
            print("âŒ å¤±è´¥çš„å ä½ç¬¦:")
            for failed in result.failed_placeholders:
                print(f"  - {failed}")
        
        # æ˜¾ç¤ºæµæ°´çº¿ç»Ÿè®¡
        stats = document_pipeline.get_pipeline_stats()
        print(f"\nğŸ“Š æµæ°´çº¿ç»Ÿè®¡:")
        print(f"  - å¤„ç†æ¨¡æ¿æ•°: {stats['templates_processed']}")
        print(f"  - ç”Ÿæˆæ–‡æ¡£æ•°: {stats['documents_generated']}")
        print(f"  - æˆåŠŸç‡: {stats['success_rate']:.2%}")
        print(f"  - å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.2f}ç§’")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_document_pipeline())