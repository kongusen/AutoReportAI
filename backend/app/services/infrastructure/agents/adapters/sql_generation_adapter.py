"""
SQL Generation Adapter (Infrastructure)

Implements Domain SqlGenerationPort by delegating to the existing Agent system
or other rule-based generators.
"""

from __future__ import annotations

from typing import Any, Dict, Optional

from app.services.domain.placeholder.ports.sql_generation_port import (
    SqlGenerationPort, QuerySpec, SchemaContext, TimeWindow, SqlGenerationResult,
)
from app.services.infrastructure.agents.adapters.schema_discovery_adapter import SchemaDiscoveryAdapter


class SqlGenerationAdapter(SqlGenerationPort):
    def __init__(self) -> None:
        # could accept a facade or container if needed
        pass

    async def generate_sql(
        self,
        query: QuerySpec,
        schema: SchemaContext,
        time: Optional[TimeWindow] = None,
        business_ctx: Optional[Dict[str, Any]] = None,
    ) -> SqlGenerationResult:
        try:
            # Lazy import to avoid hard coupling in Domain
            from app.services.infrastructure.agents.facade import AgentFacade
            from app.services.infrastructure.agents.types import (
                AgentInput, PlaceholderSpec as APS, SchemaInfo as ASI,
                TaskContext as ATC, AgentConstraints
            )
            from app.core.container import Container

            # Ensure schema is available; if empty and have data_source_id, introspect
            if (not schema.tables or not schema.columns) and business_ctx and business_ctx.get("data_source_id"):
                print(f"ğŸ” Schemaä¸ºç©ºï¼Œå°è¯•introspectæ•°æ®æº: {business_ctx.get('data_source_id')}")
                try:
                    introspector = SchemaDiscoveryAdapter()
                    sc = await introspector.introspect(business_ctx["data_source_id"])
                    original_tables = len(schema.tables)
                    original_columns = len(schema.columns)
                    schema = SchemaContext(tables=sc.tables, columns=sc.columns)
                    print(f"âœ… Schema introspectæˆåŠŸ: {original_tables}->{len(schema.tables)} è¡¨, "
                          f"{original_columns}->{len(schema.columns)} åˆ—é›†åˆ")
                except Exception as e:
                    print(f"âŒ Schema introspectå¤±è´¥: {e}")
                    import traceback
                    print(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

            # Parse semantic hints from query intent if possible
            semantic_type, top_n = self._infer_semantics(query.intent)

            # Build technical prompt from structured query
            time_hint = ""
            if time and (time.start_date or time.end_date):
                time_hint = f" æ—¶é—´èŒƒå›´: {time.start_date or ''}~{time.end_date or ''}."
            measures = ", ".join(query.measures) if query.measures else ""
            dims = ", ".join(query.dimensions) if query.dimensions else ""
            filters_desc = "; ".join([
                f"{f.get('field', '')} {f.get('op', '')} {f.get('value', '')}"
                for f in (query.filters or [])
            ]) if query.filters else ""
            group_by_desc = ", ".join(query.group_by) if query.group_by else dims
            order_by_desc = ", ".join([
                f"{o.get('field')} {o.get('dir', 'desc')}"
                for o in (query.order_by or [])
            ])
            guidance_extra = []
            if semantic_type == "ranking":
                guidance_extra.append(f"æŒ‰åº¦é‡é™åºæ’åºå¹¶å–å‰{top_n or 'N'}")
            if semantic_type == "compare":
                guidance_extra.append("è¾“å‡ºåŸºå‡†ã€å¯¹æ¯”ã€å·®å€¼ä¸ç™¾åˆ†æ¯”å˜åŒ–åˆ—")
            guidance_extra.append("ä¸ºå¤§è¡¨æ·»åŠ æ—¶é—´è¿‡æ»¤æˆ–LIMITï¼Œé¿å…å…¨è¡¨æ‰«æ")
            guidance = "\n- ".join(guidance_extra)

            user_prompt = (
                f"æ ¹æ®éœ€æ±‚ç”Ÿæˆå¯æ‰§è¡ŒSQLã€‚\n"
                f"éœ€æ±‚: {query.intent}.{time_hint}\n"
                f"åˆ†ç»„ç»´åº¦: {dims or group_by_desc}\n"
                f"åº¦é‡: {measures or 'è‡ªåŠ¨æ¨æ–­'}\n"
                f"ç­›é€‰: {filters_desc or 'æ— '}\n"
                f"æ’åº: {order_by_desc or 'é€‚é…éœ€æ±‚'}\n"
                f"é™åˆ¶: {query.limit or 'æŒ‰ç­–ç•¥é™åˆ¶'}\n"
                f"- {guidance}"
                f"\nåªè¿”å›SQLï¼Œä¸è¦è§£é‡Šã€‚"
            ).strip()

            # æ„å»ºAgentInputå¹¶è®°å½•è¯¦ç»†ä¿¡æ¯
            schema_info = ASI(tables=schema.tables, columns=schema.columns)
            print(f"ğŸ¤– æ„å»ºAgentInput - schema: {len(schema_info.tables)} è¡¨, {len(schema_info.columns)} åˆ—é›†åˆ")
            print(f"ğŸ¤– Schema tables: {schema_info.tables[:3]}{'...' if len(schema_info.tables) > 3 else ''}")
            for table in list(schema_info.columns.keys())[:2]:
                cols = schema_info.columns[table]
                print(f"ğŸ¤– è¡¨ {table}: {len(cols)} åˆ— {cols[:5]}{'...' if len(cols) > 5 else ''}")

            ai = AgentInput(
                user_prompt=user_prompt,
                placeholder=APS(
                    id="sql_gen",
                    description=query.intent,
                    type="stat",
                    granularity=time.granularity if time else "daily"
                ),
                schema=schema_info,
                context=ATC(
                    task_time=None,
                    timezone="Asia/Shanghai",
                    window={
                        "start_date": time.start_date if time else None,
                        "end_date": time.end_date if time else None
                    }
                ),
                constraints=AgentConstraints(
                    sql_only=True,
                    output_kind="sql",
                    max_attempts=3,
                    policy_row_limit=5000,
                    quality_min_rows=10
                ),
                template_id=business_ctx.get("template_id") if business_ctx else None,
                data_source={
                    "data_source_id": business_ctx.get("data_source_id")
                } if business_ctx and business_ctx.get("data_source_id") else None,
                task_driven_context={
                    "placeholder_contexts": [
                        {
                            "placeholder_name": query.intent[:60],
                            "semantic_type": semantic_type,
                            "parsed_params": {"top_n": top_n},
                        }
                    ]
                },
            )

            print(f"ğŸ¤– AgentInputæ„å»ºå®Œæˆ: semantic_type={semantic_type}, top_n={top_n}")

            facade = AgentFacade(Container())
            out = await facade.execute(ai)
            sql_text = out.result if out and out.success else ""
            quality_score = (
                out.metadata.get("quality_score", 0.0)
                if out and out.metadata else 0.0
            )
            reasoning = (out.metadata or {}).get("reasoning")
            return SqlGenerationResult(
                sql=sql_text,
                quality_score=quality_score,
                reasoning=reasoning
            )
        except Exception:
            # Fallback stub keeps system running; use a harmless SELECT
            sql = "SELECT 1 AS stub"
            return SqlGenerationResult(sql=sql, quality_score=0.0, reasoning="fallback_stub")

    def _infer_semantics(self, intent: str) -> tuple[str, Optional[int]]:
        t = (intent or "").lower()
        # ranking detection
        import re
        top_n = None
        m = re.search(r"top\s*(\d+)", t)
        if m:
            top_n = int(m.group(1))
            return ("ranking", top_n)
        for kw in ["æ’å", "å‰", "top", "æ’è¡Œ"]:
            if kw in intent:
                top_n = top_n or None
                return ("ranking", top_n)
        for kw in ["åŒæ¯”", "ç¯æ¯”", "å¯¹æ¯”", "compare", "vs", "å·®å€¼"]:
            if kw in intent:
                return ("compare", None)
        return (None, None)
