"""
Agent é…ç½®

å®šä¹‰ Agent ç³»ç»Ÿçš„æ ¸å¿ƒé…ç½®
åŒ…æ‹¬ LLM é…ç½®ã€å·¥å…·é…ç½®å’Œ Agent è¡Œä¸ºé…ç½®
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional, Callable, Union
from dataclasses import dataclass, field

from ..types import LLMConfig, ToolConfig, AgentConfig, ExecutionStage, TaskComplexity
from .coordination import AdvancedCoordinationConfig, create_default_coordination_config

logger = logging.getLogger(__name__)


@dataclass
class LLMRuntimeConfig(LLMConfig):
    """LLM è¿è¡Œæ—¶é…ç½®"""
    # åŸºç¡€é…ç½®
    provider: str = "container"  # ä½¿ç”¨å®¹å™¨LLMæœåŠ¡
    model: str = "auto"  # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
    temperature: float = 0.0
    max_tokens: Optional[int] = None
    
    # é«˜çº§é…ç½®
    enable_tool_calling: bool = True
    enable_streaming: bool = False
    
    # ç­–ç•¥é…ç½®
    selection_policy: Dict[str, Any] = field(default_factory=dict)
    fallback_strategy: str = "auto_retry"
    
    # æ€§èƒ½é…ç½®
    request_timeout: int = 30  # ç§’
    max_retries: int = 3
    retry_delay: float = 1.0  # ç§’
    
    # ç¼“å­˜é…ç½®
    enable_response_caching: bool = True
    cache_ttl: int = 300  # ç§’
    cache_size: int = 100


@dataclass
class ToolRuntimeConfig(ToolConfig):
    """å·¥å…·è¿è¡Œæ—¶é…ç½®"""
    # å·¥å…·å¯ç”¨çŠ¶æ€
    enabled_tools: List[str] = field(default_factory=lambda: [
        "schema_discovery", "schema_retrieval", "schema_cache",
        "sql_generator", "sql_validator", "sql_column_checker", 
        "sql_auto_fixer", "sql_executor",
        "data_sampler", "data_analyzer",
        "time_window", "chart_generator", "chart_analyzer"
    ])
    
    # å·¥å…·è¶…æ—¶
    tool_timeout: int = 30  # ç§’
    
    # å·¥å…·é‡è¯•
    max_retries: int = 3
    retry_delay: float = 1.0  # ç§’
    
    # å·¥å…·é™åˆ¶
    max_tool_calls_per_iteration: int = 5
    max_total_tool_calls: int = 50
    
    # å·¥å…·ä¼˜å…ˆçº§
    tool_priorities: Dict[str, int] = field(default_factory=lambda: {
        "schema_discovery": 10,
        "schema_retrieval": 9,
        "sql_generator": 8,
        "sql_validator": 7,
        "sql_executor": 6,
        "data_sampler": 5,
        "data_analyzer": 4,
        "chart_generator": 3,
    })
    
    # å·¥å…·ç»„åˆç­–ç•¥
    enable_tool_combination: bool = True
    combination_strategies: List[str] = field(default_factory=lambda: [
        "sequential", "parallel", "conditional"
    ])


@dataclass
class AgentBehaviorConfig:
    """Agent è¡Œä¸ºé…ç½®"""
    # æ‰§è¡Œç­–ç•¥
    execution_strategy: str = "adaptive"  # adaptive, aggressive, conservative
    enable_self_correction: bool = True
    enable_learning: bool = True
    
    # å†³ç­–é…ç½®
    decision_threshold: float = 0.7
    confidence_threshold: float = 0.8
    uncertainty_handling: str = "ask_for_clarification"  # ask_for_clarification, make_best_guess, abort
    
    # äº¤äº’é…ç½®
    enable_user_interaction: bool = False
    interaction_timeout: int = 60  # ç§’
    max_interaction_rounds: int = 3
    
    # é”™è¯¯å¤„ç†
    error_recovery_strategy: str = "retry_with_backoff"  # retry_with_backoff, fallback_tool, abort
    max_error_recovery_attempts: int = 3
    error_recovery_delay: float = 2.0  # ç§’
    
    # è´¨é‡ä¿è¯
    enable_result_validation: bool = True
    validation_strategies: List[str] = field(default_factory=lambda: [
        "syntax_check", "semantic_check", "data_consistency_check"
    ])
    quality_threshold: float = 0.8


@dataclass
class AgentRuntimeConfig(AgentConfig):
    """Agent è¿è¡Œæ—¶é…ç½®"""
    # æ ¸å¿ƒé…ç½®
    llm: LLMRuntimeConfig = field(default_factory=LLMRuntimeConfig)
    tools: ToolRuntimeConfig = field(default_factory=ToolRuntimeConfig)
    coordination: AdvancedCoordinationConfig = field(default_factory=create_default_coordination_config)
    
    # è¡Œä¸ºé…ç½®
    behavior: AgentBehaviorConfig = field(default_factory=AgentBehaviorConfig)
    
    # æ‰§è¡Œé…ç½®
    max_iterations: int = 10
    max_context_tokens: int = 16000
    
    # ç³»ç»Ÿæç¤º
    system_prompt: Optional[str] = None
    
    # å›è°ƒå‡½æ•°
    callbacks: List[Callable] = field(default_factory=list)
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)


class AgentConfigManager:
    """Agent é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config: AgentConfig):
        self.config = config
        self._user_model_resolver = None
        self._validation_rules: Dict[str, Callable] = {}
        self._setup_validation_rules()
    
    async def resolve_user_config(
        self,
        user_id: str,
        task_type: str = "placeholder_analysis",
        task_complexity: Union[TaskComplexity, float] = 0.5
    ) -> AgentConfig:
        """
        åŸºäºç”¨æˆ·é…ç½®è§£æAgenté…ç½®

        Args:
            user_id: ç”¨æˆ·ID
            task_type: ä»»åŠ¡ç±»å‹
            task_complexity: ä»»åŠ¡å¤æ‚åº¦ï¼Œå¯ä»¥æ˜¯ TaskComplexity æšä¸¾æˆ– float (0.0-1.0)

        Returns:
            AgentConfig: è§£æåçš„Agenté…ç½®
        """
        try:
            from .user_model_resolver import get_user_model_config, user_model_resolver

            # è½¬æ¢ task_complexity ä¸º float
            complexity_value = float(task_complexity) if isinstance(task_complexity, (TaskComplexity, float, int)) else 0.5

            # è·å–ç”¨æˆ·æ¨¡å‹é…ç½®
            user_model_config = await get_user_model_config(user_id, task_type)

            # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
            selected_model = user_model_resolver.select_model_for_task(
                user_model_config, complexity_value, task_type
            )

            # è®¡ç®—æœ€å¤§ä¸Šä¸‹æ–‡tokens
            max_context_tokens = user_model_resolver.get_max_context_tokens(
                user_model_config, selected_model
            )
            
            # åˆ›å»ºæ–°çš„é…ç½®å®ä¾‹
            resolved_config = AgentConfig(
                llm=LLMRuntimeConfig(
                    provider="container",
                    model=selected_model.model_name,
                    temperature=selected_model.temperature,
                    max_tokens=selected_model.max_tokens,
                    enable_tool_calling=selected_model.supports_function_calls,
                    enable_streaming=False,
                    selection_policy={
                        "user_model": selected_model.model_name,
                        "model_type": selected_model.model_type,
                        "supports_thinking": selected_model.supports_thinking,
                        "task_complexity": complexity_value
                    },
                    fallback_strategy="auto_retry",
                    request_timeout=30,
                    max_retries=3,
                    retry_delay=1.0,
                    enable_response_caching=True,
                    cache_ttl=300,
                    cache_size=100
                ),
                tools=self.config.tools,
                coordination=self.config.coordination,
                max_iterations=self.config.max_iterations,
                max_context_tokens=max_context_tokens,  # ğŸ”¥ å…³é”®ï¼šä½¿ç”¨åŠ¨æ€è®¡ç®—çš„context_tokens
                system_prompt=self.config.system_prompt,
                callbacks=self.config.callbacks,
                metadata={
                    **self.config.metadata,
                    "user_id": user_id,
                    "task_type": task_type,
                    "task_complexity": complexity_value,
                    "selected_model": selected_model.model_name,
                    "model_type": selected_model.model_type,
                    "supports_thinking": selected_model.supports_thinking,
                    "max_context_tokens": max_context_tokens
                }
            )

            logger.info(f"âœ… è§£æç”¨æˆ·é…ç½®å®Œæˆ: user_id={user_id}, model={selected_model.model_name}({selected_model.model_type}), context_tokens={max_context_tokens}")
            return resolved_config
            
        except Exception as e:
            logger.error(f"âŒ è§£æç”¨æˆ·é…ç½®å¤±è´¥: {e}")
            # å›é€€åˆ°åŸå§‹é…ç½®
            return self.config
    
    def validate_config(self) -> Dict[str, List[str]]:
        """éªŒè¯é…ç½®"""
        errors = {}
        
        for key, validator in self._validation_rules.items():
            try:
                config_value = getattr(self.config, key, None)
                if config_value:
                    errors[key] = validator(config_value)
                else:
                    errors[key] = []
            except Exception as e:
                errors[key] = [f"éªŒè¯ {key} é…ç½®æ—¶å‡ºé”™: {str(e)}"]
        
        return errors
    
    def _setup_validation_rules(self):
        """è®¾ç½®éªŒè¯è§„åˆ™"""
        self._validation_rules = {
            "llm": self._validate_llm_config,
            "tools": self._validate_tools_config,
            "coordination": self._validate_coordination_config,
            "behavior": self._validate_behavior_config,
        }
    
    def _validate_llm_config(self, config: LLMRuntimeConfig) -> List[str]:
        """éªŒè¯ LLM é…ç½®"""
        errors = []
        
        if config.temperature < 0 or config.temperature > 2:
            errors.append("Temperature å¿…é¡»åœ¨ 0-2 ä¹‹é—´")
        
        if config.max_tokens and config.max_tokens < 100:
            errors.append("Max tokens å¿…é¡»è‡³å°‘ä¸º 100")
        
        if config.request_timeout < 1:
            errors.append("Request timeout å¿…é¡»è‡³å°‘ä¸º 1 ç§’")
        
        if config.max_retries < 0:
            errors.append("Max retries ä¸èƒ½ä¸ºè´Ÿæ•°")
        
        return errors
    
    def _validate_tools_config(self, config: ToolRuntimeConfig) -> List[str]:
        """éªŒè¯å·¥å…·é…ç½®"""
        errors = []
        
        if config.tool_timeout < 1:
            errors.append("Tool timeout å¿…é¡»è‡³å°‘ä¸º 1 ç§’")
        
        if config.max_tool_calls_per_iteration < 1:
            errors.append("Max tool calls per iteration å¿…é¡»è‡³å°‘ä¸º 1")
        
        if config.max_total_tool_calls < config.max_tool_calls_per_iteration:
            errors.append("Max total tool calls å¿…é¡»å¤§äºç­‰äº max tool calls per iteration")
        
        # éªŒè¯å·¥å…·ä¼˜å…ˆçº§
        priorities = list(config.tool_priorities.values())
        if priorities and (min(priorities) < 1 or max(priorities) > 10):
            errors.append("Tool priorities å¿…é¡»åœ¨ 1-10 ä¹‹é—´")
        
        return errors
    
    def _validate_coordination_config(self, config: AdvancedCoordinationConfig) -> List[str]:
        """éªŒè¯åè°ƒé…ç½®"""
        errors = []
        
        if config.recursion.max_recursion_depth < 1:
            errors.append("Max recursion depth å¿…é¡»è‡³å°‘ä¸º 1")
        
        if config.token_budget.max_tokens_per_iteration < 1000:
            errors.append("Max tokens per iteration å¿…é¡»è‡³å°‘ä¸º 1000")
        
        if config.token_budget.max_total_tokens < config.token_budget.max_tokens_per_iteration:
            errors.append("Max total tokens å¿…é¡»å¤§äºç­‰äº max tokens per iteration")
        
        return errors
    
    def _validate_behavior_config(self, config: AgentBehaviorConfig) -> List[str]:
        """éªŒè¯è¡Œä¸ºé…ç½®"""
        errors = []
        
        if config.decision_threshold < 0 or config.decision_threshold > 1:
            errors.append("Decision threshold å¿…é¡»åœ¨ 0-1 ä¹‹é—´")
        
        if config.confidence_threshold < 0 or config.confidence_threshold > 1:
            errors.append("Confidence threshold å¿…é¡»åœ¨ 0-1 ä¹‹é—´")
        
        if config.max_error_recovery_attempts < 0:
            errors.append("Max error recovery attempts ä¸èƒ½ä¸ºè´Ÿæ•°")
        
        if config.quality_threshold < 0 or config.quality_threshold > 1:
            errors.append("Quality threshold å¿…é¡»åœ¨ 0-1 ä¹‹é—´")
        
        return errors
    
    def validate_config(self) -> Dict[str, List[str]]:
        """éªŒè¯æ•´ä¸ªé…ç½®"""
        validation_results = {}
        
        # éªŒè¯å„ä¸ªé…ç½®æ¨¡å—
        validation_results["llm"] = self._validate_llm_config(self.config.llm)
        validation_results["tools"] = self._validate_tools_config(self.config.tools)
        validation_results["coordination"] = self._validate_coordination_config(self.config.coordination)
        validation_results["behavior"] = self._validate_behavior_config(self.config.behavior)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        all_errors = []
        for module, errors in validation_results.items():
            all_errors.extend([f"{module}: {error}" for error in errors])
        
        if all_errors:
            logger.warning(f"âš ï¸ é…ç½®éªŒè¯å‘ç°é—®é¢˜: {all_errors}")
        else:
            logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        
        return validation_results
    
    def optimize_config(self, performance_metrics: Dict[str, Any]) -> AgentRuntimeConfig:
        """æ ¹æ®æ€§èƒ½æŒ‡æ ‡ä¼˜åŒ–é…ç½®"""
        optimized_config = self.config
        
        # æ ¹æ®æ‰§è¡Œæ—¶é—´ä¼˜åŒ–
        avg_execution_time = performance_metrics.get("average_execution_time", 0)
        if avg_execution_time > 10000:  # 10ç§’
            # å¢åŠ å¹¶è¡Œåº¦
            optimized_config.coordination.performance.max_concurrent_tools = min(
                optimized_config.coordination.performance.max_concurrent_tools + 1, 5
            )
            # å‡å°‘è¿­ä»£æ¬¡æ•°
            optimized_config.max_iterations = max(optimized_config.max_iterations - 1, 5)
        
        # æ ¹æ®å·¥å…·è°ƒç”¨é¢‘ç‡ä¼˜åŒ–
        tool_call_count = performance_metrics.get("tool_call_count", 0)
        if tool_call_count > 30:
            # å¯ç”¨å·¥å…·ç¼“å­˜
            optimized_config.tools.enable_tool_result_caching = True
            # å¢åŠ å·¥å…·è¶…æ—¶
            optimized_config.tools.tool_timeout = min(
                optimized_config.tools.tool_timeout + 5, 60
            )
        
        # æ ¹æ® Token ä½¿ç”¨ä¼˜åŒ–
        token_usage = performance_metrics.get("token_usage", {})
        if token_usage.get("total", 0) > optimized_config.coordination.token_budget.max_total_tokens * 0.9:
            # å¢åŠ  Token é¢„ç®—
            optimized_config.coordination.token_budget.max_total_tokens += 2000
            optimized_config.max_context_tokens += 2000
        
        logger.info("ğŸ”§ [AgentConfigManager] é…ç½®å·²æ ¹æ®æ€§èƒ½æŒ‡æ ‡ä¼˜åŒ–")
        return optimized_config
    
    def get_config_for_stage(self, stage: ExecutionStage) -> Dict[str, Any]:
        """è·å–ç‰¹å®šé˜¶æ®µçš„é…ç½®"""
        stage_configs = {
            ExecutionStage.SCHEMA_DISCOVERY: {
                "enabled_tools": ["schema_discovery", "schema_retrieval"],
                "max_iterations": 3,
                "tool_timeout": 20,
            },
            ExecutionStage.SQL_GENERATION: {
                "enabled_tools": ["sql_generator", "sql_validator"],
                "max_iterations": 5,
                "tool_timeout": 30,
            },
            ExecutionStage.SQL_VALIDATION: {
                "enabled_tools": ["sql_validator", "sql_column_checker"],
                "max_iterations": 3,
                "tool_timeout": 15,
            },
            ExecutionStage.DATA_EXTRACTION: {
                "enabled_tools": ["sql_executor", "data_sampler"],
                "max_iterations": 2,
                "tool_timeout": 45,
            },
            ExecutionStage.ANALYSIS: {
                "enabled_tools": ["data_analyzer"],
                "max_iterations": 3,
                "tool_timeout": 30,
            },
            ExecutionStage.CHART_GENERATION: {
                "enabled_tools": ["chart_generator", "chart_analyzer"],
                "max_iterations": 2,
                "tool_timeout": 20,
            },
        }
        
        return stage_configs.get(stage, {})
    
    def get_config_for_complexity(self, complexity: TaskComplexity) -> Dict[str, Any]:
        """è·å–ç‰¹å®šå¤æ‚åº¦çš„é…ç½®"""
        complexity_configs = {
            TaskComplexity.SIMPLE: {
                "max_iterations": 5,
                "max_tool_calls_per_iteration": 3,
                "tool_timeout": 20,
                "enable_parallel_execution": False,
            },
            TaskComplexity.MEDIUM: {
                "max_iterations": 8,
                "max_tool_calls_per_iteration": 5,
                "tool_timeout": 30,
                "enable_parallel_execution": True,
            },
            TaskComplexity.COMPLEX: {
                "max_iterations": 12,
                "max_tool_calls_per_iteration": 7,
                "tool_timeout": 45,
                "enable_parallel_execution": True,
                "max_concurrent_tools": 4,
            },
        }
        
        return complexity_configs.get(complexity, {})


def create_default_agent_config() -> AgentRuntimeConfig:
    """åˆ›å»ºé»˜è®¤ Agent é…ç½®"""
    return AgentRuntimeConfig()


def create_high_performance_agent_config() -> AgentRuntimeConfig:
    """åˆ›å»ºé«˜æ€§èƒ½ Agent é…ç½®"""
    config = AgentRuntimeConfig()
    
    # ä¼˜åŒ– LLM é…ç½®
    config.llm.enable_response_caching = True
    config.llm.cache_size = 200
    config.llm.request_timeout = 60
    
    # ä¼˜åŒ–å·¥å…·é…ç½®
    config.tools.enable_tool_combination = True
    config.tools.max_concurrent_tools = 4
    config.tools.tool_timeout = 45
    
    # ä¼˜åŒ–åè°ƒé…ç½®
    config.coordination = create_default_coordination_config()
    config.coordination.performance.enable_parallel_execution = True
    config.coordination.performance.max_concurrent_tools = 5
    
    # ä¼˜åŒ–è¡Œä¸ºé…ç½®
    config.behavior.enable_self_correction = True
    config.behavior.enable_result_validation = True
    
    return config


def create_debug_agent_config() -> AgentRuntimeConfig:
    """åˆ›å»ºè°ƒè¯• Agent é…ç½®"""
    config = AgentRuntimeConfig()
    
    # å¯ç”¨è°ƒè¯•åŠŸèƒ½
    config.coordination.monitoring.enable_debug_mode = True
    config.coordination.monitoring.debug_tool_calls = True
    config.coordination.monitoring.enable_detailed_logging = True
    config.coordination.monitoring.log_level = "DEBUG"
    
    # å‡å°‘é™åˆ¶ä»¥ä¾¿è°ƒè¯•
    config.max_iterations = 15
    config.tools.max_total_tool_calls = 100
    config.tools.tool_timeout = 60
    
    # å¯ç”¨æ‰€æœ‰å·¥å…·
    config.tools.enabled_tools = [
        "schema_discovery", "schema_retrieval", "schema_cache",
        "sql_generator", "sql_validator", "sql_column_checker", 
        "sql_auto_fixer", "sql_executor",
        "data_sampler", "data_analyzer",
        "time_window", "chart_generator", "chart_analyzer"
    ]
    
    return config


def create_lightweight_agent_config() -> AgentRuntimeConfig:
    """åˆ›å»ºè½»é‡çº§ Agent é…ç½®"""
    config = AgentRuntimeConfig()
    
    # å‡å°‘èµ„æºä½¿ç”¨
    config.max_iterations = 5
    config.max_context_tokens = 8000
    config.tools.max_tool_calls_per_iteration = 3
    config.tools.max_total_tool_calls = 20
    
    # ç¦ç”¨é«˜çº§åŠŸèƒ½
    config.coordination.performance.enable_parallel_execution = False
    config.coordination.performance.enable_batch_processing = False
    config.tools.enable_tool_combination = False
    
    # åªå¯ç”¨æ ¸å¿ƒå·¥å…·
    config.tools.enabled_tools = [
        "schema_retrieval", "sql_generator", "sql_validator", "sql_executor"
    ]
    
    return config


# å¯¼å‡º
__all__ = [
    "AgentRuntimeConfig",
    "AgentConfigManager",
    "create_default_agent_config",
    "create_high_performance_agent_config",
    "create_debug_agent_config",
    "create_lightweight_agent_config",
]