"""
æ­¥éª¤æ‰§è¡Œå™¨

æ‰§è¡Œè®¡åˆ’ä¸­çš„å·¥å…·æ­¥éª¤åºåˆ—
ç»´æŠ¤æ‰§è¡Œä¸Šä¸‹æ–‡å¹¶äº§ç”Ÿè§‚å¯Ÿè®°å½•
æ”¯æŒç®€å•çš„é‡è¯•å’Œé”™è¯¯å¤„ç†
"""

import time
import logging
from typing import Any, Dict, List

from .types import AgentInput
from .tools.registry import ToolRegistry
from .auth_context import auth_manager


class StepExecutor:
    """æ­¥éª¤æ‰§è¡Œå™¨"""

    def __init__(self, container) -> None:
        """
        åˆå§‹åŒ–æ‰§è¡Œå™¨

        Args:
            container: backupç³»ç»Ÿçš„æœåŠ¡å®¹å™¨
        """
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)
        self.registry = ToolRegistry()
        self._setup_tools()
        # é«˜å¯ç”¨ï¼šå·¥å…·è°ƒç”¨é‡è¯•é…ç½®
        self.max_tool_retries = 2
        self.retry_backoff_base = 0.5  # seconds

    def _setup_tools(self) -> None:
        """è®¾ç½®å’Œæ³¨å†Œå·¥å…·"""
        # å¯¼å…¥æ ¸å¿ƒå·¥å…· (ç¨ååˆ›å»º) - SQLDraftToolå·²åˆ é™¤
        from .tools.sql_tools import SQLValidateTool, SQLExecuteTool, SQLRefineTool, SQLPolicyTool
        from .tools.schema_tools import SchemaListColumnsTool, SchemaListTablesTool, SchemaGetColumnsTool
        from .tools.chart_tools import ChartSpecTool, WordChartGeneratorTool
        from .tools.time_tools import TimeWindowTool
        from .tools.data_quality_tools import DataQualityTool
        from .tools.workflow_tools import StatBasicWorkflowTool, StatRatioWorkflowTool, StatCategoryMixWorkflowTool

        # æ³¨å†ŒåŸºç¡€å·¥å…· - ç§»é™¤SQLDraftToolæ³¨å†Œ
        self.registry.register(SchemaListTablesTool(self.container))
        self.registry.register(SchemaListColumnsTool(self.container))
        self.registry.register(SchemaGetColumnsTool(self.container))
        # ä¸å†æ³¨å†Œç»Ÿä¸€æŸ¥è¯¢å·¥å…·ï¼Œé‡‡ç”¨ä¸¤æ­¥Schemaï¼ˆlist_tables â†’ get_columnsï¼‰
        self.registry.register(SQLValidateTool(self.container))
        self.registry.register(SQLRefineTool(self.container))
        self.registry.register(SQLExecuteTool(self.container))
        self.registry.register(SQLPolicyTool(self.container))
        self.registry.register(ChartSpecTool(self.container))
        self.registry.register(WordChartGeneratorTool(self.container))
        self.registry.register(TimeWindowTool(self.container))
        self.registry.register(DataQualityTool(self.container))
        # å·¥ä½œæµå·¥å…·ï¼ˆPTOF å¤åˆå·¥å…·ï¼‰
        self.registry.register(StatBasicWorkflowTool(self.container))
        self.registry.register(StatRatioWorkflowTool(self.container))
        self.registry.register(StatCategoryMixWorkflowTool(self.container))

        self._logger.info(f"å·²æ³¨å†Œ {len(self.registry._tools)} ä¸ªå·¥å…·")

    async def execute(self, plan: Dict[str, Any], ai: AgentInput) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ­¥éª¤è®¡åˆ’ - Plan-Tool-Active-Validateå¾ªç¯

        Args:
            plan: å•æ­¥éª¤æ‰§è¡Œè®¡åˆ’
            ai: Agentè¾“å…¥ä¸Šä¸‹æ–‡

        Returns:
            Dict: æ‰§è¡Œç»“æœï¼Œæ”¯æŒAgentç»§ç»­å†³ç­–
        """
        steps = plan.get("steps", [])
        if not steps:
            return {"success": False, "error": "no_steps", "context": {}}

        # åªæ‰§è¡Œç¬¬ä¸€ä¸ªæ­¥éª¤ - å•æ­¥éª¤å¾ªç¯åŸåˆ™
        step = steps[0]
        observations = []

        # ä»ä»»åŠ¡ä¸Šä¸‹æ–‡ä¸­æå–å¯é€‰çš„è¯­ä¹‰ä¸å‚æ•°
        semantic_info = self._extract_semantic_info(ai)

        # å°†çº¦æŸä¼ å…¥ä¸Šä¸‹æ–‡
        constraints_dict = None
        try:
            c = ai.constraints
            constraints_dict = {
                "sql_only": c.sql_only,
                "output_kind": c.output_kind,
                "max_attempts": c.max_attempts,
                "policy_row_limit": c.policy_row_limit,
                "quality_min_rows": c.quality_min_rows,
            }
        except Exception:
            constraints_dict = None

        # è·å– user_id
        user_id = ai.user_id or auth_manager.get_current_user_id() or "system"

        # è§„èŒƒåŒ–æ•°æ®æºï¼ˆå…¼å®¹ data_source_id â†’ idï¼‰
        ds = ai.data_source if isinstance(ai.data_source, dict) else (ai.data_source or {})
        try:
            if ds and isinstance(ds, dict) and ("data_source_id" in ds) and ("id" not in ds):
                ds = {**ds, "id": ds.get("data_source_id")}
        except Exception:
            pass

        # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        context = {
            "user_prompt": ai.user_prompt,
            "placeholder_description": ai.placeholder.description,
            "tables": ai.schema.tables,
            "columns": ai.schema.columns,
            "window": ai.context.window,
            "data_source": ds,
            "user_id": user_id,
            "constraints": constraints_dict,
            "semantic_type": semantic_info.get("semantic_type"),
            "top_n": semantic_info.get("top_n"),
            "template_context": None,
        }
        # æ³¨å…¥æ¨¡æ¿ä¸Šä¸‹æ–‡å’Œç´¯ç§¯çš„schemaä¿¡æ¯ï¼ˆå¦‚å¯ç”¨ï¼‰
        try:
            tdc = ai.task_driven_context or {}
            if isinstance(tdc, dict):
                # ä¼˜å…ˆä½¿ç”¨ snippetï¼Œå…¶æ¬¡ä½¿ç”¨å®Œæ•´ template_contextï¼ˆdict ç”¨äºè°ƒåº¦ï¼‰
                if tdc.get("template_context_snippet"):
                    context["template_context"] = tdc.get("template_context_snippet")
                elif tdc.get("template_context"):
                    context["template_context"] = tdc.get("template_context")

                # ä»task_driven_contextè·å–ç´¯ç§¯çš„schemaä¿¡æ¯
                if tdc.get("column_details"):
                    context["column_details"] = tdc["column_details"]
                    self._logger.info(f"ğŸ“‹ [Executor] ä»task_driven_contextè·å–column_details: {len(tdc['column_details'])}å¼ è¡¨")
                if tdc.get("schema_summary"):
                    context["schema_summary"] = tdc["schema_summary"]
                    self._logger.info(f"ğŸ“‹ [Executor] ä»task_driven_contextè·å–schema_summary: {len(tdc['schema_summary'])}å­—ç¬¦")
                if tdc.get("recommended_time_column"):
                    context["recommended_time_column"] = tdc["recommended_time_column"]
                    self._logger.info(f"ğŸ“‹ [Executor] ä»task_driven_contextè·å–æ¨èæ—¶é—´åˆ—: {tdc['recommended_time_column']}")
                # è¦†ç›–åŸºç¡€çš„tableså’Œcolumnså¦‚æœtask_driven_contextæœ‰æ›´æ–°çš„ç‰ˆæœ¬
                if tdc.get("tables"):
                    context["tables"] = tdc["tables"]
                if tdc.get("columns"):
                    context["columns"] = tdc["columns"]
        except Exception:
            pass

        self._logger.info(f"ğŸ”„ [å•æ­¥éª¤æ‰§è¡Œ] å¼€å§‹æ‰§è¡Œ: {step.get('action', 'tool_call')}")

        try:
            step_start = time.time()
            step_action = step.get("action", "tool_call")

            # SQLç”ŸæˆåŠ¨ä½œ - ç›´æ¥è°ƒç”¨LLMç”ŸæˆSQLï¼ˆä¸é€šè¿‡å·¥å…·ï¼‰
            if step_action == "sql_generation":
                reason = step.get("reason", "Agentç”ŸæˆSQL")
                self._logger.info(f"ğŸ§  [Agentæ€è€ƒ] {reason}")

                # æ„å»ºSQLç”Ÿæˆçš„å®Œæ•´ä¸Šä¸‹æ–‡
                # å…ˆåšç¡¬æ€§å‰ç½®æ¡ä»¶æ£€æŸ¥ï¼ˆgatingï¼‰
                missing_time = not (context.get("start_date") or (isinstance(context.get("window"), dict) and context.get("window", {}).get("start_date")))
                missing_schema = not context.get("schema_summary") and not (context.get("columns") and len(context.get("columns")) > 0)

                # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥schemaä¿¡æ¯çŠ¶æ€
                self._logger.debug(f"ğŸ” [Schemaæ£€æŸ¥] schema_summaryå­˜åœ¨: {bool(context.get('schema_summary'))}")
                self._logger.debug(f"ğŸ” [Schemaæ£€æŸ¥] columnså­˜åœ¨: {bool(context.get('columns'))}")
                if context.get("columns"):
                    self._logger.debug(f"ğŸ” [Schemaæ£€æŸ¥] columnsæ•°é‡: {len(context.get('columns'))}")
                    self._logger.debug(f"ğŸ” [Schemaæ£€æŸ¥] columnså†…å®¹: {list(context.get('columns').keys()) if isinstance(context.get('columns'), dict) else context.get('columns')}")
                self._logger.info(f"ğŸ” [Schemaæ£€æŸ¥] missing_schemaåˆ¤å®š: {missing_schema}")
                if missing_time:
                    observations.append("âš ï¸ ç¼ºå°‘æ—¶é—´èŒƒå›´ï¼Œå»ºè®®å…ˆè®¡ç®—æ—¶é—´çª—å£ time.window")
                    decision = {
                        "success": True,
                        "action": "gating",
                        "gating_redirect": "time.window",
                        "message": "ç¼ºå°‘æ—¶é—´èŒƒå›´ï¼Œå·²å»ºè®®å…ˆæ‰§è¡Œ time.window",
                        "next_step_hint": "è¯·å…ˆè°ƒç”¨ time.window è®¡ç®—ç»Ÿè®¡æ—¶é—´èŒƒå›´"
                    }
                    # è¿”å›è®©ä¸‹ä¸€è½®æŒ‰å»ºè®®æ‰§è¡Œ
                    return {
                        "success": True,
                        "step_result": decision,
                        "context": context,
                        "observations": observations,
                        "decision_info": {
                            "step_completed": "gating",
                            "step_reason": "ç¼ºå°‘æ—¶é—´èŒƒå›´",
                            "next_recommendations": ["è°ƒç”¨ time.window è®¡ç®—æ—¶é—´çª—å£"]
                        },
                        "execution_time": int((time.time() - step_start) * 1000)
                    }

                if missing_schema:
                    observations.append("âš ï¸ ç¼ºå°‘è¡¨åˆ—ä¿¡æ¯ï¼Œå»ºè®®å…ˆè·å–åˆ—ä¿¡æ¯ schema.get_columns")

                    # é¢„é€‰ä¸€æ‰¹æœ€ç›¸å…³çš„è¡¨ï¼Œä¾¿äºä¸‹ä¸€æ­¥ç›´æ¥ä¼ å…¥ schema.get_columns
                    try:
                        suggested_tables = self._suggest_tables_from_names(
                            context.get("tables") or [],
                            context.get("placeholder_description") or ""
                        )
                        if suggested_tables:
                            context["suggested_tables"] = suggested_tables
                    except Exception:
                        suggested_tables = []

                    decision = {
                        "success": True,
                        "action": "gating",
                        "gating_redirect": "schema.get_columns",
                        "message": "ç¼ºå°‘è¡¨åˆ—ä¿¡æ¯ï¼Œå·²å»ºè®®å…ˆæ‰§è¡Œ schema.get_columns",
                        "next_step_hint": "è¯·å…ˆè°ƒç”¨ schema.get_columns è·å–ç›®æ ‡è¡¨åˆ—ä¿¡æ¯",
                        "suggested_tables": suggested_tables
                    }
                    return {
                        "success": True,
                        "step_result": decision,
                        "context": context,
                        "observations": observations,
                        "decision_info": {
                            "step_completed": "gating",
                            "step_reason": "ç¼ºå°‘è¡¨åˆ—ä¿¡æ¯",
                            "next_recommendations": ([f"è°ƒç”¨ schema.get_columns(tables={suggested_tables}) è·å–åˆ—ä¿¡æ¯"] if suggested_tables else ["è°ƒç”¨ schema.get_columns è·å–åˆ—ä¿¡æ¯"]) 
                        },
                        "execution_time": int((time.time() - step_start) * 1000)
                    }

                # å‰ç½®ç»¼åˆåˆ†æï¼ˆè¡¨/åˆ—/æ¨¡æ¿/æ—¶é—´/å ä½ç¬¦ï¼‰ï¼ŒæŒ‡å¯¼SQLç”Ÿæˆ
                if not context.get("pre_sql_analysis"):
                    try:
                        pre = await self._run_pre_sql_analysis(context, user_id)
                        if pre:
                            context["pre_sql_analysis"] = pre
                            observations.append("âœ… å·²å®Œæˆå‰ç½®åˆ†æï¼ŒæŒ‡å¯¼SQLç”Ÿæˆ")
                    except Exception:
                        pass

                sql_prompt = self._build_sql_generation_prompt(context, step.get("input", {}))

                # é€‰æ‹©LLMç­–ç•¥
                try:
                    llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
                    if not llm_service:
                        raise ValueError("LLM service not found in container")

                    # æ ¹æ®ä¸Šä¸‹æ–‡æ„å»ºpolicy
                    from .llm_strategy_manager import llm_strategy_manager
                    llm_policy = llm_strategy_manager.build_llm_policy(
                        user_id=user_id,
                        stage="tool",
                        complexity="high",
                        tool_name="sql.draft",
                        output_kind="sql",
                        context=context
                    )

                    # è°ƒç”¨LLMç”Ÿæˆç»“æ„åŒ–JSONï¼Œä¼˜å…ˆä» {"sql": "..."} è·å–SQL
                    llm_text = await self._call_llm(llm_service, sql_prompt, user_id, llm_policy)
                    extracted_sql = ""
                    gen_struct = None
                    try:
                        from .utils.json_utils import parse_json_safely
                        gen_struct = parse_json_safely(llm_text)
                        if isinstance(gen_struct, dict) and isinstance(gen_struct.get("sql"), str):
                            extracted_sql = gen_struct["sql"].strip()
                    except Exception:
                        gen_struct = None
                    # å…¼å®¹å›é€€ï¼šä»æ–‡æœ¬ä¸­æå–SQL
                    if not extracted_sql:
                        extracted_sql = self._extract_sql(llm_text)

                    if not extracted_sql:
                        # å›é€€åˆ°æç¤ºè¯ï¼Œè¦æ±‚åç»­æ­¥éª¤ç»§ç»­
                        result = {
                            "success": False,
                            "action": "sql_generation",
                            "sql_generation_prompt": sql_prompt,
                            "error": "æœªèƒ½ä»LLMè¾“å‡ºä¸­æå–SQL",
                            "llm_raw": llm_text,
                        }
                    else:
                        result = {
                            "success": True,
                            "action": "sql_generation",
                            "sql_generation_prompt": sql_prompt,
                            "current_sql": extracted_sql,
                            "sql": extracted_sql,
                            "generation_struct": gen_struct,
                            "message": "SQLå·²ç”Ÿæˆ",
                            "next_step_hint": "è°ƒç”¨sql.validateéªŒè¯SQL"
                        }
                except Exception as e:
                    result = {
                        "success": False,
                        "action": "sql_generation",
                        "sql_generation_prompt": sql_prompt,
                        "error": f"llm_generation_failed: {str(e)}"
                    }

            # å·¥å…·è°ƒç”¨åŠ¨ä½œ
            else:
                tool_name = step.get("tool")
                tool_input = step.get("input", {})
                reason = step.get("reason", f"æ‰§è¡Œ{tool_name}")

                tool = self.registry.get(tool_name)
                if not tool:
                    return {
                        "success": False,
                        "error": f"tool_not_found: {tool_name}",
                        "context": context,
                        "observations": [f"å·¥å…· {tool_name} æœªæ‰¾åˆ°"]
                    }

                # åˆå¹¶ä¸Šä¸‹æ–‡åˆ°å·¥å…·è¾“å…¥
                enriched_input = {**tool_input, **context}

                # ğŸ”§ ä¸ºå¯èƒ½è®¿é—®æ•°æ®åº“çš„å·¥å…·æ·»åŠ æ•°æ®æºè¿æ¥é…ç½®
                if tool_name in ("schema.list_columns", "schema.get_columns", "sql.validate", "sql.execute",
                                 "workflow.stat_basic", "workflow.stat_ratio", "workflow.stat_category_mix") and ai.data_source:
                    data_source_id = ai.data_source.get("data_source_id")
                    user_id = ai.user_id

                    if data_source_id and user_id:
                        try:
                            # è·å–ç”¨æˆ·æ•°æ®æºé…ç½®
                            if hasattr(self.container, 'user_data_source_service'):
                                data_source = await self.container.user_data_source_service.get_user_data_source(
                                    user_id=user_id,
                                    data_source_id=data_source_id
                                )

                                if data_source and hasattr(data_source, 'connection_config'):
                                    # å°†è¿æ¥é…ç½®æ·»åŠ åˆ°å·¥å…·è¾“å…¥ï¼ˆç»Ÿä¸€ä½¿ç”¨ data_source å­—æ®µæ‰¿è½½ï¼‰
                                    # å…¼å®¹ï¼šä¿ç•™åŸå§‹ ai.data_source ä¾›ä¸Šæ¸¸ä½¿ç”¨
                                    enriched_input["data_source"] = data_source.connection_config
                                    enriched_input["connection_config"] = data_source.connection_config
                                    self._logger.info(f"ğŸ“‹ [Executor] ä¸º{tool_name}æ·»åŠ æ•°æ®æºè¿æ¥é…ç½®: {data_source_id}")
                                else:
                                    self._logger.warning(f"ğŸ“‹ [Executor] æœªæ‰¾åˆ°æ•°æ®æºæˆ–è¿æ¥é…ç½®: {data_source_id}")
                            else:
                                self._logger.warning(f"ğŸ“‹ [Executor] user_data_source_serviceä¸å¯ç”¨ï¼Œæ— æ³•è·å–è¿æ¥é…ç½®")
                        except Exception as e:
                            self._logger.error(f"ğŸ“‹ [Executor] è·å–æ•°æ®æºè¿æ¥é…ç½®å¤±è´¥: {e}")
                    else:
                        self._logger.debug(f"ğŸ“‹ [Executor] ç¼ºå°‘data_source_idæˆ–user_idï¼Œè·³è¿‡è¿æ¥é…ç½®è·å–")

                # ğŸš¨ é¢å¤–ä¿æŠ¤ï¼šæ£€æŸ¥å·¥å…·è¾“å…¥ä¸­çš„SQLå­—æ®µæ˜¯å¦ä¸ºæè¿°æ€§æ–‡æœ¬
                for sql_field in ["current_sql", "sql"]:
                    if sql_field in enriched_input:
                        sql_value = enriched_input[sql_field]
                        if sql_value and self._is_description_text(sql_value):
                            self._logger.error(f"ğŸš¨ [è¾“å…¥ä¿æŠ¤] {tool_name}.{sql_field} åŒ…å«æè¿°æ€§æ–‡æœ¬: '{sql_value[:50]}'")
                            # å°è¯•ä»contextä¸­è·å–æ­£ç¡®çš„SQL
                            if sql_field != "current_sql" and context.get("current_sql"):
                                corrected_sql = context["current_sql"]
                                if not self._is_description_text(corrected_sql):
                                    self._logger.info(f"âœ… [è¾“å…¥ä¿®å¤] ä½¿ç”¨context.current_sqlä¿®å¤{sql_field}: '{corrected_sql[:50]}...'")
                                    enriched_input[sql_field] = corrected_sql
                                else:
                                    self._logger.error(f"âŒ [è¾“å…¥ä¿æŠ¤] context.current_sqlä¹Ÿæ˜¯æè¿°æ€§æ–‡æœ¬ï¼Œæ— æ³•ä¿®å¤")
                                    return {
                                        "success": False,
                                        "error": "invalid_sql_description",
                                        "message": f"å·¥å…· {tool_name} çš„ {sql_field} å‚æ•°åŒ…å«æè¿°æ€§æ–‡æœ¬ï¼Œæ— æ³•ä¿®å¤",
                                        "context": context,
                                        "observations": observations + [f"âŒ {tool_name}.{sql_field} å‚æ•°é”™è¯¯"]
                                    }

                # æ™ºèƒ½è¡¥å…¨ - é€‰æ‹©ç›®æ ‡è¡¨ï¼š
                # - å½“è°ƒç”¨ schema.list_columns æˆ– schema.get_columns ä¸”æœªæ˜¾å¼ä¼ å…¥ tables æ—¶ï¼Œ
                #   åŸºäºå ä½ç¬¦ä¸å·²å‘ç°è¡¨åè‡ªåŠ¨é€‰æ‹©ç›®æ ‡è¡¨
                if tool_name in ("schema.list_columns", "schema.get_columns"):
                    try:
                        tables_input = enriched_input.get("tables") or []
                        if not tables_input:
                            candidates = []
                            # å·²åœ¨ä¸Šä¸‹æ–‡ä¸­çš„è¡¨åï¼ˆç¬¬ä¸€æ­¥å‘ç°ï¼‰
                            if isinstance(context.get("tables"), list):
                                candidates = context.get("tables")
                            # å…¼å®¹ AgentInput ä¸­çš„ schema è¡¨
                            if not candidates:
                                try:
                                    if ai.schema and isinstance(ai.schema.tables, list):
                                        candidates = ai.schema.tables
                                except Exception:
                                    pass

                            # ä»å ä½ç¬¦æè¿°æ¨æ–­å…³é”®è¯
                            keywords = self._infer_table_keywords(getattr(ai.placeholder, 'description', ''))

                            selected: List[str] = []
                            # åŸºäºå…³é”®è¯ä»å€™é€‰è¡¨ç­›é€‰
                            if candidates and keywords:
                                lowered = [k for k in keywords]
                                selected = [t for t in candidates if any(k in str(t).lower() for k in lowered)]

                            # è‹¥æ— å…³é”®è¯æˆ–æœªå‘½ä¸­ï¼Œé‡‡ç”¨æ‰¹æ¬¡æ‰«æç­–ç•¥
                            if candidates and not selected:
                                batch_size = int(enriched_input.get("batch_size") or 5)
                                offset = int(context.get("schema_scan_offset") or 0)
                                # ç®€å•ç›¸ä¼¼åº¦ï¼šæ ¹æ®æè¿°ä¸­çš„çŸ­è¯å¯¹è¡¨åè¿›è¡ŒåŒ…å«åŒ¹é…ï¼Œä¼˜å…ˆåŒ¹é…åˆ°çš„å‰è‹¥å¹²ä¸ª
                                tokens = self._extract_tokens(getattr(ai.placeholder, 'description', ''))
                                ranked = []
                                for t in candidates:
                                    name = str(t).lower()
                                    score = sum(1 for tok in tokens if tok and tok in name)
                                    ranked.append((score, t))
                                ranked.sort(key=lambda x: (-x[0], str(x[1])))
                                # å¦‚æœæœ‰å¾—åˆ†>0çš„ï¼Œå–å‰ batch_sizeï¼›å¦åˆ™æŒ‰offsetåˆ†æ‰¹
                                positives = [t for s, t in ranked if s > 0]
                                if positives:
                                    selected = positives[:batch_size]
                                else:
                                    selected = candidates[offset:offset + batch_size]
                                    context["schema_scan_offset"] = offset + batch_size

                            # è‹¥ä»æœªé€‰ä¸­ï¼Œå°è¯•ä» reason / tool_input ä¸­è§£ææ˜¾å¼è¡¨å
                            if not selected:
                                explicit = self._extract_explicit_tables(reason, tool_input, candidates)
                                if explicit:
                                    selected = explicit

                            if selected:
                                enriched_input["tables"] = selected
                                self._logger.info(f"ğŸ§­ [Schemaæ‰¹æ¬¡é€‰æ‹©] é€‰æ‹©è¡¨: {selected}")
                    except Exception:
                        pass

                # å‰ç½®ä¿éšœï¼šæ ¡éªŒç±»/ç­–ç•¥ç±»/æ‰§è¡Œç±»å·¥å…·éœ€è¦SQL
                if tool_name in ("sql.validate", "sql.policy", "sql.execute"):
                    sql_in = (enriched_input.get("current_sql") or enriched_input.get("sql") or "").strip()

                    # ğŸš¨ æ–°å¢ï¼šæ£€æŸ¥SQLæ˜¯å¦ä¸ºæè¿°æ–‡æœ¬
                    if sql_in and self._is_description_text(sql_in):
                        self._logger.error(f"ğŸš¨ [å·¥å…·ä¿æŠ¤] {tool_name} æ”¶åˆ°æè¿°æ–‡æœ¬è€ŒéSQL: '{sql_in[:50]}'")
                        return {
                            "success": False,
                            "error": "invalid_sql_input",
                            "message": f"å·¥å…· {tool_name} æ”¶åˆ°æè¿°æ–‡æœ¬è€ŒéSQLè¯­å¥",
                            "context": context,
                            "observations": observations + [f"âŒ {tool_name} æ”¶åˆ°æ— æ•ˆSQLè¾“å…¥"]
                        }

                    if not sql_in:
                        # è‹¥æœ‰ç”Ÿæˆæç¤ºï¼Œå°è¯•å³æ—¶ç”Ÿæˆä¸€æ¬¡ï¼Œé¿å…ç©ºSQLéªŒè¯
                        try:
                            gen_prompt = context.get("sql_generation_prompt")
                            if gen_prompt:
                                self._logger.info("ğŸ§© [é¢„ç”ŸæˆSQL] ç¼ºå°‘current_sqlï¼Œä½¿ç”¨å·²å­˜åœ¨çš„ç”Ÿæˆæç¤ºå³æ—¶äº§å‡ºä¸€ç‰ˆ")
                                llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
                                llm_policy = None
                                llm_text = await self._call_llm(llm_service, gen_prompt, user_id)
                                extracted = ""
                                try:
                                    from .utils.json_utils import parse_json_safely
                                    gen_struct = parse_json_safely(llm_text)
                                    if isinstance(gen_struct, dict) and isinstance(gen_struct.get("sql"), str):
                                        extracted = gen_struct["sql"].strip()
                                except Exception:
                                    pass
                                if not extracted:
                                    extracted = self._extract_sql(llm_text)
                                if extracted:
                                    enriched_input["current_sql"] = extracted
                                    context["current_sql"] = extracted
                                else:
                                    return {
                                        "success": False,
                                        "error": "missing_current_sql",
                                        "message": "éªŒè¯/æ‰§è¡Œéœ€è¦SQLï¼Œä½†å½“å‰ä¸ºç©ºã€‚è¯·å…ˆæ‰§è¡Œsql_generationã€‚",
                                        "observations": observations + ["âš ï¸ ç¼ºå°‘current_sqlï¼Œä¸”å³æ—¶ç”Ÿæˆå¤±è´¥"],
                                        "context": context
                                    }
                            else:
                                return {
                                    "success": False,
                                    "error": "missing_current_sql",
                                    "message": "éªŒè¯/æ‰§è¡Œéœ€è¦SQLï¼Œä½†å½“å‰ä¸ºç©ºã€‚è¯·å…ˆæ‰§è¡Œsql_generationã€‚",
                                    "observations": observations + ["âš ï¸ ç¼ºå°‘current_sqlï¼Œå»ºè®®å…ˆç”ŸæˆSQL"],
                                    "context": context
                                }
                        except Exception as _:
                            return {
                                "success": False,
                                "error": "missing_current_sql",
                                "message": "éªŒè¯/æ‰§è¡Œéœ€è¦SQLï¼Œä½†å½“å‰ä¸ºç©ºã€‚è¯·å…ˆæ‰§è¡Œsql_generationã€‚",
                                "observations": observations + ["âš ï¸ ç¼ºå°‘current_sqlï¼Œä¸”å³æ—¶ç”Ÿæˆå‡ºé”™"],
                                "context": context
                            }

                self._logger.info(f"ğŸ”§ [å·¥å…·æ‰§è¡Œ] {tool_name} - {reason}")
                result = await self._execute_tool_with_retry(tool_name, tool, enriched_input)

            step_duration = int((time.time() - step_start) * 1000)

            # å¤„ç†æ‰§è¡Œç»“æœ
            if result.get("success"):
                observations.append(f"âœ… {reason} - æˆåŠŸ ({step_duration}ms)")

                # æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€
                self._update_context_state(context, result, step.get("tool"))
                # è£å‰ªä¸Šä¸‹æ–‡ï¼Œä¿ç•™å¯¹ä¸‹ä¸€è½®å†³ç­–æœ€æœ‰ç”¨çš„å…³é”®ä¿¡æ¯
                try:
                    self._reduce_context(context, step.get("tool"), result)
                except Exception:
                    pass

                # ä¸ºAgentæä¾›å†³ç­–æ”¯æŒä¿¡æ¯
                decision_info = self._build_decision_info(result, step)

                return {
                    "success": True,
                    "step_result": result,
                    "context": context,
                    "observations": observations,
                    "decision_info": decision_info,
                    "execution_time": step_duration
                }
            else:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                observations.append(f"âŒ {reason} - å¤±è´¥: {error_msg}")

                return {
                    "success": False,
                    "error": error_msg,
                    "step_result": result,
                    "context": context,
                    "observations": observations,
                    "execution_time": step_duration
                }

        except Exception as e:
            step_duration = int((time.time() - step_start) * 1000)
            error_msg = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            self._logger.error(f"ğŸš¨ [æ‰§è¡Œå¼‚å¸¸] {error_msg}")

            return {
                "success": False,
                "error": f"execution_exception: {str(e)}",
                "context": context,
                "observations": [f"âŒ æ‰§è¡Œå¼‚å¸¸: {error_msg} ({step_duration}ms)"],
                "execution_time": step_duration
            }

    def _build_sql_generation_prompt(self, context: Dict[str, Any], step_input: Dict[str, Any]) -> str:
        """æ„å»ºSQLç”Ÿæˆçš„å®Œæ•´æç¤ºè¯ï¼ˆJSONè¾“å‡ºï¼‰"""

        # æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        placeholder_desc = step_input.get("placeholder", {}).get("description", "")
        if not placeholder_desc:
            placeholder_desc = context.get("placeholder_description", "")

        schema_summary = context.get("schema_summary", "")
        # ä¼˜å…ˆä»æ‰å¹³å­—æ®µå–æ—¶é—´ï¼Œå…¶æ¬¡ä» window å–
        start_date = context.get("start_date", "")
        end_date = context.get("end_date", "")
        if (not start_date or not end_date) and isinstance(context.get("window"), dict):
            w = context.get("window") or {}
            start_date = start_date or w.get("start_date") or w.get("data_start_time") or ""
            end_date = end_date or w.get("end_date") or w.get("data_end_time") or ""
        semantic_type = context.get("semantic_type", "")
        top_n = context.get("top_n", "")

        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        self._logger.info(f"ğŸ” [SQLç”Ÿæˆæç¤º] placeholder_desc: {placeholder_desc}")
        self._logger.info(f"ğŸ” [SQLç”Ÿæˆæç¤º] schema_summary: {schema_summary[:200] if schema_summary else 'æ— schemaæ‘˜è¦'}...")
        self._logger.info(f"ğŸ” [SQLç”Ÿæˆæç¤º] æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        self._logger.info(f"ğŸ” [SQLç”Ÿæˆæç¤º] semantic_type: {semantic_type}, top_n: {top_n}")

        # ä¸å†ç¡¬ç¼–ç æ¨èæ—¶é—´åˆ—ï¼Œè®©Agentä»å®é™…è¡¨ç»“æ„ä¸­æ™ºèƒ½é€‰æ‹©
        rec_time_col = None  # ä¸ç»™é»˜è®¤å€¼ï¼Œè®©Agentè‡ªå·±åˆ¤æ–­

        # æ„å»ºæ—¶é—´æç¤º - å¼ºè°ƒä½¿ç”¨å ä½ç¬¦æ ¼å¼
        time_hint = ""
        if start_date and end_date:
            if start_date == end_date:
                time_hint = f"å‚è€ƒæ—¶é—´èŒƒå›´: {start_date}ï¼ˆå•æ—¥ï¼‰ã€‚é‡è¦ï¼šSQLä¸­å¿…é¡»ä½¿ç”¨å ä½ç¬¦æ ¼å¼ {{{{start_date}}}} å’Œ {{{{end_date}}}} è€Œä¸æ˜¯å…·ä½“æ—¥æœŸã€‚"
            else:
                time_hint = f"å‚è€ƒæ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}ã€‚é‡è¦ï¼šSQLä¸­å¿…é¡»ä½¿ç”¨å ä½ç¬¦æ ¼å¼ {{{{start_date}}}} å’Œ {{{{end_date}}}} è€Œä¸æ˜¯å…·ä½“æ—¥æœŸã€‚"
        else:
            time_hint = "æ—¶é—´èŒƒå›´: æœªæŒ‡å®šå…·ä½“æ—¥æœŸã€‚SQLä¸­å¿…é¡»ä½¿ç”¨å ä½ç¬¦æ ¼å¼ {{start_date}} å’Œ {{end_date}} è¿›è¡Œæ—¶é—´è¿‡æ»¤ã€‚"

        # æ„å»ºè¯­ä¹‰ç±»å‹æŒ‡å¯¼
        type_guidance = ""
        if semantic_type == "ranking" and top_n:
            type_guidance = f"è¿™æ˜¯æ’åç±»æŸ¥è¯¢ï¼Œéœ€è¦æŒ‰åº¦é‡é™åºæ’åºå¹¶å–å‰{top_n}å"
        elif semantic_type == "compare":
            type_guidance = "è¿™æ˜¯å¯¹æ¯”ç±»æŸ¥è¯¢ï¼Œéœ€è¦è¾“å‡ºåŸºå‡†å€¼ã€å¯¹æ¯”å€¼ã€å·®å€¼å’Œç™¾åˆ†æ¯”å˜åŒ–"
        elif semantic_type == "statistical":
            type_guidance = "è¿™æ˜¯ç»Ÿè®¡ç±»æŸ¥è¯¢ï¼Œéœ€è¦è®¡ç®—æ€»è®¡ã€å¹³å‡å€¼æˆ–è®¡æ•°"

        # è‹¥æ²¡æœ‰schemaæ‘˜è¦ï¼Œè‡³å°‘æä¾›è¡¨ååˆ—è¡¨ï¼Œå¸®åŠ©LLMé¿å…å¹»è§‰
        if not schema_summary:
            tables = context.get("tables") or []
            columns = context.get("columns") or {}

            if tables:
                preview = ", ".join(tables[:15]) + ("..." if len(tables) > 15 else "")
                schema_summary = f"å¯ç”¨æ•°æ®è¡¨(éƒ¨åˆ†): {preview}"

                # å¦‚æœæœ‰åˆ—ä¿¡æ¯ï¼Œæ·»åŠ åˆ°schemaæ‘˜è¦ä¸­
                if isinstance(columns, dict) and columns:
                    schema_details = []
                    for table, cols in columns.items():
                        if isinstance(cols, list) and cols:
                            cols_preview = ", ".join(cols[:10]) + ("..." if len(cols) > 10 else "")
                            schema_details.append(f"**{table}** ({len(cols)}åˆ—): {cols_preview}")
                    if schema_details:
                        schema_summary += "\n\nè¯¦ç»†è¡¨ç»“æ„:\n" + "\n".join(schema_details)

        # è‹¥æœ‰å·²ç­›é€‰çš„ç›®æ ‡è¡¨ï¼Œæ˜ç¡®å‘ŠçŸ¥åªèƒ½ä½¿ç”¨è¿™äº›è¡¨
        selected_tables = context.get("selected_tables") or []
        allowed_tables_note = ""
        if selected_tables:
            allowed_tables_note = f"\n**ä¸¥æ ¼é™åˆ¶å¯ç”¨è¡¨**: ä½ åªèƒ½ä½¿ç”¨ä»¥ä¸‹è¡¨åä¹‹ä¸€: {', '.join(selected_tables)}\n"
        prompt = f"""
# SQLæŸ¥è¯¢ç”Ÿæˆä»»åŠ¡

## ä¸šåŠ¡éœ€æ±‚
**ç”¨æˆ·éœ€æ±‚**: {placeholder_desc}
**æŸ¥è¯¢ç±»å‹**: {semantic_type if semantic_type else "ç»Ÿè®¡æŸ¥è¯¢"}
**æ—¶é—´ä¸Šä¸‹æ–‡**: {time_hint if time_hint else "æ— ç‰¹å®šæ—¶é—´èŒƒå›´"}

## æ•°æ®åº“æ¶æ„
{schema_summary}
{allowed_tables_note}

## æŸ¥è¯¢æŒ‡å¯¼
{type_guidance if type_guidance else "ç”Ÿæˆç¬¦åˆä¸šåŠ¡éœ€æ±‚çš„ç»Ÿè®¡æŸ¥è¯¢"}

## å‰ç½®åˆ†æï¼ˆç»“æ„åŒ–ï¼‰
{context.get('pre_sql_analysis') or 'ï¼ˆæœ¬æ¬¡æ— å‰ç½®åˆ†æï¼‰'}

## è¾“å‡ºè¦æ±‚ï¼ˆä»…è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸è¦å…¶ä»–æ–‡æœ¬ï¼‰
{{
  "sql": "ä»¥å•è¡Œå­—ç¬¦ä¸²è¿”å›å®Œæ•´SELECTè¯­å¥ï¼Œæ—¶é—´è¿‡æ»¤å¿…é¡»ä½¿ç”¨å ä½ç¬¦æ ¼å¼",
  "time": {{
    "column": "å®é™…ä½¿ç”¨çš„æ—¶é—´åˆ—å",
    "range": {{"start_date": "{{{{start_date}}}}", "end_date": "{{{{end_date}}}}"}}
  }},
  "tables": ["æ¶‰åŠåˆ°çš„çœŸå®è¡¨ååˆ—è¡¨"],
  "measures": ["COUNT(*) as cnt", "å¯é€‰å…¶ä»–åº¦é‡"],
  "dimensions": ["å¯é€‰ç»´åº¦åˆ—å"],
  "filters": [{{"field":"åˆ—å","op":"=|IN|BETWEEN|LIKE","value":"å€¼æˆ–æ•°ç»„"}}],
  "assumptions": ["å¯é€‰ï¼šå¯¹ä¸ç¡®å®šä¿¡æ¯çš„å‡è®¾"],
  "notes": ["å¯é€‰ï¼šä»»ä½•æ³¨æ„äº‹é¡¹"]
}}

## é‡è¦è§„åˆ™
1. **è¡¨ååˆ—å**: ä¸¥æ ¼ä½¿ç”¨ä¸Šè¿°æ•°æ®åº“æ¶æ„ä¸­çš„çœŸå®è¡¨åå’Œåˆ—åï¼Œç¦æ­¢è™šæ„
2. **æ—¶é—´å­—æ®µé€‰æ‹©**: ä»è¡¨ç»“æ„ä¸­æ™ºèƒ½é€‰æ‹©åˆé€‚çš„æ—¶é—´å­—æ®µï¼ˆé€šå¸¸æ˜¯dateã€datetimeæˆ–timestampç±»å‹çš„å­—æ®µï¼‰
3. **æ—¶é—´è¿‡æ»¤æ ¼å¼ï¼ˆå…³é”®ï¼‰**: å¿…é¡»ä½¿ç”¨å ä½ç¬¦æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨å…·ä½“æ—¥æœŸï¼š
   - âœ… æ­£ç¡®: `WHERE dt >= {{{{start_date}}}} AND dt <= {{{{end_date}}}}`
   - âœ… æ­£ç¡®: `WHERE DATE(æ—¶é—´åˆ—) BETWEEN {{{{start_date}}}} AND {{{{end_date}}}}`
   - âŒ é”™è¯¯: `WHERE dt >= '2025-09-27' AND dt <= '2025-09-27'`
   - âŒ é”™è¯¯: `WHERE DATE(æ—¶é—´åˆ—) = '2025-09-27'`
4. **å ä½ç¬¦æ ¼å¼**: ä½¿ç”¨åŒå¤§æ‹¬å·æ ¼å¼ {{{{start_date}}}} å’Œ {{{{end_date}}}}ï¼Œè¿™æ ·ç”Ÿæˆçš„SQLæ¨¡æ¿å¯ä»¥åç»­æ›¿æ¢ä¸ºå®é™…æ—¥æœŸ
5. **æ™ºèƒ½åˆ¤æ–­**: é€šè¿‡å­—æ®µåç§°ã€ç±»å‹ã€æ³¨é‡Šæ¥åˆ¤æ–­å“ªä¸ªæ˜¯æ—¶é—´å­—æ®µï¼Œä¸è¦ç¡¬ç¼–ç 

ä»…è¿”å›çº¯JSONï¼Œä¸è¦ä½¿ç”¨Markdownä»£ç å—ã€‚
        """
        return prompt.strip()

    async def _run_pre_sql_analysis(self, context: Dict[str, Any], user_id: str) -> str:
        """ä½¿ç”¨LLMå¯¹è¡¨/åˆ—/æ¨¡æ¿/æ—¶é—´/å ä½ç¬¦è¿›è¡Œä¸€æ¬¡ç»“æ„åŒ–åˆ†æï¼Œè¾“å‡ºJSONæŒ‡å¯¼ç‚¹ã€‚

        ç›®æ ‡ï¼šé€‰å®šç›®æ ‡è¡¨/æ—¶é—´åˆ—/å…³é”®è¿‡æ»¤/åº¦é‡ä¸ç»´åº¦å»ºè®®ï¼Œé¿å…åç»­SQLç”Ÿæˆèµ°åã€‚
        """
        llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
        if not llm_service:
            return ""

        # ç»„è£…ç®€è¦åˆ—ä¿¡æ¯ï¼ˆä»…é€‰ä¸­è¡¨æˆ–æœ€å¤š3å¼ è¡¨ï¼Œæ¯è¡¨æœ€å¤š20åˆ—ï¼‰
        selected = context.get("selected_tables") or context.get("tables") or []
        selected = selected[:3] if isinstance(selected, list) else []
        details = context.get("column_details") or {}
        self._logger.info(f"ğŸ“‹ [Executor] SQLç”Ÿæˆæç¤ºä¸­ä½¿ç”¨è¯¦ç»†å­—æ®µä¿¡æ¯: {len(details)}å¼ è¡¨, é€‰ä¸­è¡¨: {selected}")
        cols_preview = {}
        for t in selected:
            tmap = details.get(t) or {}
            cols_preview[t] = [{"name": k, "type": (v.get("type") if isinstance(v, dict) else None), "comment": (v.get("comment") if isinstance(v, dict) else None)} for i, (k, v) in enumerate(tmap.items()) if i < 20]

        prompt = f"""
ä½ æ˜¯æ•°æ®å»ºæ¨¡ä¸SQLè§„åˆ’ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ç”Ÿæˆä¸€ä»½â€œSQLç”Ÿæˆå‰çš„ç»“æ„åŒ–åˆ†æâ€ï¼ˆJSONå¯¹è±¡ï¼‰ï¼ŒæŒ‡å¯¼ä¸‹ä¸€æ­¥SQLç¼–å†™ã€‚

ä¸Šä¸‹æ–‡ï¼š
- å ä½ç¬¦æè¿°: {context.get('placeholder_description')}
- å¯é€‰è¡¨: {', '.join(selected) if selected else '(æœªæä¾›)'}
- æ¨èæ—¶é—´åˆ—: {context.get('recommended_time_column')}
- æ—¶é—´èŒƒå›´: {context.get('start_date') or context.get('window', {}).get('start_date')} ~ {context.get('end_date') or context.get('window', {}).get('end_date')}
- æ¨¡æ¿ä¸Šä¸‹æ–‡: {str(context.get('template_context'))[:300] if context.get('template_context') else '(æ— )'}
- é€‰è¡¨åˆ—é¢„è§ˆ: {cols_preview}

è¯·è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼š
{{
  "target_table": "å»ºè®®ä½¿ç”¨çš„è¡¨åï¼ˆå¿…é¡»åœ¨å¯é€‰è¡¨ä¸­ï¼‰",
  "time_column": "å»ºè®®ä½¿ç”¨çš„æ—¶é—´åˆ—",
  "measures": ["COUNT(*) as ..." æˆ–å…¶ä»–åº¦é‡è¡¨è¾¾å¼],
  "filters": [{{"field":"åˆ—å","op":"=|IN|BETWEEN|LIKE","value":"å€¼æˆ–æ•°ç»„"}}],
  "dimensions": ["ç»´åº¦åˆ—å"],
  "sql_skeleton": "å¯é€‰ï¼Œç»™å‡ºä¸€ä¸ªSQLéª¨æ¶ï¼ˆFROM/WHERE/æ—¶é—´è¿‡æ»¤/åˆ†ç»„/èšåˆï¼‰",
  "notes": ["ä»»ä½•æ³¨æ„äº‹é¡¹"]
}}
åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚
"""

        try:
            # å°½é‡è¿”å›JSON
            if hasattr(llm_service, 'ask'):
                res = await llm_service.ask(user_id=user_id, prompt=prompt, response_format={"type": "json_object"})
                text = res.get("response", "") if isinstance(res, dict) else str(res)
            elif hasattr(llm_service, 'generate_response'):
                res = await llm_service.generate_response(prompt=prompt, user_id=user_id, response_format={"type": "json_object"})
                text = res.get("response", "") if isinstance(res, dict) else str(res)
            else:
                text = await llm_service(prompt)
            return text.strip()
        except Exception:
            return ""

    async def _call_llm(self, llm_service, prompt: str, user_id: str = "system", llm_policy: Dict[str, Any] | None = None) -> str:
        """ç»Ÿä¸€è°ƒç”¨LLMï¼Œå°½é‡ä¸Planner/Orchestratorä¿æŒä¸€è‡´æ¥å£ã€‚"""
        try:
            if hasattr(llm_service, 'ask'):
                result = await llm_service.ask(
                    user_id=user_id,
                    prompt=prompt,
                    response_format={"type": "json_object"},
                    llm_policy=llm_policy or {"stage": "tool", "output_kind": "sql"}
                )
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif hasattr(llm_service, 'generate_response'):
                result = await llm_service.generate_response(
                    prompt=prompt,
                    user_id=user_id,
                    response_format={"type": "json_object"},
                    llm_policy=llm_policy or {"stage": "tool", "output_kind": "sql"}
                )
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif callable(llm_service):
                return await llm_service(prompt)
            else:
                raise ValueError("Unsupported LLM service interface")
        except Exception as e:
            self._logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    def _extract_sql(self, text: str) -> str:
        """ä»LLMæ–‡æœ¬ä¸­æå–SQLï¼Œæ”¯æŒ```sql```ä»£ç å—æˆ–çº¯æ–‡æœ¬ã€‚"""
        try:
            t = (text or "").strip()
            if not t:
                return ""
            # ä¼˜å…ˆæå–```sql```ä»£ç å—
            import re
            code_fence = re.search(r"```sql\s*([\s\S]*?)```", t, re.IGNORECASE)
            if code_fence:
                candidate = code_fence.group(1).strip()
            else:
                # å»æ‰é€šç”¨ä»£ç å—
                generic_fence = re.search(r"```\s*([\s\S]*?)```", t)
                candidate = (generic_fence.group(1).strip() if generic_fence else t)

            # å»æ‰å¼€å¤´çš„æ³¨é‡Šè¡Œï¼Œä»…ä¿ç•™ä»¥SELECT/WITHå¼€å¤´çš„ä¸»ä½“
            lines = [ln for ln in candidate.splitlines() if ln.strip()]
            body = []
            started = False
            for ln in lines:
                ln_strip = ln.strip()
                up = ln_strip.upper()
                if not started and (up.startswith("SELECT") or up.startswith("WITH")):
                    started = True
                if started:
                    body.append(ln)
            sql = "\n".join(body).strip()
            # æ¸…ç†å°¾éšåå¼•å·/å¤šä½™å†…å®¹
            sql = sql.strip().strip('`').strip()
            return sql
        except Exception:
            return (text or "").strip()

    async def _execute_tool_with_retry(self, tool_name: str, tool, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·ï¼Œå¸¦åŸºæœ¬é‡è¯•å’Œç»“æœæ ‡å‡†åŒ–ã€‚"""
        import asyncio
        from .utils.json_utils import normalize_tool_result, is_transient_error

        last_result: Dict[str, Any] | None = None
        for attempt in range(self.max_tool_retries + 1):
            if attempt > 0:
                await asyncio.sleep(self.retry_backoff_base * (2 ** (attempt - 1)))
            try:
                raw = await tool.execute(input_data)
            except Exception as e:
                raw = {"success": False, "error": str(e)}

            result = normalize_tool_result(tool_name, raw)
            last_result = result

            # æˆåŠŸæˆ–éç¬æ—¶é”™è¯¯åˆ™åœæ­¢é‡è¯•
            if result.get("success") and not result.get("error"):
                break
            if not is_transient_error(result.get("error")):
                break

        return last_result or {"success": False, "error": "unknown_error"}

    def _infer_table_keywords(self, description: str) -> List[str]:
        """ä»å ä½ç¬¦æè¿°ä¸­æ¨æ–­ç”¨äºåŒ¹é…è¡¨åçš„å…³é”®è¯ã€‚"""
        try:
            text = (description or "").lower()
            keywords: List[str] = []
            # å¸¸è§é€€è´§/é€€æ¬¾åœºæ™¯å…³é”®è¯
            if any(k in text for k in ["é€€è´§", "é€€æ¬¾", "return", "refund"]):
                keywords.extend(["refund", "return", "é€€è´§", "é€€æ¬¾"])
            # å¸¸è§ODS/DWå‰ç¼€ä¸å¼ºåˆ¶æ·»åŠ ï¼Œç”±å€™é€‰è¡¨åŒ¹é…
            # å»é‡å¹¶ä¿æŒé¡ºåº
            seen = set()
            ordered = []
            for k in keywords:
                if k not in seen:
                    ordered.append(k)
                    seen.add(k)
            return ordered
        except Exception:
            return []

    def _extract_tokens(self, text: str) -> List[str]:
        """æå–ç”¨äºç›¸ä¼¼åº¦åŒ¹é…çš„çŸ­è¯/ç¼©å†™ï¼ˆç®€å•åˆ†è¯ä¸é™å™ªï¼‰ã€‚"""
        try:
            t = (text or "").lower()
            # åŸºç¡€åˆ†è¯ï¼šéå­—æ¯æ•°å­—æ‹†åˆ† + å»åœç”¨è¯ + é•¿åº¦è¿‡æ»¤
            import re
            raw = re.split(r"[^a-z0-9\u4e00-\u9fa5]+", t)
            stop = {"çš„", "å’Œ", "ä¸", "æ€»æ•°", "ç»Ÿè®¡", "æ•°é‡", "ä¸ªæ•°", "ä¿¡æ¯", "æ•°æ®", "è¡¨", "ç”³è¯·"}
            tokens = [w for w in raw if w and w not in stop and len(w) >= 2]
            # æ·»åŠ å¸¸è§ç¼©å†™æ˜ å°„ï¼ˆå¯æ‰©å±•ï¼‰
            mapped: List[str] = []
            alias = {
                "refund": ["rf", "rfd"],
                "return": ["ret", "rtn"],
            }
            for w in tokens:
                mapped.append(w)
                for key, al in alias.items():
                    if w.startswith(key):
                        mapped.extend(al)
            # å»é‡
            seen: set[str] = set()
            ordered: List[str] = []
            for w in mapped:
                if w not in seen:
                    ordered.append(w)
                    seen.add(w)
            return ordered
        except Exception:
            return []

    def _extract_explicit_tables(self, reason: str, tool_input: Dict[str, Any], candidates: List[str]) -> List[str]:
        """ä»reasonæˆ–è¾“å…¥ä¸­è§£ææ˜¾å¼è¡¨åï¼ˆä¾‹å¦‚åŒ…å« `è·å– ods_refund è¡¨`ï¼‰ã€‚"""
        try:
            explicit: List[str] = []
            # 1) ç›´æ¥ä» tool_input.tables è¯»å–ï¼ˆå­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰
            if isinstance(tool_input.get("tables"), list) and tool_input["tables"]:
                return tool_input["tables"]
            if isinstance(tool_input.get("tables"), str) and tool_input["tables"].strip():
                return [tool_input["tables"].strip()]

            # 2) ä» reason ä¸­æ­£åˆ™æå–å•è¯ï¼ŒåŒ¹é…å€™é€‰è¡¨
            import re
            text = f"{reason or ''}"
            words = re.findall(r"[A-Za-z0-9_\.]+", text)
            lowered = {c.lower(): c for c in candidates}
            for w in words:
                lw = w.lower()
                if lw in lowered:
                    explicit.append(lowered[lw])
            # å»é‡ä¿æŒé¡ºåº
            seen: set[str] = set()
            ordered: List[str] = []
            for t in explicit:
                if t not in seen:
                    ordered.append(t)
                    seen.add(t)
            return ordered
        except Exception:
            return []

    async def execute_single_tool(self, tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…· (ç”¨äºè°ƒè¯•å’Œæµ‹è¯•)

        Args:
            tool_name: å·¥å…·åç§°
            tool_input: å·¥å…·è¾“å…¥

        Returns:
            Dict: å·¥å…·æ‰§è¡Œç»“æœ
        """
        tool = self.registry.get(tool_name)
        if not tool:
            return {"success": False, "error": f"å·¥å…· {tool_name} æœªæ‰¾åˆ°"}

        try:
            result = await tool.execute(tool_input)
            return result
        except Exception as e:
            return {"success": False, "error": f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}"}

    def _is_description_text(self, sql: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºæè¿°æ–‡æœ¬è€ŒéSQL - ä¸SQLValidateToolä¿æŒä¸€è‡´"""
        if not sql or not isinstance(sql, str):
            return False

        sql_lower = sql.lower().strip()

        # æ˜æ˜¾çš„æè¿°æ€§å…³é”®è¯
        description_keywords = [
            "å½“å‰å€™é€‰", "å€™é€‰sql", "sqlå†…å®¹", "å·²æœ‰sql", "ç°æœ‰sql",
            "å¾…éªŒè¯", "ç­‰å¾…", "è¯·", "éœ€è¦", "å»ºè®®", "åº”è¯¥",
            "å€™é€‰çš„", "å½“å‰çš„", "ç”Ÿæˆçš„", "æä¾›çš„", "è¿”å›çš„"
        ]

        # å¦‚æœåŒ…å«æè¿°æ€§å…³é”®è¯ä½†ä¸åŒ…å«SQLå…³é”®è¯ï¼Œå¯èƒ½æ˜¯æè¿°æ–‡æœ¬
        has_description = any(keyword in sql_lower for keyword in description_keywords)
        has_sql_keywords = any(keyword in sql_lower for keyword in ["select", "from", "where", "insert", "update", "delete"])

        if has_description and not has_sql_keywords:
            return True

        # å¦‚æœæ˜¯å¾ˆçŸ­çš„æ–‡æœ¬ä¸”ä¸åŒ…å«SQLå…³é”®è¯ï¼Œå¯èƒ½æ˜¯æè¿°
        if len(sql.strip()) < 50 and not has_sql_keywords:
            return True

        # å¦‚æœåŒ…å«ä¸­æ–‡æè¿°æ€§è¯è¯­
        chinese_description = ["å½“å‰", "å€™é€‰", "å†…å®¹", "æè¿°", "ä¿¡æ¯", "æ•°æ®", "ç»“æœ"]
        has_chinese_desc = any(keyword in sql for keyword in chinese_description)
        if has_chinese_desc and not has_sql_keywords:
            return True

        return False

    def list_available_tools(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨å·¥å…·"""
        return list(self.registry._tools.keys())

    def get_tool_info(self, tool_name: str) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        tool = self.registry.get(tool_name)
        if not tool:
            return {"exists": False}

        return {
            "exists": True,
            "name": tool.name,
            "description": getattr(tool, 'description', 'No description available'),
            "type": tool.__class__.__name__
        }

    def _extract_semantic_info(self, ai: AgentInput) -> Dict[str, Any]:
        """ä»AgentInputçš„task_driven_contextä¸­æå–å ä½ç¬¦è¯­ä¹‰ä¿¡æ¯ï¼ˆsemantic_typeã€top_nï¼‰ã€‚"""
        info: Dict[str, Any] = {}
        try:
            tdc = ai.task_driven_context or {}
            # ä¼˜å…ˆä½¿ç”¨å ä½ç¬¦IDã€å…¶æ¬¡æè¿°ï¼Œå°½é‡åŒ¹é…æ¨¡æ¿ä¸Šä¸‹æ–‡ä¸­çš„placeholder_name
            ph_candidates = []
            try:
                if ai.placeholder.id:
                    ph_candidates.append(str(ai.placeholder.id))
            except Exception:
                pass
            try:
                if ai.placeholder.description:
                    ph_candidates.append(str(ai.placeholder.description))
            except Exception:
                pass
            # å»é‡
            ph_candidates = list(dict.fromkeys(ph_candidates))
            contexts = tdc.get("placeholder_contexts") or []
            match = None
            for c in contexts:
                pname = c.get("placeholder_name")
                if not pname:
                    continue
                if any(pname == cand or pname in cand or cand in pname for cand in ph_candidates):
                    match = c
                    break
            if match:
                info["semantic_type"] = match.get("semantic_type")
                params = match.get("parsed_params") or {}
                if isinstance(params, dict):
                    info["top_n"] = params.get("top_n")
        except Exception:
            pass
        return info

    def _update_context_state(self, context: Dict[str, Any], result: Dict[str, Any], tool_name: str) -> None:
        """æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡çŠ¶æ€"""
        # å°†å·¥å…·æ‰§è¡Œç»“æœåˆå¹¶åˆ°ä¸Šä¸‹æ–‡
        if isinstance(result, dict):
            for key, value in result.items():
                if key not in ["success", "error", "action", "message"]:
                    context[key] = value

        # ç‰¹æ®Šå¤„ç†å…³é”®å·¥å…·çš„ç»“æœ
        if tool_name == "sql.validate":
            if result.get("issues"):
                context["validation_issues"] = result["issues"]
            if result.get("warnings"):
                context["validation_warnings"] = result["warnings"]
            if result.get("corrected_sql"):
                context["corrected_sql"] = result["corrected_sql"]
                # è‡ªåŠ¨é‡‡ç”¨ä¿®æ­£åçš„SQLä½œä¸ºå½“å‰SQLï¼Œä¾¿äºåç»­ç­–ç•¥ä¸æ‰§è¡Œ
                try:
                    if result["corrected_sql"]:
                        context["current_sql"] = result["corrected_sql"]
                except Exception:
                    pass
            if result.get("agent_analysis"):
                context["agent_analysis"] = result["agent_analysis"]

        elif tool_name == "sql.execute":
            if result.get("rows"):
                context["execution_result"] = {
                    "rows": result["rows"],
                    "columns": result.get("columns", []),
                    "row_count": len(result["rows"])
                }
                context["sql_executed_successfully"] = True

        # é€šç”¨ï¼šè‹¥å·¥å…·è¿”å›äº†sqlå­—æ®µï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºå½“å‰SQLï¼ˆå¦‚sql.policyã€workflow.* ç­‰ï¼‰
        try:
            if isinstance(result.get("sql"), str) and result.get("sql").strip():
                context["current_sql"] = result["sql"].strip()
        except Exception:
            pass

        # é€šç”¨ï¼šè‹¥å·¥å…·è¿”å›äº†æ‰§è¡Œç»“æœæ•°æ®ï¼ˆrows/columnsï¼‰ï¼Œä¹Ÿè§†ä¸ºä¸€æ¬¡æ‰§è¡ŒæˆåŠŸï¼ˆå¦‚workflow.*å†…éƒ¨å·²æ‰§è¡ŒSQLï¼‰
        try:
            if isinstance(result.get("rows"), list):
                context["execution_result"] = {
                    "rows": result.get("rows", []),
                    "columns": result.get("columns", []),
                    "row_count": len(result.get("rows", []))
                }
                context["sql_executed_successfully"] = True
        except Exception:
            pass

        if tool_name == "schema.list_columns":
            if result.get("schema_summary"):
                context["schema_summary"] = result["schema_summary"]
            if result.get("columns"):
                context["columns"] = result["columns"]
            if result.get("column_details"):
                context["column_details"] = result["column_details"]
                self._logger.info(f"ğŸ“‹ [Executor] å­˜å‚¨schema.list_columnsè¯¦ç»†å­—æ®µä¿¡æ¯: {len(result['column_details'])}å¼ è¡¨")

        elif tool_name == "schema.get_columns":
            self._logger.info(f"ğŸ“‹ [Executor] å¤„ç†schema.get_columnsç»“æœ: success={result.get('success')}")
            self._logger.info(f"ğŸ“‹ [Executor] ç»“æœåŒ…å«çš„é”®: {list(result.keys()) if isinstance(result, dict) else 'Not dict'}")

            if result.get("schema_summary"):
                context["schema_summary"] = result["schema_summary"]
                self._logger.info(f"ğŸ“‹ [Executor] å­˜å‚¨schema_summary: {len(result['schema_summary'])}å­—ç¬¦")
            if result.get("columns"):
                context["columns"] = result["columns"]
                self._logger.info(f"ğŸ“‹ [Executor] å­˜å‚¨columns: {len(result['columns'])}å¼ è¡¨")
            if result.get("column_details"):
                context["column_details"] = result["column_details"]
                self._logger.info(f"ğŸ“‹ [Executor] å­˜å‚¨schema.get_columnsè¯¦ç»†å­—æ®µä¿¡æ¯: {len(result['column_details'])}å¼ è¡¨")
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªè¡¨çš„è¯¦ç»†ä¿¡æ¯ä½œä¸ºæ ·ä¾‹
                if result['column_details']:
                    first_table = list(result['column_details'].keys())[0]
                    first_columns = result['column_details'][first_table]
                    self._logger.info(f"ğŸ“‹ [Executor] æ ·ä¾‹è¡¨{first_table}çš„å­—æ®µ: {list(first_columns.keys())}")
            # ä¸å†ç¡¬ç¼–ç æ¨èæ—¶é—´åˆ—ï¼Œè®©Agenté€šè¿‡æŸ¥çœ‹å®é™…æ•°æ®æ¥æ™ºèƒ½åˆ¤æ–­
            # Agentæ¯”æˆ‘ä»¬çš„ç®—æ³•èªæ˜ï¼Œç›´æ¥æŸ¥5è¡Œæ•°æ®å°±çŸ¥é“å“ªä¸ªæ˜¯æ—¶é—´å­—æ®µäº†
            try:
                self._logger.info("ğŸ“‹ [Executor] è·³è¿‡ç¡¬ç¼–ç æ—¶é—´åˆ—æ¨èï¼Œè®©Agenté€šè¿‡æ•°æ®æŸ¥è¯¢æ™ºèƒ½åˆ¤æ–­")
                context["use_agent_time_column_detection"] = True
            except Exception:
                pass

            # è¡¨å†ç­›é€‰ï¼šåŸºäºæ—¶é—´åˆ—ã€è¡¨åå…³é”®è¯ã€ç»´åº¦åˆ—å‘½ä¸­å¯¹è¡¨è¿›è¡Œæ’åºä¸é€‰æ‹©
            try:
                selected = self._rank_and_select_tables(context, result)
                if selected:
                    context["selected_tables"] = selected
                    # å°† tables é¡ºåºè°ƒæ•´ä¸ºæ‰€é€‰è¡¨ä¼˜å…ˆ
                    tlist = context.get("tables") or []
                    rest = [t for t in tlist if t not in selected]
                    context["tables"] = selected + rest

                    # è°ƒæ•´æ¨èæ—¶é—´åˆ—ä»¥é€‚é…é¦–é€‰ç›®æ ‡è¡¨ï¼ˆä¼˜å…ˆä¿è¯å¯ç”¨æ€§ï¼‰
                    try:
                        top_table = selected[0]
                        # é¦–å…ˆå°è¯•ä»è¯¦ç»†å­—æ®µä¸­è·å–è¯¥è¡¨åˆ—é›†åˆï¼Œå¦åˆ™é€€å› columns ç®€è¡¨
                        t_details = (result.get("column_details") or {}).get(top_table) or {}
                        if isinstance(t_details, dict) and t_details:
                            table_cols = {c.lower() for c in t_details.keys()}
                        else:
                            table_cols = {c.lower() for c in (result.get("columns") or {}).get(top_table, [])}

                        rec = (context.get("recommended_time_column") or "").lower()

                        # ä¸å†ç¡¬ç¼–ç è°ƒæ•´æ—¶é—´åˆ—ï¼Œè®©Agentä»å®é™…æ•°æ®ä¸­åˆ¤æ–­
                        self._logger.info(f"ğŸ“‹ [Executor] è·³è¿‡ç¡¬ç¼–ç æ—¶é—´åˆ—è°ƒæ•´ï¼Œè®©Agentæ™ºèƒ½é€‰æ‹© (è¡¨: {top_table})")
                    except Exception:
                        pass
            except Exception:
                pass

        elif tool_name == "time.window":
            if result.get("start_date"):
                context["start_date"] = result["start_date"]
            if result.get("end_date"):
                context["end_date"] = result["end_date"]

        elif tool_name == "chart.spec":
            if result.get("chart_spec"):
                context["chart_spec"] = result["chart_spec"]

        elif tool_name == "word_chart_generator":
            if result.get("chart_image_path"):
                context["chart_image_path"] = result["chart_image_path"]

    def _build_decision_info(self, result: Dict[str, Any], step: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºAgentå†³ç­–æ”¯æŒä¿¡æ¯"""
        decision_info = {
            "step_completed": step.get("action", "tool_call"),
            "step_reason": step.get("reason", ""),
            "next_recommendations": []
        }

        # åŸºäºæ‰§è¡Œç»“æœæä¾›ä¸‹ä¸€æ­¥å»ºè®®
        if result.get("success"):
            action = step.get("action")
            tool_name = step.get("tool")

            # SQLç”Ÿæˆå®Œæˆå»ºè®®
            if action == "sql_generation":
                decision_info["next_recommendations"] = [
                    "Agentåº”ç”ŸæˆSQLè¯­å¥",
                    "ç„¶åè°ƒç”¨sql.validateéªŒè¯SQLæ­£ç¡®æ€§",
                    "å¦‚æœ‰é—®é¢˜åˆ™ä¿®æ­£SQL"
                ]

            # Schemaä¿¡æ¯è·å–å®Œæˆå»ºè®®
            elif tool_name == "schema.list_columns":
                decision_info["next_recommendations"] = [
                    "Schemaä¿¡æ¯å·²è·å–ï¼Œå¯ä»¥å¼€å§‹ç”ŸæˆSQL",
                    "å»ºè®®ä½¿ç”¨sql_generationåŠ¨ä½œç”ŸæˆSQL",
                    "ç¡®ä¿ä½¿ç”¨çœŸå®çš„è¡¨åå’Œåˆ—å"
                ]

            elif tool_name == "schema.list_tables":
                decision_info["next_recommendations"] = [
                    "å·²åˆ—å‡ºå¯ç”¨è¡¨å",
                    "è¯·é€‰æ‹©ä¸éœ€æ±‚ç›¸å…³çš„è¡¨å¹¶è°ƒç”¨schema.get_columnsè·å–åˆ—ä¿¡æ¯",
                    "éšåä½¿ç”¨sql_generationç”ŸæˆSQL"
                ]

            elif tool_name == "schema.get_columns":
                decision_info["next_recommendations"] = [
                    "å·²è·å–ç›®æ ‡è¡¨çš„åˆ—ä¿¡æ¯",
                    "å»ºè®®ä½¿ç”¨sql_generationç”ŸæˆSQL",
                    "ç”Ÿæˆåè°ƒç”¨sql.validateéªŒè¯"
                ]

            # æ—¶é—´çª—å£è®¡ç®—å®Œæˆå»ºè®®
            elif tool_name == "time.window":
                decision_info["next_recommendations"] = [
                    "æ—¶é—´çª—å£å·²è®¡ç®—å®Œæˆ",
                    "å»ºè®®è·å–Schemaä¿¡æ¯æˆ–ç›´æ¥ç”ŸæˆSQL",
                    "ç¡®ä¿åœ¨SQLä¸­æ·»åŠ æ—¶é—´è¿‡æ»¤æ¡ä»¶"
                ]

            # SQLéªŒè¯å®Œæˆå»ºè®®
            elif tool_name == "sql.validate":
                if result.get("issues"):
                    decision_info["next_recommendations"] = [
                        "SQLéªŒè¯å‘ç°é—®é¢˜ï¼Œéœ€è¦ä¿®æ­£",
                        "å»ºè®®é‡æ–°ç”ŸæˆSQLè§£å†³éªŒè¯é—®é¢˜",
                        "æˆ–è°ƒç”¨sql.refineå·¥å…·ä¿®æ­£SQL"
                    ]
                else:
                    decision_info["next_recommendations"] = [
                        "SQLéªŒè¯é€šè¿‡ï¼Œå¯ä»¥æ‰§è¡Œ",
                        "å»ºè®®è°ƒç”¨sql.executeè·å–æ•°æ®",
                        "ç„¶åæ£€æŸ¥æ•°æ®è´¨é‡"
                    ]

            # SQLæ‰§è¡Œå®Œæˆå»ºè®®
            elif tool_name == "sql.execute":
                if result.get("rows"):
                    decision_info["next_recommendations"] = [
                        "SQLæ‰§è¡ŒæˆåŠŸï¼Œæ•°æ®å·²è·å–",
                        "å»ºè®®è°ƒç”¨data.qualityæ£€æŸ¥æ•°æ®è´¨é‡",
                        "å¦‚éœ€å›¾è¡¨åˆ™è°ƒç”¨chart.specç”Ÿæˆé…ç½®"
                    ]
                else:
                    decision_info["next_recommendations"] = [
                        "SQLæ‰§è¡Œæ— ç»“æœï¼Œæ£€æŸ¥SQLé€»è¾‘",
                        "å¯èƒ½éœ€è¦è°ƒæ•´æ—¶é—´èŒƒå›´æˆ–è¿‡æ»¤æ¡ä»¶"
                    ]

            # å·¥ä½œæµå·¥å…·å®Œæˆå»ºè®®
            elif tool_name in ("workflow.stat_basic", "workflow.stat_ratio", "workflow.stat_category_mix"):
                if result.get("rows"):
                    decision_info["next_recommendations"] = [
                        "å·¥ä½œæµå·²è¿”å›ç»Ÿè®¡ç»“æœ",
                        "å¦‚éœ€ç»§ç»­å¯è¿›è¡Œdata.qualityæˆ–æ¸²æŸ“å›¾è¡¨",
                        "å¦åˆ™å¯ç»“æŸæœ¬è½®PTAV"
                    ]
                else:
                    decision_info["next_recommendations"] = [
                        "å·¥ä½œæµæœªè¿”å›æ•°æ®ï¼Œæ£€æŸ¥ç”Ÿæˆçš„SQLä¸è¿‡æ»¤æ¡ä»¶",
                        "å¿…è¦æ—¶é‡æ–°ç”Ÿæˆæˆ–æ”¾å®½æ¡ä»¶"
                    ]

        else:
            # æ‰§è¡Œå¤±è´¥çš„é€šç”¨å»ºè®®
            decision_info["next_recommendations"] = [
                "ä¸Šä¸€æ­¥æ‰§è¡Œå¤±è´¥ï¼Œåˆ†æé”™è¯¯åŸå› ",
                "å¯èƒ½éœ€è¦é‡æ–°è§„åˆ’æˆ–è°ƒæ•´ç­–ç•¥",
                "æ£€æŸ¥è¾“å…¥å‚æ•°å’Œä¸Šä¸‹æ–‡æ˜¯å¦æ­£ç¡®"
            ]

        return decision_info

    def _rank_and_select_tables(self, context: Dict[str, Any], result: Dict[str, Any]) -> List[str]:
        """æ ¹æ®åˆ—è¯¦æƒ…ä¸å ä½ç¬¦æè¿°ä¸ºè¡¨æ‰“åˆ†é€‰æ‹©æœ€ç›¸å…³çš„è‹¥å¹²è¡¨ã€‚

        æ‰“åˆ†è¦ç´ ï¼š
        - è‹¥è¡¨åŒ…å«æ¨èæ—¶é—´åˆ— +5
        - è¡¨åå‘½ä¸­å ä½ç¬¦å…³é”®è¯ï¼ˆrefund/return/é€€è´§/é€€æ¬¾ç­‰ï¼‰æ¯å‘½ä¸­ +3
        - è¡¨å†…åˆ—å/æ³¨é‡Šå‘½ä¸­ç»´åº¦å…³é”®è¯ï¼ˆtype/category/ç±»åˆ«/å•†å“/äº§å“ï¼‰æ¯å‘½ä¸­ +2ï¼ˆæœ€å¤šåŠ 6ï¼‰
        - tokens ç›¸ä¼¼åŒ…å«æ¯å‘½ä¸­ +1ï¼ˆæœ€å¤šåŠ 5ï¼‰
        """
        from collections import defaultdict

        details = result.get("column_details") or {}
        columns_map = result.get("columns") or {}
        tables = list(columns_map.keys())
        if not tables:
            return []

        placeholder_desc = context.get("placeholder_description", "")
        # å…³é”®è¯ä¸token
        kw = set(self._infer_table_keywords(placeholder_desc))
        toks = set(self._extract_tokens(placeholder_desc))
        time_col = (context.get("recommended_time_column") or "").lower()

        def score_table(tname: str) -> int:
            s = 0
            lower_name = str(tname).lower()
            # è¡¨åå…³é”®è¯
            for k in kw:
                if k in lower_name:
                    s += 3
            # tokens
            tok_hits = sum(1 for tok in toks if tok and tok in lower_name)
            s += min(tok_hits, 5)  # cap

            # æ—¶é—´åˆ—å‘½ä¸­
            tdetails = details.get(tname) or {}
            if time_col and time_col in {c.lower() for c in tdetails.keys()}:
                s += 5

            # ç»´åº¦å…³é”®è¯å‘½ä¸­
            dim_kws = ["type", "category", "kind", "class", "å•†å“", "å“ç±»", "ç±»åˆ«", "äº§å“"]
            dim_hits = 0
            for col, meta in tdetails.items():
                name_l = col.lower()
                if any(dk in name_l for dk in dim_kws):
                    dim_hits += 1
                cmt = meta.get("comment")
                if isinstance(cmt, str) and any(dk in cmt for dk in dim_kws):
                    dim_hits += 1
                if dim_hits >= 3:  # cap
                    break
            s += min(dim_hits * 2, 6)
            return s

        ranked = sorted(tables, key=lambda t: (-score_table(t), t))
        top_k = min(3, len(ranked))
        return ranked[:top_k]

    def _suggest_tables_from_names(self, candidates: List[str], description: str, top_k: int = 3) -> List[str]:
        """åœ¨åªæœ‰è¡¨åæ—¶çš„è½»é‡æ¨èï¼šåŸºäºå…³é”®è¯ä¸tokenså‘½ä¸­è¿›è¡Œæ’åºã€‚"""
        try:
            kw = set(self._infer_table_keywords(description))
            toks = set(self._extract_tokens(description))
            def score(name: str) -> int:
                n = (name or "").lower()
                s = 0
                for k in kw:
                    if k in n:
                        s += 3
                s += min(sum(1 for t in toks if t and t in n), 5)
                return s
            ranked = sorted(candidates or [], key=lambda n: (-score(n), n))
            return ranked[:min(top_k, len(ranked))]
        except Exception:
            return (candidates or [])[:min(top_k, len(candidates or []))]

    def _reduce_context(self, context: Dict[str, Any], tool_name: str, result: Dict[str, Any] | None = None) -> None:
        """è£å‰ªä¸Šä¸‹æ–‡ï¼Œåˆ é™¤æ— å…³æˆ–è¿‡å¤§çš„å­—æ®µï¼Œä¿ç•™å¯¹ä¸‹ä¸€æ­¥å†³ç­–æœ‰ä»·å€¼çš„å…³é”®ä¿¡æ¯ã€‚

        ç­–ç•¥ï¼š
        - æ°¸ä¹…ä¿ç•™ï¼šcurrent_sql, sql_executed_successfully, execution_result(rows/columns/row_count),
          start_date, end_date, timezone, window(ä»…ä¿ç•™è½»é‡é”®), tables(æœ€å¤šå‰50ä¸ª), schema_summary,
          recommended_time_column, validation_issues/warningsï¼ˆçŸ­æ–‡æœ¬ï¼‰ã€‚
        - column_detailsï¼šä»…ä¿ç•™å½“å‰å‘½ä¸­çš„è¡¨ï¼ˆå¦‚æœ‰ï¼‰ä¸”æ¯è¡¨æœ€å¤šå‰20åˆ—ï¼›å¦åˆ™åˆ é™¤ä»¥å‡å°ä½“ç§¯ã€‚
        - åˆ é™¤ï¼šå¤§å‹ä¸´æ—¶æ–‡æœ¬ï¼ˆagent_analysis, llm_raw ç­‰ï¼‰ã€schema_scan_offset ç­‰å†…éƒ¨å…‰æ ‡ã€‚
        """
        if not isinstance(context, dict):
            return

        keep_keys = {
            "current_sql", "sql_executed_successfully", "execution_result",
            "start_date", "end_date", "timezone", "window", "tables",
            "schema_summary", "recommended_time_column",
            "validation_issues", "validation_warnings",
        }

        # è½»é‡åŒ– window
        if isinstance(context.get("window"), dict):
            w = context["window"]
            light_w = {
                k: w.get(k) for k in ["start_date", "end_date", "time_column", "timezone", "cron_expression"] if k in w
            }
            context["window"] = light_w

        # tables é™åˆ¶é•¿åº¦
        if isinstance(context.get("tables"), list) and len(context["tables"]) > 50:
            context["tables"] = context["tables"][:50]

        # execution_result é™åˆ¶æ ·æœ¬è¡Œæ•°
        if isinstance(context.get("execution_result"), dict):
            er = context["execution_result"]
            rows = er.get("rows")
            if isinstance(rows, list) and len(rows) > 5:
                er["rows"] = rows[:5]
                er["row_count"] = er.get("row_count", len(rows))
            context["execution_result"] = er

        # column_details ä»…ä¿ç•™å‘½ä¸­çš„è¡¨ä¸”é™åˆ¶æ¯è¡¨åˆ—æ•°
        if isinstance(context.get("column_details"), dict):
            details = context["column_details"]
            selected_tables = []
            # ä» result æˆ– context ä¸­æ¨æ–­å‘½ä¸­çš„è¡¨
            if isinstance(result, dict):
                if isinstance(result.get("tables"), list):
                    selected_tables = result.get("tables")
            if not selected_tables and isinstance(context.get("tables"), list):
                selected_tables = context.get("tables")[:3]

            new_details = {}
            for t in selected_tables:
                cols = details.get(t)
                if isinstance(cols, dict):
                    # æ¯è¡¨æœ€å¤šä¿ç•™20åˆ—çš„å…ƒä¿¡æ¯
                    limited = {}
                    for i, (col, meta) in enumerate(cols.items()):
                        if i >= 20:
                            break
                        limited[col] = meta
                    new_details[t] = limited
            if new_details:
                context["column_details"] = new_details
            else:
                # æ— å‘½ä¸­åˆ™åˆ é™¤ï¼Œé¿å…è¿‡å¤§
                context.pop("column_details", None)

        # åˆ é™¤ä¸å¿…è¦çš„ä¸´æ—¶/å¤§å‹é”®
        for k in ["agent_analysis", "llm_raw", "schema_scan_offset", "sql_generation_candidates"]:
            if k in context:
                context.pop(k, None)

        # ä¸¥æ ¼ä¿ç•™ç™½åå•ï¼ˆé¿å…è¯¯åˆ å·²æœ‰å…³é”®é”®ï¼‰
        keys = list(context.keys())
        for k in keys:
            if k not in keep_keys and k not in {"column_details"}:
                # ä¸åˆ é™¤ç”¨äºå†…éƒ¨ç»§ç»­ä½¿ç”¨çš„è‹¥å¹²é”®ï¼ˆå¦‚ constraints, data_source ç­‰ï¼‰
                if k in {"constraints", "data_source"}:
                    continue
                # å…¶ä»–é”®è‹¥ä¸æ˜¯å¿…é¡»ä¿ç•™çš„ï¼Œä¿ç•™ç°çŠ¶ï¼ˆé¿å…æ‰“ç ´å…¼å®¹ï¼‰ã€‚ä»…åœ¨ä¸Šé¢é’ˆå¯¹å¤§å¯¹è±¡åšè£å‰ªã€‚
                pass
