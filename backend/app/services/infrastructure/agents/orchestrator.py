"""
ç»Ÿä¸€ç¼–æ’å™¨ (Unified Orchestrator) - å•æ­¥éª¤å¾ªç¯ç‰ˆæœ¬

å®ç°Plan-Tool-Active-Validate (PTAV) å•æ­¥éª¤å¾ªç¯æ¶æ„:
1. Plan: Agentåˆ†æå½“å‰çŠ¶æ€å¹¶å†³ç­–ä¸‹ä¸€æ­¥è¡ŒåŠ¨
2. Tool: æ‰§è¡ŒAgentå†³å®šçš„å•ä¸ªå·¥å…·/åŠ¨ä½œ
3. Active: Agentåˆ†æå·¥å…·æ‰§è¡Œç»“æœ
4. Validate: AgentéªŒè¯æ˜¯å¦è¾¾åˆ°ç›®æ ‡ï¼Œå†³å®šç»§ç»­æˆ–ç»“æŸ

å…³é”®ç‰¹æ€§ï¼š
- å•æ­¥éª¤æ‰§è¡Œï¼šæ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªæ“ä½œï¼Œç«‹å³è¿”å›ç»™Agentåˆ†æ
- Agentä¸»å¯¼ï¼šæ‰€æœ‰å†³ç­–ç”±Agentåšå‡ºï¼Œå·¥å…·åªæ‰§è¡Œ
- çœŸå®éªŒè¯ï¼šé€šè¿‡å®é™…æ•°æ®åº“æ‰§è¡ŒéªŒè¯SQLæ­£ç¡®æ€§
- çŠ¶æ€ç»´æŠ¤ï¼šåœ¨å¾ªç¯ä¸­ç»´æŠ¤æ‰§è¡Œä¸Šä¸‹æ–‡å’Œè¿›åº¦

é€‚é…åˆ°backupç³»ç»Ÿçš„æœåŠ¡å®¹å™¨
"""

import json
import time
import uuid
import logging
from typing import Any, Dict

from .types import AgentInput, AgentOutput
from .planner import AgentPlanner
from .context_prompt_controller import ContextPromptController
from .executor import StepExecutor
from .auth_context import auth_manager
from .config_context import config_manager
from .resource_pool import ResourcePool, ContextMemory
from .llm_strategy_manager import llm_strategy_manager


class UnifiedOrchestrator:
    """ç»Ÿä¸€ç¼–æ’å™¨ - å®ç°Plan-Tool-Active-Validateå•æ­¥éª¤å¾ªç¯"""

    def __init__(self, container) -> None:
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            container: backupç³»ç»Ÿçš„æœåŠ¡å®¹å™¨
        """
        self.container = container
        self.planner = AgentPlanner(container)
        self.executor = StepExecutor(container)
        self._ctrl = ContextPromptController()
        self._logger = logging.getLogger(self.__class__.__name__)

        # å¾ªç¯æ§åˆ¶é…ç½®
        self.max_iterations = 15  # æœ€å¤§è¿­ä»£æ¬¡æ•°é˜²æ­¢æ— é™å¾ªç¯
        self.iteration_timeout = 300  # æ€»è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    async def execute(self, ai: AgentInput, mode: str = "ptof") -> AgentOutput:
        """
        ç»Ÿä¸€æ‰§è¡Œå…¥å£ - æ”¯æŒå¤šç§æ‰§è¡Œæ¨¡å¼

        Args:
            ai: Agentè¾“å…¥
            mode: æ‰§è¡Œæ¨¡å¼
                - "ptof": ä¼ ç»ŸPlan-Tool-Observe-Finalizeä¸€æ¬¡æ€§æµç¨‹
                - "ptav": Plan-Tool-Active-Validateå•æ­¥éª¤å¾ªç¯æµç¨‹
                - "task_sql_validation": Taskä»»åŠ¡ä¸­SQLæœ‰æ•ˆæ€§éªŒè¯å’Œæ›´æ–°
                - "report_chart_generation": æŠ¥å‘Šç”Ÿæˆä¸­æ•°æ®è½¬å›¾è¡¨æµç¨‹

        Returns:
            AgentOutput: æ‰§è¡Œç»“æœ
        """
        self._logger.info(f"ğŸš€ å¼€å§‹Agentæ‰§è¡Œ [æ¨¡å¼: {mode}]: {ai.user_prompt}")

        # æ¸…é™¤LLMç­–ç•¥ç®¡ç†å™¨çš„è¯·æ±‚çº§ç¼“å­˜ï¼Œé¿å…è·¨è¯·æ±‚æ•°æ®æ±¡æŸ“
        llm_strategy_manager.clear_cache()
        self._logger.debug("å·²æ¸…é™¤LLMç­–ç•¥ç®¡ç†å™¨ç¼“å­˜")

        try:
            if mode == "ptof":
                return await self._execute_ptof(ai)
            elif mode == "ptav":
                return await self._execute_ptav_loop(ai)
            elif mode == "task_sql_validation":
                return await self._execute_task_sql_validation(ai)
            elif mode == "report_chart_generation":
                return await self._execute_report_chart_generation(ai)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ‰§è¡Œæ¨¡å¼: {mode}")

        except Exception as e:
            error = {"error": f"orchestrator_exception: {str(e)}", "mode": mode}
            self._logger.error(f"Agentæ‰§è¡Œå¼‚å¸¸ [æ¨¡å¼: {mode}]: {str(e)}")
            return AgentOutput(False, "", error)

    async def _execute_ptof(self, ai: AgentInput) -> AgentOutput:
        """
        æ‰§è¡Œä¼ ç»ŸPTOFå·¥ä½œæµç¨‹ - ç”¨äºç®€å•çš„ä¸€æ¬¡æ€§ä»»åŠ¡

        Args:
            ai: Agentè¾“å…¥

        Returns:
            AgentOutput: æ‰§è¡Œç»“æœ
        """
        iteration_id = str(uuid.uuid4())
        self._logger.info(f"ğŸ“‹ [PTOFæ¨¡å¼] å¼€å§‹æ‰§è¡Œ {iteration_id}")

        try:
            # Phase 1: Plan - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            plan_start = time.time()
            plan_result = await self.planner.generate_plan(ai)
            plan_duration = int((time.time() - plan_start) * 1000)

            self._logger.info(f"è®¡åˆ’ç”Ÿæˆå®Œæˆ {iteration_id}: {plan_duration}ms")

            if not plan_result.get("success"):
                self._logger.error(f"è®¡åˆ’ç”Ÿæˆå¤±è´¥ {iteration_id}: {plan_result}")
                return AgentOutput(False, "", plan_result)

            plan = plan_result["plan"]

            # Phase 2: Tool - æ‰§è¡Œå·¥å…·
            tools_start = time.time()
            exec_result = await self.executor.execute(plan, ai)
            tools_duration = int((time.time() - tools_start) * 1000)

            self._logger.info(f"å·¥å…·æ‰§è¡Œå®Œæˆ {iteration_id}: {tools_duration}ms")

            # Phase 3: Observe - è§‚å¯Ÿå’Œæ€»ç»“
            observe_start = time.time()
            observation_report = self._build_observation_report(plan, exec_result)
            observe_duration = int((time.time() - observe_start) * 1000)

            self._logger.info(f"è§‚å¯Ÿæ€»ç»“å®Œæˆ {iteration_id}: {observe_duration}ms")

            # Phase 4: Finalize - æœ€ç»ˆå†³ç­–
            finalize_start = time.time()
            finalize_prompt = self._ctrl.build_finalize_prompt(ai, plan, exec_result)

            # é€‚é…backupç³»ç»Ÿçš„LLMæœåŠ¡
            llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
            if not llm_service:
                raise ValueError("LLM service not found in container")

            # è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆå†³ç­–
            user_id = ai.user_id or auth_manager.get_current_user_id()
            if not user_id:
                self._logger.warning("âš ï¸ [Orchestrator] æœªæä¾›user_idï¼Œå°†ä½¿ç”¨å…¨å±€æ¨¡å‹é…ç½®")

            # ä½¿ç”¨ç­–ç•¥ç®¡ç†å™¨æ„å»ºfinalizeé˜¶æ®µçš„LLMç­–ç•¥
            finalize_llm_policy = llm_strategy_manager.build_llm_policy(
                user_id=user_id,
                stage="finalize",
                complexity="high",  # finalizeé˜¶æ®µæ€»æ˜¯é«˜å¤æ‚åº¦
                output_kind=ai.constraints.output_kind if ai.constraints else "sql"
            )

            llm_decision = await self._call_llm(llm_service, finalize_prompt, user_id, finalize_llm_policy)
            decision = self._parse_final_decision(llm_decision, ai)
            finalize_duration = int((time.time() - finalize_start) * 1000)

            self._logger.info(f"æœ€ç»ˆå†³ç­–å®Œæˆ {iteration_id}: {finalize_duration}ms")

            # è¿”å›ç»“æœ - æ— è®ºæˆåŠŸå¤±è´¥éƒ½è¿”å›SQLç»“æœ
            sql_result = decision.get("result", "")
            if decision.get("success"):
                self._logger.info(f"âœ… [PTOFæ¨¡å¼] Agentæ‰§è¡ŒæˆåŠŸ {iteration_id}")
                return AgentOutput(True, sql_result, decision)
            else:
                self._logger.warning(f"âš ï¸ [PTOFæ¨¡å¼] Agentæ‰§è¡Œå¤±è´¥ä½†è¿”å›SQL {iteration_id}: {decision}")
                # å³ä½¿å¤±è´¥ä¹Ÿè¿”å›SQLï¼Œè®©å‰ç«¯å¯ä»¥æ˜¾ç¤ºå’Œè°ƒè¯•
                return AgentOutput(False, sql_result, decision)

        except Exception as e:
            error = {"error": f"ptof_execution_exception: {str(e)}"}
            self._logger.error(f"âŒ [PTOFæ¨¡å¼] Agentæ‰§è¡Œå¼‚å¸¸ {iteration_id}: {str(e)}")
            return AgentOutput(False, "", error)

    async def _execute_ptav_loop(self, ai: AgentInput) -> AgentOutput:
        """
        æ‰§è¡ŒPlan-Tool-Active-Validateå•æ­¥éª¤å¾ªç¯ - ç”¨äºå¤æ‚SQLç”Ÿæˆå’ŒéªŒè¯

        å…³é”®ç‰¹æ€§ï¼š
        1. Agentåˆ†æå½“å‰çŠ¶æ€å¹¶å†³ç­–ä¸‹ä¸€æ­¥
        2. æ‰§è¡Œå•ä¸ªå·¥å…·/åŠ¨ä½œ
        3. Agentåˆ†æç»“æœå¹¶éªŒè¯
        4. å¾ªç¯ç›´åˆ°è¾¾åˆ°ç›®æ ‡æˆ–è¶…æ—¶

        Args:
            ai: Agentè¾“å…¥

        Returns:
            AgentOutput: æ‰§è¡Œç»“æœ
        """
        session_id = str(uuid.uuid4())
        start_time = time.time()
        iteration = 0

        self._logger.info(f"ğŸ”„ [PTAVå¾ªç¯] å¼€å§‹ä¼šè¯ {session_id}")

        # ğŸ—„ï¸ [ResourcePoolæ¨¡å¼] åˆå§‹åŒ–èµ„æºæ±  - ç²¾ç®€è®°å¿†ï¼Œå‡å°‘tokenæ¶ˆè€—
        resource_pool = ResourcePool()
        self._logger.info(f"ğŸ—„ï¸ [PTAVå¾ªç¯] ä½¿ç”¨ResourcePoolæ¨¡å¼ï¼ˆç²¾ç®€è®°å¿†ï¼Œé€‚ç”¨äºå¤§å‹æ•°æ®åº“ï¼‰")

        # åˆå§‹åŒ–æ‰§è¡Œä¸Šä¸‹æ–‡ - åœ¨å¾ªç¯ä¸­ç»´æŠ¤çŠ¶æ€
        execution_context = {
            "session_id": session_id,
            "current_sql": "",
            "validation_results": [],
            "execution_history": [],
            "goal_achieved": False,
            "last_error": None,
            "accumulated_observations": [],
            "resource_pool": resource_pool
        }

        try:
            while iteration < self.max_iterations:
                iteration += 1
                iteration_start = time.time()

                # æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > self.iteration_timeout:
                    self._logger.warning(f"â° [PTAVå¾ªç¯] ä¼šè¯è¶…æ—¶ {session_id}")
                    break

                self._logger.info(f"ğŸ” [PTAVå¾ªç¯] ç¬¬{iteration}è½® - åˆ†æå½“å‰çŠ¶æ€")

                # Phase 1: Plan - Agentåˆ†æå½“å‰çŠ¶æ€å¹¶å†³ç­–ä¸‹ä¸€æ­¥
                plan_result = await self.planner.generate_plan(ai)
                if not plan_result.get("success"):
                    self._logger.error(f"âŒ [PTAVå¾ªç¯] ç¬¬{iteration}è½®è®¡åˆ’å¤±è´¥: {plan_result}")
                    execution_context["last_error"] = plan_result.get("error")
                    break

                # Phase 2: Tool - æ‰§è¡ŒAgentå†³å®šçš„å•ä¸ªåŠ¨ä½œ
                plan = plan_result["plan"]
                self._logger.info(f"ğŸ”§ [PTAVå¾ªç¯] ç¬¬{iteration}è½®æ‰§è¡ŒåŠ¨ä½œ: {plan.get('steps', [{}])[0].get('action', 'unknown')}")

                exec_result = await self.executor.execute(plan, ai)
                execution_time = int((time.time() - iteration_start) * 1000)

                # ğŸš¨ é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿exec_resultæ˜¯å­—å…¸
                if not isinstance(exec_result, dict):
                    self._logger.error(f"ğŸš¨ [PTAVå¾ªç¯] exec_resultä¸æ˜¯å­—å…¸ç±»å‹: {type(exec_result)}, å†…å®¹: {exec_result}")
                    exec_result = {
                        "success": False,
                        "error": "invalid_exec_result_type",
                        "context": {},
                        "observations": [f"âŒ Executorè¿”å›äº†éå­—å…¸ç±»å‹: {type(exec_result)}"]
                    }

                # æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡
                execution_context["execution_history"].append({
                    "iteration": iteration,
                    "plan": plan,
                    "exec_result": exec_result,
                    "execution_time": execution_time
                })

                # ç´¯ç§¯è§‚å¯Ÿè®°å½•
                if exec_result.get("observations"):
                    execution_context["accumulated_observations"].extend(exec_result["observations"])

                # ğŸ”§ [ç»Ÿä¸€Contextç®¡ç†] ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•æ›´æ–°execution_context
                context = exec_result.get("context", {})
                self._update_execution_context(execution_context, context)

                # Phase 3: Active - Agentåˆ†æå·¥å…·æ‰§è¡Œç»“æœ
                self._logger.info(f"ğŸ§  [PTAVå¾ªç¯] ç¬¬{iteration}è½®åˆ†æç»“æœ: æˆåŠŸ={exec_result.get('success')}")

                # Phase 4: Validate - AgentéªŒè¯æ˜¯å¦è¾¾åˆ°ç›®æ ‡ï¼ˆå¢å¼ºæ™ºèƒ½åˆ¤æ–­ï¼‰
                # 4.1: æ™ºèƒ½æ¨¡å¼åˆ†æ - æ£€æµ‹æ˜¯å¦åº”è¯¥æå‰é€€å‡º
                pattern_analysis = self._analyze_execution_pattern(execution_context, iteration)
                if pattern_analysis.get("should_exit"):
                    self._logger.warning(f"ğŸ¤– [PTAVæ™ºèƒ½é€€å‡º] {pattern_analysis.get('reason')}")
                    execution_context["last_error"] = pattern_analysis.get("reason")
                    execution_context["exit_suggestion"] = pattern_analysis.get("suggestion")
                    break

                # 4.2: ç›®æ ‡è¾¾æˆéªŒè¯
                validation_result = await self._validate_goal_achievement(ai, execution_context, exec_result)

                if validation_result.get("goal_achieved"):
                    self._logger.info(f"ğŸ¯ [PTAVå¾ªç¯] ç›®æ ‡è¾¾æˆï¼Œç¬¬{iteration}è½®å®Œæˆ")
                    execution_context["goal_achieved"] = True
                    break

                elif validation_result.get("should_continue", True):
                    self._logger.info(f"â¡ï¸ [PTAVå¾ªç¯] ç»§ç»­ç¬¬{iteration+1}è½®ï¼ŒåŸå› : {validation_result.get('reason', '')}")
                    # æ›´æ–°AIè¾“å…¥ä»¥ä¼ é€’æœ€æ–°çŠ¶æ€
                    ai = self._update_ai_with_context(ai, execution_context)
                else:
                    self._logger.warning(f"ğŸ›‘ [PTAVå¾ªç¯] åœæ­¢å¾ªç¯ï¼ŒåŸå› : {validation_result.get('reason', '')}")
                    execution_context["last_error"] = validation_result.get("reason")
                    break

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = await self._finalize_ptav_result(ai, execution_context)

            total_time = int((time.time() - start_time) * 1000)
            self._logger.info(f"ğŸ [PTAVå¾ªç¯] ä¼šè¯ç»“æŸ {session_id}: {iteration}è½®, {total_time}ms")

            if final_result.get("success"):
                return AgentOutput(True, final_result.get("result", ""), final_result)
            else:
                # å¤±è´¥æ—¶ä¹Ÿè¿”å›partial_resultä¸­çš„SQLï¼Œè®©å‰ç«¯å¯ä»¥æ˜¾ç¤ºå’Œè°ƒè¯•
                partial_sql = final_result.get("partial_result", "")
                return AgentOutput(False, partial_sql, final_result)

        except Exception as e:
            error = {"error": f"ptav_loop_exception: {str(e)}", "session_id": session_id, "iteration": iteration}
            self._logger.error(f"âŒ [PTAVå¾ªç¯] å¼‚å¸¸ {session_id}: {str(e)}")
            return AgentOutput(False, "", error)

    def _analyze_execution_pattern(self, execution_context: Dict[str, Any], iteration: int) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œæ¨¡å¼ï¼Œåˆ¤æ–­æ˜¯å¦åº”è¯¥æ™ºèƒ½é€€å‡º"""
        execution_history = execution_context.get("execution_history", [])

        # æ£€æµ‹é‡å¤å¤±è´¥æ¨¡å¼
        if len(execution_history) >= 3:
            last_3_actions = [h.get("plan", {}).get("steps", [{}])[0].get("action", "") for h in execution_history[-3:]]
            last_3_success = [h.get("exec_result", {}).get("success", False) for h in execution_history[-3:]]

            # åŒä¸€åŠ¨ä½œè¿ç»­å¤±è´¥3æ¬¡
            if len(set(last_3_actions)) == 1 and not any(last_3_success):
                return {
                    "should_exit": True,
                    "reason": f"é‡å¤æ‰§è¡Œ{last_3_actions[0]}å¤±è´¥3æ¬¡",
                    "suggestion": "å»ºè®®é‡æ–°åˆ†æé—®é¢˜æˆ–æ›´æ¢ç­–ç•¥"
                }

        # æ£€æµ‹Schemaè·å–å¤±è´¥
        if iteration > 3 and not execution_context.get("tables"):
            schema_attempts = sum(1 for h in execution_history if "schema" in str(h.get("plan", {}).get("steps", [{}])[0].get("action", "")))
            if schema_attempts >= 2:
                return {
                    "should_exit": True,
                    "reason": "å¤šæ¬¡å°è¯•åä»æ— Schemaä¿¡æ¯",
                    "suggestion": "å»ºè®®æ£€æŸ¥æ•°æ®æºé…ç½®"
                }

        # æ£€æµ‹ç½‘ç»œ/æ•°æ®åº“è¿æ¥é—®é¢˜
        connection_failures = sum(1 for h in execution_history if any(keyword in str(h.get("exec_result", {}).get("error", "")).lower()
                                  for keyword in ["network", "connection", "http query failed", "mysql", "doris"]))
        if connection_failures >= 3:
            return {
                "should_exit": True,
                "reason": "æ•°æ®åº“è¿æ¥é¢‘ç¹å¤±è´¥",
                "suggestion": "å»ºè®®æ£€æŸ¥æ•°æ®æºé…ç½®å’Œç½‘ç»œè¿æ¥"
            }

        # æ£€æµ‹æ— è¿›å±•çŠ¶æ€
        if iteration > 5:
            has_sql = bool(execution_context.get("current_sql"))
            if not has_sql and iteration > 5:
                return {
                    "should_exit": True,
                    "reason": "5è½®åä»æ— SQLç”Ÿæˆ",
                    "suggestion": "å»ºè®®æ£€æŸ¥è¡¨ç»“æ„æˆ–é™ä½å¤æ‚åº¦"
                }

        return {"should_exit": False}

    async def _validate_goal_achievement(self, ai: AgentInput, execution_context: Dict[str, Any], exec_result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ˜¯å¦è¾¾æˆç›®æ ‡ - å¢å¼ºæ™ºèƒ½åˆ¤æ–­ + SQLä¿®å¤å¾ªç¯"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„SQLä¸”é€šè¿‡äº†æ•°æ®åº“éªŒè¯
        current_sql = execution_context.get("current_sql", "")
        context = exec_result.get("context", {})

        # SQLç”Ÿæˆä¸”æ•°æ®åº“éªŒè¯æˆåŠŸ
        if (current_sql and
            context.get("sql_executed_successfully") and
            context.get("execution_result", {}).get("rows")):

            return {
                "goal_achieved": True,
                "reason": "SQLç”Ÿæˆå¹¶é€šè¿‡æ•°æ®åº“éªŒè¯ï¼Œè·å¾—äº†æœ‰æ•ˆæ•°æ®",
                "result": current_sql
            }

        # å¦‚æœSQLé€šè¿‡äº†è¯­æ³•éªŒè¯ä½†æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œä¹Ÿåº”è¯¥ç®—ä½œæˆåŠŸ
        if (current_sql and
            context.get("database_validated") is False and
            not context.get("issues") and
            any(keyword in str(context.get("database_error", "")).lower()
                for keyword in ["connection", "network", "http query failed", "mysql", "doris"])):

            return {
                "goal_achieved": True,
                "reason": "SQLç”Ÿæˆå¹¶é€šè¿‡è¯­æ³•éªŒè¯ï¼Œæ•°æ®åº“è¿æ¥é—®é¢˜ä¸å½±å“SQLæ­£ç¡®æ€§",
                "result": current_sql,
                "note": "å»ºè®®æ£€æŸ¥æ•°æ®æºè¿æ¥é…ç½®"
            }

        # å›¾è¡¨ç”Ÿæˆå®Œæˆ
        if context.get("chart_image_path"):
            return {
                "goal_achieved": True,
                "reason": "å›¾è¡¨ç”Ÿæˆå®Œæˆ",
                "result": context.get("chart_image_path")
            }

        # SQLéªŒè¯å¤±è´¥ - è¿›å…¥ä¿®å¤å¾ªç¯é€»è¾‘
        if not exec_result.get("success") and current_sql:
            issues = context.get("issues", [])
            if issues:
                # è·å–æˆ–åˆå§‹åŒ–ä¿®å¤è®¡æ•°å™¨
                sql_fix_attempts = execution_context.get("sql_fix_attempts", 0)

                # å¦‚æœä¿®å¤æ¬¡æ•°æœªè¾¾åˆ°ä¸Šé™ï¼ˆ3æ¬¡ï¼‰ï¼Œç»§ç»­ä¿®å¤
                if sql_fix_attempts < 3:
                    execution_context["sql_fix_attempts"] = sql_fix_attempts + 1
                    execution_context["last_sql_issues"] = issues

                    self._logger.info(f"ğŸ”§ [SQLä¿®å¤å¾ªç¯] ç¬¬{sql_fix_attempts + 1}æ¬¡ä¿®å¤å°è¯•ï¼Œé—®é¢˜: {len(issues)}ä¸ª")

                    # å¦‚æœæœ‰ä¿®æ­£å»ºè®®ï¼Œä½¿ç”¨ä¿®æ­£å»ºè®®
                    if context.get("corrected_sql"):
                        execution_context["current_sql"] = context["corrected_sql"]
                        return {
                            "goal_achieved": False,
                            "should_continue": True,
                            "reason": f"åº”ç”¨ä¿®æ­£å»ºè®®ï¼Œç¬¬{sql_fix_attempts + 1}æ¬¡ä¿®å¤å°è¯•"
                        }
                    else:
                        # æ²¡æœ‰ä¿®æ­£å»ºè®®ï¼Œè¯·æ±‚AgentåŸºäºé—®é¢˜è¿›è¡Œä¿®å¤
                        return {
                            "goal_achieved": False,
                            "should_continue": True,
                            "reason": f"SQLæœ‰é—®é¢˜éœ€è¦ä¿®å¤ï¼Œç¬¬{sql_fix_attempts + 1}æ¬¡å°è¯•"
                        }
                else:
                    # ä¿®å¤æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œæ”¾å¼ƒä¿®å¤
                    self._logger.warning(f"âš ï¸ [SQLä¿®å¤å¾ªç¯] 3æ¬¡ä¿®å¤åä»æœ‰é—®é¢˜ï¼Œæ”¾å¼ƒä¿®å¤")
                    return {
                        "goal_achieved": False,
                        "should_continue": False,
                        "reason": "SQLä¿®å¤å¤±è´¥ï¼š3æ¬¡å°è¯•åä»æœ‰é—®é¢˜"
                    }

        # æ‰§è¡Œå¤±è´¥ä¸”æ— ä¿®æ­£å»ºè®®
        if not exec_result.get("success") and not context.get("corrected_sql"):
            return {
                "goal_achieved": False,
                "should_continue": False,
                "reason": "æ‰§è¡Œå¤±è´¥ä¸”æ— ä¿®æ­£å»ºè®®"
            }

        # ç»§ç»­æ‰§è¡Œ
        return {
            "goal_achieved": False,
            "should_continue": True,
            "reason": "éœ€è¦æ›´å¤šæ­¥éª¤å®Œæˆç›®æ ‡"
        }

    def _update_execution_context(self, execution_context: Dict[str, Any], context: Dict[str, Any]) -> None:
        """ğŸ—„ï¸ ResourcePoolæ¨¡å¼çš„execution_contextæ›´æ–°é€»è¾‘

        å°†è¯¦ç»†ä¿¡æ¯å­˜å…¥ResourcePoolï¼Œexecution_contextä¿æŒè½»é‡ã€‚

        Args:
            execution_context: PTAVå¾ªç¯çš„æ‰§è¡Œä¸Šä¸‹æ–‡
            context: å•è½®æ‰§è¡Œè¿”å›çš„context
        """
        resource_pool = execution_context.get("resource_pool")
        if not resource_pool:
            self._logger.error("âš ï¸ ResourcePoolæœªåˆå§‹åŒ–")
            return

        # å‡†å¤‡æ›´æ–°æ•°æ®
        updates = {}

        # current_sql: æ—¢å­˜å…¥ResourcePoolï¼Œä¹Ÿä¿ç•™åœ¨execution_contextï¼ˆç”¨äºå¿«é€Ÿè®¿é—®ï¼‰
        if context.get("current_sql"):
            execution_context["current_sql"] = context["current_sql"]
            updates["current_sql"] = context["current_sql"]

        # column_details: å­˜å…¥ResourcePoolï¼ˆå®Œæ•´æ•°æ®ï¼‰
        if context.get("column_details"):
            updates["column_details"] = context["column_details"]
            table_count = len(context["column_details"])
            table_names = list(context["column_details"].keys())
            self._logger.info(
                f"ğŸ—„ï¸ [ResourcePool] å­˜å‚¨column_details: "
                f"{table_count}å¼ è¡¨ - {table_names}"
            )

        # schema_summary: å­˜å…¥ResourcePool
        if context.get("schema_summary"):
            updates["schema_summary"] = context["schema_summary"]

        # recommended_time_column: å­˜å…¥ResourcePool
        if context.get("recommended_time_column"):
            updates["recommended_time_column"] = context["recommended_time_column"]
            self._logger.info(
                f"ğŸ—„ï¸ [ResourcePool] å­˜å‚¨æ¨èæ—¶é—´åˆ—: "
                f"{context['recommended_time_column']}"
            )

        if context.get("coordinator_metadata"):
            updates["coordinator_metadata"] = context.get("coordinator_metadata")
            execution_context["coordinator_metadata"] = context.get("coordinator_metadata")

        # template_context: å­˜å…¥ResourcePoolï¼ˆç”¨äºSQLç”Ÿæˆï¼‰
        if context.get("template_context"):
            updates["template_context"] = context["template_context"]

        # æ‰¹é‡æ›´æ–°ResourcePool
        if updates:
            resource_pool.update(updates)
            stats = resource_pool.get_stats()
            self._logger.debug(f"ğŸ—„ï¸ [ResourcePool] å½“å‰çŠ¶æ€: {stats}")

    def _update_ai_with_context(self, ai: AgentInput, execution_context: Dict[str, Any]) -> AgentInput:
        """ä½¿ç”¨æ‰§è¡Œä¸Šä¸‹æ–‡æ›´æ–°AIè¾“å…¥

        å‘ä¸‹ä¸€è½®Planæä¾›å¯è§çš„ä¸Šä¸‹æ–‡çº¿ç´¢ï¼Œé¿å…é‡å¤æ— æ•ˆåŠ¨ä½œï¼š
        - å·²æœ‰/æ›´æ–°çš„schema
        - æ˜¯å¦å·²æœ‰current_sql
        - ä¸Šä¸€æ­¥æ‰§è¡Œçš„å·¥å…·ä¸å»ºè®®
        - éªŒè¯é—®é¢˜æç¤º
        """
        try:
            from dataclasses import replace
            from .types import SchemaInfo

            # æœ€è¿‘ä¸€æ¬¡æ‰§è¡Œç»“æœ
            last = (execution_context.get("execution_history") or [])[-1] if execution_context.get("execution_history") else None
            last_plan = (last or {}).get("plan", {})
            last_step = (last_plan.get("steps", []) or [{}])[0] if last_plan else {}
            last_tool = last_step.get("tool") or last_step.get("action")
            last_exec = (last or {}).get("exec_result", {})
            last_ctx = last_exec.get("context", {})
            decision_info = last_exec.get("decision_info", {})

            # æå–schemaæ›´æ–° - ä¼˜å…ˆä½¿ç”¨ç´¯ç§¯çš„execution_contextä¿¡æ¯
            new_tables = execution_context.get("tables") or last_ctx.get("tables") or getattr(ai.schema, 'tables', [])
            new_columns = execution_context.get("columns") or last_ctx.get("columns") or getattr(ai.schema, 'columns', {})

            # è§„åˆ’æç¤º - å¢å¼ºSQLä¿®å¤ä¿¡æ¯ä¼ é€’
            planning_hints = {
                "has_current_sql": bool(last_ctx.get("current_sql")),
                "last_step": last_tool,
                "next_recommendations": decision_info.get("next_recommendations", []),
                "validation_issues": last_ctx.get("issues", []) or last_ctx.get("validation_issues", []),
                "warnings": last_ctx.get("warnings", []) or last_ctx.get("validation_warnings", []),
                "sql_fix_attempts": execution_context.get("sql_fix_attempts", 0),
                "last_sql_issues": execution_context.get("last_sql_issues", []),
            }

            # åˆå¹¶åˆ°task_driven_context
            tdc = dict(getattr(ai, 'task_driven_context', {}) or {})
            tdc["planning_hints"] = planning_hints

            # ğŸ—„ï¸ [ResourcePoolæ¨¡å¼] ä¼ é€’è½»é‡çº§ContextMemoryå’ŒResourcePoolå¼•ç”¨
            resource_pool = execution_context.get("resource_pool")

            if resource_pool:
                # ä»ResourcePoolæ„å»ºContextMemory
                context_memory = resource_pool.build_context_memory()
                tdc["context_memory"] = context_memory.to_dict()

                # ğŸ”§ ä¼ é€’ResourcePoolå¼•ç”¨ç»™Executorï¼ˆExecutoréœ€è¦æŒ‰éœ€æå–è¯¦ç»†ä¿¡æ¯ï¼‰
                tdc["resource_pool"] = resource_pool

                self._logger.info(
                    f"ğŸ—„ï¸ [AI Context] ä¼ é€’ContextMemory + ResourcePoolå¼•ç”¨: "
                    f"has_sql={context_memory.has_sql}, "
                    f"schema_available={context_memory.schema_available}, "
                    f"tables={len(context_memory.available_tables)}"
                )

                # æ³¨æ„ï¼šä¸å†ä¼ é€’å®Œæ•´çš„column_detailsåˆ°AI Context
                # Executoré€šè¿‡ContextMemoryäº†è§£çŠ¶æ€ï¼Œéœ€è¦è¯¦ç»†ä¿¡æ¯æ—¶ä»ResourcePoolæŒ‰éœ€æå–
            else:
                self._logger.warning("âš ï¸ [AI Context] ResourcePoolæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¼ é€’ContextMemory")

            # æ›´æ–°schema
            new_schema = SchemaInfo(tables=new_tables, columns=new_columns)
            return replace(ai, schema=new_schema, task_driven_context=tdc)
        except Exception:
            return ai

    async def _finalize_ptav_result(self, ai: AgentInput, execution_context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆPTAVå¾ªç¯çš„æœ€ç»ˆç»“æœ"""
        if execution_context.get("goal_achieved"):
            return {
                "success": True,
                "result": execution_context.get("current_sql", ""),
                "execution_summary": f"å®Œæˆ{len(execution_context['execution_history'])}è½®è¿­ä»£",
                "final_sql": execution_context.get("current_sql"),
                "iteration_count": len(execution_context["execution_history"]),
                "observations": execution_context.get("accumulated_observations", [])
            }
        else:
            return {
                "success": False,
                "error": execution_context.get("last_error", "æœªèƒ½è¾¾æˆç›®æ ‡"),
                "execution_summary": f"æ‰§è¡Œ{len(execution_context['execution_history'])}è½®ååœæ­¢",
                "partial_result": execution_context.get("current_sql", ""),
                "iteration_count": len(execution_context["execution_history"]),
                "observations": execution_context.get("accumulated_observations", [])
            }

    async def _execute_task_sql_validation(self, ai: AgentInput) -> AgentOutput:
        """
        æ‰§è¡ŒTaskä»»åŠ¡ä¸­çš„SQLæœ‰æ•ˆæ€§éªŒè¯å’Œæ›´æ–°æµç¨‹

        ä¸“é—¨ç”¨äºä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼š
        1. æ£€æŸ¥ç°æœ‰SQLæ˜¯å¦è¿‡æ—¶æˆ–æœ‰ç¼ºé™·
        2. åŸºäºæœ€æ–°schemaå’Œä¸šåŠ¡éœ€æ±‚éªŒè¯SQL
        3. å¦‚éœ€è¦åˆ™æ›´æ–°SQLï¼Œç¡®ä¿èƒ½æ­£ç¡®æ‰§è¡Œ
        4. é’ˆå¯¹æ€§éªŒè¯ï¼Œä¸åšå®Œæ•´é‡å»º

        Args:
            ai: Agentè¾“å…¥ï¼Œåº”åŒ…å«ç°æœ‰çš„SQLå’Œä»»åŠ¡ä¸Šä¸‹æ–‡

        Returns:
            AgentOutput: éªŒè¯å’Œæ›´æ–°ç»“æœ
        """
        task_id = str(uuid.uuid4())
        self._logger.info(f"ğŸ” [SQLéªŒè¯æ¨¡å¼] å¼€å§‹ä»»åŠ¡éªŒè¯ {task_id}")

        try:
            current_sql = getattr(ai, 'current_sql', '') or ai.context.current_sql if hasattr(ai.context, 'current_sql') else ""

            if not current_sql:
                self._logger.warning(f"âš ï¸ [SQLéªŒè¯æ¨¡å¼] æ— ç°æœ‰SQLéœ€è¦éªŒè¯")
                return AgentOutput(False, "", {"error": "missing_current_sql", "message": "æ²¡æœ‰æä¾›éœ€è¦éªŒè¯çš„SQL"})

            self._logger.info(f"ğŸ“ [SQLéªŒè¯æ¨¡å¼] éªŒè¯SQL: {current_sql[:100]}...")

            # æ„å»ºéªŒè¯ä¸“ç”¨çš„AgentInput - é‡ç‚¹å…³æ³¨éªŒè¯è€Œéé‡æ–°ç”Ÿæˆ
            validation_context = {
                "mode": "sql_validation",
                "current_sql": current_sql,
                "validation_focus": "compatibility_check",  # å…¼å®¹æ€§æ£€æŸ¥ï¼Œä¸å®Œæ•´é‡å»º
                "preserve_logic": True  # ä¿æŒåŸæœ‰é€»è¾‘
            }

            # æ‰§è¡Œå¢å¼ºéªŒè¯æµç¨‹ï¼šæ—¶é—´å±æ€§æ£€æŸ¥ -> Schemaå…¼å®¹æ€§ -> è¯­æ³•æ£€æŸ¥ -> æ•°æ®åº“éªŒè¯
            validation_steps = [
                {"action": "tool_call", "tool": "time.window", "reason": "æ£€æŸ¥å’Œæ›´æ–°æ—¶é—´å±æ€§", "input": {}},
                {"action": "tool_call", "tool": "schema.list_columns", "reason": "ç¡®è®¤schemaå˜æ›´", "input": {}},
                {"action": "tool_call", "tool": "sql.validate", "reason": "éªŒè¯SQLå…¼å®¹æ€§", "input": {"current_sql": current_sql}},
            ]

            # åªæœ‰åœ¨éªŒè¯å¤±è´¥æ—¶æ‰å°è¯•ä¿®æ­£
            plan = {
                "thought": "éªŒè¯ç°æœ‰SQLçš„æœ‰æ•ˆæ€§ï¼Œä»…åœ¨å¿…è¦æ—¶è¿›è¡Œæœ€å°åŒ–ä¿®æ­£",
                "steps": validation_steps,
                "expected_outcome": "validated_sql"
            }

            # æ‰§è¡ŒéªŒè¯
            exec_result = await self.executor.execute({"plan": plan}, ai)
            context = exec_result.get("context", {})

            # åˆ†æéªŒè¯ç»“æœï¼Œç‰¹åˆ«å…³æ³¨æ—¶é—´å±æ€§
            time_updated = context.get("start_date") or context.get("end_date")
            time_issues = [issue for issue in context.get("issues", []) if any(keyword in str(issue).lower() for keyword in ["æ—¶é—´", "æ—¥æœŸ", "date", "time"])]

            if context.get("database_validated") and not context.get("issues"):
                # SQLéªŒè¯é€šè¿‡
                message = "ç°æœ‰SQLéªŒè¯é€šè¿‡"
                if time_updated:
                    message += f"ï¼Œæ—¶é—´å±æ€§å·²æ›´æ–°({context.get('start_date', '')} - {context.get('end_date', '')})"

                self._logger.info(f"âœ… [SQLéªŒè¯æ¨¡å¼] {message}")
                return AgentOutput(True, current_sql, {
                    "validation_status": "passed",
                    "current_sql": current_sql,
                    "message": message,
                    "time_updated": bool(time_updated),
                    "time_range": {
                        "start_date": context.get("start_date"),
                        "end_date": context.get("end_date")
                    },
                    "validation_details": context
                })

            elif context.get("issues") or context.get("database_error"):
                # SQLæœ‰é—®é¢˜ï¼Œéœ€è¦ä¿®æ­£
                issues = context.get("issues", [])
                time_issue_count = len(time_issues)

                self._logger.warning(f"âš ï¸ [SQLéªŒè¯æ¨¡å¼] å‘ç°{len(issues)}ä¸ªé—®é¢˜(å…¶ä¸­{time_issue_count}ä¸ªæ—¶é—´ç›¸å…³)ï¼Œéœ€è¦ä¿®æ­£")

                # å¦‚æœæœ‰ä¿®æ­£å»ºè®®ï¼Œåº”ç”¨ä¿®æ­£
                if context.get("corrected_sql"):
                    corrected_sql = context["corrected_sql"]
                    self._logger.info(f"ğŸ”§ [SQLéªŒè¯æ¨¡å¼] åº”ç”¨ä¿®æ­£å»ºè®®")

                    # éªŒè¯ä¿®æ­£åçš„SQL
                    validation_result = await self._quick_validate_sql(corrected_sql, ai)
                    if validation_result.get("success"):
                        message = f"SQLå·²ä¿®æ­£ï¼Œè§£å†³äº†{len(issues)}ä¸ªé—®é¢˜"
                        if time_issue_count > 0:
                            message += f"(åŒ…æ‹¬{time_issue_count}ä¸ªæ—¶é—´å±æ€§é—®é¢˜)"

                        return AgentOutput(True, corrected_sql, {
                            "validation_status": "corrected",
                            "original_sql": current_sql,
                            "current_sql": corrected_sql,
                            "issues_fixed": issues,
                            "time_issues_fixed": time_issues,
                            "time_updated": bool(time_updated),
                            "time_range": {
                                "start_date": context.get("start_date"),
                                "end_date": context.get("end_date")
                            },
                            "message": message
                        })

                # ä¿®æ­£å¤±è´¥ï¼Œè¿”å›é—®é¢˜è¯¦æƒ…
                return AgentOutput(False, "", {
                    "validation_status": "failed",
                    "current_sql": current_sql,
                    "issues": issues,
                    "error": "SQLéªŒè¯å¤±è´¥ä¸”æ— æ³•è‡ªåŠ¨ä¿®æ­£",
                    "database_error": context.get("database_error"),
                    "recommendations": "éœ€è¦æ‰‹åŠ¨æ£€æŸ¥SQLæˆ–é‡æ–°ç”Ÿæˆ"
                })

            else:
                # éªŒè¯çŠ¶æ€ä¸æ˜ç¡®
                return AgentOutput(False, "", {
                    "validation_status": "unknown",
                    "current_sql": current_sql,
                    "error": "SQLéªŒè¯ç»“æœä¸æ˜ç¡®",
                    "exec_result": exec_result
                })

        except Exception as e:
            error = {"error": f"task_sql_validation_exception: {str(e)}", "task_id": task_id}
            self._logger.error(f"âŒ [SQLéªŒè¯æ¨¡å¼] å¼‚å¸¸ {task_id}: {str(e)}")
            return AgentOutput(False, "", error)

    async def _execute_report_chart_generation(self, ai: AgentInput) -> AgentOutput:
        """
        æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆä¸­çš„æ•°æ®è½¬å›¾è¡¨æµç¨‹

        ä¸“é—¨ç”¨äºæŠ¥å‘Šç”Ÿæˆä¸­ï¼š
        1. éªŒè¯æŸ¥è¯¢ç»“æœæ•°æ®çš„å®Œæ•´æ€§å’Œæ ¼å¼
        2. æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©åˆé€‚çš„å›¾è¡¨ç±»å‹
        3. ç”Ÿæˆå›¾è¡¨é…ç½®å’Œæ ·å¼
        4. ç”Ÿæˆæœ€ç»ˆå›¾è¡¨æ–‡ä»¶
        5. æ·»åŠ å›¾ä¾‹è¯´æ˜å’Œæ ¼å¼åŒ–

        Args:
            ai: Agentè¾“å…¥ï¼Œåº”åŒ…å«æŸ¥è¯¢ç»“æœæ•°æ®

        Returns:
            AgentOutput: å›¾è¡¨ç”Ÿæˆç»“æœ
        """
        chart_session_id = str(uuid.uuid4())
        self._logger.info(f"ğŸ“Š [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å¼€å§‹å›¾è¡¨ç”Ÿæˆ {chart_session_id}")

        try:
            # æ£€æŸ¥è¾“å…¥æ•°æ®
            data_rows = getattr(ai, 'data_rows', []) or []
            data_columns = getattr(ai, 'data_columns', []) or []

            if not data_rows or not data_columns:
                context = getattr(ai, 'context', {})
                if hasattr(context, 'execution_result'):
                    data_rows = context.execution_result.get('rows', [])
                    data_columns = context.execution_result.get('columns', [])

            if not data_rows:
                self._logger.warning(f"âš ï¸ [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] æ— æ•°æ®å¯ç”¨äºç”Ÿæˆå›¾è¡¨")
                return AgentOutput(False, "", {
                    "error": "missing_data",
                    "message": "æ²¡æœ‰æä¾›å¯ç”¨äºç”Ÿæˆå›¾è¡¨çš„æ•°æ®"
                })

            self._logger.info(f"ğŸ“Š [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å¤„ç†æ•°æ®: {len(data_rows)}è¡Œ x {len(data_columns)}åˆ—")

            # æ„å»ºå›¾è¡¨ç”Ÿæˆç®¡é“
            chart_pipeline = [
                {"action": "tool_call", "tool": "data.quality", "reason": "éªŒè¯æ•°æ®è´¨é‡å’Œæ ¼å¼", "input": {}},
                {"action": "tool_call", "tool": "chart.spec", "reason": "ç”Ÿæˆå›¾è¡¨é…ç½®", "input": {}},
                {"action": "tool_call", "tool": "word_chart_generator", "reason": "ç”Ÿæˆæœ€ç»ˆå›¾è¡¨", "input": {}}
            ]

            plan = {
                "thought": "æ•°æ®è´¨é‡éªŒè¯ -> å›¾è¡¨é…ç½®ç”Ÿæˆ -> å›¾è¡¨æ¸²æŸ“",
                "steps": chart_pipeline,
                "expected_outcome": "chart"
            }

            # æ‰§è¡Œå›¾è¡¨ç”Ÿæˆç®¡é“
            exec_result = await self.executor.execute({"plan": plan}, ai)
            context = exec_result.get("context", {})

            # æ£€æŸ¥å›¾è¡¨ç”Ÿæˆç»“æœ
            if context.get("chart_image_path"):
                chart_path = context["chart_image_path"]
                chart_spec = context.get("chart_spec", {})

                self._logger.info(f"âœ… [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å›¾è¡¨ç”ŸæˆæˆåŠŸ: {chart_path}")

                return AgentOutput(True, chart_path, {
                    "generation_status": "success",
                    "chart_image_path": chart_path,
                    "chart_spec": chart_spec,
                    "data_summary": {
                        "row_count": len(data_rows),
                        "column_count": len(data_columns),
                        "columns": data_columns[:10]  # åªè¿”å›å‰10åˆ—é¿å…è¿‡é•¿
                    },
                    "message": f"æˆåŠŸç”Ÿæˆå›¾è¡¨ï¼Œå¤„ç†äº†{len(data_rows)}è¡Œæ•°æ®"
                })

            elif context.get("chart_spec"):
                # å›¾è¡¨é…ç½®ç”Ÿæˆäº†ä½†å›¾ç‰‡ç”Ÿæˆå¤±è´¥
                self._logger.warning(f"âš ï¸ [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å›¾è¡¨é…ç½®ç”ŸæˆæˆåŠŸä½†å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
                return AgentOutput(False, "", {
                    "generation_status": "partial_success",
                    "chart_spec": context["chart_spec"],
                    "error": "å›¾è¡¨é…ç½®ç”ŸæˆæˆåŠŸä½†å›¾ç‰‡æ¸²æŸ“å¤±è´¥",
                    "data_summary": {"row_count": len(data_rows), "column_count": len(data_columns)}
                })

            else:
                # å›¾è¡¨ç”Ÿæˆå®Œå…¨å¤±è´¥
                error_details = exec_result.get("observations", [])
                self._logger.error(f"âŒ [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å›¾è¡¨ç”Ÿæˆå¤±è´¥")
                return AgentOutput(False, "", {
                    "generation_status": "failed",
                    "error": "å›¾è¡¨ç”Ÿæˆæµç¨‹å¤±è´¥",
                    "error_details": error_details,
                    "data_summary": {"row_count": len(data_rows), "column_count": len(data_columns)}
                })

        except Exception as e:
            error = {"error": f"chart_generation_exception: {str(e)}", "chart_session_id": chart_session_id}
            self._logger.error(f"âŒ [å›¾è¡¨ç”Ÿæˆæ¨¡å¼] å¼‚å¸¸ {chart_session_id}: {str(e)}")
            return AgentOutput(False, "", error)

    async def _quick_validate_sql(self, sql: str, ai: AgentInput) -> Dict[str, Any]:
        """å¿«é€ŸSQLéªŒè¯ - ç”¨äºä»»åŠ¡éªŒè¯æ¨¡å¼"""
        try:
            validation_plan = {
                "steps": [{"action": "tool_call", "tool": "sql.validate", "reason": "å¿«é€ŸéªŒè¯", "input": {"current_sql": sql}}]
            }
            result = await self.executor.execute(validation_plan, ai)
            context = result.get("context", {})

            return {
                "success": not bool(context.get("issues")),
                "issues": context.get("issues", []),
                "database_validated": context.get("database_validated", False)
            }
        except Exception:
            return {"success": False, "issues": ["éªŒè¯è¿‡ç¨‹å¼‚å¸¸"]}


    async def _call_llm(self, llm_service, prompt: str, user_id: str = "system", llm_policy: Dict[str, Any] = None) -> str:
        """
        è°ƒç”¨LLMæœåŠ¡ï¼Œé€‚é…backupç³»ç»Ÿçš„ä¸åŒæ¥å£

        Args:
            llm_service: LLMæœåŠ¡å®ä¾‹
            prompt: æç¤ºè¯
            user_id: ç”¨æˆ·ID

        Returns:
            str: LLMå“åº”
        """
        # å°è¯•ä¸åŒçš„LLMæœåŠ¡æ¥å£
        try:
            # é»˜è®¤LLMç­–ç•¥ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
            if not llm_policy:
                llm_policy = {
                    "stage": "finalize",
                    "complexity": "high",
                    "output_kind": "sql"
                }

            # å°è¯•æ–¹å¼1: askæ–¹æ³• (ç±»ä¼¼å½“å‰ç³»ç»Ÿ)
            if hasattr(llm_service, 'ask'):
                result = await llm_service.ask(
                    user_id=user_id,
                    prompt=prompt,
                    response_format={"type": "json_object"},
                    llm_policy=llm_policy
                )
                return result.get("response", "{}") if isinstance(result, dict) else (result or "{}")

            # å°è¯•æ–¹å¼2: generate_responseæ–¹æ³•
            elif hasattr(llm_service, 'generate_response'):
                result = await llm_service.generate_response(
                    prompt=prompt,
                    user_id=user_id,
                    response_format={"type": "json_object"}
                )
                return result.get("response", "{}") if isinstance(result, dict) else (result or "{}")

            # å°è¯•æ–¹å¼3: ç›´æ¥è°ƒç”¨
            elif callable(llm_service):
                result = await llm_service(prompt)
                return result

            else:
                raise ValueError("Unsupported LLM service interface")

        except Exception as e:
            self._logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return '{"success": false, "error": "llm_call_failed"}'

    def _build_observation_report(self, plan: Dict[str, Any], exec_result: Dict[str, Any]) -> str:
        """æ„å»ºè§‚å¯ŸæŠ¥å‘Š"""
        obs = exec_result.get("observations", [])
        lines = [
            f"è®¡åˆ’æ­¥éª¤: {len(plan.get('steps', []))}",
            f"æˆåŠŸæ­¥éª¤: {exec_result.get('successful_steps', 0)}/{exec_result.get('total_steps', 0)}",
            "",
            "è§‚æµ‹è®°å½•:",
        ]

        for i, o in enumerate(obs, 1):
            lines.append(f"{i}. {o}")

        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        ctx = exec_result.get("context", {})
        if ctx.get("current_sql"):
            lines.extend(["", f"å½“å‰SQL: {ctx['current_sql']}"])
        if ctx.get("execution_result"):
            rows = ctx["execution_result"].get("rows", [])
            lines.append(f"æ‰§è¡Œè¡Œæ•°: {len(rows)}")
        if ctx.get("chart_spec"):
            lines.append("å·²ç”Ÿæˆå›¾è¡¨é…ç½®")
        if ctx.get("chart_image_path"):
            lines.append(f"å›¾è¡¨å›¾ç‰‡è·¯å¾„: {ctx['chart_image_path']}")

        return "\n".join(lines)

    def _parse_final_decision(self, text: str, ai: AgentInput) -> Dict[str, Any]:
        """è§£ææœ€ç»ˆå†³ç­–"""
        try:
            t = (text or "").strip()
            if t.startswith("```json"):
                t = t.replace("```json", "").replace("```", "").strip()

            data = json.loads(t)

            if not isinstance(data.get("success"), bool):
                return {"success": False, "error": "invalid_decision_format"}

            if data.get("success") and not data.get("result"):
                return {"success": False, "error": "missing_result"}

            # SQLç»“æœéªŒè¯
            if (ai.constraints.output_kind or "sql").lower() == "sql" and data.get("success"):
                sql = str(data.get("result", ""))
                if "SELECT" not in sql.upper():
                    return {"success": False, "error": "invalid_sql_in_decision"}

            return data

        except Exception as e:
            return {
                "success": False,
                "error": f"decision_parse_failed: {str(e)}",
                "raw": text
            }
