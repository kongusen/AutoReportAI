"""
TT é€’å½’æ‰§è¡Œè¿è¡Œæ—¶

åŸºäº Loom tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£æ¨ç†
è¿™æ˜¯æ•´ä¸ª Agent ç³»ç»Ÿçš„æ ¸å¿ƒæ‰§è¡Œå¼•æ“
"""

from __future__ import annotations

import asyncio
import logging
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, AsyncGenerator, Callable, Tuple

from loom import Agent, agent as build_agent
from loom.interfaces.tool import BaseTool
from loom.interfaces.llm import BaseLLM

from .types import (
    AgentRequest, AgentResponse, ExecutionState, ExecutionStage,
    ToolCall, ContextInfo, AgentConfig, AgentEvent, TaskComplexity
)
from .llm_adapter import (
    ContainerLLMAdapter, create_llm_adapter,
    _CURRENT_USER_ID, _CURRENT_STAGE  # å¯¼å…¥ context variables
)
from .context_retriever import SchemaContextRetriever, create_schema_context_retriever

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from app.db.session import get_db_session
from app import crud

# ğŸ”¥ å¯¼å…¥Loomæ ¸å¿ƒç±»å‹ç”¨äºè‡ªå®šä¹‰Executor
from loom.core.agent_executor import AgentExecutor
from loom.core.events import AgentEvent as LoomAgentEvent, AgentEventType
from loom.core.types import Message, ToolResult
from loom.core.turn_state import TurnState
from loom.core.execution_context import ExecutionContext
from .quality_scorer import (
    EnhancedQualityScorer, QualityScorerConfig, QualityScore,
    create_quality_scorer
)
from .config.stage_config import StageConfigManager, get_stage_config_manager
from .tools import (
    create_schema_discovery_tool,
    create_schema_retrieval_tool,
    create_schema_cache_tool,
    create_sql_generator_tool,
    create_sql_validator_tool,
    create_sql_column_checker_tool,
    create_sql_auto_fixer_tool,
    create_sql_executor_tool,
    create_data_sampler_tool,
    create_data_analyzer_tool,
    create_time_window_tool,
    create_chart_generator_tool,
    create_chart_analyzer_tool
)
from .tool_result_formatter import format_tool_result, FormattedToolResult

logger = logging.getLogger(__name__)


class ContextAwareAgentExecutor(AgentExecutor):
    """
    ğŸ”¥ ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„Agent Executor
    
    é‡å†™é€’å½’æ¶ˆæ¯å‡†å¤‡é€»è¾‘ï¼Œç¡®ä¿å·¥å…·ç»“æœå’Œå†å²æ¶ˆæ¯èƒ½æ­£ç¡®ä¼ é€’åˆ°ä¸‹ä¸€è½®é€’å½’ä¸­
    """
    
    def __init__(self, original_executor: AgentExecutor, context_retriever: Optional[SchemaContextRetriever] = None):
        # å¤åˆ¶åŸå§‹executorçš„æ‰€æœ‰å±æ€§
        for attr_name in dir(original_executor):
            if not attr_name.startswith('_') and not callable(getattr(original_executor, attr_name)):
                setattr(self, attr_name, getattr(original_executor, attr_name))

        # ä¿å­˜åŸå§‹executorçš„å¼•ç”¨
        self._original_executor = original_executor
        self._context_retriever = context_retriever

        # å¤åˆ¶æ‰€æœ‰æ–¹æ³•
        for attr_name in dir(original_executor):
            if not attr_name.startswith('_') and callable(getattr(original_executor, attr_name)):
                if attr_name not in ['_prepare_recursive_messages']:  # é‡å†™è¿™ä¸ªæ–¹æ³•
                    setattr(self, attr_name, getattr(original_executor, attr_name))

    def _check_recursion_termination(
        self,
        turn_state: TurnState,
        tool_results: List[ToolResult],
        tt_context: Dict[str, Any]
    ) -> Optional[str]:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ç»ˆæ­¢é€’å½’

        Returns:
            Optional[str]: ç»ˆæ­¢åŸå› ï¼ŒNoneè¡¨ç¤ºç»§ç»­æ‰§è¡Œ
        """
        current_turn = tt_context.get("turn_counter", turn_state.turn_counter)
        deep_recursion_threshold = 3
        max_recursion_threshold = 5

        # æ£€æŸ¥å·¥å…·è°ƒç”¨å†å²ï¼Œæ£€æµ‹é‡å¤è°ƒç”¨
        tool_call_history = getattr(turn_state, 'tool_call_history', [])
        if tool_call_history:
            tool_names = [getattr(call, 'tool_name', 'unknown') for call in tool_call_history]
            schema_discovery_count = tool_names.count('schema_discovery')

            # å¦‚æœschema_discoveryè¢«è°ƒç”¨è¶…è¿‡2æ¬¡ï¼Œå¼ºåˆ¶ç»ˆæ­¢
            if schema_discovery_count > 2:
                logger.warning(f"ğŸš¨ [ContextAwareExecutor] æ£€æµ‹åˆ°é‡å¤è°ƒç”¨schema_discoveryï¼ˆ{schema_discovery_count}æ¬¡ï¼‰ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                return "duplicate_tool_calls"

        # æ£€æŸ¥æœ€å¤§é€’å½’æ¬¡æ•°
        if current_turn > max_recursion_threshold:
            logger.warning(f"ğŸš¨ [ContextAwareExecutor] è¾¾åˆ°æœ€å¤§é€’å½’æ¬¡æ•°ï¼ˆç¬¬{current_turn}è½®ï¼‰ï¼Œå¼ºåˆ¶ç»ˆæ­¢å¾ªç¯")
            return "max_recursion"

        # æ£€æŸ¥æ·±åº¦é€’å½’
        if current_turn > deep_recursion_threshold:
            logger.info(f"ğŸ” [ContextAwareExecutor] æ£€æµ‹åˆ°æ·±åº¦é€’å½’ï¼ˆç¬¬{current_turn}è½®ï¼‰ï¼Œè°ƒæ•´ä¸Šä¸‹æ–‡ç­–ç•¥")
            return "deep_recursion"

        return None

    def _build_termination_message(self, reason: str) -> Message:
        """
        æ„å»ºé€’å½’ç»ˆæ­¢æ¶ˆæ¯

        Args:
            reason: ç»ˆæ­¢åŸå›  (duplicate_tool_calls, max_recursion, deep_recursion)
        """
        if reason == "duplicate_tool_calls":
            content = """# é‡å¤å·¥å…·è°ƒç”¨æ£€æµ‹

âš ï¸ æ£€æµ‹åˆ°é‡å¤è°ƒç”¨schema_discoveryå·¥å…·ï¼Œç³»ç»Ÿå¼ºåˆ¶ç»ˆæ­¢ï¼

è¯·ç«‹å³ç”ŸæˆSQLæŸ¥è¯¢ï¼Œä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼š

```json
{
  "reasoning": "å·²å¤šæ¬¡è°ƒç”¨schema_discoveryï¼Œç°åœ¨ç”ŸæˆSQL",
  "action": "finish",
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}
```

ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼"""

        elif reason == "max_recursion":
            content = """# ç´§æ€¥ç»ˆæ­¢æŒ‡ä»¤

âš ï¸ æ£€æµ‹åˆ°æ— é™å¾ªç¯ï¼Œç³»ç»Ÿå¼ºåˆ¶ç»ˆæ­¢ï¼

è¯·ç«‹å³ç”Ÿæˆä¸€ä¸ªç®€å•çš„SQLæŸ¥è¯¢ï¼Œä¸è¦ç»§ç»­è°ƒç”¨å·¥å…·ï¼š

```json
{
  "reasoning": "ç³»ç»Ÿæ£€æµ‹åˆ°å¾ªç¯ï¼Œå¼ºåˆ¶ç”ŸæˆSQL",
  "action": "finish",
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}
```

ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼"""

        else:  # deep_recursion - è¿™ä¸ªä¸æ˜¯å®Œå…¨ç»ˆæ­¢ï¼Œåªæ˜¯è­¦å‘Š
            content = f"""# å¾ªç¯æ£€æµ‹è­¦å‘Š

âš ï¸ æ£€æµ‹åˆ°æ·±åº¦é€’å½’ï¼Œè¯·ç«‹å³ç”ŸæˆSQLï¼Œä¸è¦å†è°ƒç”¨å·¥å…·ï¼

å¦‚æœå·²ç»è·å–äº†è¡¨ç»“æ„ä¿¡æ¯ï¼Œè¯·ç›´æ¥ç”ŸæˆSQLï¼š
```json
{{
  "reasoning": "å·²è·å–è¡¨ç»“æ„ï¼Œç”ŸæˆSQLæŸ¥è¯¢",
  "action": "finish",
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}}
```

ä¸è¦å†è°ƒç”¨ schema_discovery æˆ–å…¶ä»–å·¥å…·ï¼"""

        return Message(role="system", content=content)

    def _prepare_history_messages(
        self,
        turn_state: TurnState,
        priority_hints: Dict[str, str],
        is_deep_recursion: bool
    ) -> List[Message]:
        """
        å‡†å¤‡å†å²æ¶ˆæ¯ï¼ˆæ”¯æŒæ™ºèƒ½æˆªæ–­ï¼‰

        Args:
            turn_state: å›åˆçŠ¶æ€
            priority_hints: ä¼˜å…ˆçº§æç¤º
            is_deep_recursion: æ˜¯å¦æ·±åº¦é€’å½’

        Returns:
            å†å²æ¶ˆæ¯åˆ—è¡¨
        """
        history_messages = []

        # å¦‚æœå†å²ä¼˜å…ˆçº§ä¸ºLOWï¼Œè·³è¿‡è·å–
        if priority_hints.get("history", "MEDIUM") == "LOW":
            logger.info(f"ğŸ“š [ContextAwareExecutor] å†å²ä¼˜å…ˆçº§ä¸ºLOWï¼Œè·³è¿‡è·å–")
            return []

        # ä»Memoryä¸­è·å–å†å²æ¶ˆæ¯
        if self.memory:
            try:
                # åŒæ­¥è°ƒç”¨get_messagesï¼ˆå› ä¸ºè¿™æ˜¯åŒæ­¥æ–¹æ³•ï¼‰
                import asyncio
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨run_in_executor
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, self.memory.get_messages())
                        history_messages = future.result()
                else:
                    history_messages = asyncio.run(self.memory.get_messages())
            except Exception as e:
                logger.warning(f"âš ï¸ [ContextAwareExecutor] è·å–å†å²æ¶ˆæ¯å¤±è´¥: {e}")
                history_messages = []

        # æ ¹æ®ä¼˜å…ˆçº§å’Œæ·±åº¦è°ƒæ•´å†å²æ¶ˆæ¯æ•°é‡
        if is_deep_recursion:
            max_history = 3  # æ·±åº¦é€’å½’æ—¶åªä¿ç•™æœ€è¿‘3æ¡
        elif priority_hints.get("history") == "HIGH":
            max_history = 15  # é«˜ä¼˜å…ˆçº§æ—¶ä¿ç•™æ›´å¤šå†å²
        else:
            max_history = 10  # é»˜è®¤ä¿ç•™10æ¡

        if history_messages:
            recent_history = history_messages[-max_history:]
            logger.info(f"ğŸ“š [ContextAwareExecutor] ä»Memoryè·å–åˆ° {len(history_messages)} æ¡å†å²æ¶ˆæ¯ï¼Œä¿ç•™ {len(recent_history)} æ¡")
            return recent_history
        else:
            logger.info(f"ğŸ“š [ContextAwareExecutor] æœªè·å–åˆ°å†å²æ¶ˆæ¯")
            return []

    def _prepare_tool_messages(self, tool_results: List[ToolResult]) -> Tuple[List[Message], List[FormattedToolResult]]:
        """
        å‡†å¤‡å·¥å…·ç»“æœæ¶ˆæ¯

        Args:
            tool_results: å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨

        Returns:
            Tuple[å·¥å…·æ¶ˆæ¯åˆ—è¡¨, æ ¼å¼åŒ–ç»“æœåˆ—è¡¨]
        """
        tool_messages = []
        formatted_results: List[FormattedToolResult] = []

        for result in tool_results:
            formatted = format_tool_result(result)
            formatted_results.append(formatted)
            tool_msg = Message(
                role="tool",
                content=formatted.message,
                tool_call_id=result.tool_call_id,
            )
            tool_messages.append(tool_msg)

        logger.info(f"ğŸ”§ [ContextAwareExecutor] å‡†å¤‡äº† {len(tool_messages)} æ¡å·¥å…·ç»“æœæ¶ˆæ¯")

        return tool_messages, formatted_results
    
    def _prepare_recursive_messages(
        self,
        messages: List[Message],
        tool_results: List[ToolResult],
        turn_state: TurnState,
        context: ExecutionContext,
    ) -> List[Message]:
        """
        ğŸ”¥ é‡å†™é€’å½’æ¶ˆæ¯å‡†å¤‡é€»è¾‘ - å¢å¼º TT ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆå·²ä¼˜åŒ–æ‹†åˆ†ï¼‰

        ç¡®ä¿å·¥å…·ç»“æœå’Œå†å²æ¶ˆæ¯èƒ½æ­£ç¡®ä¼ é€’åˆ°ä¸‹ä¸€è½®é€’å½’ä¸­
        æ”¯æŒæ·±åº¦æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ä¼˜å…ˆçº§è°ƒæ•´å’Œæ™ºèƒ½æˆªæ–­
        """
        # ä» ExecutionContext metadata ä¸­æå– TT ä¸Šä¸‹æ–‡ä¿¡æ¯
        tt_context = context.metadata.get("tt", {}) if context.metadata else {}
        current_turn = tt_context.get("turn_counter", turn_state.turn_counter)
        priority_hints = tt_context.get("priority_hints", {})
        task_type = tt_context.get("task_type", "general")
        complexity = tt_context.get("complexity", "medium")

        logger.info(f"ğŸ”„ [ContextAwareExecutor] å‡†å¤‡é€’å½’æ¶ˆæ¯ï¼ˆç¬¬{current_turn}è½®ï¼‰")
        logger.info(f"   ä»»åŠ¡ç±»å‹: {task_type}, å¤æ‚åº¦: {complexity}")
        logger.info(f"   ä¼˜å…ˆçº§æç¤º: {priority_hints}")

        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦ç»ˆæ­¢é€’å½’
        termination_reason = self._check_recursion_termination(turn_state, tool_results, tt_context)

        # å¤„ç†æ·±åº¦é€’å½’ï¼ˆç‰¹æ®Šæƒ…å†µï¼šä¸å®Œå…¨ç»ˆæ­¢ï¼Œåªæ˜¯è°ƒæ•´ç­–ç•¥ï¼‰
        is_deep_recursion = termination_reason == "deep_recursion"
        if is_deep_recursion:
            # æ·±åº¦é€’å½’æ—¶ï¼Œè°ƒæ•´ä¼˜å…ˆçº§
            priority_hints = {
                "base_instructions": "CRITICAL",
                "tool_definitions": "HIGH",
                "examples": "LOW",
                "history": "LOW"
            }
            # æ·»åŠ è­¦å‘Šæ¶ˆæ¯
            warning_message = self._build_termination_message("deep_recursion")
            messages = [warning_message] + messages
        elif termination_reason:
            # å…¶ä»–ç»ˆæ­¢åŸå› ï¼šç›´æ¥è¿”å›ç»ˆæ­¢æ¶ˆæ¯
            return [self._build_termination_message(termination_reason)]

        # 2. å‡†å¤‡å†å²æ¶ˆæ¯ï¼ˆæ”¯æŒæ™ºèƒ½æˆªæ–­ï¼‰
        history_messages = self._prepare_history_messages(
            turn_state, priority_hints, is_deep_recursion
        )

        # 3. å‡†å¤‡å·¥å…·ç»“æœæ¶ˆæ¯
        tool_messages, formatted_results = self._prepare_tool_messages(tool_results)

        # 4. ç”Ÿæˆæ™ºèƒ½æŒ‡å¯¼æ¶ˆæ¯
        guidance_message = self._generate_context_aware_guidance(
            messages, formatted_results, turn_state, history_messages,
            task_type=task_type, complexity=complexity, is_deep_recursion=is_deep_recursion
        )

        # 5. ç»„è£…å®Œæ•´çš„é€’å½’æ¶ˆæ¯
        recursive_messages = []
        recursive_messages.extend(history_messages)  # å†å²æ¶ˆæ¯
        recursive_messages.extend(messages)  # å½“å‰è½®æ¶ˆæ¯
        recursive_messages.extend(tool_messages)  # å·¥å…·ç»“æœæ¶ˆæ¯
        recursive_messages.append(Message(role="user", content=guidance_message))  # æŒ‡å¯¼æ¶ˆæ¯

        # 6. ä¸Šä¸‹æ–‡å¤§å°ç›‘æ§å’Œæ—¥å¿—è®°å½•
        total_messages = len(recursive_messages)
        total_chars = sum(len(msg.content) for msg in recursive_messages if hasattr(msg, 'content'))
        estimated_tokens = total_chars // 4  # ç²—ç•¥ä¼°ç®—ï¼š4å­—ç¬¦â‰ˆ1token

        logger.info(f"âœ… [ContextAwareExecutor] é€’å½’æ¶ˆæ¯å‡†å¤‡å®Œæˆ")
        logger.info(f"   æ€»æ¶ˆæ¯æ•°: {total_messages}")
        logger.info(f"   æ€»å­—ç¬¦æ•°: {total_chars}")
        logger.info(f"   ä¼°ç®—Tokenæ•°: {estimated_tokens}")
        logger.info(f"   æ·±åº¦é€’å½’æ¨¡å¼: {'æ˜¯' if is_deep_recursion else 'å¦'}")

        # å¦‚æœä¸Šä¸‹æ–‡è¿‡å¤§ï¼Œè®°å½•è­¦å‘Š
        if estimated_tokens > 8000:  # å‡è®¾æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ä¸º8K
            logger.warning(f"âš ï¸ [ContextAwareExecutor] ä¸Šä¸‹æ–‡å¯èƒ½è¿‡å¤§ï¼ˆ{estimated_tokens} tokensï¼‰ï¼Œå»ºè®®ä¼˜åŒ–")

        return recursive_messages
    
    def _generate_context_aware_guidance(
        self,
        messages: List[Message],
        formatted_results: List[FormattedToolResult],
        turn_state: TurnState,
        history_messages: List[Message],
        task_type: str = "general",
        complexity: str = "medium",
        is_deep_recursion: bool = False
    ) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é€’å½’æŒ‡å¯¼æ¶ˆæ¯ - å¢å¼ºä»»åŠ¡ç±»å‹å’Œæ·±åº¦æ„ŸçŸ¥
        """
        # åˆ†æå·¥å…·ç»“æœ
        has_schema_data = False
        has_query_data = False
        tool_summaries: List[str] = []
        tool_names_called = set()
        schema_info: Optional[FormattedToolResult] = None
        
        for formatted in formatted_results:
            tool_names_called.add(formatted.tool_name)
            tool_summaries.append(f"{formatted.tool_name}: {formatted.message}")
            if formatted.tool_name == "schema_discovery":
                schema_info = formatted
                tables_count = formatted.structured_summary.get("tables_count", 0)
                has_schema_data = tables_count > 0
            if formatted.tool_name in {"sql_generator", "sql_validator", "sql_executor"}:
                has_query_data = True
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ å·¥å…·è°ƒç”¨å†å²æ£€æµ‹å’Œæ˜ç¡®æŒ‡å¯¼
        guidance_parts = [f"ç¬¬{turn_state.turn_counter}è½®é€’å½’æ‰§è¡Œ"]
        
        # åˆ†æå·²è°ƒç”¨çš„å·¥å…·ï¼Œæä¾›æ˜ç¡®çš„ä¸‹ä¸€æ­¥æŒ‡å¯¼
        if schema_info:
            tables_count = schema_info.structured_summary.get("tables_count", 0)
            preview = schema_info.structured_summary.get("tables_preview", []) or []
            preview_text = "ã€".join(preview[:3]) if preview else "æš‚æ— ç¤ºä¾‹è¡¨"

            if schema_info.duplicate_call:
                guidance_parts.append("âš ï¸ schema_discovery å·²åœ¨å…ˆå‰æ­¥éª¤å®Œæˆï¼Œæœ¬è½®å¤ç”¨äº†ç¼“å­˜ç»“æœ")
            else:
                guidance_parts.append(f"âœ… schema_discovery å®Œæˆï¼Œå‘ç° {tables_count} å¼ è¡¨ï¼ˆå¦‚ï¼š{preview_text}ï¼‰")

            if schema_info.next_actions:
                guidance_parts.append(f"ğŸ“‹ æ¨èä¸‹ä¸€æ­¥ï¼š{'ï¼›'.join(schema_info.next_actions)}")
        else:
            guidance_parts.append("ğŸ“‹ å°šæœªè·å–æ•°æ®åº“ç»“æ„ï¼Œè¯·å…ˆè°ƒç”¨ schema_discovery å·¥å…·")

        if "schema_retrieval" in tool_names_called:
            guidance_parts.append("âœ… schema_retrieval å·²æä¾›åˆ—çº§ä¿¡æ¯ï¼Œæ¥ä¸‹æ¥ä½¿ç”¨ sql_generator ç”Ÿæˆ SQL")
        if "sql_generator" in tool_names_called and "sql_validator" not in tool_names_called:
            guidance_parts.append("ğŸ“‹ ä¸‹ä¸€æ­¥ï¼šè°ƒç”¨ sql_validator å·¥å…·éªŒè¯ç”Ÿæˆçš„ SQL")
        if "sql_validator" in tool_names_called:
            guidance_parts.append("âœ… SQL å·²é€šè¿‡éªŒè¯ï¼Œå¦‚æ— é—®é¢˜å¯ä»¥æ•´ç†æœ€ç»ˆç­”æ¡ˆæˆ–æ‰§è¡Œåç»­æ“ä½œ")
        if schema_info and schema_info.duplicate_call:
            guidance_parts.append("ğŸš« è¯·å‹¿å†æ¬¡è°ƒç”¨ schema_discoveryï¼Œç›´æ¥æ‰§è¡Œä¸Šä¸€æ­¥å»ºè®®çš„å·¥å…·")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ é¢å¤–æŒ‡å¯¼
        if task_type == "sql_generation":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šç”Ÿæˆå‡†ç¡®çš„ SQL æŸ¥è¯¢")
            if has_schema_data:
                guidance_parts.append("âœ… è¡¨ç»“æ„ä¿¡æ¯å·²è·å–")
            if has_query_data:
                guidance_parts.append("âœ… æŸ¥è¯¢å·²æ‰§è¡Œ")
        elif task_type == "chart_generation":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šç”Ÿæˆå›¾è¡¨")
            if has_query_data:
                guidance_parts.append("âœ… æŸ¥è¯¢æ•°æ®å·²è·å–")
        elif task_type == "completion":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šå®Œæˆæ–‡æ¡£ç”Ÿæˆ")
        
        # æ·»åŠ å¤æ‚åº¦æç¤º
        if complexity == "high":
            guidance_parts.append("âš ï¸ å¤æ‚ä»»åŠ¡ï¼Œéœ€è¦ä»”ç»†åˆ†æ")
        elif complexity == "low":
            guidance_parts.append("âœ… ç®€å•ä»»åŠ¡ï¼Œå¯ä»¥å¿«é€Ÿå¤„ç†")
        
        # æ·±åº¦é€’å½’æ—¶çš„ç‰¹æ®Šå¤„ç†
        if is_deep_recursion:
            guidance_parts.append("âš ï¸ æ·±åº¦é€’å½’æ¨¡å¼ï¼Œè¯·ä¿æŒç®€æ´ï¼Œé¿å…é‡å¤è°ƒç”¨ç›¸åŒå·¥å…·")
            # åªæ˜¾ç¤ºå…³é”®çš„å·¥å…·ç»“æœ
            if tool_summaries:
                key_summaries = [s for s in tool_summaries if any(keyword in s.lower() for keyword in ["schema", "table", "sql"])]
                if key_summaries:
                    guidance_parts.append(f"ğŸ”§ å…³é”®å·¥å…·ç»“æœ: {'; '.join(key_summaries[:2])}")
        else:
            # æ­£å¸¸é€’å½’æ—¶æ˜¾ç¤ºæ‰€æœ‰å·¥å…·ç»“æœ
            if tool_summaries:
                guidance_parts.append(f"ğŸ”§ å·¥å…·ç»“æœ: {'; '.join(tool_summaries)}")
        
        guidance = "ã€‚".join(guidance_parts) + "ã€‚è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»§ç»­æ‰§è¡Œã€‚"
        
        return guidance


# ğŸ”¥ å·¥å…·å®ä¾‹ç¼“å­˜ç®¡ç†å™¨
class ToolInstanceCache:
    """å·¥å…·å®ä¾‹ç¼“å­˜ç®¡ç†å™¨ï¼Œé¿å…é‡å¤åˆ›å»ºå·¥å…·"""
    
    def __init__(self):
        self._cache: Dict[str, BaseTool] = {}
        self._cache_keys: Dict[str, str] = {}
    
    def _generate_cache_key(self, tool_name: str, connection_config: Optional[Dict] = None) -> str:
        """ç”Ÿæˆå·¥å…·ç¼“å­˜é”®"""
        # ğŸ”¥ ä¼˜åŒ–ï¼šåªæœ‰çœŸæ­£éœ€è¦connection_configçš„å·¥å…·æ‰åŒºåˆ†é…ç½®
        # å¿…é¡»ä¸ _create_tools_from_config ä¸­çš„ tools_requiring_connection ä¿æŒä¸€è‡´
        tools_requiring_connection = {
            "schema_discovery",
            "schema_retrieval",
            "sql_executor",
            "sql_validator"  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  sql_validator
        }

        if connection_config and tool_name in tools_requiring_connection:
            # åŸºäºè¿æ¥é…ç½®ç”Ÿæˆé”® - ä½¿ç”¨å®é™…çš„å­—æ®µå
            host = connection_config.get('fe_hosts', [''])[0] if connection_config.get('fe_hosts') else ''
            port = connection_config.get('http_port', '')
            database = connection_config.get('name', '')
            config_key = f"{host}:{port}:{database}"
            return f"{tool_name}:{config_key}"
        else:
            # ğŸ”¥ å¯¹äºä¸éœ€è¦connection_configçš„å·¥å…·ï¼Œç»Ÿä¸€ä½¿ç”¨defaulté”®
            return f"{tool_name}:default"
    
    def get_tool(self, tool_name: str, connection_config: Optional[Dict] = None) -> Optional[BaseTool]:
        """è·å–ç¼“å­˜çš„å·¥å…·å®ä¾‹"""
        cache_key = self._generate_cache_key(tool_name, connection_config)
        return self._cache.get(cache_key)
    
    def set_tool(self, tool_name: str, tool: BaseTool, connection_config: Optional[Dict] = None):
        """ç¼“å­˜å·¥å…·å®ä¾‹"""
        cache_key = self._generate_cache_key(tool_name, connection_config)
        self._cache[cache_key] = tool
        self._cache_keys[tool_name] = cache_key
        logger.debug(f"ğŸ”§ [ToolCache] ç¼“å­˜å·¥å…·: {tool_name} -> {cache_key}")
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        self._cache_keys.clear()
        logger.info("ğŸ§¹ [ToolCache] æ¸…ç©ºå·¥å…·ç¼“å­˜")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        # ç»Ÿè®¡å”¯ä¸€çš„å·¥å…·å
        unique_tool_names = set()
        for cache_key in self._cache.keys():
            tool_name = cache_key.split(':')[0]  # æå–å·¥å…·å
            unique_tool_names.add(tool_name)
        
        return {
            "cached_tools": len(self._cache),
            "unique_tool_names": len(unique_tool_names),
            "tool_names": list(unique_tool_names),
            "memory_usage": f"{len(self._cache)} tools"
        }


# å…¨å±€å·¥å…·ç¼“å­˜å®ä¾‹
_tool_cache = ToolInstanceCache()


def _create_tools_from_config(container: Any, config: AgentConfig) -> List[BaseTool]:
    """
    æ ¹æ®é…ç½®è‡ªåŠ¨åˆ›å»ºå·¥å…·å®ä¾‹

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®

    Returns:
        å·¥å…·å®ä¾‹åˆ—è¡¨
    """
    tools = []
    enabled_tools = config.tools.enabled_tools if hasattr(config.tools, 'enabled_tools') else []

    # ğŸ”¥ ä»containerä¸­è¯»å–ä¸´æ—¶å­˜å‚¨çš„connection_config
    connection_config = getattr(container, '_temp_connection_config', None)

    # ğŸ”§ è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ”§ [ToolRegistry] connection_config å¯ç”¨: {connection_config is not None}")
    if connection_config:
        logger.info(f"ğŸ”§ [ToolRegistry] connection_config keys: {list(connection_config.keys())[:5]}")

    # å·¥å…·åç§°åˆ°åˆ›å»ºå‡½æ•°çš„æ˜ å°„
    tool_factory_map = {
        "schema_discovery": create_schema_discovery_tool,
        "schema_retrieval": create_schema_retrieval_tool,
        "schema_cache": create_schema_cache_tool,
        "sql_generator": create_sql_generator_tool,
        "sql_validator": create_sql_validator_tool,
        "sql_column_checker": create_sql_column_checker_tool,
        "sql_auto_fixer": create_sql_auto_fixer_tool,
        "sql_executor": create_sql_executor_tool,
        "data_sampler": create_data_sampler_tool,
        "data_analyzer": create_data_analyzer_tool,
        "time_window": create_time_window_tool,
        "chart_generator": create_chart_generator_tool,
        "chart_analyzer": create_chart_analyzer_tool,
    }

    # éœ€è¦connection_configçš„å·¥å…·åˆ—è¡¨
    tools_requiring_connection = {
        "schema_discovery",
        "schema_retrieval", 
        "sql_executor",
        "sql_validator"  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  sql_validator åˆ°éœ€è¦ connection_config çš„å·¥å…·åˆ—è¡¨
    }

    # ğŸ”¥ ä½¿ç”¨ç¼“å­˜æœºåˆ¶åˆ›å»ºå·¥å…·
    for tool_name in enabled_tools:
        # 1. æ£€æŸ¥ç¼“å­˜
        cached_tool = _tool_cache.get_tool(tool_name, connection_config)
        if cached_tool:
            tools.append(cached_tool)
            logger.info(f"â™»ï¸ [ToolRegistry] ä½¿ç”¨ç¼“å­˜å·¥å…·: {tool_name}")
            continue
        
        # 2. åˆ›å»ºæ–°å·¥å…·
        factory_func = tool_factory_map.get(tool_name)
        if factory_func:
            try:
                # ğŸ”¥ å¦‚æœæ˜¯éœ€è¦connection_configçš„å·¥å…·ï¼Œä¸”connection_configå¯ç”¨ï¼Œåˆ™ä¼ é€’å®ƒ
                if tool_name in tools_requiring_connection and connection_config:
                    tool = factory_func(container, connection_config=connection_config)
                    logger.info(f"âœ… [ToolRegistry] æˆåŠŸåˆ›å»ºå·¥å…·ï¼ˆå¸¦connection_configï¼‰: {tool_name}")
                else:
                    tool = factory_func(container)
                    logger.info(f"âœ… [ToolRegistry] æˆåŠŸåˆ›å»ºå·¥å…·: {tool_name}")

                # 3. ç¼“å­˜å·¥å…·å®ä¾‹
                _tool_cache.set_tool(tool_name, tool, connection_config)
                tools.append(tool)
            except Exception as e:
                logger.warning(f"âš ï¸ [ToolRegistry] åˆ›å»ºå·¥å…·å¤±è´¥: {tool_name}, é”™è¯¯: {e}")
                import traceback
                logger.warning(traceback.format_exc())
        else:
            logger.warning(f"âš ï¸ [ToolRegistry] æœªçŸ¥å·¥å…·: {tool_name}")

    # è®°å½•ç¼“å­˜ç»Ÿè®¡
    cache_stats = _tool_cache.get_cache_stats()
    logger.info(f"ğŸ“¦ [ToolRegistry] å…±åˆ›å»º {len(tools)} ä¸ªå·¥å…·ï¼Œç¼“å­˜ç»Ÿè®¡: {cache_stats}")
    return tools


def _extract_response_metrics(response_payload: Any) -> Tuple[float, int]:
    """æå–è´¨é‡è¯„åˆ†å’Œè¿­ä»£æ¬¡æ•°ï¼Œå…¼å®¹å­—å…¸å’ŒAgentResponseå¯¹è±¡"""
    if isinstance(response_payload, AgentResponse):
        return (
            response_payload.quality_score or 0.0,
            response_payload.iterations_used or 0,
        )
    if isinstance(response_payload, dict):
        quality = response_payload.get("quality_score", 0.0) or 0.0
        iterations = response_payload.get("iterations_used", 0) or 0
        return (float(quality), int(iterations))
    return 0.0, 0


class ActionType(Enum):
    """ä¸‹ä¸€æ­¥è¡ŒåŠ¨ç±»å‹"""
    CONTINUE = "continue"  # ç»§ç»­å½“å‰ç­–ç•¥
    RETRY = "retry"  # é‡è¯•å½“å‰æ­¥éª¤
    FALLBACK = "fallback"  # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    CHANGE_STRATEGY = "change_strategy"  # æ”¹å˜ç­–ç•¥
    EXPLORE = "explore"  # æ¢ç´¢æ–°æ–¹æ³•
    TERMINATE = "terminate"  # ç»ˆæ­¢æ‰§è¡Œ


@dataclass
class IterationStep:
    """å•æ¬¡è¿­ä»£æ­¥éª¤è®°å½•"""
    iteration: int
    timestamp: float
    tool_calls: List[str] = field(default_factory=list)
    has_error: bool = False
    error_message: Optional[str] = None
    error_type: Optional[str] = None
    quality_score: Optional[float] = None
    result_summary: Optional[str] = None
    tokens_used: int = 0

    @property
    def is_successful(self) -> bool:
        """æ˜¯å¦æˆåŠŸ"""
        return not self.has_error and self.quality_score and self.quality_score > 0.7


@dataclass
class ActionPlan:
    """è¡ŒåŠ¨è®¡åˆ’"""
    type: ActionType
    reason: str
    suggestion: str = ""
    priority: int = 1  # 1-5, 5æœ€é«˜

    def __str__(self):
        return f"[{self.type.value}] {self.reason} - {self.suggestion}"


class AdaptiveIterationTracker:
    """
    è‡ªé€‚åº”è¿­ä»£è·Ÿè¸ªå™¨ - åŠ¨æ€è°ƒæ•´ç­–ç•¥

    åŠŸèƒ½ï¼š
    - è·Ÿè¸ªæ¯æ¬¡è¿­ä»£çš„è¯¦ç»†ä¿¡æ¯
    - åˆ†æé”™è¯¯æ¨¡å¼å’Œè´¨é‡è¶‹åŠ¿
    - åŸºäºå†å²å»ºè®®ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    - æ£€æµ‹å¾ªç¯å’Œå¡é¡¿
    """

    def __init__(self, goal: str, max_iterations: int = 10):
        self.goal = goal
        self.max_iterations = max_iterations

        # å†å²è®°å½•
        self.iteration_history: List[IterationStep] = []
        self.quality_trend: List[float] = []
        self.error_count = 0
        self.consecutive_errors = 0

        # å·¥å…·è°ƒç”¨ç»Ÿè®¡
        self.tool_call_count = 0
        self.tool_call_frequency: Dict[str, int] = {}

        # ç›®æ ‡è¿›åº¦
        self.goal_progress: float = 0.0

        # çŠ¶æ€
        self.is_stuck = False
        self.last_tool_call_time = 0

    def record_step(
        self,
        iteration: int,
        tool_calls: List[str],
        result: Any = None,
        error: Optional[Exception] = None,
        quality_score: Optional[float] = None
    ):
        """
        è®°å½•ä¸€æ¬¡è¿­ä»£æ­¥éª¤

        Args:
            iteration: è¿­ä»£æ¬¡æ•°
            tool_calls: æœ¬è½®è°ƒç”¨çš„å·¥å…·åˆ—è¡¨
            result: æ‰§è¡Œç»“æœ
            error: é”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
            quality_score: è´¨é‡è¯„åˆ†
        """
        # åˆ›å»ºæ­¥éª¤è®°å½•
        step = IterationStep(
            iteration=iteration,
            timestamp=time.time(),
            tool_calls=tool_calls,
            has_error=error is not None,
            error_message=str(error) if error else None,
            error_type=type(error).__name__ if error else None,
            quality_score=quality_score,
            result_summary=str(result)[:200] if result else None
        )

        # æ·»åŠ åˆ°å†å²
        self.iteration_history.append(step)

        # æ›´æ–°ç»Ÿè®¡
        if error:
            self.error_count += 1
            self.consecutive_errors += 1
        else:
            self.consecutive_errors = 0

        # æ›´æ–°å·¥å…·è°ƒç”¨ç»Ÿè®¡
        for tool in tool_calls:
            self.tool_call_count += 1
            self.tool_call_frequency[tool] = self.tool_call_frequency.get(tool, 0) + 1

        # æ›´æ–°è´¨é‡è¶‹åŠ¿
        if quality_score is not None:
            self.quality_trend.append(quality_score)
            self._update_goal_progress(quality_score)

        # æ£€æµ‹æ˜¯å¦å¡ä½
        self._check_if_stuck()

        logger.info(f"ğŸ“Š [AdaptiveTracker] è®°å½•ç¬¬{iteration}è½®: "
                   f"å·¥å…·={len(tool_calls)}, é”™è¯¯={step.has_error}, è´¨é‡={quality_score:.2f if quality_score else 'N/A'}")

    def on_tool_call(self, tool_name: str):
        """å·¥å…·è°ƒç”¨æ—¶è°ƒç”¨"""
        self.last_tool_call_time = time.time()
        self.tool_call_frequency[tool_name] = self.tool_call_frequency.get(tool_name, 0) + 1

    def suggest_next_action(self) -> ActionPlan:
        """
        åŸºäºå†å²å»ºè®®ä¸‹ä¸€æ­¥è¡ŒåŠ¨

        Returns:
            ActionPlan: è¡ŒåŠ¨è®¡åˆ’
        """
        # 1. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢
        if len(self.iteration_history) >= self.max_iterations:
            return ActionPlan(
                type=ActionType.TERMINATE,
                reason="è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
                suggestion=f"å·²æ‰§è¡Œ{len(self.iteration_history)}è½®ï¼Œå»ºè®®ç»ˆæ­¢",
                priority=5
            )

        # 2. æ£€æŸ¥æ˜¯å¦å¡ä½
        if self.is_stuck:
            return ActionPlan(
                type=ActionType.FALLBACK,
                reason="æ£€æµ‹åˆ°é‡å¤å¾ªç¯",
                suggestion="å»ºè®®åˆ‡æ¢åˆ°å¤‡ç”¨ç­–ç•¥æˆ–ç®€åŒ–ä»»åŠ¡",
                priority=5
            )

        # 3. æ£€æŸ¥è¿ç»­é”™è¯¯
        if self.consecutive_errors >= 2:
            return ActionPlan(
                type=ActionType.CHANGE_STRATEGY,
                reason=f"è¿ç»­{self.consecutive_errors}æ¬¡é”™è¯¯",
                suggestion="å»ºè®®æ”¹å˜å½“å‰æ–¹æ³•ï¼Œå°è¯•ä¸åŒçš„å·¥å…·ç»„åˆ",
                priority=4
            )

        # 4. æ£€æŸ¥è´¨é‡è¶‹åŠ¿
        if len(self.quality_trend) >= 3:
            recent_trend = self._analyze_quality_trend()
            if recent_trend == "improving":
                return ActionPlan(
                    type=ActionType.CONTINUE,
                    reason="è´¨é‡æŒç»­æå‡",
                    suggestion="ç»§ç»­å½“å‰ç­–ç•¥",
                    priority=2
                )
            elif recent_trend == "declining":
                return ActionPlan(
                    type=ActionType.CHANGE_STRATEGY,
                    reason="è´¨é‡ä¸‹é™",
                    suggestion="å»ºè®®è°ƒæ•´æ–¹æ³•æˆ–å›é€€åˆ°ä¹‹å‰çš„çŠ¶æ€",
                    priority=3
                )

        # 5. æ£€æŸ¥å•ä¸ªå·¥å…·è°ƒç”¨é¢‘ç‡
        if self._has_tool_overuse():
            overused_tool = max(self.tool_call_frequency, key=self.tool_call_frequency.get)
            return ActionPlan(
                type=ActionType.CHANGE_STRATEGY,
                reason=f"å·¥å…· {overused_tool} è¢«è¿‡åº¦ä½¿ç”¨",
                suggestion=f"é¿å…é‡å¤è°ƒç”¨ {overused_tool}ï¼Œå°è¯•å…¶ä»–å·¥å…·",
                priority=4
            )

        # 6. é»˜è®¤ï¼šæ¢ç´¢
        return ActionPlan(
            type=ActionType.EXPLORE,
            reason="æ­£å¸¸æ‰§è¡Œä¸­",
            suggestion="ç»§ç»­æ¢ç´¢ï¼Œä½¿ç”¨åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡",
            priority=1
        )

    def estimate_iteration_count(self) -> int:
        """ä¼°ç®—è¿­ä»£æ¬¡æ•°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
        return len(self.iteration_history) or max(1, self.tool_call_count // 2)

    def reset(self):
        """é‡ç½®è·Ÿè¸ªå™¨"""
        self.iteration_history.clear()
        self.quality_trend.clear()
        self.error_count = 0
        self.consecutive_errors = 0
        self.tool_call_count = 0
        self.tool_call_frequency.clear()
        self.goal_progress = 0.0
        self.is_stuck = False

    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œæ‘˜è¦"""
        return {
            "total_iterations": len(self.iteration_history),
            "total_tool_calls": self.tool_call_count,
            "error_count": self.error_count,
            "error_rate": self.error_count / len(self.iteration_history) if self.iteration_history else 0,
            "goal_progress": self.goal_progress,
            "quality_trend": self._analyze_quality_trend(),
            "most_used_tools": sorted(
                self.tool_call_frequency.items(),
                key=lambda x: x[1],
                reverse=True
            )[:3],
            "is_stuck": self.is_stuck
        }

    # ===== ç§æœ‰æ–¹æ³• =====

    def _update_goal_progress(self, quality_score: float):
        """æ›´æ–°ç›®æ ‡è¿›åº¦"""
        # åŸºäºè´¨é‡è¯„åˆ†å’Œè¿­ä»£æ¬¡æ•°ç»¼åˆè®¡ç®—
        iteration_progress = len(self.iteration_history) / self.max_iterations
        quality_weight = 0.7
        iteration_weight = 0.3

        self.goal_progress = min(1.0,
            quality_weight * quality_score + iteration_weight * iteration_progress
        )

    def _check_if_stuck(self):
        """æ£€æµ‹æ˜¯å¦å¡ä½ï¼ˆå¾ªç¯ï¼‰"""
        if len(self.iteration_history) < 3:
            return

        # æ£€æŸ¥æœ€è¿‘3æ¬¡è¿­ä»£æ˜¯å¦æœ‰é‡å¤çš„å·¥å…·è°ƒç”¨æ¨¡å¼
        recent_steps = self.iteration_history[-3:]
        tool_patterns = [set(step.tool_calls) for step in recent_steps]

        # å¦‚æœæ‰€æœ‰æ¨¡å¼éƒ½ç›¸åŒï¼Œè®¤ä¸ºå¡ä½äº†
        if len(set(map(frozenset, tool_patterns))) == 1:
            self.is_stuck = True
            logger.warning("ğŸš¨ [AdaptiveTracker] æ£€æµ‹åˆ°å¾ªç¯ï¼šæœ€è¿‘3æ¬¡è¿­ä»£ä½¿ç”¨ç›¸åŒå·¥å…·")

    def _analyze_quality_trend(self) -> str:
        """åˆ†æè´¨é‡è¶‹åŠ¿"""
        if len(self.quality_trend) < 2:
            return "insufficient_data"

        recent = self.quality_trend[-3:]

        # æ£€æŸ¥æ˜¯å¦æŒç»­æå‡
        if all(recent[i] >= recent[i-1] for i in range(1, len(recent))):
            return "improving"

        # æ£€æŸ¥æ˜¯å¦æŒç»­ä¸‹é™
        if all(recent[i] <= recent[i-1] for i in range(1, len(recent))):
            return "declining"

        # æ£€æŸ¥æ˜¯å¦ç¨³å®š
        variance = sum((x - sum(recent)/len(recent))**2 for x in recent) / len(recent)
        if variance < 0.01:
            return "stable"

        return "fluctuating"

    def _has_tool_overuse(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è¢«è¿‡åº¦ä½¿ç”¨"""
        if not self.tool_call_frequency:
            return False

        max_calls = max(self.tool_call_frequency.values())
        total_calls = sum(self.tool_call_frequency.values())

        # å¦‚æœæŸä¸ªå·¥å…·å æ¯”è¶…è¿‡60%ï¼Œè®¤ä¸ºè¿‡åº¦ä½¿ç”¨
        return max_calls / total_calls > 0.6 and max_calls > 3


class AdaptivePromptGenerator:
    """
    è‡ªé€‚åº”æç¤ºè¯ç”Ÿæˆå™¨ - æ ¹æ®æ‰§è¡ŒçŠ¶æ€åŠ¨æ€ç”Ÿæˆæç¤º

    åŠŸèƒ½ï¼š
    - æ ¹æ®ç›®æ ‡å’Œå½“å‰è¿›åº¦ç”Ÿæˆæç¤º
    - åŸºäºé”™è¯¯å†å²æä¾›ä¿®å¤å»ºè®®
    - æ ¹æ®è´¨é‡è¶‹åŠ¿è°ƒæ•´ç­–ç•¥
    - åŠ¨æ€è°ƒæ•´æç¤ºå†…å®¹å’Œä¼˜å…ˆçº§

    é›†æˆ prompts æ¨¡å—ï¼š
    - SystemPromptBuilder: ç³»ç»Ÿçº§æç¤ºè¯
    - StagePromptManager: é˜¶æ®µæ„ŸçŸ¥æç¤º
    - PromptTemplateManager: æ¨¡æ¿åŒ–å†…å®¹
    - ContextFormatter: ä¸Šä¸‹æ–‡æ ¼å¼åŒ–
    """

    def __init__(
        self,
        goal: str,
        tracker: AdaptiveIterationTracker,
        stage: Optional[ExecutionStage] = None,
        complexity: Optional[TaskComplexity] = None,
        context: Optional[ContextInfo] = None,
        base_system_prompt: Optional[str] = None
    ):
        """
        Args:
            goal: ä»»åŠ¡ç›®æ ‡æè¿°
            tracker: è‡ªé€‚åº”è¿­ä»£è·Ÿè¸ªå™¨
            stage: å½“å‰æ‰§è¡Œé˜¶æ®µï¼ˆå¯é€‰ï¼‰
            complexity: ä»»åŠ¡å¤æ‚åº¦ï¼ˆå¯é€‰ï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            base_system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤ï¼‰
        """
        self.goal = goal
        self.tracker = tracker
        self.stage = stage
        self.complexity = complexity
        self.context = context

        # âœ… å¯¼å…¥å¹¶åˆå§‹åŒ– prompts ç»„ä»¶
        from .prompts import (
            SystemPromptBuilder,
            StagePromptManager,
            PromptTemplateManager,
            ContextFormatter
        )

        self._system_builder = SystemPromptBuilder()
        self._stage_manager = StagePromptManager()
        self._template_manager = PromptTemplateManager()
        self._context_formatter = ContextFormatter()

        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ SystemPromptBuilder ç”Ÿæˆ
        if base_system_prompt:
            self.base_system_prompt = base_system_prompt
        else:
            self.base_system_prompt = self._system_builder.build_system_prompt(
                stage=stage,
                complexity=complexity
            )

    def generate_next_prompt(
        self,
        last_error: Optional[Exception] = None,
        last_result: Optional[str] = None
    ) -> str:
        """
        åŸºäºå½“å‰çŠ¶æ€ç”Ÿæˆä¸‹ä¸€æ­¥æç¤º

        Args:
            last_error: ä¸Šä¸€æ­¥çš„é”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
            last_result: ä¸Šä¸€æ­¥çš„ç»“æœ

        Returns:
            ç”Ÿæˆçš„æç¤ºè¯
        """
        prompt_parts = []

        # 1. åŸºç¡€ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if self.base_system_prompt:
            prompt_parts.append(self.base_system_prompt)

        # 2. ç›®æ ‡å’Œè¿›åº¦æé†’
        progress = self.tracker.goal_progress
        prompt_parts.append(self._generate_goal_section(progress))

        # 3. å½“å‰çŠ¶æ€åˆ†æ
        if last_error:
            prompt_parts.append(self._generate_error_guidance(last_error))
        elif last_result:
            prompt_parts.append(self._generate_progress_feedback(last_result))

        # 4. ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®
        action_plan = self.tracker.suggest_next_action()
        prompt_parts.append(self._generate_action_guidance(action_plan))

        # 5. åŠ¨æ€çº¦æŸæ¡ä»¶
        constraints = self._generate_dynamic_constraints()
        if constraints:
            prompt_parts.append(constraints)

        # 6. æ‰§è¡Œæ‘˜è¦ï¼ˆå¦‚æœæœ‰å†å²ï¼‰
        if self.tracker.iteration_history:
            prompt_parts.append(self._generate_execution_summary())

        return "\n\n".join(prompt_parts)

    def generate_initial_prompt(self, task_description: str) -> str:
        """
        ç”Ÿæˆåˆå§‹æç¤ºè¯

        Args:
            task_description: ä»»åŠ¡æè¿°

        Returns:
            åˆå§‹æç¤ºè¯
        """
        prompt_parts = []

        # 1. ç³»ç»Ÿæç¤º
        if self.base_system_prompt:
            prompt_parts.append(self.base_system_prompt)

        # 2. ä»»åŠ¡ç›®æ ‡
        prompt_parts.append(f"# ä»»åŠ¡ç›®æ ‡\n\n{self.goal}")

        # 3. ä»»åŠ¡æè¿°
        prompt_parts.append(f"# ä»»åŠ¡æè¿°\n\n{task_description}")

        # 4. åˆå§‹æŒ‡å¯¼
        prompt_parts.append(self._generate_initial_guidance())

        return "\n\n".join(prompt_parts)

    # ===== ç§æœ‰æ–¹æ³•ï¼šç”Ÿæˆå„éƒ¨åˆ†æç¤º =====

    def _generate_goal_section(self, progress: float) -> str:
        """ç”Ÿæˆç›®æ ‡å’Œè¿›åº¦éƒ¨åˆ†"""
        progress_bar = "â–ˆ" * int(progress * 10) + "â–‘" * (10 - int(progress * 10))
        progress_emoji = "ğŸ¯" if progress < 0.3 else "ğŸ“ˆ" if progress < 0.7 else "âœ¨"

        return f"""# ç›®æ ‡è¿½è¸ª

{progress_emoji} **å½“å‰ç›®æ ‡**: {self.goal}
**è¿›åº¦**: [{progress_bar}] {progress:.0%}
**è¿­ä»£**: ç¬¬ {len(self.tracker.iteration_history) + 1} / {self.tracker.max_iterations} è½®"""

    def _generate_error_guidance(self, error: Exception) -> str:
        """ç”Ÿæˆé”™è¯¯æŒ‡å¯¼"""
        error_type = type(error).__name__
        error_msg = str(error)

        # åˆ†æé”™è¯¯æ¨¡å¼
        if self.tracker.consecutive_errors > 1:
            pattern = f"âš ï¸ **è­¦å‘Š**: å·²è¿ç»­{self.tracker.consecutive_errors}æ¬¡é”™è¯¯ï¼Œå»ºè®®æ”¹å˜ç­–ç•¥"
        else:
            pattern = ""

        # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å»ºè®®
        suggestions = self._get_error_fix_suggestions(error_type, error_msg)

        return f"""# âš ï¸ ä¸Šä¸€æ­¥æ‰§è¡Œå¤±è´¥

**é”™è¯¯ç±»å‹**: {error_type}
**é”™è¯¯ä¿¡æ¯**: {error_msg}
{pattern}

## å»ºè®®ä¿®å¤æ–¹æ¡ˆ

{suggestions}"""

    def _generate_progress_feedback(self, result: str) -> str:
        """ç”Ÿæˆè¿›åº¦åé¦ˆ"""
        # åˆ†æè´¨é‡è¶‹åŠ¿
        trend = self.tracker._analyze_quality_trend()
        trend_emoji = {
            "improving": "ğŸ“ˆ",
            "stable": "â¡ï¸",
            "declining": "ğŸ“‰",
            "fluctuating": "ã€°ï¸",
            "insufficient_data": "â“"
        }.get(trend, "â“")

        latest_quality = self.tracker.quality_trend[-1] if self.tracker.quality_trend else 0.0

        return f"""# âœ… ä¸Šä¸€æ­¥æ‰§è¡ŒæˆåŠŸ

**è´¨é‡è¯„åˆ†**: {latest_quality:.2f}
**è¶‹åŠ¿**: {trend_emoji} {trend}

**ç»“æœæ‘˜è¦**: {result[:150]}{"..." if len(result) > 150 else ""}"""

    def _generate_action_guidance(self, action_plan: ActionPlan) -> str:
        """ç”Ÿæˆè¡ŒåŠ¨æŒ‡å¯¼"""
        priority_emoji = "ğŸ”´" if action_plan.priority >= 4 else "ğŸŸ¡" if action_plan.priority >= 2 else "ğŸŸ¢"

        return f"""# ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’

{priority_emoji} **ç­–ç•¥**: {action_plan.type.value}
**åŸå› **: {action_plan.reason}
**å»ºè®®**: {action_plan.suggestion or "ç»§ç»­æ‰§è¡Œä»»åŠ¡"}"""

    def _generate_dynamic_constraints(self) -> str:
        """ç”ŸæˆåŠ¨æ€çº¦æŸ"""
        constraints = []

        # åŸºäºå·¥å…·ä½¿ç”¨é¢‘ç‡çš„çº¦æŸ
        if self.tracker.tool_call_frequency:
            overused_tools = [
                tool for tool, count in self.tracker.tool_call_frequency.items()
                if count > 3
            ]
            if overused_tools:
                constraints.append(
                    f"- âš ï¸ é¿å…è¿‡åº¦ä½¿ç”¨ä»¥ä¸‹å·¥å…·: {', '.join(overused_tools)}"
                )

        # åŸºäºé”™è¯¯å†å²çš„çº¦æŸ
        if self.tracker.error_count > 0:
            constraints.append(
                f"- ğŸ’¡ å·²å‘ç”Ÿ {self.tracker.error_count} æ¬¡é”™è¯¯ï¼Œè¯·ä»”ç»†éªŒè¯æ¯ä¸ªæ­¥éª¤"
            )

        # åŸºäºè¿­ä»£æ¬¡æ•°çš„çº¦æŸ
        remaining = self.tracker.max_iterations - len(self.tracker.iteration_history)
        if remaining <= 2:
            constraints.append(
                f"- â° å‰©ä½™è¿­ä»£æ¬¡æ•°: {remaining}ï¼Œè¯·å°½å¿«å®Œæˆä»»åŠ¡"
            )

        if not constraints:
            return ""

        return f"""# æ‰§è¡Œçº¦æŸ

{chr(10).join(constraints)}"""

    def _generate_execution_summary(self) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = self.tracker.get_summary()

        most_used = ", ".join([f"{tool}({count})" for tool, count in summary["most_used_tools"][:3]])

        return f"""# æ‰§è¡Œæ‘˜è¦

- **æ€»è¿­ä»£**: {summary['total_iterations']}
- **å·¥å…·è°ƒç”¨**: {summary['total_tool_calls']} æ¬¡
- **é”™è¯¯ç‡**: {summary['error_rate']:.1%}
- **å¸¸ç”¨å·¥å…·**: {most_used}
- **è´¨é‡è¶‹åŠ¿**: {summary['quality_trend']}"""

    def _generate_initial_guidance(self) -> str:
        """
        ç”Ÿæˆåˆå§‹æŒ‡å¯¼

        âœ… é›†æˆ StagePromptManagerï¼Œæ”¯æŒé˜¶æ®µæ„ŸçŸ¥çš„åˆå§‹æŒ‡å¯¼

        Returns:
            åˆå§‹æŒ‡å¯¼æ–‡æœ¬
        """
        # å¦‚æœæœ‰æŒ‡å®šé˜¶æ®µï¼Œä½¿ç”¨é˜¶æ®µç‰¹å®šçš„æŒ‡å¯¼
        if self.stage:
            try:
                stage_prompt = self._stage_manager.get_stage_prompt(
                    stage=self.stage,
                    context=self.context,
                    complexity=self.complexity
                )
                return f"""# æ‰§è¡ŒæŒ‡å¯¼

## å½“å‰é˜¶æ®µ: {self.stage.value}

{stage_prompt}

## é€šç”¨åŸåˆ™

1. **ç†è§£éœ€æ±‚**: ä»”ç»†åˆ†æä»»åŠ¡ç›®æ ‡å’Œæè¿°
2. **åˆ¶å®šè®¡åˆ’**: ç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·å’Œæ‰§è¡Œé¡ºåº
3. **é€æ­¥æ‰§è¡Œ**: ä½¿ç”¨åˆé€‚çš„å·¥å…·ï¼ŒéªŒè¯æ¯ä¸€æ­¥çš„ç»“æœ
4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®åé¦ˆè°ƒæ•´ç­–ç•¥ï¼Œå‘ç›®æ ‡é æ‹¢
5. **è´¨é‡éªŒè¯**: ç¡®ä¿æœ€ç»ˆç»“æœç¬¦åˆè¦æ±‚

**é‡è¦æç¤º**:
- æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªå…³é”®æ­¥éª¤
- é‡åˆ°é”™è¯¯æ—¶ï¼Œåˆ†æåŸå› å¹¶è°ƒæ•´æ–¹æ³•
- ä½¿ç”¨å·¥å…·å‰å…ˆç¡®è®¤å…¶é€‚ç”¨æ€§
- ä¿æŒè¾“å‡ºçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§"""
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–é˜¶æ®µæç¤ºå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æŒ‡å¯¼")

        # é»˜è®¤é€šç”¨æŒ‡å¯¼
        return """# æ‰§è¡ŒæŒ‡å¯¼

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š

1. **ç†è§£éœ€æ±‚**: ä»”ç»†åˆ†æä»»åŠ¡ç›®æ ‡å’Œæè¿°
2. **åˆ¶å®šè®¡åˆ’**: ç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·å’Œæ‰§è¡Œé¡ºåº
3. **é€æ­¥æ‰§è¡Œ**: ä½¿ç”¨åˆé€‚çš„å·¥å…·ï¼ŒéªŒè¯æ¯ä¸€æ­¥çš„ç»“æœ
4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®åé¦ˆè°ƒæ•´ç­–ç•¥ï¼Œå‘ç›®æ ‡é æ‹¢
5. **è´¨é‡éªŒè¯**: ç¡®ä¿æœ€ç»ˆç»“æœç¬¦åˆè¦æ±‚

**é‡è¦æç¤º**:
- æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªå…³é”®æ­¥éª¤
- é‡åˆ°é”™è¯¯æ—¶ï¼Œåˆ†æåŸå› å¹¶è°ƒæ•´æ–¹æ³•
- ä½¿ç”¨å·¥å…·å‰å…ˆç¡®è®¤å…¶é€‚ç”¨æ€§
- ä¿æŒè¾“å‡ºçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§"""

    # ===== ç±»å¸¸é‡ï¼šé”™è¯¯ä¿®å¤å»ºè®®æ˜ å°„ =====
    ERROR_FIX_SUGGESTIONS = {
        "TableNotFoundError": """
- æ£€æŸ¥è¡¨åæ˜¯å¦æ­£ç¡®ï¼ˆå¯èƒ½éœ€è¦ä½¿ç”¨ schema_discovery å·¥å…·ï¼‰
- ç¡®è®¤æ•°æ®åº“è¿æ¥é…ç½®æ˜¯å¦æ­£ç¡®
- ä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­æä¾›çš„è¡¨åï¼Œé¿å…çŒœæµ‹""",

        "ColumnNotFoundError": """
- ä½¿ç”¨ schema_retrieval å·¥å…·è·å–è¡¨çš„åˆ—ä¿¡æ¯
- æ£€æŸ¥åˆ—åæ‹¼å†™æ˜¯å¦æ­£ç¡®
- ç¡®è®¤è¯¥åˆ—æ˜¯å¦å­˜åœ¨äºç›®æ ‡è¡¨ä¸­""",

        "SyntaxError": """
- æ£€æŸ¥ SQL è¯­æ³•æ˜¯å¦ç¬¦åˆ Doris è§„èŒƒ
- ä½¿ç”¨ sql_validator å·¥å…·éªŒè¯ SQL
- å‚è€ƒç³»ç»Ÿæç¤ºä¸­çš„ SQL ç¤ºä¾‹""",

        "ConnectionError": """
- æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®
- ç¡®è®¤ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
- ç¨åé‡è¯•æ“ä½œ""",

        "TimeoutError": """
- ç®€åŒ–æŸ¥è¯¢é€»è¾‘
- å‡å°‘æ•°æ®é‡
- ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½""",

        "ValidationError": """
- æ£€æŸ¥è¾“å…¥æ•°æ®çš„æ ¼å¼å’Œç±»å‹
- ç¡®è®¤æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å·²æä¾›
- éªŒè¯æ•°æ®æ˜¯å¦ç¬¦åˆçº¦æŸæ¡ä»¶""",

        "ToolExecutionError": """
- æ£€æŸ¥å·¥å…·å‚æ•°æ˜¯å¦æ­£ç¡®
- ç¡®è®¤å·¥å…·çš„å‰ç½®æ¡ä»¶å·²æ»¡è¶³
- æŸ¥çœ‹å·¥å…·æ–‡æ¡£äº†è§£æ­£ç¡®ç”¨æ³•"""
    }

    DEFAULT_ERROR_SUGGESTION = """
- ä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯ï¼Œç†è§£é—®é¢˜æ ¹æº
- æ£€æŸ¥ä¸Šä¸€æ­¥çš„æ“ä½œæ˜¯å¦æ­£ç¡®
- å°è¯•ä½¿ç”¨ä¸åŒçš„æ–¹æ³•æˆ–å·¥å…·
- å¦‚æœé—®é¢˜æŒç»­ï¼Œè€ƒè™‘ç®€åŒ–ä»»åŠ¡æˆ–ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ"""

    def _get_error_fix_suggestions(self, error_type: str, error_msg: str) -> str:
        """
        æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¿®å¤å»ºè®®

        âœ… ä½¿ç”¨ç±»å¸¸é‡æ›¿ä»£ç¡¬ç¼–ç å­—å…¸ï¼Œæé«˜å¯ç»´æŠ¤æ€§

        Args:
            error_type: é”™è¯¯ç±»å‹åç§°
            error_msg: é”™è¯¯ä¿¡æ¯

        Returns:
            ä¿®å¤å»ºè®®æ–‡æœ¬
        """
        # æŸ¥æ‰¾åŒ¹é…çš„é”™è¯¯ç±»å‹
        for key, suggestion in self.ERROR_FIX_SUGGESTIONS.items():
            if key in error_type or key.lower() in error_msg.lower():
                return suggestion

        # é»˜è®¤å»ºè®®
        return self.DEFAULT_ERROR_SUGGESTION


class LoomAgentRuntime:
    """
    Loom Agent è¿è¡Œæ—¶
    
    åŸºäº Loom 0.0.3 çš„ TT é€’å½’æ‰§è¡Œæœºåˆ¶ï¼Œæä¾›è‡ªåŠ¨è¿­ä»£æ¨ç†èƒ½åŠ›
    
    ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿å·¥å…·ç»“æœåœ¨é€’å½’å¾ªç¯ä¸­æ­£ç¡®ä¼ é€’åˆ°ä¸Šä¸‹æ–‡ä¸­
    """

    def __init__(
        self,
        agent: Agent,
        tools: List[BaseTool],
        config: AgentConfig,
        context_retriever: Optional[SchemaContextRetriever] = None,
        container: Optional[Any] = None,
    ):
        """
        Args:
            agent: Loom Agent å®ä¾‹
            tools: å·¥å…·åˆ—è¡¨
            config: Agent é…ç½®
            context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
            container: æœåŠ¡å®¹å™¨ï¼ˆç”¨äºé«˜çº§åŠŸèƒ½ï¼‰
        """
        self._agent = agent
        self._tools = tools
        self._config = config
        self._context_retriever = context_retriever
        self.container = container  # æ·»åŠ  container å±æ€§

        # æ‰§è¡ŒçŠ¶æ€
        self._current_state: Optional[ExecutionState] = None
        self._event_callbacks: List[Callable[[AgentEvent], None]] = []

        # ğŸ”¥ ä½¿ç”¨å¢å¼ºçš„è‡ªé€‚åº”è¿­ä»£è·Ÿè¸ªå™¨ï¼ˆå¾…åˆå§‹åŒ–ï¼Œéœ€è¦goalä¿¡æ¯ï¼‰
        self._iteration_tracker: Optional[AdaptiveIterationTracker] = None
        self._prompt_generator: Optional[AdaptivePromptGenerator] = None

        # è´¨é‡è¯„åˆ†å™¨
        self._quality_scorer = create_quality_scorer()

        # è®¾ç½®å·¥å…·è°ƒç”¨å›è°ƒ
        self._setup_tool_call_tracking()

    @property
    def agent(self) -> Agent:
        """è·å– Loom Agent å®ä¾‹"""
        return self._agent

    @property
    def config(self) -> AgentConfig:
        """è·å–é…ç½®"""
        return self._config

    @property
    def tools(self) -> List[BaseTool]:
        """è·å–å·¥å…·åˆ—è¡¨"""
        return self._tools

    @property
    def context_retriever(self) -> Optional[SchemaContextRetriever]:
        """è·å–ä¸Šä¸‹æ–‡æ£€ç´¢å™¨"""
        return self._context_retriever

    async def execute_with_tt(
        self,
        request: AgentRequest,
        max_iterations: Optional[int] = None
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        ä½¿ç”¨ TT é€’å½’æ‰§è¡Œ - è‡ªåŠ¨è¿­ä»£æ¨ç†
        
        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œä½¿ç”¨ Loom 0.0.3 çš„ tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£
        
        Args:
            request: Agent è¯·æ±‚
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Yields:
            AgentEvent: æ‰§è¡Œäº‹ä»¶æµ
        """
        start_time = time.time()
        max_iterations = max_iterations or request.max_iterations

        logger.info(f"ğŸš€ [LoomAgentRuntime] å¼€å§‹ TT é€’å½’æ‰§è¡Œ")
        logger.info(f"   å ä½ç¬¦: {request.placeholder[:100]}...")
        logger.info(f"   æ•°æ®æºID: {request.data_source_id}")
        logger.info(f"   ç”¨æˆ·ID: {request.user_id}")
        logger.info(f"   æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")

        # ğŸ”¥ åˆå§‹åŒ–è‡ªé€‚åº”è·Ÿè¸ªå™¨å’Œæç¤ºè¯ç”Ÿæˆå™¨
        goal = f"å®Œæˆ{request.stage.value}é˜¶æ®µä»»åŠ¡: {request.placeholder[:50]}"
        self._iteration_tracker = AdaptiveIterationTracker(
            goal=goal,
            max_iterations=max_iterations
        )

        # âœ… åˆ›å»ºåˆå§‹ä¸Šä¸‹æ–‡ï¼ˆä»è¯·æ±‚ä¸­è·å–ï¼‰
        initial_context = ContextInfo()
        if hasattr(request, 'context') and request.context:
            initial_context = request.context

        # âœ… åˆå§‹åŒ–è‡ªé€‚åº”æç¤ºè¯ç”Ÿæˆå™¨ï¼Œä¼ å…¥ stage, complexity, context
        self._prompt_generator = AdaptivePromptGenerator(
            goal=goal,
            tracker=self._iteration_tracker,
            stage=request.stage,  # âœ… ä¼ å…¥é˜¶æ®µä¿¡æ¯
            complexity=getattr(request, 'complexity', None),  # âœ… ä¼ å…¥å¤æ‚åº¦
            context=initial_context,  # âœ… ä¼ å…¥ä¸Šä¸‹æ–‡
            base_system_prompt=self._config.system_prompt  # å¯é€‰ï¼šè¦†ç›–é»˜è®¤ç³»ç»Ÿæç¤º
        )

        logger.info(f"ğŸ¯ [AdaptiveRuntime] ç›®æ ‡: {goal}")

        # åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€
        self._current_state = ExecutionState(
            current_stage=request.stage,
            iteration_count=0,
            start_time=start_time,
            context=ContextInfo(),
            max_iterations=max_iterations,
            max_context_tokens=self._config.max_context_tokens
        )

        # å‘é€åˆå§‹åŒ–äº‹ä»¶
        init_event = AgentEvent(
            event_type="execution_started",
            stage=request.stage,
            data={
                "request": request,
                "max_iterations": max_iterations,
                "timestamp": start_time
            }
        )
        yield init_event
        await self._notify_callbacks(init_event)

        # ğŸ”¥ è®¾ç½®ç”¨æˆ·IDçš„ context variableï¼Œä»¥ä¾¿ LLM adapter å¯ä»¥è·å–
        token = _CURRENT_USER_ID.set(request.user_id)

        try:
            # ğŸ”¥ æ ¸å¿ƒï¼šä½¿ç”¨ Loom çš„ Agent.run() è¿›è¡Œ TT é€’å½’æ‰§è¡Œ
            # Loom 0.0.3 çš„ Agent.run() å†…éƒ¨ä½¿ç”¨ tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£

            # æ„å»ºåˆå§‹ prompt
            initial_prompt = await self._build_initial_prompt(request)

            logger.info(f"ğŸ“ [LoomAgentRuntime] åˆå§‹ prompt é•¿åº¦: {len(initial_prompt)} å­—ç¬¦")

            # ğŸ”¥ TT é€’å½’æ‰§è¡Œ - ä½¿ç”¨ execute() è·å–äº‹ä»¶æµ
            from loom.core.events import AgentEventType

            result = ""
            tool_call_count = 0

            async for event in self._agent.execute(initial_prompt):
                # è®°å½• LLM å¼€å§‹
                if event.type == AgentEventType.LLM_START:
                    logger.info(f"ğŸ§  [LoomAgentRuntime] LLM å¼€å§‹ç”Ÿæˆï¼ˆè¿­ä»£ {self._current_state.iteration_count + 1}ï¼‰")

                # è®°å½•å·¥å…·è°ƒç”¨äº‹ä»¶
                elif event.type == AgentEventType.LLM_TOOL_CALLS:
                    tool_count = event.metadata.get("tool_count", 0)
                    tool_names = event.metadata.get("tool_names", [])
                    tool_call_count += tool_count
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] LLM è°ƒç”¨äº† {tool_count} ä¸ªå·¥å…·: {tool_names}")

                    # æ›´æ–°è¿­ä»£è®¡æ•°
                    if self._current_state:
                        self._current_state.iteration_count += 1

                # å·¥å…·æ‰§è¡Œè¿›åº¦
                elif event.type == AgentEventType.TOOL_PROGRESS:
                    tool_name = event.metadata.get("tool_name", "unknown")
                    status = event.metadata.get("status", "unknown")
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] å·¥å…· {tool_name}: {status}")

                # å·¥å…·æ‰§è¡Œç»“æœ
                elif event.type == AgentEventType.TOOL_RESULT:
                    logger.info(f"âœ… [LoomAgentRuntime] å·¥å…·æ‰§è¡Œå®Œæˆ")

                # ğŸ”¥ é€’å½’äº‹ä»¶
                elif event.type == AgentEventType.RECURSION:
                    logger.info(f"ğŸ”„ [LoomAgentRuntime] å¼€å§‹é€’å½’ï¼ˆåŸºäºå·¥å…·ç»“æœï¼‰")

                # è®°å½• LLM è¾“å‡ºå¢é‡
                elif event.type == AgentEventType.LLM_DELTA:
                    if event.content:
                        result += event.content

                # Agent å®Œæˆ
                elif event.type == AgentEventType.AGENT_FINISH:
                    result = event.content or result
                    logger.info(f"âœ… [LoomAgentRuntime] Agent æ‰§è¡Œå®Œæˆ")
                    logger.info(f"ğŸ“Š [LoomAgentRuntime] æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}")
                    logger.info(f"ğŸ“Š [LoomAgentRuntime] æ€»è¿­ä»£æ¬¡æ•°: {self._current_state.iteration_count}")
                    break

                # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
                elif event.type == AgentEventType.MAX_ITERATIONS_REACHED:
                    logger.warning(f"âš ï¸ [LoomAgentRuntime] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°")
                    break

                # é”™è¯¯å¤„ç†
                elif event.type == AgentEventType.ERROR:
                    error_msg = str(event.error) if event.error else "Unknown error"
                    logger.error(f"âŒ [LoomAgentRuntime] Agent æ‰§è¡Œé”™è¯¯: {error_msg}")
                    if event.error:
                        raise event.error
                    break

            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            execution_time_ms = int((time.time() - start_time) * 1000)
            
            # æ›´æ–°è¿­ä»£è®¡æ•°
            estimated_iterations = self._iteration_tracker.estimate_iteration_count()
            self._current_state.iteration_count = estimated_iterations
            
            # æ„å»ºå“åº”
            response = await self._build_response(request, result, execution_time_ms)
            
            # å‘é€å®Œæˆäº‹ä»¶
            completion_event = AgentEvent(
                event_type="execution_completed",
                stage=ExecutionStage.COMPLETION,
                data={
                    "response": response,
                    "execution_time_ms": execution_time_ms,
                    "iterations_used": self._current_state.iteration_count
                }
            )
            yield completion_event
            await self._notify_callbacks(completion_event)
            
            logger.info(f"âœ… [LoomAgentRuntime] TT é€’å½’æ‰§è¡Œå®Œæˆ")
            logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time_ms}ms")
            logger.info(f"   è¿­ä»£æ¬¡æ•°: {self._current_state.iteration_count}")
            logger.info(f"   å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(self._current_state.tool_call_history)}")
            
        except Exception as e:
            execution_time_ms = int((time.time() - start_time) * 1000)
            logger.error(f"âŒ [LoomAgentRuntime] TT é€’å½’æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
            # å‘é€é”™è¯¯äº‹ä»¶
            error_event = AgentEvent(
                event_type="execution_failed",
                stage=self._current_state.current_stage,
                data={
                    "error": str(e),
                    "execution_time_ms": execution_time_ms,
                    "iterations_used": self._current_state.iteration_count
                }
            )
            yield error_event
            await self._notify_callbacks(error_event)

            # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            raise
        finally:
            # ğŸ”¥ æ¸…ç† context variable
            try:
                _CURRENT_USER_ID.reset(token)
            except (ValueError, LookupError) as e:
                # åœ¨ç”Ÿæˆå™¨å…³é—­æ—¶ï¼Œtoken å¯èƒ½å·²ç»åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­
                # è¿™ç§æƒ…å†µä¸‹å¿½ç•¥ reset é”™è¯¯
                logger.debug(f"âš ï¸ Context variable reset failed (å¯ä»¥å¿½ç•¥): {e}")

    async def _build_initial_prompt(self, request: AgentRequest) -> str:
        """æ„å»ºåˆå§‹ prompt"""
        prompt_parts = []

        # 1. ç³»ç»ŸæŒ‡ä»¤ï¼ˆğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç³»ç»Ÿæç¤ºè¢«åŒ…å«ï¼‰
        # âœ… ä½¿ç”¨ SystemPromptBuilder ç”Ÿæˆç³»ç»Ÿæç¤ºï¼ˆå»é™¤ç¡¬ç¼–ç ï¼‰
        from .prompts import SystemPromptBuilder

        system_builder = SystemPromptBuilder()

        if self._config.system_prompt:
            # ä½¿ç”¨é…ç½®çš„ç³»ç»Ÿæç¤º
            prompt_parts.append(f"# ç³»ç»ŸæŒ‡ä»¤\n{self._config.system_prompt}")
        else:
            # ä½¿ç”¨ SystemPromptBuilder åŠ¨æ€ç”Ÿæˆ
            system_prompt = system_builder.build_system_prompt(
                stage=request.stage,
                complexity=getattr(request, 'complexity', None)
            )
            prompt_parts.append(f"# ç³»ç»ŸæŒ‡ä»¤\n{system_prompt}")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ‰‹åŠ¨è°ƒç”¨ context_retriever å¹¶æ³¨å…¥ Schema ä¿¡æ¯
        if self._context_retriever:
            try:
                logger.info("ğŸ” [_build_initial_prompt] æ‰‹åŠ¨è°ƒç”¨ ContextRetriever è·å– Schema")
                # è°ƒç”¨ retrieve æ–¹æ³•è·å–ç›¸å…³è¡¨ç»“æ„
                documents = await self._context_retriever.retrieve(
                    query=request.placeholder,
                    top_k=5  # è·å–æœ€ç›¸å…³çš„5ä¸ªè¡¨
                )

                if documents:
                    logger.info(f"âœ… [_build_initial_prompt] æ£€ç´¢åˆ° {len(documents)} ä¸ªè¡¨ç»“æ„")
                    # æ„å»º Schema ä¸Šä¸‹æ–‡éƒ¨åˆ†
                    schema_lines = ["# æ•°æ®åº“ Schema ä¿¡æ¯", ""]
                    for doc in documents:
                        schema_lines.append(doc.content)
                        schema_lines.append("")  # ç©ºè¡Œåˆ†éš”

                    schema_context = "\n".join(schema_lines)
                    prompt_parts.append(schema_context)

                    logger.info(f"âœ… [_build_initial_prompt] Schema ä¿¡æ¯å·²æ³¨å…¥åˆ° promptï¼ˆ{len(schema_context)} å­—ç¬¦ï¼‰")
                else:
                    logger.warning("âš ï¸ [_build_initial_prompt] ContextRetriever æœªè¿”å›ä»»ä½•è¡¨ç»“æ„")
            except Exception as e:
                logger.error(f"âŒ [_build_initial_prompt] è°ƒç”¨ ContextRetriever å¤±è´¥: {e}", exc_info=True)

        # 2. ä»»åŠ¡æè¿°
        prompt_parts.append(f"# ä»»åŠ¡æè¿°\n{request.placeholder}")

        # 3. ä¸Šä¸‹æ–‡ä¿¡æ¯
        if request.task_context:
            prompt_parts.append(f"# ä»»åŠ¡ä¸Šä¸‹æ–‡\n{self._format_context(request.task_context)}")

        # 4. çº¦æŸæ¡ä»¶
        if request.constraints:
            prompt_parts.append(f"# çº¦æŸæ¡ä»¶\n{self._format_constraints(request.constraints)}")

        # 5. æ‰§è¡ŒæŒ‡å¯¼
        prompt_parts.append(self._get_execution_guidance(request))

        return "\n\n".join(prompt_parts)

    def _format_context(self, context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        lines = []
        for key, value in context.items():
            if isinstance(value, (dict, list)):
                lines.append(f"- {key}: {str(value)[:200]}...")
            else:
                lines.append(f"- {key}: {value}")
        return "\n".join(lines)

    def _format_constraints(self, constraints: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–çº¦æŸæ¡ä»¶"""
        lines = []
        for key, value in constraints.items():
            lines.append(f"- {key}: {value}")
        return "\n".join(lines)

    def _get_execution_guidance(self, request: AgentRequest) -> str:
        """è·å–æ‰§è¡ŒæŒ‡å¯¼"""
        guidance = [
            "# æ‰§è¡ŒæŒ‡å¯¼",
            "",
            "è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š",
            "",
            "1. **ç†è§£éœ€æ±‚**: ä»”ç»†åˆ†æå ä½ç¬¦ä¸­çš„ä¸šåŠ¡éœ€æ±‚",
            "2. **æ¢ç´¢æ•°æ®**: ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ¢ç´¢æ•°æ®æºç»“æ„",
            "3. **ç”ŸæˆSQL**: åŸºäºæ•°æ®ç»“æ„å’Œéœ€æ±‚ç”Ÿæˆå‡†ç¡®çš„SQLæŸ¥è¯¢",
            "4. **éªŒè¯ç»“æœ**: éªŒè¯SQLçš„æ­£ç¡®æ€§å’Œç»“æœçš„åˆç†æ€§",
            "5. **ä¼˜åŒ–æ”¹è¿›**: æ ¹æ®éªŒè¯ç»“æœä¼˜åŒ–æŸ¥è¯¢",
            "",
            "**é‡è¦æç¤º**:",
            "- ä¼˜å…ˆä½¿ç”¨å·¥å…·è·å–å‡†ç¡®çš„æ•°æ®ç»“æ„ä¿¡æ¯",
            "- ç”Ÿæˆçš„SQLå¿…é¡»ç¬¦åˆæ•°æ®åº“è¯­æ³•è§„èŒƒ",
            "- ç¡®ä¿æŸ¥è¯¢ç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§",
            "- å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·å°è¯•ä¸åŒçš„æ–¹æ³•æˆ–å·¥å…·",
        ]
        
        # æ ¹æ®å¤æ‚åº¦æ·»åŠ ç‰¹å®šæŒ‡å¯¼
        if request.complexity == TaskComplexity.COMPLEX:
            guidance.extend([
                "",
                "**å¤æ‚ä»»åŠ¡æŒ‡å¯¼**:",
                "- å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤",
                "- é€æ­¥éªŒè¯æ¯ä¸ªæ­¥éª¤çš„ç»“æœ",
                "- ä½¿ç”¨å¤šä¸ªå·¥å…·ç»„åˆå®Œæˆä»»åŠ¡",
            ])
        
        return "\n".join(guidance)

    async def _build_response(
        self, 
        request: AgentRequest, 
        result: Any, 
        execution_time_ms: int
    ) -> AgentResponse:
        """æ„å»ºå“åº”"""
        # æå–ç»“æœå†…å®¹
        if isinstance(result, str):
            content = result
        elif isinstance(result, dict):
            content = result.get("content", result.get("result", str(result)))
        else:
            content = str(result)
        
        # è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = await self._calculate_quality_score(content, request)
        
        return AgentResponse(
            success=True,
            result=content,
            stage=ExecutionStage.COMPLETION,
            iterations_used=self._current_state.iteration_count,
            execution_time_ms=execution_time_ms,
            reasoning=self._extract_reasoning(result),
            quality_score=quality_score,
            tool_calls=self._current_state.tool_call_history,
            metadata={
                "data_source_id": request.data_source_id,
                "user_id": request.user_id,
                "complexity": request.complexity.value,
                "config": self._config.metadata
            }
        )

    async def _calculate_quality_score(self, content: str, request: AgentRequest) -> float:
        """
        è®¡ç®—è´¨é‡è¯„åˆ†

        ä½¿ç”¨å¢å¼ºçš„å¤šç»´åº¦è´¨é‡è¯„åˆ†ç³»ç»Ÿï¼Œæ”¯æŒé˜¶æ®µæ„ŸçŸ¥çš„è´¨é‡é˜ˆå€¼
        """
        try:
            # ğŸ”¥ è·å–å½“å‰é˜¶æ®µçš„è´¨é‡é˜ˆå€¼ï¼ˆä¼˜å…ˆä½¿ç”¨é˜¶æ®µé…ç½®ï¼‰
            quality_threshold = 0.8  # é»˜è®¤é˜ˆå€¼
            if hasattr(self, 'stage_config_manager'):
                stage_config = self.stage_config_manager.get_stage_config(request.stage)
                if stage_config:
                    quality_threshold = stage_config.quality_threshold
                    logger.debug(f"ğŸ¯ [è´¨é‡è¯„åˆ†] ä½¿ç”¨é˜¶æ®µé˜ˆå€¼: {quality_threshold} (é˜¶æ®µ: {request.stage.value})")
            
            # åŠ¨æ€æ›´æ–°è´¨é‡è¯„åˆ†å™¨çš„é˜ˆå€¼
            if hasattr(self._quality_scorer, 'config'):
                self._quality_scorer.config.passing_threshold = quality_threshold
                logger.debug(f"ğŸ“ [è´¨é‡è¯„åˆ†] è´¨é‡è¯„åˆ†å™¨é˜ˆå€¼å·²æ›´æ–°ä¸º: {quality_threshold}")

            # å‡†å¤‡æ‰§è¡Œç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            execution_result = None
            if hasattr(self._current_state, 'accumulated_results') and self._current_state.accumulated_results:
                # è·å–æœ€åä¸€ä¸ªæ‰§è¡Œç»“æœ
                last_result = self._current_state.accumulated_results[-1]
                if isinstance(last_result, dict):
                    execution_result = last_result

            # å‡†å¤‡æ•°æ®æºæœåŠ¡å’Œè¿æ¥é…ç½®ï¼ˆç”¨äºSQLæ‰§è¡ŒéªŒè¯ï¼‰
            data_source_service = None
            connection_config = None
            
            if hasattr(self.container, 'data_source') and request.data_source_id:
                try:
                    data_source_service = self.container.data_source
                    # è·å–æ•°æ®æºé…ç½®
                    with get_db_session() as db:
                        data_source = crud.data_source.get(db, id=request.data_source_id)
                        if data_source:
                            connection_config = {
                                "source_type": data_source.source_type,
                                "name": data_source.name,
                                "doris_fe_hosts": data_source.doris_fe_hosts,
                                "doris_be_hosts": data_source.doris_be_hosts,
                                "doris_http_port": data_source.doris_http_port,
                                "doris_query_port": data_source.doris_query_port,
                                "doris_database": data_source.doris_database,
                                "doris_username": data_source.doris_username,
                                "doris_password": data_source.doris_password,
                            }
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")

            # ä½¿ç”¨å¢å¼ºçš„è´¨é‡è¯„åˆ†å™¨
            quality_score_result = await self._quality_scorer.calculate_quality_score(
                content=content,
                execution_result=execution_result,
                tool_call_history=self._current_state.tool_call_history if self._current_state else None,
                request_context={
                    "complexity": request.complexity.value,
                    "stage": request.stage.value,
                    "constraints": request.constraints,
                    "quality_threshold": quality_threshold,  # ğŸ”¥ ä¼ é€’è´¨é‡é˜ˆå€¼åˆ°ä¸Šä¸‹æ–‡
                },
                data_source_service=data_source_service,
                connection_config=connection_config
            )

            # ğŸ”¥ å¢å¼ºçš„æ—¥å¿—è®°å½•ï¼šæ˜¾ç¤ºé˜ˆå€¼å’Œæ˜¯å¦é€šè¿‡
            passed_status = "âœ… é€šè¿‡" if quality_score_result.passed else "âŒ æœªé€šè¿‡"
            logger.info(f"ğŸ“Š [è´¨é‡è¯„åˆ†] æ€»ä½“è¯„åˆ†: {quality_score_result.overall_score:.2f}/{quality_threshold:.2f} ({quality_score_result.grade}) {passed_status}")
            
            # è®°å½•å„ç»´åº¦è¯„åˆ†ï¼ˆä»…åœ¨debugæ¨¡å¼ä¸‹æˆ–æœªé€šè¿‡æ—¶æ˜¾ç¤ºï¼‰
            if not quality_score_result.passed or logger.isEnabledFor(logging.DEBUG):
                for dimension, dim_score in quality_score_result.dimension_scores.items():
                    logger.debug(f"   ğŸ“ˆ {dimension.value}: {dim_score.score:.2f} (æƒé‡: {dim_score.weight:.2f})")
            
            # è®°å½•å»ºè®®ï¼ˆä»…åœ¨æœªé€šè¿‡æˆ–debugæ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
            if quality_score_result.suggestions:
                if not quality_score_result.passed:
                    logger.warning(f"ğŸ’¡ [è´¨é‡å»ºè®®] {len(quality_score_result.suggestions)} æ¡æ”¹è¿›å»ºè®®:")
                    for suggestion in quality_score_result.suggestions[:5]:  # æ˜¾ç¤ºå‰5æ¡
                        logger.warning(f"   - {suggestion}")
                elif logger.isEnabledFor(logging.DEBUG):
                    logger.debug(f"ğŸ’¡ [è´¨é‡å»ºè®®] {len(quality_score_result.suggestions)} æ¡ä¼˜åŒ–å»ºè®®:")
                    for suggestion in quality_score_result.suggestions[:3]:  # debugæ¨¡å¼ä¸‹åªæ˜¾ç¤ºå‰3æ¡
                        logger.debug(f"   - {suggestion}")

            return quality_score_result.overall_score

        except Exception as e:
            logger.warning(f"âš ï¸ è´¨é‡è¯„åˆ†å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†: {e}")
            # é™çº§åˆ°åŸºç¡€è¯„åˆ†
            return self._calculate_basic_quality_score(content)

    def _calculate_basic_quality_score(self, content: str) -> float:
        """åŸºç¡€è´¨é‡è¯„åˆ†ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        score = 0.0

        # åŸºç¡€è¯„åˆ†
        if content and len(content.strip()) > 0:
            score += 0.3

        # SQL è´¨é‡è¯„åˆ†
        if "SELECT" in content.upper() or "WITH" in content.upper():
            score += 0.4

            # æ£€æŸ¥ SQL ç»“æ„
            if "FROM" in content.upper():
                score += 0.1
            if "WHERE" in content.upper() or "GROUP BY" in content.upper():
                score += 0.1
            if "ORDER BY" in content.upper():
                score += 0.1

        # å·¥å…·ä½¿ç”¨è¯„åˆ†
        if self._current_state and self._current_state.tool_call_history:
            score += min(0.2, len(self._current_state.tool_call_history) * 0.05)

        return min(1.0, score)

    def _extract_reasoning(self, result: Any) -> str:
        """æå–æ¨ç†è¿‡ç¨‹"""
        if isinstance(result, dict):
            return result.get("reasoning", result.get("explanation", ""))
        return ""

    async def run(self, prompt: str, **kwargs) -> str:
        """
        ç®€åŒ–çš„è¿è¡Œæ¥å£
        
        Args:
            prompt: è¾“å…¥ prompt
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # åˆ›å»ºä¸´æ—¶è¯·æ±‚
        request = AgentRequest(
            placeholder=prompt,
            data_source_id=kwargs.get("data_source_id", 0),
            user_id=kwargs.get("user_id", "system")
        )
        
        # æ‰§è¡Œå¹¶æ”¶é›†ç»“æœ
        result = None
        async for event in self.execute_with_tt(request):
            if event.event_type == "execution_completed":
                result = event.data["response"].result
                break
        
        return result or ""

    async def stream(self, prompt: str):
        """æµå¼æ‰§è¡Œ"""
        request = AgentRequest(
            placeholder=prompt,
            data_source_id=0,
            user_id="system"
        )
        
        async for event in self.execute_with_tt(request):
            yield event

    def add_event_callback(self, callback: Callable[[AgentEvent], None]):
        """æ·»åŠ äº‹ä»¶å›è°ƒ"""
        self._event_callbacks.append(callback)

    def remove_event_callback(self, callback: Callable[[AgentEvent], None]):
        """ç§»é™¤äº‹ä»¶å›è°ƒ"""
        if callback in self._event_callbacks:
            self._event_callbacks.remove(callback)

    async def _notify_callbacks(self, event: AgentEvent):
        """é€šçŸ¥å›è°ƒå‡½æ•°"""
        for callback in self._event_callbacks:
            try:
                callback(event)
            except Exception as e:
                logger.warning(f"âš ï¸ äº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    def _setup_tool_call_tracking(self):
        """è®¾ç½®å·¥å…·è°ƒç”¨è·Ÿè¸ª"""
        # å¦‚æœ agent æœ‰ LLM é€‚é…å™¨ï¼Œè®¾ç½®å·¥å…·è°ƒç”¨å›è°ƒ
        if hasattr(self._agent, 'llm') and hasattr(self._agent.llm, '_tool_call_callback'):
            def tool_call_callback(tool_name: str, arguments: Dict[str, Any]):
                """å·¥å…·è°ƒç”¨å›è°ƒ"""
                if self._current_state:
                    # è®°å½•å·¥å…·è°ƒç”¨
                    tool_call = ToolCall(
                        tool_name=tool_name,
                        arguments=arguments,
                        timestamp=time.time(),
                        success=True
                    )
                    self._current_state.tool_call_history.append(tool_call)
                    
                    # æ›´æ–°è¿­ä»£è·Ÿè¸ªå™¨
                    self._iteration_tracker.on_tool_call()
                    
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] å·¥å…·è°ƒç”¨: {tool_name}")
            
            # è®¾ç½®å›è°ƒ
            self._agent.llm._tool_call_callback = tool_call_callback


def build_default_runtime(
    *,
    container: Any,
    config: Optional[AgentConfig] = None,
    additional_tools: Optional[List[BaseTool]] = None,
    llm: Optional[BaseLLM] = None,
    context_retriever: Optional[SchemaContextRetriever] = None,
) -> LoomAgentRuntime:
    """
    æ„å»ºé»˜è®¤è¿è¡Œæ—¶

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®
        additional_tools: é¢å¤–å·¥å…·
        llm: LLM å®ä¾‹
        context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨

    Returns:
        LoomAgentRuntime å®ä¾‹
    """
    from .types import create_default_agent_config

    # ä½¿ç”¨é»˜è®¤é…ç½®
    if config is None:
        config = create_default_agent_config()

    # åˆ›å»º LLM é€‚é…å™¨
    if llm is None:
        llm = create_llm_adapter(container)

    # ğŸ”¥ æ„å»ºå·¥å…·åˆ—è¡¨ - ä»é…ç½®è‡ªåŠ¨åˆ›å»º
    tools = _create_tools_from_config(container, config)
    if additional_tools:
        tools.extend(additional_tools)
        logger.info(f"â• [ToolRegistry] æ·»åŠ é¢å¤–å·¥å…·: {len(additional_tools)} ä¸ª")

    logger.info(f"ğŸ”§ [LoomAgentRuntime] æœ€ç»ˆå·¥å…·æ•°é‡: {len(tools)}")

    # åˆ›å»º Loom Agent
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  memory ä»¥æ”¯æŒå¯¹è¯å†å²ç®¡ç†
    from loom.builtin.memory import InMemoryMemory

    agent_kwargs = {
        "llm": llm,
        "tools": tools,
        "memory": InMemoryMemory(),  # ğŸ”¥ æ·»åŠ  memory
        "max_iterations": config.max_iterations,
        "max_context_tokens": config.max_context_tokens,
    }

    if config.system_prompt:
        agent_kwargs["system_instructions"] = config.system_prompt

    if context_retriever:
        agent_kwargs["context_retriever"] = context_retriever
        try:
            logger.info(f"ğŸ§© [LoomAgentRuntime] å·²æ³¨å…¥ ContextRetriever: {type(context_retriever).__name__}")
        except Exception:
            logger.info("ğŸ§© [LoomAgentRuntime] å·²æ³¨å…¥ ContextRetriever")

    agent = build_agent(**agent_kwargs)

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›¿æ¢é»˜è®¤çš„executorä¸ºè‡ªå®šä¹‰çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥executor
    agent._executor = ContextAwareAgentExecutor(
        original_executor=agent.executor,
        context_retriever=context_retriever
    )

    logger.info(f"âœ… [LoomAgentRuntime] Agent å·²åˆ›å»ºï¼Œé…ç½®äº† memory: True å’Œ ContextAwareExecutor")
    
    return LoomAgentRuntime(
        agent=agent,
        tools=tools,
        config=config,
        context_retriever=context_retriever
    )


def create_runtime_with_context_retriever(
    container: Any,
    data_source_id: str,
    connection_config: Dict[str, Any],
    config: Optional[AgentConfig] = None
) -> LoomAgentRuntime:
    """
    åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡æ£€ç´¢å™¨çš„è¿è¡Œæ—¶
    
    Args:
        container: æœåŠ¡å®¹å™¨
        data_source_id: æ•°æ®æºID
        connection_config: è¿æ¥é…ç½®
        config: Agent é…ç½®
        
    Returns:
        LoomAgentRuntime å®ä¾‹
    """
    # åˆ›å»ºä¸Šä¸‹æ–‡æ£€ç´¢å™¨
    context_retriever = create_schema_context_retriever(
        data_source_id=data_source_id,
        connection_config=connection_config,
        container=container
    )
    
    # åˆ›å»ºè¿è¡Œæ—¶
    return build_default_runtime(
        container=container,
        config=config,
        context_retriever=context_retriever
    )


class StageAwareRuntime(LoomAgentRuntime):
    """
    é˜¶æ®µæ„ŸçŸ¥çš„Runtime
    
    ä¿ç•™TTé€’å½’èƒ½åŠ›ï¼Œæ ¹æ®å½“å‰é˜¶æ®µåŠ¨æ€åˆ‡æ¢é…ç½®
    è¿™æ˜¯åŸºäºTTé€’å½’çš„ä¸‰é˜¶æ®µAgentæ¶æ„çš„æ ¸å¿ƒå®ç°
    """
    
    def __init__(
        self,
        agent: Agent,
        tools: List[BaseTool],
        config: AgentConfig,
        context_retriever: Optional[SchemaContextRetriever] = None,
        stage_config_manager: Optional[StageConfigManager] = None,
    ):
        """
        Args:
            agent: Loom Agent å®ä¾‹
            tools: å·¥å…·åˆ—è¡¨
            config: Agent é…ç½®
            context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
            stage_config_manager: é˜¶æ®µé…ç½®ç®¡ç†å™¨
        """
        super().__init__(agent, tools, config, context_retriever)
        
        # å½“å‰æ‰§è¡Œé˜¶æ®µ
        self.current_stage: Optional[ExecutionStage] = None
        
        # é˜¶æ®µé…ç½®ç®¡ç†å™¨
        self.stage_config_manager = stage_config_manager or get_stage_config_manager()
        
        # åŸå§‹é…ç½®å¤‡ä»½ï¼ˆç”¨äºæ¢å¤ï¼‰
        self._original_config = AgentConfig(
            llm=config.llm,
            tools=config.tools,
            coordination=config.coordination,
            max_iterations=config.max_iterations,
            max_context_tokens=config.max_context_tokens,
            system_prompt=config.system_prompt,
            callbacks=config.callbacks.copy(),
            metadata=config.metadata.copy()
        )
        
        logger.info("ğŸ¯ [StageAwareRuntime] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ”¯æŒé˜¶æ®µ: {self.stage_config_manager.get_all_stages()}")
    
    async def execute_with_stage(
        self,
        request: AgentRequest,
        stage: ExecutionStage
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        åœ¨æŒ‡å®šé˜¶æ®µæ‰§è¡Œï¼ˆä¿ç•™TTé€’å½’ï¼‰
        
        Args:
            request: Agentè¯·æ±‚
            stage: æ‰§è¡Œé˜¶æ®µ
            
        Yields:
            AgentEvent: æ‰§è¡Œäº‹ä»¶ï¼ˆåŒ…å«TTé€’å½’çš„æ‰€æœ‰æ­¥éª¤ï¼‰
        """
        # 1. åˆ‡æ¢åˆ°å¯¹åº”é˜¶æ®µé…ç½®
        self.current_stage = stage
        stage_config = self.stage_config_manager.get_stage_config(stage)
        
        if not stage_config:
            logger.error(f"âŒ [StageAwareRuntime] æœªæ‰¾åˆ°é˜¶æ®µé…ç½®: {stage.value}")
            raise ValueError(f"æœªæ‰¾åˆ°é˜¶æ®µé…ç½®: {stage.value}")
        
        # åº”ç”¨é˜¶æ®µé…ç½®
        self._apply_stage_config(stage_config)
        
        # ğŸ”¥ å¢å¼ºçš„é˜¶æ®µè¿›å…¥æ—¥å¿—
        logger.info(f"ğŸ¯ [StageAwareRuntime] è¿›å…¥é˜¶æ®µ: {stage.value}")
        logger.info(f"   ğŸ”§ å¯ç”¨å·¥å…·: {len(stage_config.enabled_tools)} ä¸ª - {', '.join(stage_config.enabled_tools[:3])}{'...' if len(stage_config.enabled_tools) > 3 else ''}")
        logger.info(f"   ğŸ¯ è´¨é‡é˜ˆå€¼: {stage_config.quality_threshold:.2f} (å¿…é¡»è¾¾åˆ°æ­¤é˜ˆå€¼æ‰èƒ½é€šè¿‡)")
        logger.info(f"   ğŸ”¢ æœ€å¤§è¿­ä»£: {stage_config.max_iterations} æ¬¡")
        logger.info(f"   ğŸ“Œ é˜¶æ®µç›®æ ‡: {stage_config.stage_goal}")
        logger.info(f"   âœ… çº¦æŸæ¡ä»¶: {list(stage_config.constraints.keys())}")
        
        # 2. æ›´æ–°è¯·æ±‚é…ç½®
        stage_request = AgentRequest(
            placeholder=request.placeholder,
            data_source_id=request.data_source_id,
            user_id=request.user_id,
            task_context=request.task_context,
            template_context=request.template_context,
            max_iterations=stage_config.max_iterations,
            complexity=request.complexity,
            stage=stage,
            constraints={**request.constraints, **stage_config.constraints},
            metadata={**request.metadata, **stage_config.metadata}
        )
        
        # 3. ä½¿ç”¨TTé€’å½’æ‰§è¡Œï¼ˆè¿™æ˜¯æ ¸å¿ƒï¼ï¼‰
        async for event in self.execute_with_tt(stage_request):
            # æ·»åŠ é˜¶æ®µä¿¡æ¯åˆ°äº‹ä»¶
            event.data['current_stage'] = stage.value
            event.data['stage_goal'] = stage_config.stage_goal
            event.data['stage_quality_threshold'] = stage_config.quality_threshold
            
            yield event
        
        logger.info(f"âœ… [StageAwareRuntime] é˜¶æ®µå®Œæˆ: {stage.value}")
        
        # 4. æ¢å¤åŸå§‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        # self._restore_original_config()
    
    def _apply_stage_config(self, stage_config):
        """åº”ç”¨é˜¶æ®µé…ç½®"""
        # åˆ‡æ¢å·¥å…·é›†ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…å·¥å…·ç®¡ç†æ–¹å¼è°ƒæ•´ï¼‰
        # æ³¨æ„ï¼šå®é™…çš„å·¥å…·åˆ‡æ¢éœ€è¦åœ¨Agentå±‚é¢å®ç°
        # è¿™é‡Œä¸»è¦æ˜¯æ›´æ–°é…ç½®ä¿¡æ¯
        
        # åˆ‡æ¢ç³»ç»Ÿæç¤º
        self._config.system_prompt = stage_config.system_prompt
        
        # ğŸ”¥ åˆ‡æ¢è´¨é‡é˜ˆå€¼ï¼ˆå¦‚æœæœ‰è´¨é‡è¯„åˆ†å™¨ï¼‰- å¢å¼ºæ—¥å¿—
        old_threshold = None
        if hasattr(self, '_quality_scorer') and hasattr(self._quality_scorer, 'config'):
            old_threshold = getattr(self._quality_scorer.config, 'passing_threshold', None)
            self._quality_scorer.config.passing_threshold = stage_config.quality_threshold
            if old_threshold != stage_config.quality_threshold:
                logger.info(f"ğŸ”„ [è´¨é‡é˜ˆå€¼] å·²æ›´æ–°: {old_threshold:.2f} â†’ {stage_config.quality_threshold:.2f}")
        
        # åˆ‡æ¢è¿­ä»£æ¬¡æ•°
        self._config.max_iterations = stage_config.max_iterations
        
        # ğŸ”¥ å¢å¼ºçš„é…ç½®åº”ç”¨æ—¥å¿—
        logger.info(f"ğŸ“ [StageAwareRuntime] å·²åº”ç”¨é˜¶æ®µé…ç½®")
        logger.info(f"   ğŸ“‹ ç³»ç»Ÿæç¤ºé•¿åº¦: {len(stage_config.system_prompt)} å­—ç¬¦")
        logger.info(f"   ğŸ¯ è´¨é‡é˜ˆå€¼: {stage_config.quality_threshold:.2f}")
        logger.info(f"   ğŸ”¢ æœ€å¤§è¿­ä»£: {stage_config.max_iterations}")
        logger.info(f"   ğŸ”§ å¯ç”¨å·¥å…·æ•°: {len(stage_config.enabled_tools)} ä¸ª")
        logger.info(f"   ğŸ“Œ é˜¶æ®µç›®æ ‡: {stage_config.stage_goal}")
    
    def _restore_original_config(self):
        """æ¢å¤åŸå§‹é…ç½®"""
        self._config.system_prompt = self._original_config.system_prompt
        self._config.max_iterations = self._original_config.max_iterations
        
        if hasattr(self, '_quality_scorer') and hasattr(self._quality_scorer, 'config'):
            self._quality_scorer.config.quality_threshold = 0.8  # é»˜è®¤é˜ˆå€¼
        
        logger.debug("ğŸ”„ [StageAwareRuntime] å·²æ¢å¤åŸå§‹é…ç½®")
    
    def get_current_stage(self) -> Optional[ExecutionStage]:
        """è·å–å½“å‰æ‰§è¡Œé˜¶æ®µ"""
        return self.current_stage
    
    def get_stage_config(self, stage: ExecutionStage):
        """è·å–é˜¶æ®µé…ç½®"""
        return self.stage_config_manager.get_stage_config(stage)
    
    def is_stage_configured(self, stage: ExecutionStage) -> bool:
        """æ£€æŸ¥é˜¶æ®µæ˜¯å¦å·²é…ç½®"""
        return self.stage_config_manager.is_stage_configured(stage)
    
    async def execute_sql_generation_stage(
        self,
        placeholder: str,
        data_source_id: int,
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡ŒSQLç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - å‘ç°Schema
        - ç”ŸæˆSQL
        - éªŒè¯SQL
        - ä¿®å¤é—®é¢˜
        - å†æ¬¡éªŒè¯
        - ... ç›´åˆ°è¾¾åˆ°è´¨é‡é˜ˆå€¼
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [SQLç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=placeholder,
            data_source_id=data_source_id,
            user_id=user_id,
            task_context=kwargs.get('task_context', {}),
            template_context=kwargs.get('template_context'),
            max_iterations=8,  # SQLé˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.SQL_GENERATION,
            constraints=kwargs.get('constraints', {})
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.SQL_GENERATION):
            # è®°å½•TTé€’å½’çš„æ¯ä¸€æ­¥
            if event.event_type == 'execution_started':
                logger.info(f"ğŸš€ [SQLé˜¶æ®µ] å¼€å§‹TTé€’å½’æ‰§è¡Œ")
            elif event.event_type == 'execution_completed':
                logger.info(f"âœ… [SQLé˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, iterations_used = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
                logger.info(f"   è¿­ä»£æ¬¡æ•°: {iterations_used}")
            
            yield event
        
        logger.info("âœ… [SQLç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")
    
    async def execute_chart_generation_stage(
        self,
        etl_data: Dict[str, Any],
        chart_placeholder: str,
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡Œå›¾è¡¨ç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - åˆ†ææ•°æ®ç‰¹å¾
        - é€‰æ‹©å›¾è¡¨ç±»å‹
        - ç”Ÿæˆå›¾è¡¨é…ç½®
        - éªŒè¯é…ç½®
        - ä¼˜åŒ–é…ç½®
        - ... ç›´åˆ°è¾¾åˆ°æœ€ä¼˜
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [å›¾è¡¨ç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=chart_placeholder,
            data_source_id=kwargs.get('data_source_id', 0),
            user_id=user_id,
            task_context={
                'etl_data': etl_data,
                'statistics': kwargs.get('statistics', {}),
                **kwargs.get('task_context', {})
            },
            max_iterations=6,  # å›¾è¡¨é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.CHART_GENERATION,
            constraints={'output_format': 'chart_config'}
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.CHART_GENERATION):
            if event.event_type == 'execution_completed':
                logger.info(f"âœ… [å›¾è¡¨é˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, _ = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
            
            yield event
        
        logger.info("âœ… [å›¾è¡¨ç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")
    
    async def execute_document_generation_stage(
        self,
        paragraph_context: str,
        placeholder_data: Dict[str, Any],
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡Œæ–‡æ¡£ç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - åˆ†ææ®µè½ç»“æ„
        - ç”Ÿæˆæ–‡æœ¬
        - æ£€æŸ¥é£æ ¼
        - éªŒè¯ä¸€è‡´æ€§
        - ä¼˜åŒ–è¡¨è¾¾
        - ... ç›´åˆ°è¾¾åˆ°æœ€ä¼˜
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [æ–‡æ¡£ç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=paragraph_context,
            data_source_id=kwargs.get('data_source_id', 0),
            user_id=user_id,
            task_context={
                'paragraph_context': paragraph_context,
                'placeholder_data': placeholder_data,
                'document_context': kwargs.get('document_context', {}),
                **kwargs.get('task_context', {})
            },
            max_iterations=5,  # æ–‡æ¡£é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.DOCUMENT_GENERATION,
            constraints={'output_format': 'text'}
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.DOCUMENT_GENERATION):
            if event.event_type == 'execution_completed':
                logger.info(f"âœ… [æ–‡æ¡£é˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, _ = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
            
            yield event
        
        logger.info("âœ… [æ–‡æ¡£ç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")


def build_stage_aware_runtime(
    *,
    container: Any,
    config: Optional[AgentConfig] = None,
    additional_tools: Optional[List[BaseTool]] = None,
    llm: Optional[BaseLLM] = None,
    context_retriever: Optional[SchemaContextRetriever] = None,
    stage_config_manager: Optional[StageConfigManager] = None,
) -> StageAwareRuntime:
    """
    æ„å»ºStage-Awareè¿è¡Œæ—¶

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®
        additional_tools: é¢å¤–å·¥å…·
        llm: LLM å®ä¾‹
        context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
        stage_config_manager: é˜¶æ®µé…ç½®ç®¡ç†å™¨

    Returns:
        StageAwareRuntime å®ä¾‹
    """
    from .types import create_default_agent_config

    # ä½¿ç”¨é»˜è®¤é…ç½®
    if config is None:
        config = create_default_agent_config()

    # åˆ›å»º LLM é€‚é…å™¨
    if llm is None:
        llm = create_llm_adapter(container)

    # ğŸ”¥ æ„å»ºå·¥å…·åˆ—è¡¨ - ä»é…ç½®è‡ªåŠ¨åˆ›å»º
    tools = _create_tools_from_config(container, config)
    if additional_tools:
        tools.extend(additional_tools)
        logger.info(f"â• [ToolRegistry] æ·»åŠ é¢å¤–å·¥å…·: {len(additional_tools)} ä¸ª")

    logger.info(f"ğŸ”§ [StageAwareRuntime] æœ€ç»ˆå·¥å…·æ•°é‡: {len(tools)}")

    # åˆ›å»º Loom Agent
    agent_kwargs = {
        "llm": llm,
        "tools": tools,
        "max_iterations": config.max_iterations,
        "max_context_tokens": config.max_context_tokens,
    }
    
    if config.system_prompt:
        agent_kwargs["system_instructions"] = config.system_prompt
    
    if context_retriever:
        agent_kwargs["context_retriever"] = context_retriever
        try:
            logger.info(f"ğŸ§© [StageAwareRuntime] å·²æ³¨å…¥ ContextRetriever: {type(context_retriever).__name__}")
        except Exception:
            logger.info("ğŸ§© [StageAwareRuntime] å·²æ³¨å…¥ ContextRetriever")
    
    agent = build_agent(**agent_kwargs)
    
    return StageAwareRuntime(
        agent=agent,
        tools=tools,
        config=config,
        context_retriever=context_retriever,
        stage_config_manager=stage_config_manager
    )


# å¯¼å‡º
__all__ = [
    "LoomAgentRuntime",
    "StageAwareRuntime",
    "build_default_runtime",
    "build_stage_aware_runtime",
    "create_runtime_with_context_retriever",
]
