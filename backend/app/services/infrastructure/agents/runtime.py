"""
TT é€’å½’æ‰§è¡Œè¿è¡Œæ—¶

åŸºäº Loom 0.0.3 çš„ tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£æ¨ç†
è¿™æ˜¯æ•´ä¸ª Agent ç³»ç»Ÿçš„æ ¸å¿ƒæ‰§è¡Œå¼•æ“
"""

from __future__ import annotations

import asyncio
import logging
import time
from typing import Any, Dict, List, Optional, AsyncGenerator, Callable, Tuple

from loom import Agent, agent as build_agent
from loom.interfaces.tool import BaseTool
from loom.interfaces.llm import BaseLLM

from .types import (
    AgentRequest, AgentResponse, ExecutionState, ExecutionStage,
    ToolCall, ContextInfo, AgentConfig, AgentEvent, TaskComplexity
)
from .llm_adapter import (
    ContainerLLMAdapter, create_llm_adapter,
    _CURRENT_USER_ID, _CURRENT_STAGE  # å¯¼å…¥ context variables
)
from .context_retriever import SchemaContextRetriever, create_schema_context_retriever

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from app.db.session import get_db_session
from app import crud

# ğŸ”¥ å¯¼å…¥Loomæ ¸å¿ƒç±»å‹ç”¨äºè‡ªå®šä¹‰Executor
from loom.core.agent_executor import AgentExecutor
from loom.core.events import AgentEvent as LoomAgentEvent, AgentEventType
from loom.core.types import Message, ToolResult
from loom.core.turn_state import TurnState
from loom.core.execution_context import ExecutionContext
from .quality_scorer import (
    EnhancedQualityScorer, QualityScorerConfig, QualityScore,
    create_quality_scorer
)
from .config.stage_config import StageConfigManager, get_stage_config_manager
from .tools import (
    create_schema_discovery_tool,
    create_schema_retrieval_tool,
    create_schema_cache_tool,
    create_sql_generator_tool,
    create_sql_validator_tool,
    create_sql_column_checker_tool,
    create_sql_auto_fixer_tool,
    create_sql_executor_tool,
    create_data_sampler_tool,
    create_data_analyzer_tool,
    create_time_window_tool,
    create_chart_generator_tool,
    create_chart_analyzer_tool
)
from .tool_result_formatter import format_tool_result, FormattedToolResult

logger = logging.getLogger(__name__)


class ContextAwareAgentExecutor(AgentExecutor):
    """
    ğŸ”¥ ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„Agent Executor
    
    é‡å†™é€’å½’æ¶ˆæ¯å‡†å¤‡é€»è¾‘ï¼Œç¡®ä¿å·¥å…·ç»“æœå’Œå†å²æ¶ˆæ¯èƒ½æ­£ç¡®ä¼ é€’åˆ°ä¸‹ä¸€è½®é€’å½’ä¸­
    """
    
    def __init__(self, original_executor: AgentExecutor, context_retriever: Optional[SchemaContextRetriever] = None):
        # å¤åˆ¶åŸå§‹executorçš„æ‰€æœ‰å±æ€§
        for attr_name in dir(original_executor):
            if not attr_name.startswith('_') and not callable(getattr(original_executor, attr_name)):
                setattr(self, attr_name, getattr(original_executor, attr_name))
        
        # ä¿å­˜åŸå§‹executorçš„å¼•ç”¨
        self._original_executor = original_executor
        self._context_retriever = context_retriever
        
        # å¤åˆ¶æ‰€æœ‰æ–¹æ³•
        for attr_name in dir(original_executor):
            if not attr_name.startswith('_') and callable(getattr(original_executor, attr_name)):
                if attr_name not in ['_prepare_recursive_messages']:  # é‡å†™è¿™ä¸ªæ–¹æ³•
                    setattr(self, attr_name, getattr(original_executor, attr_name))
    
    def _prepare_recursive_messages(
        self,
        messages: List[Message],
        tool_results: List[ToolResult],
        turn_state: TurnState,
        context: ExecutionContext,
    ) -> List[Message]:
        """
        ğŸ”¥ é‡å†™é€’å½’æ¶ˆæ¯å‡†å¤‡é€»è¾‘ - å¢å¼º TT ä¸Šä¸‹æ–‡ç®¡ç†
        
        ç¡®ä¿å·¥å…·ç»“æœå’Œå†å²æ¶ˆæ¯èƒ½æ­£ç¡®ä¼ é€’åˆ°ä¸‹ä¸€è½®é€’å½’ä¸­
        æ”¯æŒæ·±åº¦æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ä¼˜å…ˆçº§è°ƒæ•´å’Œæ™ºèƒ½æˆªæ–­
        """
        # ä» ExecutionContext metadata ä¸­æå– TT ä¸Šä¸‹æ–‡ä¿¡æ¯
        tt_context = context.metadata.get("tt", {}) if context.metadata else {}
        current_turn = tt_context.get("turn_counter", turn_state.turn_counter)
        priority_hints = tt_context.get("priority_hints", {})
        task_type = tt_context.get("task_type", "general")
        complexity = tt_context.get("complexity", "medium")
        
        logger.info(f"ğŸ”„ [ContextAwareExecutor] å‡†å¤‡é€’å½’æ¶ˆæ¯ï¼ˆç¬¬{current_turn}è½®ï¼‰")
        logger.info(f"   ä»»åŠ¡ç±»å‹: {task_type}, å¤æ‚åº¦: {complexity}")
        logger.info(f"   ä¼˜å…ˆçº§æç¤º: {priority_hints}")
        
        # ğŸ”¥ å¢å¼ºçš„å¾ªç¯æ£€æµ‹å’Œç»ˆæ­¢æœºåˆ¶
        deep_recursion_threshold = 3
        max_recursion_threshold = 5  # æœ€å¤§é€’å½’æ¬¡æ•°
        is_deep_recursion = current_turn > deep_recursion_threshold
        is_max_recursion = current_turn > max_recursion_threshold
        
        # ğŸ”¥ æ£€æŸ¥å·¥å…·è°ƒç”¨å†å²ï¼Œæ£€æµ‹é‡å¤è°ƒç”¨
        tool_call_history = getattr(turn_state, 'tool_call_history', [])
        if tool_call_history:
            tool_names = [getattr(call, 'tool_name', 'unknown') for call in tool_call_history]
            schema_discovery_count = tool_names.count('schema_discovery')
            
            # å¦‚æœschema_discoveryè¢«è°ƒç”¨è¶…è¿‡2æ¬¡ï¼Œå¼ºåˆ¶ç»ˆæ­¢
            if schema_discovery_count > 2:
                logger.warning(f"ğŸš¨ [ContextAwareExecutor] æ£€æµ‹åˆ°é‡å¤è°ƒç”¨schema_discoveryï¼ˆ{schema_discovery_count}æ¬¡ï¼‰ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                return [Message(role="system", content="""# é‡å¤å·¥å…·è°ƒç”¨æ£€æµ‹

âš ï¸ æ£€æµ‹åˆ°é‡å¤è°ƒç”¨schema_discoveryå·¥å…·ï¼Œç³»ç»Ÿå¼ºåˆ¶ç»ˆæ­¢ï¼

è¯·ç«‹å³ç”ŸæˆSQLæŸ¥è¯¢ï¼Œä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼š

```json
{
  "reasoning": "å·²å¤šæ¬¡è°ƒç”¨schema_discoveryï¼Œç°åœ¨ç”ŸæˆSQL",
  "action": "finish",
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}
```

ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼""")]
        
        if is_max_recursion:
            logger.warning(f"ğŸš¨ [ContextAwareExecutor] è¾¾åˆ°æœ€å¤§é€’å½’æ¬¡æ•°ï¼ˆç¬¬{current_turn}è½®ï¼‰ï¼Œå¼ºåˆ¶ç»ˆæ­¢å¾ªç¯")
            # å¼ºåˆ¶ç»ˆæ­¢ï¼Œè¿”å›ç®€å•çš„SQL
            return [Message(role="system", content="""# ç´§æ€¥ç»ˆæ­¢æŒ‡ä»¤

âš ï¸ æ£€æµ‹åˆ°æ— é™å¾ªç¯ï¼Œç³»ç»Ÿå¼ºåˆ¶ç»ˆæ­¢ï¼

è¯·ç«‹å³ç”Ÿæˆä¸€ä¸ªç®€å•çš„SQLæŸ¥è¯¢ï¼Œä¸è¦ç»§ç»­è°ƒç”¨å·¥å…·ï¼š

```json
{
  "reasoning": "ç³»ç»Ÿæ£€æµ‹åˆ°å¾ªç¯ï¼Œå¼ºåˆ¶ç”ŸæˆSQL",
  "action": "finish",
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}
```

ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼""")]
        
        if is_deep_recursion:
            logger.info(f"ğŸ” [ContextAwareExecutor] æ£€æµ‹åˆ°æ·±åº¦é€’å½’ï¼ˆç¬¬{current_turn}è½®ï¼‰ï¼Œè°ƒæ•´ä¸Šä¸‹æ–‡ç­–ç•¥")
            # æ·±åº¦é€’å½’æ—¶ï¼Œä¼˜å…ˆä¿ç•™æ ¸å¿ƒæŒ‡ä»¤ï¼Œå‡å°‘ç¤ºä¾‹å’Œå†å²æ¶ˆæ¯
            priority_hints = {
                "base_instructions": "CRITICAL",
                "tool_definitions": "HIGH", 
                "examples": "LOW",  # é™ä½ç¤ºä¾‹ä¼˜å…ˆçº§
                "history": "LOW"   # é™ä½å†å²æ¶ˆæ¯ä¼˜å…ˆçº§
            }
            
            # ğŸ”¥ æ·»åŠ å¾ªç¯æ£€æµ‹è­¦å‘Š
            warning_message = Message(role="system", content=f"""# å¾ªç¯æ£€æµ‹è­¦å‘Š

âš ï¸ æ£€æµ‹åˆ°æ·±åº¦é€’å½’ï¼ˆç¬¬{current_turn}è½®ï¼‰ï¼Œè¯·ç«‹å³ç”ŸæˆSQLï¼Œä¸è¦å†è°ƒç”¨å·¥å…·ï¼

å¦‚æœå·²ç»è·å–äº†è¡¨ç»“æ„ä¿¡æ¯ï¼Œè¯·ç›´æ¥ç”ŸæˆSQLï¼š
```json
{{
  "reasoning": "å·²è·å–è¡¨ç»“æ„ï¼Œç”ŸæˆSQLæŸ¥è¯¢",
  "action": "finish", 
  "content": "SELECT COUNT(*) FROM ods_refund WHERE status = 'é€€è´§æˆåŠŸ'"
}}
```

ä¸è¦å†è°ƒç”¨ schema_discovery æˆ–å…¶ä»–å·¥å…·ï¼""")
            
            # å°†è­¦å‘Šæ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨å¼€å¤´
            messages = [warning_message] + messages
        
        # 1. è·å–å†å²æ¶ˆæ¯ï¼ˆä»Memoryä¸­ï¼‰- æ”¯æŒæ™ºèƒ½æˆªæ–­
        history_messages = []
        if self.memory and priority_hints.get("history", "MEDIUM") != "LOW":
            try:
                # åŒæ­¥è°ƒç”¨get_messagesï¼ˆå› ä¸ºè¿™æ˜¯åŒæ­¥æ–¹æ³•ï¼‰
                import asyncio
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨run_in_executor
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, self.memory.get_messages())
                        history_messages = future.result()
                else:
                    history_messages = asyncio.run(self.memory.get_messages())
            except Exception as e:
                logger.warning(f"âš ï¸ [ContextAwareExecutor] è·å–å†å²æ¶ˆæ¯å¤±è´¥: {e}")
                history_messages = []
        
        # æ ¹æ®ä¼˜å…ˆçº§å’Œæ·±åº¦è°ƒæ•´å†å²æ¶ˆæ¯æ•°é‡
        if is_deep_recursion:
            max_history = 3  # æ·±åº¦é€’å½’æ—¶åªä¿ç•™æœ€è¿‘3æ¡
        elif priority_hints.get("history") == "HIGH":
            max_history = 15  # é«˜ä¼˜å…ˆçº§æ—¶ä¿ç•™æ›´å¤šå†å²
        else:
            max_history = 10  # é»˜è®¤ä¿ç•™10æ¡
            
        if history_messages:
            recent_history = history_messages[-max_history:]
            logger.info(f"ğŸ“š [ContextAwareExecutor] ä»Memoryè·å–åˆ° {len(history_messages)} æ¡å†å²æ¶ˆæ¯ï¼Œä¿ç•™ {len(recent_history)} æ¡")
        else:
            recent_history = []
            logger.info(f"ğŸ“š [ContextAwareExecutor] æœªè·å–åˆ°å†å²æ¶ˆæ¯")
        
        # 2. å‡†å¤‡å·¥å…·ç»“æœæ¶ˆæ¯
        tool_messages = []
        formatted_results: List[FormattedToolResult] = []
        for result in tool_results:
            formatted = format_tool_result(result)
            formatted_results.append(formatted)
            tool_msg = Message(
                role="tool",
                content=formatted.message,
                tool_call_id=result.tool_call_id,
            )
            tool_messages.append(tool_msg)
        
        logger.info(f"ğŸ”§ [ContextAwareExecutor] å‡†å¤‡äº† {len(tool_messages)} æ¡å·¥å…·ç»“æœæ¶ˆæ¯")
        
        # 3. ç”Ÿæˆæ™ºèƒ½æŒ‡å¯¼æ¶ˆæ¯ - æ”¯æŒä»»åŠ¡ç±»å‹æ„ŸçŸ¥
        guidance_message = self._generate_context_aware_guidance(
            messages, formatted_results, turn_state, recent_history, 
            task_type=task_type, complexity=complexity, is_deep_recursion=is_deep_recursion
        )
        
        # 4. ç»„è£…å®Œæ•´çš„é€’å½’æ¶ˆæ¯
        recursive_messages = []
        
        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆå·²æ ¹æ®ä¼˜å…ˆçº§è°ƒæ•´æ•°é‡ï¼‰
        recursive_messages.extend(recent_history)
        
        # æ·»åŠ å½“å‰è½®çš„æ¶ˆæ¯
        recursive_messages.extend(messages)
        
        # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
        recursive_messages.extend(tool_messages)
        
        # æ·»åŠ æ™ºèƒ½æŒ‡å¯¼æ¶ˆæ¯
        recursive_messages.append(Message(role="user", content=guidance_message))
        
        # 5. ä¸Šä¸‹æ–‡å¤§å°ç›‘æ§å’Œæ—¥å¿—è®°å½•
        total_messages = len(recursive_messages)
        total_chars = sum(len(msg.content) for msg in recursive_messages if hasattr(msg, 'content'))
        estimated_tokens = total_chars // 4  # ç²—ç•¥ä¼°ç®—ï¼š4å­—ç¬¦â‰ˆ1token
        
        logger.info(f"âœ… [ContextAwareExecutor] é€’å½’æ¶ˆæ¯å‡†å¤‡å®Œæˆ")
        logger.info(f"   æ€»æ¶ˆæ¯æ•°: {total_messages}")
        logger.info(f"   æ€»å­—ç¬¦æ•°: {total_chars}")
        logger.info(f"   ä¼°ç®—Tokenæ•°: {estimated_tokens}")
        logger.info(f"   æ·±åº¦é€’å½’æ¨¡å¼: {'æ˜¯' if is_deep_recursion else 'å¦'}")
        
        # å¦‚æœä¸Šä¸‹æ–‡è¿‡å¤§ï¼Œè®°å½•è­¦å‘Š
        if estimated_tokens > 8000:  # å‡è®¾æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ä¸º8K
            logger.warning(f"âš ï¸ [ContextAwareExecutor] ä¸Šä¸‹æ–‡å¯èƒ½è¿‡å¤§ï¼ˆ{estimated_tokens} tokensï¼‰ï¼Œå»ºè®®ä¼˜åŒ–")
        
        return recursive_messages
    
    def _generate_context_aware_guidance(
        self,
        messages: List[Message],
        formatted_results: List[FormattedToolResult],
        turn_state: TurnState,
        history_messages: List[Message],
        task_type: str = "general",
        complexity: str = "medium",
        is_deep_recursion: bool = False
    ) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é€’å½’æŒ‡å¯¼æ¶ˆæ¯ - å¢å¼ºä»»åŠ¡ç±»å‹å’Œæ·±åº¦æ„ŸçŸ¥
        """
        # åˆ†æå·¥å…·ç»“æœ
        has_schema_data = False
        has_query_data = False
        tool_summaries: List[str] = []
        tool_names_called = set()
        schema_info: Optional[FormattedToolResult] = None
        
        for formatted in formatted_results:
            tool_names_called.add(formatted.tool_name)
            tool_summaries.append(f"{formatted.tool_name}: {formatted.message}")
            if formatted.tool_name == "schema_discovery":
                schema_info = formatted
                tables_count = formatted.structured_summary.get("tables_count", 0)
                has_schema_data = tables_count > 0
            if formatted.tool_name in {"sql_generator", "sql_validator", "sql_executor"}:
                has_query_data = True
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ å·¥å…·è°ƒç”¨å†å²æ£€æµ‹å’Œæ˜ç¡®æŒ‡å¯¼
        guidance_parts = [f"ç¬¬{turn_state.turn_counter}è½®é€’å½’æ‰§è¡Œ"]
        
        # åˆ†æå·²è°ƒç”¨çš„å·¥å…·ï¼Œæä¾›æ˜ç¡®çš„ä¸‹ä¸€æ­¥æŒ‡å¯¼
        if schema_info:
            tables_count = schema_info.structured_summary.get("tables_count", 0)
            preview = schema_info.structured_summary.get("tables_preview", []) or []
            preview_text = "ã€".join(preview[:3]) if preview else "æš‚æ— ç¤ºä¾‹è¡¨"

            if schema_info.duplicate_call:
                guidance_parts.append("âš ï¸ schema_discovery å·²åœ¨å…ˆå‰æ­¥éª¤å®Œæˆï¼Œæœ¬è½®å¤ç”¨äº†ç¼“å­˜ç»“æœ")
            else:
                guidance_parts.append(f"âœ… schema_discovery å®Œæˆï¼Œå‘ç° {tables_count} å¼ è¡¨ï¼ˆå¦‚ï¼š{preview_text}ï¼‰")

            if schema_info.next_actions:
                guidance_parts.append(f"ğŸ“‹ æ¨èä¸‹ä¸€æ­¥ï¼š{'ï¼›'.join(schema_info.next_actions)}")
        else:
            guidance_parts.append("ğŸ“‹ å°šæœªè·å–æ•°æ®åº“ç»“æ„ï¼Œè¯·å…ˆè°ƒç”¨ schema_discovery å·¥å…·")

        if "schema_retrieval" in tool_names_called:
            guidance_parts.append("âœ… schema_retrieval å·²æä¾›åˆ—çº§ä¿¡æ¯ï¼Œæ¥ä¸‹æ¥ä½¿ç”¨ sql_generator ç”Ÿæˆ SQL")
        if "sql_generator" in tool_names_called and "sql_validator" not in tool_names_called:
            guidance_parts.append("ğŸ“‹ ä¸‹ä¸€æ­¥ï¼šè°ƒç”¨ sql_validator å·¥å…·éªŒè¯ç”Ÿæˆçš„ SQL")
        if "sql_validator" in tool_names_called:
            guidance_parts.append("âœ… SQL å·²é€šè¿‡éªŒè¯ï¼Œå¦‚æ— é—®é¢˜å¯ä»¥æ•´ç†æœ€ç»ˆç­”æ¡ˆæˆ–æ‰§è¡Œåç»­æ“ä½œ")
        if schema_info and schema_info.duplicate_call:
            guidance_parts.append("ğŸš« è¯·å‹¿å†æ¬¡è°ƒç”¨ schema_discoveryï¼Œç›´æ¥æ‰§è¡Œä¸Šä¸€æ­¥å»ºè®®çš„å·¥å…·")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ é¢å¤–æŒ‡å¯¼
        if task_type == "sql_generation":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šç”Ÿæˆå‡†ç¡®çš„ SQL æŸ¥è¯¢")
            if has_schema_data:
                guidance_parts.append("âœ… è¡¨ç»“æ„ä¿¡æ¯å·²è·å–")
            if has_query_data:
                guidance_parts.append("âœ… æŸ¥è¯¢å·²æ‰§è¡Œ")
        elif task_type == "chart_generation":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šç”Ÿæˆå›¾è¡¨")
            if has_query_data:
                guidance_parts.append("âœ… æŸ¥è¯¢æ•°æ®å·²è·å–")
        elif task_type == "completion":
            guidance_parts.append("ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼šå®Œæˆæ–‡æ¡£ç”Ÿæˆ")
        
        # æ·»åŠ å¤æ‚åº¦æç¤º
        if complexity == "high":
            guidance_parts.append("âš ï¸ å¤æ‚ä»»åŠ¡ï¼Œéœ€è¦ä»”ç»†åˆ†æ")
        elif complexity == "low":
            guidance_parts.append("âœ… ç®€å•ä»»åŠ¡ï¼Œå¯ä»¥å¿«é€Ÿå¤„ç†")
        
        # æ·±åº¦é€’å½’æ—¶çš„ç‰¹æ®Šå¤„ç†
        if is_deep_recursion:
            guidance_parts.append("âš ï¸ æ·±åº¦é€’å½’æ¨¡å¼ï¼Œè¯·ä¿æŒç®€æ´ï¼Œé¿å…é‡å¤è°ƒç”¨ç›¸åŒå·¥å…·")
            # åªæ˜¾ç¤ºå…³é”®çš„å·¥å…·ç»“æœ
            if tool_summaries:
                key_summaries = [s for s in tool_summaries if any(keyword in s.lower() for keyword in ["schema", "table", "sql"])]
                if key_summaries:
                    guidance_parts.append(f"ğŸ”§ å…³é”®å·¥å…·ç»“æœ: {'; '.join(key_summaries[:2])}")
        else:
            # æ­£å¸¸é€’å½’æ—¶æ˜¾ç¤ºæ‰€æœ‰å·¥å…·ç»“æœ
            if tool_summaries:
                guidance_parts.append(f"ğŸ”§ å·¥å…·ç»“æœ: {'; '.join(tool_summaries)}")
        
        guidance = "ã€‚".join(guidance_parts) + "ã€‚è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç»§ç»­æ‰§è¡Œã€‚"
        
        return guidance


# ğŸ”¥ å·¥å…·å®ä¾‹ç¼“å­˜ç®¡ç†å™¨
class ToolInstanceCache:
    """å·¥å…·å®ä¾‹ç¼“å­˜ç®¡ç†å™¨ï¼Œé¿å…é‡å¤åˆ›å»ºå·¥å…·"""
    
    def __init__(self):
        self._cache: Dict[str, BaseTool] = {}
        self._cache_keys: Dict[str, str] = {}
    
    def _generate_cache_key(self, tool_name: str, connection_config: Optional[Dict] = None) -> str:
        """ç”Ÿæˆå·¥å…·ç¼“å­˜é”®"""
        # ğŸ”¥ ä¼˜åŒ–ï¼šåªæœ‰çœŸæ­£éœ€è¦connection_configçš„å·¥å…·æ‰åŒºåˆ†é…ç½®
        tools_requiring_connection = {
            "schema_discovery",
            "schema_retrieval", 
            "sql_executor"
        }
        
        if connection_config and tool_name in tools_requiring_connection:
            # åŸºäºè¿æ¥é…ç½®ç”Ÿæˆé”® - ä½¿ç”¨å®é™…çš„å­—æ®µå
            host = connection_config.get('fe_hosts', [''])[0] if connection_config.get('fe_hosts') else ''
            port = connection_config.get('http_port', '')
            database = connection_config.get('name', '')
            config_key = f"{host}:{port}:{database}"
            return f"{tool_name}:{config_key}"
        else:
            # ğŸ”¥ å¯¹äºä¸éœ€è¦connection_configçš„å·¥å…·ï¼Œç»Ÿä¸€ä½¿ç”¨defaulté”®
            return f"{tool_name}:default"
    
    def get_tool(self, tool_name: str, connection_config: Optional[Dict] = None) -> Optional[BaseTool]:
        """è·å–ç¼“å­˜çš„å·¥å…·å®ä¾‹"""
        cache_key = self._generate_cache_key(tool_name, connection_config)
        return self._cache.get(cache_key)
    
    def set_tool(self, tool_name: str, tool: BaseTool, connection_config: Optional[Dict] = None):
        """ç¼“å­˜å·¥å…·å®ä¾‹"""
        cache_key = self._generate_cache_key(tool_name, connection_config)
        self._cache[cache_key] = tool
        self._cache_keys[tool_name] = cache_key
        logger.debug(f"ğŸ”§ [ToolCache] ç¼“å­˜å·¥å…·: {tool_name} -> {cache_key}")
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        self._cache_keys.clear()
        logger.info("ğŸ§¹ [ToolCache] æ¸…ç©ºå·¥å…·ç¼“å­˜")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        # ç»Ÿè®¡å”¯ä¸€çš„å·¥å…·å
        unique_tool_names = set()
        for cache_key in self._cache.keys():
            tool_name = cache_key.split(':')[0]  # æå–å·¥å…·å
            unique_tool_names.add(tool_name)
        
        return {
            "cached_tools": len(self._cache),
            "unique_tool_names": len(unique_tool_names),
            "tool_names": list(unique_tool_names),
            "memory_usage": f"{len(self._cache)} tools"
        }


# å…¨å±€å·¥å…·ç¼“å­˜å®ä¾‹
_tool_cache = ToolInstanceCache()


def _create_tools_from_config(container: Any, config: AgentConfig) -> List[BaseTool]:
    """
    æ ¹æ®é…ç½®è‡ªåŠ¨åˆ›å»ºå·¥å…·å®ä¾‹

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®

    Returns:
        å·¥å…·å®ä¾‹åˆ—è¡¨
    """
    tools = []
    enabled_tools = config.tools.enabled_tools if hasattr(config.tools, 'enabled_tools') else []

    # ğŸ”¥ ä»containerä¸­è¯»å–ä¸´æ—¶å­˜å‚¨çš„connection_config
    connection_config = getattr(container, '_temp_connection_config', None)

    # ğŸ”§ è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ”§ [ToolRegistry] connection_config å¯ç”¨: {connection_config is not None}")
    if connection_config:
        logger.info(f"ğŸ”§ [ToolRegistry] connection_config keys: {list(connection_config.keys())[:5]}")

    # å·¥å…·åç§°åˆ°åˆ›å»ºå‡½æ•°çš„æ˜ å°„
    tool_factory_map = {
        "schema_discovery": create_schema_discovery_tool,
        "schema_retrieval": create_schema_retrieval_tool,
        "schema_cache": create_schema_cache_tool,
        "sql_generator": create_sql_generator_tool,
        "sql_validator": create_sql_validator_tool,
        "sql_column_checker": create_sql_column_checker_tool,
        "sql_auto_fixer": create_sql_auto_fixer_tool,
        "sql_executor": create_sql_executor_tool,
        "data_sampler": create_data_sampler_tool,
        "data_analyzer": create_data_analyzer_tool,
        "time_window": create_time_window_tool,
        "chart_generator": create_chart_generator_tool,
        "chart_analyzer": create_chart_analyzer_tool,
    }

    # éœ€è¦connection_configçš„å·¥å…·åˆ—è¡¨
    tools_requiring_connection = {
        "schema_discovery",
        "schema_retrieval", 
        "sql_executor"
    }

    # ğŸ”¥ ä½¿ç”¨ç¼“å­˜æœºåˆ¶åˆ›å»ºå·¥å…·
    for tool_name in enabled_tools:
        # 1. æ£€æŸ¥ç¼“å­˜
        cached_tool = _tool_cache.get_tool(tool_name, connection_config)
        if cached_tool:
            tools.append(cached_tool)
            logger.info(f"â™»ï¸ [ToolRegistry] ä½¿ç”¨ç¼“å­˜å·¥å…·: {tool_name}")
            continue
        
        # 2. åˆ›å»ºæ–°å·¥å…·
        factory_func = tool_factory_map.get(tool_name)
        if factory_func:
            try:
                # ğŸ”¥ å¦‚æœæ˜¯éœ€è¦connection_configçš„å·¥å…·ï¼Œä¸”connection_configå¯ç”¨ï¼Œåˆ™ä¼ é€’å®ƒ
                if tool_name in tools_requiring_connection and connection_config:
                    tool = factory_func(container, connection_config=connection_config)
                    logger.info(f"âœ… [ToolRegistry] æˆåŠŸåˆ›å»ºå·¥å…·ï¼ˆå¸¦connection_configï¼‰: {tool_name}")
                else:
                    tool = factory_func(container)
                    logger.info(f"âœ… [ToolRegistry] æˆåŠŸåˆ›å»ºå·¥å…·: {tool_name}")

                # 3. ç¼“å­˜å·¥å…·å®ä¾‹
                _tool_cache.set_tool(tool_name, tool, connection_config)
                tools.append(tool)
            except Exception as e:
                logger.warning(f"âš ï¸ [ToolRegistry] åˆ›å»ºå·¥å…·å¤±è´¥: {tool_name}, é”™è¯¯: {e}")
                import traceback
                logger.warning(traceback.format_exc())
        else:
            logger.warning(f"âš ï¸ [ToolRegistry] æœªçŸ¥å·¥å…·: {tool_name}")

    # è®°å½•ç¼“å­˜ç»Ÿè®¡
    cache_stats = _tool_cache.get_cache_stats()
    logger.info(f"ğŸ“¦ [ToolRegistry] å…±åˆ›å»º {len(tools)} ä¸ªå·¥å…·ï¼Œç¼“å­˜ç»Ÿè®¡: {cache_stats}")
    return tools


def _extract_response_metrics(response_payload: Any) -> Tuple[float, int]:
    """æå–è´¨é‡è¯„åˆ†å’Œè¿­ä»£æ¬¡æ•°ï¼Œå…¼å®¹å­—å…¸å’ŒAgentResponseå¯¹è±¡"""
    if isinstance(response_payload, AgentResponse):
        return (
            response_payload.quality_score or 0.0,
            response_payload.iterations_used or 0,
        )
    if isinstance(response_payload, dict):
        quality = response_payload.get("quality_score", 0.0) or 0.0
        iterations = response_payload.get("iterations_used", 0) or 0
        return (float(quality), int(iterations))
    return 0.0, 0


class IterationTracker:
    """è¿­ä»£è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.count = 0
        self.tool_call_count = 0
        self.last_tool_call_time = 0
        
    def on_tool_call(self):
        """å·¥å…·è°ƒç”¨æ—¶è°ƒç”¨"""
        self.tool_call_count += 1
        self.last_tool_call_time = time.time()
        
    def estimate_iteration_count(self) -> int:
        """ä¼°ç®—è¿­ä»£æ¬¡æ•°"""
        # åŸºäºå·¥å…·è°ƒç”¨æ¬¡æ•°ä¼°ç®—è¿­ä»£æ¬¡æ•°
        # å‡è®¾æ¯æ¬¡è¿­ä»£å¹³å‡è°ƒç”¨ 1-2 ä¸ªå·¥å…·
        if self.tool_call_count == 0:
            return 1  # è‡³å°‘æœ‰ä¸€æ¬¡è¿­ä»£
        return max(1, self.tool_call_count // 2)
        
    def reset(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.count = 0
        self.tool_call_count = 0
        self.last_tool_call_time = 0


class LoomAgentRuntime:
    """
    Loom Agent è¿è¡Œæ—¶
    
    åŸºäº Loom 0.0.3 çš„ TT é€’å½’æ‰§è¡Œæœºåˆ¶ï¼Œæä¾›è‡ªåŠ¨è¿­ä»£æ¨ç†èƒ½åŠ›
    
    ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿å·¥å…·ç»“æœåœ¨é€’å½’å¾ªç¯ä¸­æ­£ç¡®ä¼ é€’åˆ°ä¸Šä¸‹æ–‡ä¸­
    """

    def __init__(
        self,
        agent: Agent,
        tools: List[BaseTool],
        config: AgentConfig,
        context_retriever: Optional[SchemaContextRetriever] = None,
    ):
        """
        Args:
            agent: Loom Agent å®ä¾‹
            tools: å·¥å…·åˆ—è¡¨
            config: Agent é…ç½®
            context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
        """
        self._agent = agent
        self._tools = tools
        self._config = config
        self._context_retriever = context_retriever

        # æ‰§è¡ŒçŠ¶æ€
        self._current_state: Optional[ExecutionState] = None
        self._event_callbacks: List[Callable[[AgentEvent], None]] = []
        self._iteration_tracker = IterationTracker()

        # è´¨é‡è¯„åˆ†å™¨
        self._quality_scorer = create_quality_scorer()

        # è®¾ç½®å·¥å…·è°ƒç”¨å›è°ƒ
        self._setup_tool_call_tracking()

    @property
    def agent(self) -> Agent:
        """è·å– Loom Agent å®ä¾‹"""
        return self._agent

    @property
    def config(self) -> AgentConfig:
        """è·å–é…ç½®"""
        return self._config

    @property
    def tools(self) -> List[BaseTool]:
        """è·å–å·¥å…·åˆ—è¡¨"""
        return self._tools

    @property
    def context_retriever(self) -> Optional[SchemaContextRetriever]:
        """è·å–ä¸Šä¸‹æ–‡æ£€ç´¢å™¨"""
        return self._context_retriever

    async def execute_with_tt(
        self,
        request: AgentRequest,
        max_iterations: Optional[int] = None
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        ä½¿ç”¨ TT é€’å½’æ‰§è¡Œ - è‡ªåŠ¨è¿­ä»£æ¨ç†
        
        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œä½¿ç”¨ Loom 0.0.3 çš„ tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£
        
        Args:
            request: Agent è¯·æ±‚
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Yields:
            AgentEvent: æ‰§è¡Œäº‹ä»¶æµ
        """
        start_time = time.time()
        max_iterations = max_iterations or request.max_iterations
        
        logger.info(f"ğŸš€ [LoomAgentRuntime] å¼€å§‹ TT é€’å½’æ‰§è¡Œ")
        logger.info(f"   å ä½ç¬¦: {request.placeholder[:100]}...")
        logger.info(f"   æ•°æ®æºID: {request.data_source_id}")
        logger.info(f"   ç”¨æˆ·ID: {request.user_id}")
        logger.info(f"   æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")

        # åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€
        self._current_state = ExecutionState(
            current_stage=request.stage,
            iteration_count=0,
            start_time=start_time,
            context=ContextInfo(),
            max_iterations=max_iterations,
            max_context_tokens=self._config.max_context_tokens
        )
        
        # é‡ç½®è¿­ä»£è·Ÿè¸ªå™¨
        self._iteration_tracker.reset()

        # å‘é€åˆå§‹åŒ–äº‹ä»¶
        init_event = AgentEvent(
            event_type="execution_started",
            stage=request.stage,
            data={
                "request": request,
                "max_iterations": max_iterations,
                "timestamp": start_time
            }
        )
        yield init_event
        await self._notify_callbacks(init_event)

        # ğŸ”¥ è®¾ç½®ç”¨æˆ·IDçš„ context variableï¼Œä»¥ä¾¿ LLM adapter å¯ä»¥è·å–
        token = _CURRENT_USER_ID.set(request.user_id)

        try:
            # ğŸ”¥ æ ¸å¿ƒï¼šä½¿ç”¨ Loom çš„ Agent.run() è¿›è¡Œ TT é€’å½’æ‰§è¡Œ
            # Loom 0.0.3 çš„ Agent.run() å†…éƒ¨ä½¿ç”¨ tt å‡½æ•°å®ç°è‡ªåŠ¨è¿­ä»£

            # æ„å»ºåˆå§‹ prompt
            initial_prompt = await self._build_initial_prompt(request)

            logger.info(f"ğŸ“ [LoomAgentRuntime] åˆå§‹ prompt é•¿åº¦: {len(initial_prompt)} å­—ç¬¦")

            # ğŸ”¥ TT é€’å½’æ‰§è¡Œ - ä½¿ç”¨ execute() è·å–äº‹ä»¶æµ
            from loom.core.events import AgentEventType

            result = ""
            tool_call_count = 0

            async for event in self._agent.execute(initial_prompt):
                # è®°å½• LLM å¼€å§‹
                if event.type == AgentEventType.LLM_START:
                    logger.info(f"ğŸ§  [LoomAgentRuntime] LLM å¼€å§‹ç”Ÿæˆï¼ˆè¿­ä»£ {self._current_state.iteration_count + 1}ï¼‰")

                # è®°å½•å·¥å…·è°ƒç”¨äº‹ä»¶
                elif event.type == AgentEventType.LLM_TOOL_CALLS:
                    tool_count = event.metadata.get("tool_count", 0)
                    tool_names = event.metadata.get("tool_names", [])
                    tool_call_count += tool_count
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] LLM è°ƒç”¨äº† {tool_count} ä¸ªå·¥å…·: {tool_names}")

                    # æ›´æ–°è¿­ä»£è®¡æ•°
                    if self._current_state:
                        self._current_state.iteration_count += 1

                # å·¥å…·æ‰§è¡Œè¿›åº¦
                elif event.type == AgentEventType.TOOL_PROGRESS:
                    tool_name = event.metadata.get("tool_name", "unknown")
                    status = event.metadata.get("status", "unknown")
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] å·¥å…· {tool_name}: {status}")

                # å·¥å…·æ‰§è¡Œç»“æœ
                elif event.type == AgentEventType.TOOL_RESULT:
                    logger.info(f"âœ… [LoomAgentRuntime] å·¥å…·æ‰§è¡Œå®Œæˆ")

                # ğŸ”¥ é€’å½’äº‹ä»¶
                elif event.type == AgentEventType.RECURSION:
                    logger.info(f"ğŸ”„ [LoomAgentRuntime] å¼€å§‹é€’å½’ï¼ˆåŸºäºå·¥å…·ç»“æœï¼‰")

                # è®°å½• LLM è¾“å‡ºå¢é‡
                elif event.type == AgentEventType.LLM_DELTA:
                    if event.content:
                        result += event.content

                # Agent å®Œæˆ
                elif event.type == AgentEventType.AGENT_FINISH:
                    result = event.content or result
                    logger.info(f"âœ… [LoomAgentRuntime] Agent æ‰§è¡Œå®Œæˆ")
                    logger.info(f"ğŸ“Š [LoomAgentRuntime] æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}")
                    logger.info(f"ğŸ“Š [LoomAgentRuntime] æ€»è¿­ä»£æ¬¡æ•°: {self._current_state.iteration_count}")
                    break

                # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
                elif event.type == AgentEventType.MAX_ITERATIONS_REACHED:
                    logger.warning(f"âš ï¸ [LoomAgentRuntime] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°")
                    break

                # é”™è¯¯å¤„ç†
                elif event.type == AgentEventType.ERROR:
                    error_msg = str(event.error) if event.error else "Unknown error"
                    logger.error(f"âŒ [LoomAgentRuntime] Agent æ‰§è¡Œé”™è¯¯: {error_msg}")
                    if event.error:
                        raise event.error
                    break

            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            execution_time_ms = int((time.time() - start_time) * 1000)
            
            # æ›´æ–°è¿­ä»£è®¡æ•°
            estimated_iterations = self._iteration_tracker.estimate_iteration_count()
            self._current_state.iteration_count = estimated_iterations
            
            # æ„å»ºå“åº”
            response = await self._build_response(request, result, execution_time_ms)
            
            # å‘é€å®Œæˆäº‹ä»¶
            completion_event = AgentEvent(
                event_type="execution_completed",
                stage=ExecutionStage.COMPLETION,
                data={
                    "response": response,
                    "execution_time_ms": execution_time_ms,
                    "iterations_used": self._current_state.iteration_count
                }
            )
            yield completion_event
            await self._notify_callbacks(completion_event)
            
            logger.info(f"âœ… [LoomAgentRuntime] TT é€’å½’æ‰§è¡Œå®Œæˆ")
            logger.info(f"   æ‰§è¡Œæ—¶é—´: {execution_time_ms}ms")
            logger.info(f"   è¿­ä»£æ¬¡æ•°: {self._current_state.iteration_count}")
            logger.info(f"   å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(self._current_state.tool_call_history)}")
            
        except Exception as e:
            execution_time_ms = int((time.time() - start_time) * 1000)
            logger.error(f"âŒ [LoomAgentRuntime] TT é€’å½’æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
            # å‘é€é”™è¯¯äº‹ä»¶
            error_event = AgentEvent(
                event_type="execution_failed",
                stage=self._current_state.current_stage,
                data={
                    "error": str(e),
                    "execution_time_ms": execution_time_ms,
                    "iterations_used": self._current_state.iteration_count
                }
            )
            yield error_event
            await self._notify_callbacks(error_event)

            # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            raise
        finally:
            # ğŸ”¥ æ¸…ç† context variable
            try:
                _CURRENT_USER_ID.reset(token)
            except (ValueError, LookupError) as e:
                # åœ¨ç”Ÿæˆå™¨å…³é—­æ—¶ï¼Œtoken å¯èƒ½å·²ç»åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­
                # è¿™ç§æƒ…å†µä¸‹å¿½ç•¥ reset é”™è¯¯
                logger.debug(f"âš ï¸ Context variable reset failed (å¯ä»¥å¿½ç•¥): {e}")

    async def _build_initial_prompt(self, request: AgentRequest) -> str:
        """æ„å»ºåˆå§‹ prompt"""
        prompt_parts = []
        
        # 1. ç³»ç»ŸæŒ‡ä»¤ï¼ˆğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç³»ç»Ÿæç¤ºè¢«åŒ…å«ï¼‰
        if self._config.system_prompt:
            prompt_parts.append(f"# ç³»ç»ŸæŒ‡ä»¤\n{self._config.system_prompt}")
        else:
            # å¦‚æœæ²¡æœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ é»˜è®¤çš„SQLç”ŸæˆæŒ‡å¯¼
            prompt_parts.append("""# ç³»ç»ŸæŒ‡ä»¤

ä½ æ˜¯ä¸€ä¸ªDoris SQLç”Ÿæˆä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£æ ¹æ®ä¸šåŠ¡éœ€æ±‚ç”Ÿæˆå‡†ç¡®ã€é«˜æ•ˆçš„Doris SQLæŸ¥è¯¢ã€‚

## ğŸ”¥ æ ¸å¿ƒä»»åŠ¡ï¼ˆå¿…é¡»å®Œæˆï¼‰
æ ¹æ®å ä½ç¬¦ä¸­çš„ä¸šåŠ¡éœ€æ±‚ï¼Œ**æœ€ç»ˆå¿…é¡»ç”Ÿæˆå¹¶è¿”å›çº¯Doris SQLæŸ¥è¯¢è¯­å¥**ã€‚

## âš ï¸ å…³é”®è¦æ±‚
- **æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯çº¯SQL**ï¼šä¸èƒ½åŒ…å«ä¸­æ–‡è§£é‡Šã€æ³¨é‡Šæˆ–å…¶ä»–æ–‡æœ¬
- **å¿…é¡»ä½¿ç”¨Doriså…¼å®¹çš„SQLè¯­æ³•**
- **å¿…é¡»åŒ…å«æ—¶é—´å ä½ç¬¦ {{start_date}} å’Œ {{end_date}}**
- **ç¦æ­¢ç¡¬ç¼–ç ä»»ä½•æ—¥æœŸå€¼**
- **æ‰€æœ‰æ—¶é—´ç›¸å…³æŸ¥è¯¢å¿…é¡»ä½¿ç”¨æ—¶é—´è¿‡æ»¤æ¡ä»¶**

## TTé€’å½’æ‰§è¡Œæµç¨‹
ä½ å°†ä½¿ç”¨TTé€’å½’æœºåˆ¶è‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼Œç›´åˆ°è¾¾åˆ°è´¨é‡é˜ˆå€¼ï¼š

1. **Thought**: åˆ†æä¸šåŠ¡éœ€æ±‚ï¼Œç†è§£æ•°æ®å…³ç³»å’Œæ—¶é—´è¦æ±‚
2. **Tool**: ä½¿ç”¨schemaå·¥å…·äº†è§£è¡¨ç»“æ„å’Œå­—æ®µä¿¡æ¯
3. **Thought**: è®¾è®¡æŸ¥è¯¢é€»è¾‘å’ŒSQLç»“æ„ï¼Œç¡®å®šæ—¶é—´è¿‡æ»¤æ¡ä»¶
4. **Tool**: ä½¿ç”¨sql_generatorç”Ÿæˆåˆå§‹Doris SQL
5. **Thought**: è¯„ä¼°SQLçš„è¯­æ³•å’Œé€»è¾‘æ­£ç¡®æ€§ï¼Œæ£€æŸ¥æ—¶é—´å ä½ç¬¦ä½¿ç”¨
6. **Tool**: ä½¿ç”¨sql_validatoréªŒè¯Dorisè¯­æ³•å’Œå­—æ®µå­˜åœ¨æ€§
7. **Thought**: å¦‚æœæœ‰é—®é¢˜ï¼Œåˆ†æå…·ä½“åŸå› 
8. **Tool**: ä½¿ç”¨sql_auto_fixerä¿®å¤å‘ç°çš„é—®é¢˜
9. **Thought**: å†æ¬¡éªŒè¯ï¼Œç¡®ä¿SQLè´¨é‡å’Œæ—¶é—´å ä½ç¬¦æ­£ç¡®æ€§
10. **Tool**: ä½¿ç”¨sql_executorè¿›è¡Œå¹²è¿è¡Œæµ‹è¯•ï¼ˆå¦‚æœå¯èƒ½ï¼‰
11. **Thought**: è¯„ä¼°æœ€ç»ˆè´¨é‡ï¼Œå†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£

## ğŸ¯ æœ€ç»ˆè¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»éµå®ˆï¼‰
**æœ€ç»ˆå¿…é¡»ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿”å›çº¯SQLï¼š**
```json
{
  "reasoning": "SQLå·²ç”Ÿæˆå¹¶éªŒè¯é€šè¿‡",
  "action": "finish",
  "content": "SELECT COUNT(*) AS total_count FROM sales_table WHERE sale_date >= '{{start_date}}' AND sale_date <= '{{end_date}}'"
}
```

**âŒ é”™è¯¯è¾“å‡ºï¼ˆç¦æ­¢ï¼‰ï¼š**
```json
{
  "reasoning": "æˆ‘éœ€è¦å…ˆäº†è§£æ•°æ®åº“ç»“æ„ï¼Œæ‰€ä»¥è°ƒç”¨ schema_discovery...",
  "action": "tool_call",
  "tool_calls": [...]
}
```

## Doris SQLç¤ºä¾‹
```sql
-- âœ… æ­£ç¡®ç¤ºä¾‹
SELECT COUNT(*) AS total_count
FROM sales_table 
WHERE sale_date >= '{{start_date}}' 
  AND sale_date <= '{{end_date}}'

-- âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆç¡¬ç¼–ç æ—¥æœŸï¼‰
SELECT COUNT(*) FROM sales_table 
WHERE sale_date >= '2024-01-01' AND sale_date <= '2024-01-31'
```

## é‡è¦åŸåˆ™
1. **æœ€ç»ˆå¿…é¡»è¿”å›çº¯SQL**ï¼šä¸èƒ½è¿”å›ä¸­æ–‡è§£é‡Šæˆ–å·¥å…·è°ƒç”¨
2. **ä¼˜å…ˆä½¿ç”¨å·¥å…·**: å§‹ç»ˆå…ˆä½¿ç”¨schemaå·¥å…·è·å–å‡†ç¡®çš„è¡¨ç»“æ„ä¿¡æ¯
3. **æ—¶é—´å ä½ç¬¦ä¼˜å…ˆ**: æ‰€æœ‰æ—¶é—´ç›¸å…³æŸ¥è¯¢å¿…é¡»ä½¿ç”¨ {{start_date}} å’Œ {{end_date}}
4. **è¿­ä»£ä¼˜åŒ–**: ä½¿ç”¨TTé€’å½’æœºåˆ¶æŒç»­æ”¹è¿›ï¼Œç›´åˆ°è¾¾åˆ°è´¨é‡é˜ˆå€¼
5. **é”™è¯¯å¤„ç†**: é‡åˆ°é—®é¢˜æ—¶ï¼Œä½¿ç”¨ç›¸åº”çš„ä¿®å¤å·¥å…·
6. **éªŒè¯ä¼˜å…ˆ**: æ¯æ¬¡ç”ŸæˆSQLåéƒ½è¦è¿›è¡ŒéªŒè¯
7. **æ€§èƒ½è€ƒè™‘**: åœ¨ä¿è¯æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½

**è®°ä½ï¼šæœ€ç»ˆå¿…é¡»è¿”å›çº¯Doris SQLæŸ¥è¯¢è¯­å¥ï¼Œä¸èƒ½åŒ…å«ä»»ä½•ä¸­æ–‡è§£é‡Šï¼**""")
        
        # 2. ä»»åŠ¡æè¿°
        prompt_parts.append(f"# ä»»åŠ¡æè¿°\n{request.placeholder}")
        
        # 3. ä¸Šä¸‹æ–‡ä¿¡æ¯
        if request.task_context:
            prompt_parts.append(f"# ä»»åŠ¡ä¸Šä¸‹æ–‡\n{self._format_context(request.task_context)}")
        
        # 4. çº¦æŸæ¡ä»¶
        if request.constraints:
            prompt_parts.append(f"# çº¦æŸæ¡ä»¶\n{self._format_constraints(request.constraints)}")
        
        # 5. æ‰§è¡ŒæŒ‡å¯¼
        prompt_parts.append(self._get_execution_guidance(request))
        
        return "\n\n".join(prompt_parts)

    def _format_context(self, context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        lines = []
        for key, value in context.items():
            if isinstance(value, (dict, list)):
                lines.append(f"- {key}: {str(value)[:200]}...")
            else:
                lines.append(f"- {key}: {value}")
        return "\n".join(lines)

    def _format_constraints(self, constraints: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–çº¦æŸæ¡ä»¶"""
        lines = []
        for key, value in constraints.items():
            lines.append(f"- {key}: {value}")
        return "\n".join(lines)

    def _get_execution_guidance(self, request: AgentRequest) -> str:
        """è·å–æ‰§è¡ŒæŒ‡å¯¼"""
        guidance = [
            "# æ‰§è¡ŒæŒ‡å¯¼",
            "",
            "è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š",
            "",
            "1. **ç†è§£éœ€æ±‚**: ä»”ç»†åˆ†æå ä½ç¬¦ä¸­çš„ä¸šåŠ¡éœ€æ±‚",
            "2. **æ¢ç´¢æ•°æ®**: ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ¢ç´¢æ•°æ®æºç»“æ„",
            "3. **ç”ŸæˆSQL**: åŸºäºæ•°æ®ç»“æ„å’Œéœ€æ±‚ç”Ÿæˆå‡†ç¡®çš„SQLæŸ¥è¯¢",
            "4. **éªŒè¯ç»“æœ**: éªŒè¯SQLçš„æ­£ç¡®æ€§å’Œç»“æœçš„åˆç†æ€§",
            "5. **ä¼˜åŒ–æ”¹è¿›**: æ ¹æ®éªŒè¯ç»“æœä¼˜åŒ–æŸ¥è¯¢",
            "",
            "**é‡è¦æç¤º**:",
            "- ä¼˜å…ˆä½¿ç”¨å·¥å…·è·å–å‡†ç¡®çš„æ•°æ®ç»“æ„ä¿¡æ¯",
            "- ç”Ÿæˆçš„SQLå¿…é¡»ç¬¦åˆæ•°æ®åº“è¯­æ³•è§„èŒƒ",
            "- ç¡®ä¿æŸ¥è¯¢ç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§",
            "- å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·å°è¯•ä¸åŒçš„æ–¹æ³•æˆ–å·¥å…·",
        ]
        
        # æ ¹æ®å¤æ‚åº¦æ·»åŠ ç‰¹å®šæŒ‡å¯¼
        if request.complexity == TaskComplexity.COMPLEX:
            guidance.extend([
                "",
                "**å¤æ‚ä»»åŠ¡æŒ‡å¯¼**:",
                "- å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤",
                "- é€æ­¥éªŒè¯æ¯ä¸ªæ­¥éª¤çš„ç»“æœ",
                "- ä½¿ç”¨å¤šä¸ªå·¥å…·ç»„åˆå®Œæˆä»»åŠ¡",
            ])
        
        return "\n".join(guidance)

    async def _build_response(
        self, 
        request: AgentRequest, 
        result: Any, 
        execution_time_ms: int
    ) -> AgentResponse:
        """æ„å»ºå“åº”"""
        # æå–ç»“æœå†…å®¹
        if isinstance(result, str):
            content = result
        elif isinstance(result, dict):
            content = result.get("content", result.get("result", str(result)))
        else:
            content = str(result)
        
        # è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = await self._calculate_quality_score(content, request)
        
        return AgentResponse(
            success=True,
            result=content,
            stage=ExecutionStage.COMPLETION,
            iterations_used=self._current_state.iteration_count,
            execution_time_ms=execution_time_ms,
            reasoning=self._extract_reasoning(result),
            quality_score=quality_score,
            tool_calls=self._current_state.tool_call_history,
            metadata={
                "data_source_id": request.data_source_id,
                "user_id": request.user_id,
                "complexity": request.complexity.value,
                "config": self._config.metadata
            }
        )

    async def _calculate_quality_score(self, content: str, request: AgentRequest) -> float:
        """
        è®¡ç®—è´¨é‡è¯„åˆ†

        ä½¿ç”¨å¢å¼ºçš„å¤šç»´åº¦è´¨é‡è¯„åˆ†ç³»ç»Ÿ
        """
        try:
            # å‡†å¤‡æ‰§è¡Œç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            execution_result = None
            if hasattr(self._current_state, 'accumulated_results') and self._current_state.accumulated_results:
                # è·å–æœ€åä¸€ä¸ªæ‰§è¡Œç»“æœ
                last_result = self._current_state.accumulated_results[-1]
                if isinstance(last_result, dict):
                    execution_result = last_result

            # å‡†å¤‡æ•°æ®æºæœåŠ¡å’Œè¿æ¥é…ç½®ï¼ˆç”¨äºSQLæ‰§è¡ŒéªŒè¯ï¼‰
            data_source_service = None
            connection_config = None
            
            if hasattr(self.container, 'data_source') and request.data_source_id:
                try:
                    data_source_service = self.container.data_source
                    # è·å–æ•°æ®æºé…ç½®
                    with get_db_session() as db:
                        data_source = crud.data_source.get(db, id=request.data_source_id)
                        if data_source:
                            connection_config = {
                                "source_type": data_source.source_type,
                                "name": data_source.name,
                                "doris_fe_hosts": data_source.doris_fe_hosts,
                                "doris_be_hosts": data_source.doris_be_hosts,
                                "doris_http_port": data_source.doris_http_port,
                                "doris_query_port": data_source.doris_query_port,
                                "doris_database": data_source.doris_database,
                                "doris_username": data_source.doris_username,
                                "doris_password": data_source.doris_password,
                            }
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–æ•°æ®æºé…ç½®å¤±è´¥: {e}")

            # ä½¿ç”¨å¢å¼ºçš„è´¨é‡è¯„åˆ†å™¨
            quality_score_result = await self._quality_scorer.calculate_quality_score(
                content=content,
                execution_result=execution_result,
                tool_call_history=self._current_state.tool_call_history if self._current_state else None,
                request_context={
                    "complexity": request.complexity.value,
                    "stage": request.stage.value,
                    "constraints": request.constraints,
                },
                data_source_service=data_source_service,
                connection_config=connection_config
            )

            # è®°å½•è¯¦ç»†è¯„åˆ†ä¿¡æ¯
            logger.info(f"ğŸ“Š [è´¨é‡è¯„åˆ†] æ€»ä½“è¯„åˆ†: {quality_score_result.overall_score:.2f} ({quality_score_result.grade})")
            for dimension, dim_score in quality_score_result.dimension_scores.items():
                logger.debug(f"   {dimension.value}: {dim_score.score:.2f} (æƒé‡: {dim_score.weight:.2f})")

            if quality_score_result.suggestions:
                logger.info(f"ğŸ’¡ [è´¨é‡å»ºè®®] {len(quality_score_result.suggestions)} æ¡å»ºè®®:")
                for suggestion in quality_score_result.suggestions[:3]:  # åªæ˜¾ç¤ºå‰3æ¡
                    logger.info(f"   - {suggestion}")

            return quality_score_result.overall_score

        except Exception as e:
            logger.warning(f"âš ï¸ è´¨é‡è¯„åˆ†å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†: {e}")
            # é™çº§åˆ°åŸºç¡€è¯„åˆ†
            return self._calculate_basic_quality_score(content)

    def _calculate_basic_quality_score(self, content: str) -> float:
        """åŸºç¡€è´¨é‡è¯„åˆ†ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        score = 0.0

        # åŸºç¡€è¯„åˆ†
        if content and len(content.strip()) > 0:
            score += 0.3

        # SQL è´¨é‡è¯„åˆ†
        if "SELECT" in content.upper() or "WITH" in content.upper():
            score += 0.4

            # æ£€æŸ¥ SQL ç»“æ„
            if "FROM" in content.upper():
                score += 0.1
            if "WHERE" in content.upper() or "GROUP BY" in content.upper():
                score += 0.1
            if "ORDER BY" in content.upper():
                score += 0.1

        # å·¥å…·ä½¿ç”¨è¯„åˆ†
        if self._current_state and self._current_state.tool_call_history:
            score += min(0.2, len(self._current_state.tool_call_history) * 0.05)

        return min(1.0, score)

    def _extract_reasoning(self, result: Any) -> str:
        """æå–æ¨ç†è¿‡ç¨‹"""
        if isinstance(result, dict):
            return result.get("reasoning", result.get("explanation", ""))
        return ""

    async def run(self, prompt: str, **kwargs) -> str:
        """
        ç®€åŒ–çš„è¿è¡Œæ¥å£
        
        Args:
            prompt: è¾“å…¥ prompt
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # åˆ›å»ºä¸´æ—¶è¯·æ±‚
        request = AgentRequest(
            placeholder=prompt,
            data_source_id=kwargs.get("data_source_id", 0),
            user_id=kwargs.get("user_id", "system")
        )
        
        # æ‰§è¡Œå¹¶æ”¶é›†ç»“æœ
        result = None
        async for event in self.execute_with_tt(request):
            if event.event_type == "execution_completed":
                result = event.data["response"].result
                break
        
        return result or ""

    async def stream(self, prompt: str):
        """æµå¼æ‰§è¡Œ"""
        request = AgentRequest(
            placeholder=prompt,
            data_source_id=0,
            user_id="system"
        )
        
        async for event in self.execute_with_tt(request):
            yield event

    def add_event_callback(self, callback: Callable[[AgentEvent], None]):
        """æ·»åŠ äº‹ä»¶å›è°ƒ"""
        self._event_callbacks.append(callback)

    def remove_event_callback(self, callback: Callable[[AgentEvent], None]):
        """ç§»é™¤äº‹ä»¶å›è°ƒ"""
        if callback in self._event_callbacks:
            self._event_callbacks.remove(callback)

    async def _notify_callbacks(self, event: AgentEvent):
        """é€šçŸ¥å›è°ƒå‡½æ•°"""
        for callback in self._event_callbacks:
            try:
                callback(event)
            except Exception as e:
                logger.warning(f"âš ï¸ äº‹ä»¶å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    def _setup_tool_call_tracking(self):
        """è®¾ç½®å·¥å…·è°ƒç”¨è·Ÿè¸ª"""
        # å¦‚æœ agent æœ‰ LLM é€‚é…å™¨ï¼Œè®¾ç½®å·¥å…·è°ƒç”¨å›è°ƒ
        if hasattr(self._agent, 'llm') and hasattr(self._agent.llm, '_tool_call_callback'):
            def tool_call_callback(tool_name: str, arguments: Dict[str, Any]):
                """å·¥å…·è°ƒç”¨å›è°ƒ"""
                if self._current_state:
                    # è®°å½•å·¥å…·è°ƒç”¨
                    tool_call = ToolCall(
                        tool_name=tool_name,
                        arguments=arguments,
                        timestamp=time.time(),
                        success=True
                    )
                    self._current_state.tool_call_history.append(tool_call)
                    
                    # æ›´æ–°è¿­ä»£è·Ÿè¸ªå™¨
                    self._iteration_tracker.on_tool_call()
                    
                    logger.info(f"ğŸ”§ [LoomAgentRuntime] å·¥å…·è°ƒç”¨: {tool_name}")
            
            # è®¾ç½®å›è°ƒ
            self._agent.llm._tool_call_callback = tool_call_callback


def build_default_runtime(
    *,
    container: Any,
    config: Optional[AgentConfig] = None,
    additional_tools: Optional[List[BaseTool]] = None,
    llm: Optional[BaseLLM] = None,
    context_retriever: Optional[SchemaContextRetriever] = None,
) -> LoomAgentRuntime:
    """
    æ„å»ºé»˜è®¤è¿è¡Œæ—¶

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®
        additional_tools: é¢å¤–å·¥å…·
        llm: LLM å®ä¾‹
        context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨

    Returns:
        LoomAgentRuntime å®ä¾‹
    """
    from .types import create_default_agent_config

    # ä½¿ç”¨é»˜è®¤é…ç½®
    if config is None:
        config = create_default_agent_config()

    # åˆ›å»º LLM é€‚é…å™¨
    if llm is None:
        llm = create_llm_adapter(container)

    # ğŸ”¥ æ„å»ºå·¥å…·åˆ—è¡¨ - ä»é…ç½®è‡ªåŠ¨åˆ›å»º
    tools = _create_tools_from_config(container, config)
    if additional_tools:
        tools.extend(additional_tools)
        logger.info(f"â• [ToolRegistry] æ·»åŠ é¢å¤–å·¥å…·: {len(additional_tools)} ä¸ª")

    logger.info(f"ğŸ”§ [LoomAgentRuntime] æœ€ç»ˆå·¥å…·æ•°é‡: {len(tools)}")

    # åˆ›å»º Loom Agent
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  memory ä»¥æ”¯æŒå¯¹è¯å†å²ç®¡ç†
    from loom.builtin.memory import InMemoryMemory

    agent_kwargs = {
        "llm": llm,
        "tools": tools,
        "memory": InMemoryMemory(),  # ğŸ”¥ æ·»åŠ  memory
        "max_iterations": config.max_iterations,
        "max_context_tokens": config.max_context_tokens,
    }

    if config.system_prompt:
        agent_kwargs["system_instructions"] = config.system_prompt

    if context_retriever:
        agent_kwargs["context_retriever"] = context_retriever
        try:
            logger.info(f"ğŸ§© [LoomAgentRuntime] å·²æ³¨å…¥ ContextRetriever: {type(context_retriever).__name__}")
        except Exception:
            logger.info("ğŸ§© [LoomAgentRuntime] å·²æ³¨å…¥ ContextRetriever")

    agent = build_agent(**agent_kwargs)

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›¿æ¢é»˜è®¤çš„executorä¸ºè‡ªå®šä¹‰çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥executor
    agent._executor = ContextAwareAgentExecutor(
        original_executor=agent.executor,
        context_retriever=context_retriever
    )

    logger.info(f"âœ… [LoomAgentRuntime] Agent å·²åˆ›å»ºï¼Œé…ç½®äº† memory: True å’Œ ContextAwareExecutor")
    
    return LoomAgentRuntime(
        agent=agent,
        tools=tools,
        config=config,
        context_retriever=context_retriever
    )


def create_runtime_with_context_retriever(
    container: Any,
    data_source_id: str,
    connection_config: Dict[str, Any],
    config: Optional[AgentConfig] = None
) -> LoomAgentRuntime:
    """
    åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡æ£€ç´¢å™¨çš„è¿è¡Œæ—¶
    
    Args:
        container: æœåŠ¡å®¹å™¨
        data_source_id: æ•°æ®æºID
        connection_config: è¿æ¥é…ç½®
        config: Agent é…ç½®
        
    Returns:
        LoomAgentRuntime å®ä¾‹
    """
    # åˆ›å»ºä¸Šä¸‹æ–‡æ£€ç´¢å™¨
    context_retriever = create_schema_context_retriever(
        data_source_id=data_source_id,
        connection_config=connection_config,
        container=container
    )
    
    # åˆ›å»ºè¿è¡Œæ—¶
    return build_default_runtime(
        container=container,
        config=config,
        context_retriever=context_retriever
    )


class StageAwareRuntime(LoomAgentRuntime):
    """
    é˜¶æ®µæ„ŸçŸ¥çš„Runtime
    
    ä¿ç•™TTé€’å½’èƒ½åŠ›ï¼Œæ ¹æ®å½“å‰é˜¶æ®µåŠ¨æ€åˆ‡æ¢é…ç½®
    è¿™æ˜¯åŸºäºTTé€’å½’çš„ä¸‰é˜¶æ®µAgentæ¶æ„çš„æ ¸å¿ƒå®ç°
    """
    
    def __init__(
        self,
        agent: Agent,
        tools: List[BaseTool],
        config: AgentConfig,
        context_retriever: Optional[SchemaContextRetriever] = None,
        stage_config_manager: Optional[StageConfigManager] = None,
    ):
        """
        Args:
            agent: Loom Agent å®ä¾‹
            tools: å·¥å…·åˆ—è¡¨
            config: Agent é…ç½®
            context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
            stage_config_manager: é˜¶æ®µé…ç½®ç®¡ç†å™¨
        """
        super().__init__(agent, tools, config, context_retriever)
        
        # å½“å‰æ‰§è¡Œé˜¶æ®µ
        self.current_stage: Optional[ExecutionStage] = None
        
        # é˜¶æ®µé…ç½®ç®¡ç†å™¨
        self.stage_config_manager = stage_config_manager or get_stage_config_manager()
        
        # åŸå§‹é…ç½®å¤‡ä»½ï¼ˆç”¨äºæ¢å¤ï¼‰
        self._original_config = AgentConfig(
            llm=config.llm,
            tools=config.tools,
            coordination=config.coordination,
            max_iterations=config.max_iterations,
            max_context_tokens=config.max_context_tokens,
            system_prompt=config.system_prompt,
            callbacks=config.callbacks.copy(),
            metadata=config.metadata.copy()
        )
        
        logger.info("ğŸ¯ [StageAwareRuntime] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ”¯æŒé˜¶æ®µ: {self.stage_config_manager.get_all_stages()}")
    
    async def execute_with_stage(
        self,
        request: AgentRequest,
        stage: ExecutionStage
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        åœ¨æŒ‡å®šé˜¶æ®µæ‰§è¡Œï¼ˆä¿ç•™TTé€’å½’ï¼‰
        
        Args:
            request: Agentè¯·æ±‚
            stage: æ‰§è¡Œé˜¶æ®µ
            
        Yields:
            AgentEvent: æ‰§è¡Œäº‹ä»¶ï¼ˆåŒ…å«TTé€’å½’çš„æ‰€æœ‰æ­¥éª¤ï¼‰
        """
        # 1. åˆ‡æ¢åˆ°å¯¹åº”é˜¶æ®µé…ç½®
        self.current_stage = stage
        stage_config = self.stage_config_manager.get_stage_config(stage)
        
        if not stage_config:
            logger.error(f"âŒ [StageAwareRuntime] æœªæ‰¾åˆ°é˜¶æ®µé…ç½®: {stage.value}")
            raise ValueError(f"æœªæ‰¾åˆ°é˜¶æ®µé…ç½®: {stage.value}")
        
        # åº”ç”¨é˜¶æ®µé…ç½®
        self._apply_stage_config(stage_config)
        
        logger.info(f"ğŸ¯ [StageAwareRuntime] è¿›å…¥é˜¶æ®µ: {stage.value}")
        logger.info(f"   å¯ç”¨å·¥å…·: {len(stage_config.enabled_tools)} ä¸ª")
        logger.info(f"   è´¨é‡é˜ˆå€¼: {stage_config.quality_threshold}")
        logger.info(f"   æœ€å¤§è¿­ä»£: {stage_config.max_iterations}")
        logger.info(f"   é˜¶æ®µç›®æ ‡: {stage_config.stage_goal}")
        
        # 2. æ›´æ–°è¯·æ±‚é…ç½®
        stage_request = AgentRequest(
            placeholder=request.placeholder,
            data_source_id=request.data_source_id,
            user_id=request.user_id,
            task_context=request.task_context,
            template_context=request.template_context,
            max_iterations=stage_config.max_iterations,
            complexity=request.complexity,
            stage=stage,
            constraints={**request.constraints, **stage_config.constraints},
            metadata={**request.metadata, **stage_config.metadata}
        )
        
        # 3. ä½¿ç”¨TTé€’å½’æ‰§è¡Œï¼ˆè¿™æ˜¯æ ¸å¿ƒï¼ï¼‰
        async for event in self.execute_with_tt(stage_request):
            # æ·»åŠ é˜¶æ®µä¿¡æ¯åˆ°äº‹ä»¶
            event.data['current_stage'] = stage.value
            event.data['stage_goal'] = stage_config.stage_goal
            event.data['stage_quality_threshold'] = stage_config.quality_threshold
            
            yield event
        
        logger.info(f"âœ… [StageAwareRuntime] é˜¶æ®µå®Œæˆ: {stage.value}")
        
        # 4. æ¢å¤åŸå§‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        # self._restore_original_config()
    
    def _apply_stage_config(self, stage_config):
        """åº”ç”¨é˜¶æ®µé…ç½®"""
        # åˆ‡æ¢å·¥å…·é›†ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…å·¥å…·ç®¡ç†æ–¹å¼è°ƒæ•´ï¼‰
        # æ³¨æ„ï¼šå®é™…çš„å·¥å…·åˆ‡æ¢éœ€è¦åœ¨Agentå±‚é¢å®ç°
        # è¿™é‡Œä¸»è¦æ˜¯æ›´æ–°é…ç½®ä¿¡æ¯
        
        # åˆ‡æ¢ç³»ç»Ÿæç¤º
        self._config.system_prompt = stage_config.system_prompt
        
        # åˆ‡æ¢è´¨é‡é˜ˆå€¼ï¼ˆå¦‚æœæœ‰è´¨é‡è¯„åˆ†å™¨ï¼‰
        if hasattr(self, '_quality_scorer') and hasattr(self._quality_scorer, 'config'):
            self._quality_scorer.config.quality_threshold = stage_config.quality_threshold
        
        # åˆ‡æ¢è¿­ä»£æ¬¡æ•°
        self._config.max_iterations = stage_config.max_iterations
        
        logger.debug(f"ğŸ“ [StageAwareRuntime] å·²åº”ç”¨é˜¶æ®µé…ç½®")
        logger.debug(f"   ç³»ç»Ÿæç¤ºé•¿åº¦: {len(stage_config.system_prompt)} å­—ç¬¦")
        logger.debug(f"   è´¨é‡é˜ˆå€¼: {stage_config.quality_threshold}")
        logger.debug(f"   æœ€å¤§è¿­ä»£: {stage_config.max_iterations}")
    
    def _restore_original_config(self):
        """æ¢å¤åŸå§‹é…ç½®"""
        self._config.system_prompt = self._original_config.system_prompt
        self._config.max_iterations = self._original_config.max_iterations
        
        if hasattr(self, '_quality_scorer') and hasattr(self._quality_scorer, 'config'):
            self._quality_scorer.config.quality_threshold = 0.8  # é»˜è®¤é˜ˆå€¼
        
        logger.debug("ğŸ”„ [StageAwareRuntime] å·²æ¢å¤åŸå§‹é…ç½®")
    
    def get_current_stage(self) -> Optional[ExecutionStage]:
        """è·å–å½“å‰æ‰§è¡Œé˜¶æ®µ"""
        return self.current_stage
    
    def get_stage_config(self, stage: ExecutionStage):
        """è·å–é˜¶æ®µé…ç½®"""
        return self.stage_config_manager.get_stage_config(stage)
    
    def is_stage_configured(self, stage: ExecutionStage) -> bool:
        """æ£€æŸ¥é˜¶æ®µæ˜¯å¦å·²é…ç½®"""
        return self.stage_config_manager.is_stage_configured(stage)
    
    async def execute_sql_generation_stage(
        self,
        placeholder: str,
        data_source_id: int,
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡ŒSQLç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - å‘ç°Schema
        - ç”ŸæˆSQL
        - éªŒè¯SQL
        - ä¿®å¤é—®é¢˜
        - å†æ¬¡éªŒè¯
        - ... ç›´åˆ°è¾¾åˆ°è´¨é‡é˜ˆå€¼
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [SQLç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=placeholder,
            data_source_id=data_source_id,
            user_id=user_id,
            task_context=kwargs.get('task_context', {}),
            template_context=kwargs.get('template_context'),
            max_iterations=8,  # SQLé˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.SQL_GENERATION,
            constraints=kwargs.get('constraints', {})
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.SQL_GENERATION):
            # è®°å½•TTé€’å½’çš„æ¯ä¸€æ­¥
            if event.event_type == 'execution_started':
                logger.info(f"ğŸš€ [SQLé˜¶æ®µ] å¼€å§‹TTé€’å½’æ‰§è¡Œ")
            elif event.event_type == 'execution_completed':
                logger.info(f"âœ… [SQLé˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, iterations_used = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
                logger.info(f"   è¿­ä»£æ¬¡æ•°: {iterations_used}")
            
            yield event
        
        logger.info("âœ… [SQLç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")
    
    async def execute_chart_generation_stage(
        self,
        etl_data: Dict[str, Any],
        chart_placeholder: str,
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡Œå›¾è¡¨ç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - åˆ†ææ•°æ®ç‰¹å¾
        - é€‰æ‹©å›¾è¡¨ç±»å‹
        - ç”Ÿæˆå›¾è¡¨é…ç½®
        - éªŒè¯é…ç½®
        - ä¼˜åŒ–é…ç½®
        - ... ç›´åˆ°è¾¾åˆ°æœ€ä¼˜
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [å›¾è¡¨ç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=chart_placeholder,
            data_source_id=kwargs.get('data_source_id', 0),
            user_id=user_id,
            task_context={
                'etl_data': etl_data,
                'statistics': kwargs.get('statistics', {}),
                **kwargs.get('task_context', {})
            },
            max_iterations=6,  # å›¾è¡¨é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.CHART_GENERATION,
            constraints={'output_format': 'chart_config'}
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.CHART_GENERATION):
            if event.event_type == 'execution_completed':
                logger.info(f"âœ… [å›¾è¡¨é˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, _ = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
            
            yield event
        
        logger.info("âœ… [å›¾è¡¨ç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")
    
    async def execute_document_generation_stage(
        self,
        paragraph_context: str,
        placeholder_data: Dict[str, Any],
        user_id: str,
        **kwargs
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡Œæ–‡æ¡£ç”Ÿæˆé˜¶æ®µï¼ˆä½¿ç”¨TTé€’å½’ï¼‰
        
        å†…éƒ¨ä¼šè‡ªåŠ¨è¿­ä»£ä¼˜åŒ–ï¼š
        - åˆ†ææ®µè½ç»“æ„
        - ç”Ÿæˆæ–‡æœ¬
        - æ£€æŸ¥é£æ ¼
        - éªŒè¯ä¸€è‡´æ€§
        - ä¼˜åŒ–è¡¨è¾¾
        - ... ç›´åˆ°è¾¾åˆ°æœ€ä¼˜
        
        Yields:
            AgentEvent: åŒ…å«æ‰€æœ‰TTé€’å½’æ­¥éª¤çš„äº‹ä»¶
        """
        logger.info("ğŸ¯ [æ–‡æ¡£ç”Ÿæˆé˜¶æ®µ] å¼€å§‹æ‰§è¡Œï¼ˆTTé€’å½’æ¨¡å¼ï¼‰")
        
        # åˆ›å»ºè¯·æ±‚
        request = AgentRequest(
            placeholder=paragraph_context,
            data_source_id=kwargs.get('data_source_id', 0),
            user_id=user_id,
            task_context={
                'paragraph_context': paragraph_context,
                'placeholder_data': placeholder_data,
                'document_context': kwargs.get('document_context', {}),
                **kwargs.get('task_context', {})
            },
            max_iterations=5,  # æ–‡æ¡£é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°
            complexity=kwargs.get('complexity', TaskComplexity.MEDIUM),
            stage=ExecutionStage.DOCUMENT_GENERATION,
            constraints={'output_format': 'text'}
        )
        
        # ä½¿ç”¨TTé€’å½’æ‰§è¡Œ
        async for event in self.execute_with_stage(request, ExecutionStage.DOCUMENT_GENERATION):
            if event.event_type == 'execution_completed':
                logger.info(f"âœ… [æ–‡æ¡£é˜¶æ®µ] TTé€’å½’æ‰§è¡Œå®Œæˆ")
                response_payload = event.data.get('response')
                quality_score, _ = _extract_response_metrics(response_payload)
                logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
            
            yield event
        
        logger.info("âœ… [æ–‡æ¡£ç”Ÿæˆé˜¶æ®µ] å®Œæˆï¼ˆTTé€’å½’è‡ªåŠ¨ä¼˜åŒ–ï¼‰")


def build_stage_aware_runtime(
    *,
    container: Any,
    config: Optional[AgentConfig] = None,
    additional_tools: Optional[List[BaseTool]] = None,
    llm: Optional[BaseLLM] = None,
    context_retriever: Optional[SchemaContextRetriever] = None,
    stage_config_manager: Optional[StageConfigManager] = None,
) -> StageAwareRuntime:
    """
    æ„å»ºStage-Awareè¿è¡Œæ—¶

    Args:
        container: æœåŠ¡å®¹å™¨
        config: Agent é…ç½®
        additional_tools: é¢å¤–å·¥å…·
        llm: LLM å®ä¾‹
        context_retriever: ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
        stage_config_manager: é˜¶æ®µé…ç½®ç®¡ç†å™¨

    Returns:
        StageAwareRuntime å®ä¾‹
    """
    from .types import create_default_agent_config

    # ä½¿ç”¨é»˜è®¤é…ç½®
    if config is None:
        config = create_default_agent_config()

    # åˆ›å»º LLM é€‚é…å™¨
    if llm is None:
        llm = create_llm_adapter(container)

    # ğŸ”¥ æ„å»ºå·¥å…·åˆ—è¡¨ - ä»é…ç½®è‡ªåŠ¨åˆ›å»º
    tools = _create_tools_from_config(container, config)
    if additional_tools:
        tools.extend(additional_tools)
        logger.info(f"â• [ToolRegistry] æ·»åŠ é¢å¤–å·¥å…·: {len(additional_tools)} ä¸ª")

    logger.info(f"ğŸ”§ [StageAwareRuntime] æœ€ç»ˆå·¥å…·æ•°é‡: {len(tools)}")

    # åˆ›å»º Loom Agent
    agent_kwargs = {
        "llm": llm,
        "tools": tools,
        "max_iterations": config.max_iterations,
        "max_context_tokens": config.max_context_tokens,
    }
    
    if config.system_prompt:
        agent_kwargs["system_instructions"] = config.system_prompt
    
    if context_retriever:
        agent_kwargs["context_retriever"] = context_retriever
        try:
            logger.info(f"ğŸ§© [StageAwareRuntime] å·²æ³¨å…¥ ContextRetriever: {type(context_retriever).__name__}")
        except Exception:
            logger.info("ğŸ§© [StageAwareRuntime] å·²æ³¨å…¥ ContextRetriever")
    
    agent = build_agent(**agent_kwargs)
    
    return StageAwareRuntime(
        agent=agent,
        tools=tools,
        config=config,
        context_retriever=context_retriever,
        stage_config_manager=stage_config_manager
    )


# å¯¼å‡º
__all__ = [
    "LoomAgentRuntime",
    "StageAwareRuntime",
    "build_default_runtime",
    "build_stage_aware_runtime",
    "create_runtime_with_context_retriever",
]
