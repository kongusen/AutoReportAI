from __future__ import annotations


from loom.interfaces.tool import BaseTool
"""
Schema ç¼“å­˜å·¥å…·

ç”¨äºç¼“å­˜å’Œç®¡ç† Schema ä¿¡æ¯
æ”¯æŒæ™ºèƒ½ç¼“å­˜ç­–ç•¥å’Œç¼“å­˜ä¼˜åŒ–
"""

import logging
import time
import json
from typing import Any, Dict, List, Optional, Union, Literal
from dataclasses import dataclass, asdict
from collections import OrderedDict
from pydantic import BaseModel, Field


from ...types import ToolCategory, ContextInfo

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    data: Any
    created_at: float
    accessed_at: float
    access_count: int = 0
    ttl: Optional[float] = None
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if self.ttl is None:
            return False
        return time.time() - self.created_at > self.ttl
    
    def touch(self):
        """æ›´æ–°è®¿é—®æ—¶é—´"""
        self.accessed_at = time.time()
        self.access_count += 1


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    total_entries: int
    hit_count: int
    miss_count: int
    hit_rate: float
    memory_usage_bytes: int
    oldest_entry_age: float
    newest_entry_age: float
    most_accessed_entry: Optional[str] = None


class SchemaCacheTool(BaseTool):
    """Schema ç¼“å­˜å·¥å…·"""
    
    def __init__(self, container: Any, max_size: int = 1000, default_ttl: float = 3600):
        """
        Args:
            container: æœåŠ¡å®¹å™¨
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
            default_ttl: é»˜è®¤TTLï¼ˆç§’ï¼‰
        """
        super().__init__()

        self.name = "schema_cache"

        self.category = ToolCategory.SCHEMA

        self.description = "ç¼“å­˜å’Œç®¡ç† Schema ä¿¡æ¯" 
        self.container = container
        self.max_size = max_size
        self.default_ttl = default_ttl
        
        # ä½¿ç”¨ OrderedDict å®ç° LRU ç¼“å­˜
        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self._stats = {
            "hit_count": 0,
            "miss_count": 0,
            "total_entries": 0
        }
        
        # ä½¿ç”¨ Pydantic å®šä¹‰å‚æ•°æ¨¡å¼ï¼ˆargs_schemaï¼‰
        class SchemaCacheArgs(BaseModel):
            action: Literal["get", "set", "delete", "clear", "stats", "list"] = Field(
                description="ç¼“å­˜æ“ä½œ"
            )
            key: Optional[str] = Field(default=None, description="ç¼“å­˜é”®")
            data: Optional[Any] = Field(default=None, description="è¦ç¼“å­˜çš„æ•°æ®ï¼ˆä»…ç”¨äº set æ“ä½œï¼‰")
            ttl: Optional[float] = Field(default=None, description="TTLæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3600")
            pattern: Optional[str] = Field(default=None, description="é”®æ¨¡å¼ï¼ˆç”¨äº list æ“ä½œï¼‰")

        self.args_schema = SchemaCacheArgs
    
    def get_schema(self) -> Dict[str, Any]:
        """è·å–å·¥å…·å‚æ•°æ¨¡å¼ï¼ˆåŸºäº args_schema ç”Ÿæˆï¼‰"""
        try:
            parameters = self.args_schema.model_json_schema()
        except Exception:
            parameters = self.args_schema.schema()  # type: ignore[attr-defined]
        return {
            "type": "function",
            "function": {
                "name": "schema_cache",
                "description": "ç¼“å­˜å’Œç®¡ç† Schema ä¿¡æ¯",
                "parameters": parameters,
            },
        }
    
    async def run(
        self,
        action: str,
        key: Optional[str] = None,
        data: Optional[Any] = None,
        ttl: Optional[float] = None,
        pattern: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œç¼“å­˜æ“ä½œ

        Args:
            action: ç¼“å­˜æ“ä½œ
            key: ç¼“å­˜é”®
            data: è¦ç¼“å­˜çš„æ•°æ®
            ttl: TTLæ—¶é—´
            pattern: é”®æ¨¡å¼

        Returns:
            Dict[str, Any]: æ“ä½œç»“æœ
        """
        logger.info(f"ğŸ—„ï¸ [SchemaCacheTool] æ‰§è¡Œæ“ä½œ: {action}")

        try:
            if action == "get":
                return await self._get(key)
            elif action == "set":
                return await self._set(key, data, ttl)
            elif action == "delete":
                return await self._delete(key)
            elif action == "clear":
                return await self._clear()
            elif action == "stats":
                return await self._get_stats()
            elif action == "list":
                return await self._list(pattern)
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ“ä½œ: {action}"
                }

        except Exception as e:
            logger.error(f"âŒ [SchemaCacheTool] æ“ä½œå¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """å‘åå…¼å®¹çš„executeæ–¹æ³•"""
        return await self.run(**kwargs)
    
    async def _get(self, key: str) -> Dict[str, Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if not key:
            return {
                "success": False,
                "error": "ç¼ºå°‘ç¼“å­˜é”®"
            }
        
        # æ£€æŸ¥ç¼“å­˜
        if key in self._cache:
            entry = self._cache[key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if entry.is_expired():
                # åˆ é™¤è¿‡æœŸæ¡ç›®
                del self._cache[key]
                self._stats["miss_count"] += 1
                return {
                    "success": False,
                    "error": "ç¼“å­˜å·²è¿‡æœŸ",
                    "data": None
                }
            
            # æ›´æ–°è®¿é—®ä¿¡æ¯
            entry.touch()
            # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆLRUï¼‰
            self._cache.move_to_end(key)
            
            self._stats["hit_count"] += 1
            
            return {
                "success": True,
                "data": entry.data,
                "metadata": {
                    "created_at": entry.created_at,
                    "accessed_at": entry.accessed_at,
                    "access_count": entry.access_count,
                    "ttl": entry.ttl
                }
            }
        else:
            self._stats["miss_count"] += 1
            return {
                "success": False,
                "error": "ç¼“å­˜æœªå‘½ä¸­",
                "data": None
            }
    
    async def _set(self, key: str, data: Any, ttl: Optional[float]) -> Dict[str, Any]:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if not key:
            return {
                "success": False,
                "error": "ç¼ºå°‘ç¼“å­˜é”®"
            }
        
        if data is None:
            return {
                "success": False,
                "error": "ç¼ºå°‘ç¼“å­˜æ•°æ®"
            }
        
        # ä½¿ç”¨é»˜è®¤TTL
        if ttl is None:
            ttl = self.default_ttl
        
        # åˆ›å»ºç¼“å­˜æ¡ç›®
        entry = CacheEntry(
            key=key,
            data=data,
            created_at=time.time(),
            accessed_at=time.time(),
            ttl=ttl
        )
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°
        if len(self._cache) >= self.max_size:
            # åˆ é™¤æœ€æ—§çš„æ¡ç›®ï¼ˆLRUï¼‰
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
            logger.info(f"ğŸ—‘ï¸ åˆ é™¤æœ€æ—§ç¼“å­˜æ¡ç›®: {oldest_key}")
        
        # è®¾ç½®ç¼“å­˜
        self._cache[key] = entry
        self._stats["total_entries"] += 1
        
        logger.info(f"âœ… è®¾ç½®ç¼“å­˜: {key}")
        
        return {
            "success": True,
            "metadata": {
                "key": key,
                "ttl": ttl,
                "created_at": entry.created_at,
                "cache_size": len(self._cache)
            }
        }
    
    async def _delete(self, key: str) -> Dict[str, Any]:
        """åˆ é™¤ç¼“å­˜æ•°æ®"""
        if not key:
            return {
                "success": False,
                "error": "ç¼ºå°‘ç¼“å­˜é”®"
            }
        
        if key in self._cache:
            del self._cache[key]
            self._stats["total_entries"] -= 1
            
            logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜: {key}")
            
            return {
                "success": True,
                "metadata": {
                    "deleted_key": key,
                    "cache_size": len(self._cache)
                }
            }
        else:
            return {
                "success": False,
                "error": "ç¼“å­˜é”®ä¸å­˜åœ¨"
            }
    
    async def _clear(self) -> Dict[str, Any]:
        """æ¸…ç©ºç¼“å­˜"""
        cleared_count = len(self._cache)
        self._cache.clear()
        self._stats["total_entries"] = 0
        
        logger.info(f"ğŸ§¹ æ¸…ç©ºç¼“å­˜: {cleared_count} ä¸ªæ¡ç›®")
        
        return {
            "success": True,
            "metadata": {
                "cleared_count": cleared_count,
                "cache_size": 0
            }
        }
    
    async def _get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        current_time = time.time()
        
        # è®¡ç®—å‘½ä¸­ç‡
        total_requests = self._stats["hit_count"] + self._stats["miss_count"]
        hit_rate = self._stats["hit_count"] / total_requests if total_requests > 0 else 0
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        memory_usage = sum(
            len(json.dumps(entry.data, default=str)) + len(entry.key)
            for entry in self._cache.values()
        )
        
        # è®¡ç®—æ¡ç›®å¹´é¾„
        ages = [current_time - entry.created_at for entry in self._cache.values()]
        oldest_age = max(ages) if ages else 0
        newest_age = min(ages) if ages else 0
        
        # æ‰¾åˆ°è®¿é—®æ¬¡æ•°æœ€å¤šçš„æ¡ç›®
        most_accessed = None
        if self._cache:
            most_accessed_entry = max(self._cache.values(), key=lambda e: e.access_count)
            most_accessed = most_accessed_entry.key
        
        stats = CacheStats(
            total_entries=len(self._cache),
            hit_count=self._stats["hit_count"],
            miss_count=self._stats["miss_count"],
            hit_rate=hit_rate,
            memory_usage_bytes=memory_usage,
            oldest_entry_age=oldest_age,
            newest_entry_age=newest_age,
            most_accessed_entry=most_accessed
        )
        
        return {
            "success": True,
            "stats": asdict(stats)
        }
    
    async def _list(self, pattern: Optional[str]) -> Dict[str, Any]:
        """åˆ—å‡ºç¼“å­˜æ¡ç›®"""
        keys = list(self._cache.keys())
        
        # åº”ç”¨æ¨¡å¼è¿‡æ»¤
        if pattern:
            import re
            regex_pattern = pattern.replace("*", ".*").replace("?", ".")
            keys = [key for key in keys if re.match(regex_pattern, key)]
        
        # è·å–æ¡ç›®ä¿¡æ¯
        entries = []
        for key in keys:
            entry = self._cache[key]
            entries.append({
                "key": key,
                "created_at": entry.created_at,
                "accessed_at": entry.accessed_at,
                "access_count": entry.access_count,
                "ttl": entry.ttl,
                "is_expired": entry.is_expired()
            })
        
        return {
            "success": True,
            "entries": entries,
            "metadata": {
                "total_entries": len(entries),
                "pattern": pattern,
                "cache_size": len(self._cache)
            }
        }
    
    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        expired_keys = []
        current_time = time.time()
        
        for key, entry in self._cache.items():
            if entry.is_expired():
                expired_keys.append(key)
        
        # åˆ é™¤è¿‡æœŸæ¡ç›®
        for key in expired_keys:
            del self._cache[key]
        
        if expired_keys:
            self._stats["total_entries"] -= len(expired_keys)
            logger.info(f"ğŸ§¹ æ¸…ç†è¿‡æœŸç¼“å­˜: {len(expired_keys)} ä¸ªæ¡ç›®")
        
        return len(expired_keys)
    
    def get_cache_size(self) -> int:
        """è·å–ç¼“å­˜å¤§å°"""
        return len(self._cache)
    
    def get_memory_usage(self) -> int:
        """è·å–å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰"""
        return sum(
            len(json.dumps(entry.data, default=str)) + len(entry.key)
            for entry in self._cache.values()
        )


class SchemaCacheManager:
    """Schema ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, container: Any, max_size: int = 1000):
        """
        Args:
            container: æœåŠ¡å®¹å™¨
            max_size: æœ€å¤§ç¼“å­˜å¤§å°
        """
        self.container = container
        self.cache_tool = SchemaCacheTool(container, max_size)
        self._cache_prefixes = {
            "table": "table:",
            "column": "column:",
            "relationship": "rel:",
            "constraint": "constraint:",
            "index": "index:"
        }
    
    def _build_key(self, prefix: str, identifier: str) -> str:
        """æ„å»ºç¼“å­˜é”®"""
        return f"{prefix}{identifier}"
    
    async def cache_table_info(self, table_name: str, table_info: Dict[str, Any], ttl: float = 3600):
        """ç¼“å­˜è¡¨ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["table"], table_name)
        return await self.cache_tool.execute("set", key, table_info, ttl)
    
    async def get_table_info(self, table_name: str) -> Optional[Dict[str, Any]]:
        """è·å–è¡¨ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["table"], table_name)
        result = await self.cache_tool.execute("get", key)
        return result.get("data") if result.get("success") else None
    
    async def cache_column_info(self, table_name: str, column_info: List[Dict[str, Any]], ttl: float = 3600):
        """ç¼“å­˜åˆ—ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["column"], table_name)
        return await self.cache_tool.execute("set", key, column_info, ttl)
    
    async def get_column_info(self, table_name: str) -> Optional[List[Dict[str, Any]]]:
        """è·å–åˆ—ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["column"], table_name)
        result = await self.cache_tool.execute("get", key)
        return result.get("data") if result.get("success") else None
    
    async def cache_relationships(self, table_name: str, relationships: List[Dict[str, Any]], ttl: float = 3600):
        """ç¼“å­˜å…³ç³»ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["relationship"], table_name)
        return await self.cache_tool.execute("set", key, relationships, ttl)
    
    async def get_relationships(self, table_name: str) -> Optional[List[Dict[str, Any]]]:
        """è·å–å…³ç³»ä¿¡æ¯"""
        key = self._build_key(self._cache_prefixes["relationship"], table_name)
        result = await self.cache_tool.execute("get", key)
        return result.get("data") if result.get("success") else None
    
    async def cache_schema_summary(self, data_source_id: str, schema_summary: Dict[str, Any], ttl: float = 7200):
        """ç¼“å­˜ Schema æ‘˜è¦"""
        key = f"schema_summary:{data_source_id}"
        return await self.cache_tool.execute("set", key, schema_summary, ttl)
    
    async def get_schema_summary(self, data_source_id: str) -> Optional[Dict[str, Any]]:
        """è·å– Schema æ‘˜è¦"""
        key = f"schema_summary:{data_source_id}"
        result = await self.cache_tool.execute("get", key)
        return result.get("data") if result.get("success") else None
    
    async def clear_table_cache(self, table_name: str):
        """æ¸…é™¤è¡¨ç›¸å…³ç¼“å­˜"""
        patterns = [
            f"{self._cache_prefixes['table']}{table_name}",
            f"{self._cache_prefixes['column']}{table_name}",
            f"{self._cache_prefixes['relationship']}{table_name}",
            f"{self._cache_prefixes['constraint']}{table_name}",
            f"{self._cache_prefixes['index']}{table_name}"
        ]
        
        for pattern in patterns:
            result = await self.cache_tool.execute("list", pattern=pattern)
            if result.get("success"):
                entries = result.get("entries", [])
                for entry in entries:
                    await self.cache_tool.execute("delete", entry["key"])
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return await self.cache_tool.execute("stats")
    
    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        return self.cache_tool.cleanup_expired()


def create_schema_cache_tool(container: Any, max_size: int = 1000) -> SchemaCacheTool:
    """
    åˆ›å»º Schema ç¼“å­˜å·¥å…·
    
    Args:
        container: æœåŠ¡å®¹å™¨
        max_size: æœ€å¤§ç¼“å­˜å¤§å°
        
    Returns:
        SchemaCacheTool å®ä¾‹
    """
    return SchemaCacheTool(container, max_size)


def create_schema_cache_manager(container: Any, max_size: int = 1000) -> SchemaCacheManager:
    """
    åˆ›å»º Schema ç¼“å­˜ç®¡ç†å™¨
    
    Args:
        container: æœåŠ¡å®¹å™¨
        max_size: æœ€å¤§ç¼“å­˜å¤§å°
        
    Returns:
        SchemaCacheManager å®ä¾‹
    """
    return SchemaCacheManager(container, max_size)


# å¯¼å‡º
__all__ = [
    "SchemaCacheTool",
    "SchemaCacheManager",
    "CacheEntry",
    "CacheStats",
    "create_schema_cache_tool",
    "create_schema_cache_manager",
]