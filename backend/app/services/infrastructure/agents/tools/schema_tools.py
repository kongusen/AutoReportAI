"""
Schemaç›¸å…³å·¥å…·

æä¾›æ•°æ®åº“æ¶æ„æŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½
"""

import logging
from typing import Dict, Any, List

from .base import Tool


class SchemaListColumnsTool(Tool):
    """æ•°æ®åº“è¡¨åˆ—ä¿¡æ¯æŸ¥è¯¢å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "schema.list_columns"
        self.description = "åˆ—å‡ºæ•°æ®åº“è¡¨çš„åˆ—ä¿¡æ¯"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥è¯¢è¡¨åˆ—ä¿¡æ¯"""
        try:
            tables = input_data.get("tables", [])
            if not tables:
                # å¼ºçº¦æŸï¼šæ—§å·¥å…·ä¸å†è´Ÿè´£åˆ—ä¸¾è¡¨ï¼Œè¯·å…ˆåˆ—å‡ºè¡¨å†æŒ‡å®š tables
                return {
                    "success": False,
                    "error": "tables_required",
                    "message": "è¯·å…ˆè°ƒç”¨ schema.list_tables è·å–è¡¨åï¼Œç„¶åä½¿ç”¨ schema.get_columns å¹¶åœ¨ input.tables æŒ‡å®šç›®æ ‡è¡¨å"
                }

            # è·å–æ•°æ®æºæœåŠ¡
            data_source_service = getattr(self.container, 'data_source_service', None) or getattr(self.container, 'data_source', None)
            if not data_source_service:
                # å¦‚æœæ²¡æœ‰æ•°æ®æºæœåŠ¡ï¼Œè¿”å›å·²æœ‰çš„åˆ—ä¿¡æ¯
                existing_columns = input_data.get("columns", {})
                return {
                    "success": True,
                    "tables": tables,
                    "columns": existing_columns,
                    "message": "ä½¿ç”¨å·²æœ‰åˆ—ä¿¡æ¯"
                }

            # ä¼˜å…ˆä½¿ç”¨å·²ç»ä¼ é€’çš„åˆ—ä¿¡æ¯ï¼Œé¿å…é‡å¤æŸ¥è¯¢ï¼ˆä»…å½“ç»“æ„ä¸º {table: [cols]} ä¸”è‡³å°‘ä¸€ä¸ªéç©ºæ—¶ï¼‰
            all_columns = {}
            existing_columns = input_data.get("columns", {})

            def _is_valid_columns_map(obj) -> bool:
                return isinstance(obj, dict) and all(
                    isinstance(v, list) for v in obj.values()
                )

            def _has_any_columns(obj) -> bool:
                try:
                    return any(isinstance(v, list) and len(v) > 0 for v in obj.values())
                except Exception:
                    return False

            explicit_tables = isinstance(input_data.get("tables"), list) and len(input_data.get("tables")) > 0

            if (not explicit_tables) and _is_valid_columns_map(existing_columns) and _has_any_columns(existing_columns):
                self._logger.info(
                    f"ğŸ” [SchemaListColumnsTool] ä½¿ç”¨å·²ä¼ é€’çš„åˆ—ä¿¡æ¯: {len(existing_columns)}ä¸ªè¡¨ï¼ˆå«éç©ºåˆ—ï¼‰"
                )
                all_columns = existing_columns
            else:
                # å¦åˆ™æŸ¥è¯¢æ¯ä¸ªè¡¨çš„åˆ—ä¿¡æ¯
                self._logger.info(f"ğŸ” [SchemaListColumnsTool] éœ€è¦é‡æ–°æŸ¥è¯¢åˆ—ä¿¡æ¯")
                for table in tables:
                    try:
                        # ä¼˜å…ˆä½¿ç”¨ SHOW FULL COLUMNS è·å–æ›´å®Œæ•´ä¿¡æ¯
                        if hasattr(self.container, 'data_source') and hasattr(self.container.data_source, 'run_query'):
                            try:
                                result = await self.container.data_source.run_query(
                                    connection_config=input_data.get("data_source", {}),
                                    sql=f"SHOW FULL COLUMNS FROM {table}",
                                    limit=1000
                                )
                                cols = []
                                detailed_cols = []  # å­˜å‚¨è¯¦ç»†çš„å­—æ®µä¿¡æ¯

                                for row in result.get("rows", []) or result.get("data", []) or []:
                                    if isinstance(row, dict):
                                        field_name = row.get("Field")
                                        if field_name:
                                            cols.append(field_name)
                                            # æ„å»ºè¯¦ç»†çš„å­—æ®µä¿¡æ¯
                                            field_info = {
                                                "name": field_name,
                                                "type": row.get("Type", ""),
                                                "nullable": row.get("Null", ""),
                                                "key": row.get("Key", ""),
                                                "default": row.get("Default", ""),
                                                "extra": row.get("Extra", ""),
                                                "comment": row.get("Comment", "")
                                            }
                                            detailed_cols.append(field_info)
                                    elif isinstance(row, list) and len(row) > 0:
                                        field_name = row[0]
                                        cols.append(field_name)
                                        # å°è¯•ä»åˆ—è¡¨ä¸­æå–è¯¦ç»†ä¿¡æ¯
                                        field_info = {
                                            "name": field_name,
                                            "type": row[1] if len(row) > 1 else "",
                                            "nullable": row[2] if len(row) > 2 else "",
                                            "key": row[3] if len(row) > 3 else "",
                                            "default": row[4] if len(row) > 4 else "",
                                            "extra": row[5] if len(row) > 5 else "",
                                            "comment": row[8] if len(row) > 8 else ""  # SHOW FULL COLUMNSçš„Commentåœ¨ç¬¬9åˆ—
                                        }
                                        detailed_cols.append(field_info)

                                if not cols:
                                    # å›é€€åˆ°åŸºç¡€æ–¹å¼
                                    cols = await self._get_table_columns(data_source_service, table, input_data)
                                    detailed_cols = [{"name": col, "type": "", "comment": ""} for col in cols]

                                all_columns[table] = cols
                                # å­˜å‚¨è¯¦ç»†ä¿¡æ¯ï¼Œä¾›schema_summaryä½¿ç”¨
                                if not hasattr(self, '_detailed_columns'):
                                    self._detailed_columns = {}
                                self._detailed_columns[table] = detailed_cols
                            except Exception:
                                cols = await self._get_table_columns(data_source_service, table, input_data)
                                all_columns[table] = cols
                        else:
                            columns = await self._get_table_columns(data_source_service, table, input_data)
                            all_columns[table] = columns
                    except Exception as e:
                        self._logger.warning(f"è·å–è¡¨ {table} åˆ—ä¿¡æ¯å¤±è´¥: {str(e)}")
                        all_columns[table] = []

            # ä¸ºLLMæ„å»ºå‹å¥½çš„schemaæè¿°
            schema_descriptions = []
            table_count = 0
            column_count = 0

            for table in tables:
                table_columns = all_columns.get(table, []) if _is_valid_columns_map(all_columns) else []
                if table_columns:
                    table_count += 1
                    column_count += len(table_columns)

                    # æ„å»ºè¡¨æè¿°ï¼ŒåŒ…å«è¯¦ç»†å­—æ®µä¿¡æ¯
                    detailed_cols = getattr(self, '_detailed_columns', {}).get(table, [])

                    if detailed_cols:
                        # ä½¿ç”¨è¯¦ç»†ä¿¡æ¯æ„å»ºæ›´ä¸°å¯Œçš„æè¿°
                        column_details = []
                        for col_info in detailed_cols:
                            name = col_info.get("name", "")
                            col_type = col_info.get("type", "")
                            comment = col_info.get("comment", "")
                            key_info = col_info.get("key", "")

                            # æ„å»ºå­—æ®µæè¿°
                            col_desc = name
                            if col_type:
                                col_desc += f"({col_type})"
                            if key_info == "PRI":
                                col_desc += "[ä¸»é”®]"
                            elif key_info:
                                col_desc += f"[{key_info}]"
                            if comment:
                                col_desc += f" '{comment}'"

                            column_details.append(col_desc)

                        columns_text = '; '.join(column_details)
                        schema_descriptions.append(f"**{table}** ({len(table_columns)}åˆ—):\n  {columns_text}")
                    else:
                        # å›é€€åˆ°ç®€å•åˆ—è¡¨
                        column_list = ', '.join(table_columns)
                        schema_descriptions.append(f"**{table}** ({len(table_columns)}åˆ—): {column_list}")
                else:
                    schema_descriptions.append(f"**{table}**: æ— åˆ—ä¿¡æ¯")

            # LLMå‹å¥½çš„schemaæ€»ç»“
            schema_summary = f"æ•°æ®åº“åŒ…å« {table_count} ä¸ªè¡¨ï¼Œå…± {column_count} ä¸ªåˆ—ã€‚\n" + \
                           "\n".join(schema_descriptions)

            result = {
                "success": True,
                "tables": tables,
                "columns": all_columns,
                "column_details": getattr(self, '_detailed_columns', {}),  # è¯¦ç»†å­—æ®µä¿¡æ¯
                "schema_summary": schema_summary,  # æ–°å¢ï¼šLLMå‹å¥½çš„æè¿°
                "table_count": table_count,
                "column_count": column_count,
                "schema_descriptions": schema_descriptions,  # æ–°å¢ï¼šç»“æ„åŒ–æè¿°
                "message": f"å·²è·å– {table_count} ä¸ªè¡¨çš„åˆ—ä¿¡æ¯ï¼Œå…± {column_count} ä¸ªåˆ—"
            }

            self._logger.info(f"ğŸ” [SchemaListColumnsTool] è¾“å‡ºç»“æœ: {table_count}ä¸ªè¡¨, {column_count}ä¸ªåˆ—")
            self._logger.info(f"ğŸ” [SchemaListColumnsTool] è¡¨å: {tables}")
            self._logger.info(f"ğŸ” [SchemaListColumnsTool] Schemaæ‘˜è¦å‰200å­—ç¬¦: {schema_summary[:200]}...")
            self._logger.info(f"ğŸ” [SchemaListColumnsTool] è¯¦ç»†åˆ—ä¿¡æ¯: {all_columns}")

            return result

        except Exception as e:
            self._logger.error(f"æŸ¥è¯¢åˆ—ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    async def _get_table_columns(self, data_source_service, table: str, context: Dict[str, Any]) -> List[str]:
        """è·å–æŒ‡å®šè¡¨çš„åˆ—ä¿¡æ¯"""
        try:
            data_source_config = context.get("data_source", {})

            # å°è¯•ä¸åŒçš„åˆ—æŸ¥è¯¢æ–¹æ³•
            if hasattr(data_source_service, 'get_table_columns'):
                result = await data_source_service.get_table_columns(table, data_source_config)
                return result if isinstance(result, list) else result.get("columns", [])
            elif hasattr(data_source_service, 'list_columns'):
                result = await data_source_service.list_columns(data_source_config, table)
                return result if isinstance(result, list) else result.get("columns", [])
            else:
                # é€šè¿‡SQLæŸ¥è¯¢è·å–åˆ—ä¿¡æ¯
                sql = f"SELECT * FROM {table} LIMIT 0"
                if hasattr(data_source_service, 'execute_query'):
                    result = await data_source_service.execute_query(sql, data_source_config)
                    return result.get("columns", [])

            return []

        except Exception as e:
            self._logger.error(f"è·å–è¡¨ {table} åˆ—ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return []


class EnhancedSchemaListColumnsTool(Tool):
    """å¢å¼ºçš„æ•°æ®åº“æ¶æ„æŸ¥è¯¢å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "enhanced_schema.list_columns"
        self.description = "å¢å¼ºçš„æ•°æ®åº“è¡¨åˆ—ä¿¡æ¯æŸ¥è¯¢ï¼ŒåŒ…å«ç±»å‹å’Œçº¦æŸä¿¡æ¯"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æŸ¥è¯¢å¢å¼ºçš„è¡¨åˆ—ä¿¡æ¯"""
        try:
            tables = input_data.get("tables", [])
            if not tables:
                tables = input_data.get("schema", {}).get("tables", [])

            if not tables:
                return {
                    "success": True,
                    "tables": [],
                    "schema_info": {},
                    "message": "æœªæŒ‡å®šæŸ¥è¯¢è¡¨"
                }

            # è·å–æ•°æ®æºæœåŠ¡
            data_source_service = getattr(self.container, 'data_source_service', None) or getattr(self.container, 'data_source', None)
            if not data_source_service:
                return {"success": False, "error": "Data source service not available"}

            # æŸ¥è¯¢æ¯ä¸ªè¡¨çš„è¯¦ç»†ä¿¡æ¯
            schema_info = {}
            for table in tables:
                try:
                    table_info = await self._get_enhanced_table_info(data_source_service, table, input_data)
                    schema_info[table] = table_info
                except Exception as e:
                    self._logger.warning(f"è·å–è¡¨ {table} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
                    schema_info[table] = {"columns": [], "types": {}, "constraints": {}}

            return {
                "success": True,
                "tables": tables,
                "schema_info": schema_info,
                "message": f"å·²è·å– {len(tables)} ä¸ªè¡¨çš„è¯¦ç»†æ¶æ„ä¿¡æ¯"
            }

        except Exception as e:
            self._logger.error(f"æŸ¥è¯¢å¢å¼ºåˆ—ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    async def _get_enhanced_table_info(self, data_source_service, table: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–è¡¨çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            data_source_config = context.get("data_source", {})

            # åŸºç¡€åˆ—ä¿¡æ¯
            columns = []
            column_types = {}
            constraints = {}

            # å°è¯•è·å–è¯¦ç»†æ¶æ„ä¿¡æ¯çš„SQL
            schema_sql = f"""
                SELECT
                    column_name,
                    data_type,
                    is_nullable,
                    column_default
                FROM information_schema.columns
                WHERE table_name = '{table}'
                ORDER BY ordinal_position
            """

            if hasattr(data_source_service, 'execute_query'):
                try:
                    result = await data_source_service.execute_query(schema_sql, data_source_config)
                    rows = result.get("rows", [])

                    for row in rows:
                        if len(row) >= 4:
                            col_name, data_type, is_nullable, default_val = row[0], row[1], row[2], row[3]
                            columns.append(col_name)
                            column_types[col_name] = data_type
                            constraints[col_name] = {
                                "nullable": is_nullable == "YES",
                                "default": default_val
                            }
                except Exception:
                    # å¦‚æœschemaæŸ¥è¯¢å¤±è´¥ï¼Œé™çº§åˆ°åŸºç¡€æŸ¥è¯¢
                    basic_result = await data_source_service.execute_query(f"SELECT * FROM {table} LIMIT 0", data_source_config)
                    columns = basic_result.get("columns", [])

            return {
                "columns": columns,
                "types": column_types,
                "constraints": constraints
            }

        except Exception as e:
            self._logger.error(f"è·å–è¡¨ {table} è¯¦ç»†ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return {"columns": [], "types": {}, "constraints": {}}


class SchemaListTablesTool(Tool):
    """åˆ—å‡ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨ï¼ˆä»…è¡¨åï¼Œä¸å«åˆ—ï¼‰ã€‚"""

    def __init__(self, container):
        super().__init__()
        self.name = "schema.list_tables"
        self.description = "åˆ—å‡ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨å"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            # ğŸ” [Debug] æ£€æŸ¥æ•°æ®æºé…ç½®
            conn_cfg = input_data.get("data_source", {})
            self._logger.info(f"ğŸ” [SchemaListTables Debug] input_data keys: {list(input_data.keys())}")
            self._logger.info(f"ğŸ” [SchemaListTables Debug] data_sourceå­˜åœ¨: {bool(conn_cfg)}")
            if conn_cfg:
                self._logger.info(f"ğŸ” [SchemaListTables Debug] data_source keys: {list(conn_cfg.keys())}")
                self._logger.info(f"ğŸ” [SchemaListTables Debug] host: {conn_cfg.get('host', 'N/A')}")
            else:
                self._logger.warning(f"âŒ [SchemaListTables Debug] ç¼ºå°‘data_sourceé…ç½®ï¼")

            if not (hasattr(self.container, 'data_source') and hasattr(self.container.data_source, 'run_query')):
                return {"success": False, "error": "Data source service not available"}

            result = await self.container.data_source.run_query(
                connection_config=conn_cfg,
                sql="SHOW TABLES",
                limit=10000
            )
            raw_rows = result.get("rows") or result.get("data") or []
            tables: List[str] = []
            for row in raw_rows:
                if isinstance(row, dict):
                    tables.append(list(row.values())[0])
                elif isinstance(row, list) and len(row) > 0:
                    tables.append(row[0])
                elif isinstance(row, str):
                    tables.append(row)

            tables = [t for t in tables if t]
            self._logger.info(f"ğŸ” [SchemaListTablesTool] å…±å‘ç° {len(tables)} ä¸ªè¡¨")
            return {
                "success": True,
                "tables": tables,
                "message": f"å·²å‘ç° {len(tables)} ä¸ªè¡¨"
            }
        except Exception as e:
            self._logger.error(f"åˆ—å‡ºè¡¨å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}


class UnifiedSchemaTool(Tool):
    """ç»Ÿä¸€çš„schemaæŸ¥è¯¢å·¥å…· - ä¸€æ¬¡è°ƒç”¨è·å–è¡¨åå’Œåˆ—ä¿¡æ¯"""

    def __init__(self, container):
        super().__init__()
        self.name = "schema.unified_query"
        self.description = "ç»Ÿä¸€æŸ¥è¯¢æ•°æ®åº“schemaä¿¡æ¯ï¼ŒåŒ…å«è¡¨åå’Œåˆ—ä¿¡æ¯"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç»Ÿä¸€æŸ¥è¯¢schemaä¿¡æ¯"""
        try:
            # æ£€æŸ¥æ•°æ®æº
            if not (hasattr(self.container, 'data_source') and hasattr(self.container.data_source, 'run_query')):
                return {"success": False, "error": "Data source service not available"}

            # è·å–æŒ‡å®šè¡¨æˆ–æ‰€æœ‰è¡¨
            target_tables = input_data.get("tables", [])
            if isinstance(target_tables, str):
                target_tables = [target_tables]

            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¡¨ï¼Œå…ˆè·å–æ‰€æœ‰è¡¨
            if not target_tables:
                try:
                    tables_result = await self.container.data_source.run_query(
                        connection_config=input_data.get("data_source", {}),
                        sql="SHOW TABLES",
                        limit=10000
                    )

                    raw_rows = tables_result.get("rows", []) or tables_result.get("data", []) or []
                    for row in raw_rows:
                        if isinstance(row, dict):
                            target_tables.append(list(row.values())[0])
                        elif isinstance(row, list) and len(row) > 0:
                            target_tables.append(row[0])
                        elif isinstance(row, str):
                            target_tables.append(row)

                    target_tables = [t for t in target_tables if t]
                    self._logger.info(f"ğŸ” [UnifiedSchemaTool] å‘ç° {len(target_tables)} ä¸ªè¡¨")

                except Exception as e:
                    self._logger.error(f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {e}")
                    return {"success": False, "error": f"Failed to get tables list: {str(e)}"}

            if not target_tables:
                return {
                    "success": True,
                    "tables": [],
                    "columns": {},
                    "schema_summary": "æ•°æ®åº“ä¸­æœªå‘ç°ä»»ä½•è¡¨",
                    "table_count": 0,
                    "column_count": 0,
                    "message": "æ•°æ®åº“ä¸­æœªå‘ç°ä»»ä½•è¡¨"
                }

            # è·å–æ¯ä¸ªè¡¨çš„åˆ—ä¿¡æ¯ï¼ˆåŒ…å«å¤šé‡å›é€€ï¼‰
            columns_map = {}
            conn_cfg = input_data.get("data_source", {})
            db_name = conn_cfg.get("database") or conn_cfg.get("db") or conn_cfg.get("schema")
            for table in target_tables:
                try:
                    # å°è¯•SHOW FULL COLUMNSæŸ¥è¯¢
                    result = await self.container.data_source.run_query(
                        connection_config=conn_cfg,
                        sql=f"SHOW FULL COLUMNS FROM {table}",
                        limit=1000
                    )

                    cols = []
                    rows = result.get("rows", []) or result.get("data", []) or []

                    for row in rows:
                        if isinstance(row, dict) and row.get("Field"):
                            cols.append(row.get("Field"))
                        elif isinstance(row, list) and len(row) > 0:
                            cols.append(str(row[0]))
                        elif isinstance(row, str):
                            cols.append(row)

                    columns_map[table] = cols
                    if cols:
                        self._logger.info(f"ğŸ” [UnifiedSchemaTool] è¡¨ {table}: {len(cols)} åˆ—")
                    if not cols:
                        # å›é€€1ï¼šDESC
                        try:
                            # DESCå‘½ä»¤ä¸æ”¯æŒLIMITï¼Œä¸ä¼ é€’limitå‚æ•°
                            desc_result = await self.container.data_source.run_query(
                                connection_config=conn_cfg,
                                sql=f"DESC {table}"
                            )
                            drows = desc_result.get("rows", []) or desc_result.get("data", []) or []

                            # å¤„ç†DataFrameå¯¹è±¡ï¼ˆUnifiedSchemaToolç‰ˆæœ¬ï¼‰
                            import pandas as pd
                            if isinstance(drows, pd.DataFrame):
                                if not drows.empty:
                                    drows = drows.to_dict('records')
                                else:
                                    drows = []
                            desc_cols = []
                            for row in drows:
                                if isinstance(row, dict) and row.get("Field"):
                                    desc_cols.append(row.get("Field"))
                                elif isinstance(row, list) and len(row) > 0:
                                    desc_cols.append(str(row[0]))
                            columns_map[table] = desc_cols
                            cols = desc_cols
                            if desc_cols:
                                self._logger.info(f"ğŸ” [UnifiedSchemaTool] è¡¨ {table} (via DESC): {len(desc_cols)} åˆ—")
                        except Exception as desc_e:
                            self._logger.warning(f"DESC {table} ä¹Ÿå¤±è´¥: {desc_e}")

                    if not cols:
                        # å›é€€2ï¼šinformation_schema.columns
                        try:
                            if db_name:
                                info_sql = (
                                    "SELECT COLUMN_NAME FROM information_schema.columns "
                                    f"WHERE TABLE_SCHEMA='{db_name}' AND TABLE_NAME='{table}' ORDER BY ORDINAL_POSITION"
                                )
                            else:
                                info_sql = (
                                    "SELECT COLUMN_NAME FROM information_schema.columns "
                                    f"WHERE TABLE_NAME='{table}' ORDER BY ORDINAL_POSITION"
                                )
                            info_result = await self.container.data_source.run_query(
                                connection_config=conn_cfg,
                                sql=info_sql,
                                limit=5000
                            )
                            irows = info_result.get("rows", []) or info_result.get("data", []) or []
                            info_cols = []
                            for row in irows:
                                if isinstance(row, dict):
                                    info_cols.append(row.get("COLUMN_NAME") or row.get("column_name") or list(row.values())[0])
                                elif isinstance(row, list) and len(row) > 0:
                                    info_cols.append(str(row[0]))
                                elif isinstance(row, str):
                                    info_cols.append(row)
                            columns_map[table] = info_cols
                            if info_cols:
                                self._logger.info(f"ğŸ” [UnifiedSchemaTool] è¡¨ {table} (via information_schema): {len(info_cols)} åˆ—")
                        except Exception as info_e:
                            self._logger.warning(f"information_schema æŸ¥è¯¢å¤±è´¥: table={table}, err={info_e}")

                except Exception as e:
                    self._logger.warning(f"è·å–è¡¨ {table} åˆ—ä¿¡æ¯å¤±è´¥: {e}")
                    columns_map[table] = []

            # æ„å»ºå‹å¥½çš„schemaæè¿°
            schema_descriptions = []
            table_count = 0
            total_column_count = 0

            for table in target_tables:
                table_cols = columns_map.get(table, [])
                if table_cols:
                    table_count += 1
                    total_column_count += len(table_cols)
                    col_list = ', '.join(table_cols[:10])  # åªæ˜¾ç¤ºå‰10åˆ—é¿å…å¤ªé•¿
                    if len(table_cols) > 10:
                        col_list += f"... (+{len(table_cols) - 10} more)"
                    schema_descriptions.append(f"**{table}** ({len(table_cols)}åˆ—): {col_list}")
                else:
                    schema_descriptions.append(f"**{table}**: æ— åˆ—ä¿¡æ¯")

            schema_summary = f"æ•°æ®åº“åŒ…å« {table_count} ä¸ªæœ‰æ•ˆè¡¨ï¼Œå…± {total_column_count} ä¸ªåˆ—ã€‚\n" + "\n".join(schema_descriptions)

            result = {
                "success": True,
                "tables": target_tables,
                "columns": columns_map,
                "schema_summary": schema_summary,
                "table_count": table_count,
                "column_count": total_column_count,
                "schema_descriptions": schema_descriptions,
                "message": f"å·²è·å– {table_count} ä¸ªè¡¨çš„schemaä¿¡æ¯ï¼Œå…± {total_column_count} ä¸ªåˆ—"
            }

            self._logger.info(f"ğŸ¯ [UnifiedSchemaTool] æˆåŠŸè¿”å›: {table_count}ä¸ªè¡¨, {total_column_count}ä¸ªåˆ—")
            return result

        except Exception as e:
            self._logger.error(f"ç»Ÿä¸€schemaæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}


class SchemaGetColumnsTool(Tool):
    """è·å–ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‡å®šè¡¨çš„åˆ—ä¿¡æ¯ï¼ˆå¼ºåˆ¶éœ€è¦ tablesï¼‰ã€‚"""

    def __init__(self, container):
        super().__init__()
        self.name = "schema.get_columns"
        self.description = "è·å–æŒ‡å®šè¡¨çš„åˆ—ä¿¡æ¯ï¼ˆSHOW FULL COLUMNSï¼‰"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            tables = input_data.get("tables")
            if isinstance(tables, str):
                tables = [tables]
            if not tables or not isinstance(tables, list):
                return {"success": False, "error": "tables_required", "message": "è¯·åœ¨ input.tables æŒ‡å®šè¦æŸ¥è¯¢çš„è¡¨åæ•°ç»„æˆ–å­—ç¬¦ä¸²"}

            if not (hasattr(self.container, 'data_source') and hasattr(self.container.data_source, 'run_query')):
                return {"success": False, "error": "Data source service not available"}

            columns_map: Dict[str, List[str]] = {}
            details_map: Dict[str, Dict[str, Dict[str, Any]]] = {}
            conn_cfg = input_data.get("data_source", {})
            db_name = conn_cfg.get("database") or conn_cfg.get("db") or conn_cfg.get("schema")

            # è¯¦ç»†æ£€æŸ¥è¿æ¥é…ç½®
            if not conn_cfg:
                self._logger.warning(f"ğŸ“‹ [SchemaGetColumns] âš ï¸ æ²¡æœ‰æä¾›data_sourceè¿æ¥é…ç½®ï¼Œæ— æ³•æŸ¥è¯¢çœŸå®æ•°æ®åº“")
                return {
                    "success": True,  # ä¿æŒæˆåŠŸçŠ¶æ€ä»¥é¿å…é˜»å¡
                    "tables": tables,
                    "columns": {table: [] for table in tables},
                    "column_details": {},
                    "schema_summary": {table: f"âš ï¸ è¡¨{table}: æ— è¿æ¥é…ç½®ï¼Œæœªè·å–åˆ—ä¿¡æ¯" for table in tables},
                    "table_count": len(tables),
                    "column_count": 0,
                    "schema_descriptions": [f"âš ï¸ ç¼ºå°‘æ•°æ®åº“è¿æ¥é…ç½®ï¼Œå»ºè®®æ£€æŸ¥data_source_idå‚æ•°"],
                    "message": f"âš ï¸ ç¼ºå°‘è¿æ¥é…ç½®ï¼Œè¿”å›ç©ºåˆ—ä¿¡æ¯ã€‚è¡¨æ•°é‡: {len(tables)}"
                }

            # è®°å½•è¿æ¥é…ç½®ä¿¡æ¯ï¼ˆå®‰å…¨æ—¥å¿—ï¼‰
            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] è¿æ¥é…ç½®é”®: {list(conn_cfg.keys())}")
            if conn_cfg.get("host"):
                self._logger.info(f"ğŸ“‹ [SchemaGetColumns] è¿æ¥ç›®æ ‡: {conn_cfg.get('host')}:{conn_cfg.get('port', 'default')}")
            if db_name:
                self._logger.info(f"ğŸ“‹ [SchemaGetColumns] ç›®æ ‡æ•°æ®åº“: {db_name}")

            for table in tables:
                try:
                    query_sql = f"SHOW FULL COLUMNS FROM {table}"
                    self._logger.info(f"ğŸ“‹ [SchemaGetColumns] æ‰§è¡ŒæŸ¥è¯¢: {query_sql}")
                    # SHOW FULL COLUMNSä¸æ”¯æŒLIMITï¼Œä¸ä¼ é€’limitå‚æ•°
                    result = await self.container.data_source.run_query(
                        connection_config=conn_cfg,
                        sql=query_sql
                    )
                    self._logger.info(f"ğŸ“‹ [SchemaGetColumns] æŸ¥è¯¢ç»“æœé”®: {list(result.keys()) if isinstance(result, dict) else 'Not dict'}")

                    cols: List[str] = []
                    details: Dict[str, Dict[str, Any]] = {}
                    rows = result.get("rows", []) or result.get("data", []) or []

                    # å¤„ç†DataFrameå¯¹è±¡
                    import pandas as pd
                    if isinstance(rows, pd.DataFrame):
                        if not rows.empty:
                            rows = rows.to_dict('records')  # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                        else:
                            rows = []

                    row_count = len(rows) if hasattr(rows, '__len__') else 0
                    self._logger.info(f"ğŸ“‹ [SchemaGetColumns] è¡¨{table}è¿”å›{row_count}è¡Œæ•°æ®")
                    if row_count > 0:
                        self._logger.info(f"ğŸ“‹ [SchemaGetColumns] ç¬¬ä¸€è¡Œæ ·ä¾‹: {rows[0]}")
                    else:
                        self._logger.warning(f"ğŸ“‹ [SchemaGetColumns] è¡¨{table}æ²¡æœ‰è¿”å›åˆ—ä¿¡æ¯ï¼Œresultç»“æ„: {result}")

                    for row in rows:
                        if isinstance(row, dict) and row.get("Field"):
                            col = row.get("Field")
                            cols.append(col)
                            details[col] = {
                                "type": row.get("Type"),
                                "nullable": True if str(row.get("Null")).upper() == "YES" else (False if str(row.get("Null")).upper() == "NO" else None),
                                "key": row.get("Key"),
                                "default": row.get("Default"),
                                "extra": row.get("Extra"),
                                "comment": row.get("Comment"),
                            }
                        elif isinstance(row, list) and len(row) > 0:
                            cols.append(row[0])
                    columns_map[table] = cols
                    if details:
                        details_map[table] = details
                    if not cols:
                        # å°è¯• DESC ä½œä¸ºå›é€€
                        self._logger.info(f"ğŸ“‹ [SchemaGetColumns] SHOW FULL COLUMNSå¤±è´¥ï¼Œå°è¯•DESCå›é€€ - è¡¨{table}")
                        try:
                            desc_sql = f"DESC {table}"
                            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] æ‰§è¡ŒDESCæŸ¥è¯¢: {desc_sql}")
                            # DESCå‘½ä»¤ä¸æ”¯æŒLIMITï¼Œä¸ä¼ é€’limitå‚æ•°
                            desc_result = await self.container.data_source.run_query(
                                connection_config=conn_cfg,
                                sql=desc_sql
                            )
                            drows = desc_result.get("rows", []) or desc_result.get("data", []) or []

                            # å¤„ç†DataFrameå¯¹è±¡
                            if isinstance(drows, pd.DataFrame):
                                if not drows.empty:
                                    drows = drows.to_dict('records')
                                else:
                                    drows = []

                            drow_count = len(drows) if hasattr(drows, '__len__') else 0
                            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] DESCæŸ¥è¯¢è¿”å›{drow_count}è¡Œ")
                            desc_cols: List[str] = []
                            ddetails: Dict[str, Dict[str, Any]] = {}
                            for row in drows:
                                if isinstance(row, dict) and row.get("Field"):
                                    col = row.get("Field")
                                    desc_cols.append(col)
                                    ddetails[col] = {
                                        "type": row.get("Type"),
                                        "nullable": True if str(row.get("Null")).upper() == "YES" else (False if str(row.get("Null")).upper() == "NO" else None),
                                        "key": row.get("Key"),
                                        "default": row.get("Default"),
                                        "extra": row.get("Extra"),
                                        "comment": None,
                                    }
                                elif isinstance(row, list) and len(row) > 0:
                                    desc_cols.append(row[0])
                            columns_map[table] = desc_cols
                            cols = desc_cols
                            if ddetails:
                                details_map[table] = ddetails
                        except Exception:
                            pass
                    if not cols:
                        # æœ€åå›é€€åˆ° information_schema.columns
                        try:
                            if db_name:
                                info_sql = (
                                    "SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_DEFAULT, COLUMN_COMMENT "
                                    "FROM information_schema.columns "
                                    f"WHERE TABLE_SCHEMA='{db_name}' AND TABLE_NAME='{table}' ORDER BY ORDINAL_POSITION"
                                )
                            else:
                                info_sql = (
                                    "SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_DEFAULT, COLUMN_COMMENT "
                                    "FROM information_schema.columns "
                                    f"WHERE TABLE_NAME='{table}' ORDER BY ORDINAL_POSITION"
                                )
                            info_result = await self.container.data_source.run_query(
                                connection_config=conn_cfg,
                                sql=info_sql,
                                limit=5000
                            )
                            irows = info_result.get("rows", []) or info_result.get("data", []) or []
                            info_cols: List[str] = []
                            idetails: Dict[str, Dict[str, Any]] = {}
                            for row in irows:
                                if isinstance(row, dict):
                                    col = row.get("COLUMN_NAME") or row.get("column_name") or list(row.values())[0]
                                    info_cols.append(col)
                                    idetails[col] = {
                                        "type": row.get("DATA_TYPE") or row.get("data_type"),
                                        "nullable": True if str(row.get("IS_NULLABLE")).upper() == "YES" else (False if str(row.get("IS_NULLABLE")).upper() == "NO" else None),
                                        "key": None,
                                        "default": row.get("COLUMN_DEFAULT"),
                                        "extra": None,
                                        "comment": row.get("COLUMN_COMMENT") or row.get("column_comment"),
                                    }
                                elif isinstance(row, list) and len(row) > 0:
                                    col = str(row[0])
                                    info_cols.append(col)
                            columns_map[table] = info_cols
                            if idetails:
                                details_map[table] = idetails
                        except Exception:
                            self._logger.warning(f"information_schema æŸ¥è¯¢å¤±è´¥: table={table}")
                except Exception as e:
                    self._logger.error(f"ğŸ“‹ [SchemaGetColumns] è·å–è¡¨ {table} åˆ—å¤±è´¥: {e}")
                    self._logger.error(f"ğŸ“‹ [SchemaGetColumns] å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
                    columns_map[table] = []

            # æ„é€ ç®€è¦æ‘˜è¦
            schema_descriptions = []
            total_cols = 0
            for t, cols in columns_map.items():
                total_cols += len(cols)
                if cols:
                    # ä½¿ç”¨è¯¦æƒ…ï¼ˆè‹¥æœ‰ï¼‰å±•ç¤ºç±»å‹/æ³¨é‡Šç‰‡æ®µ
                    det = details_map.get(t, {})
                    items: List[str] = []
                    for col in cols[:10]:
                        meta = det.get(col) or {}
                        tp = meta.get("type") or ""
                        cmt = meta.get("comment") or ""
                        cmt_short = (cmt[:20] + "â€¦") if (isinstance(cmt, str) and len(cmt) > 20) else cmt
                        if tp or cmt_short:
                            items.append(f"{col}({tp}{', '+cmt_short if cmt_short else ''})")
                        else:
                            items.append(col)
                    schema_descriptions.append(f"**{t}** ({len(cols)}åˆ—): {', '.join(items)}{'...' if len(cols) > 10 else ''}")
                else:
                    schema_descriptions.append(f"**{t}**: æ— åˆ—ä¿¡æ¯")

            summary = f"å…± {len(columns_map)} å¼ è¡¨, åˆè®¡ {total_cols} åˆ—\n" + "\n".join(schema_descriptions)

            # æ·»åŠ è¯¦ç»†è°ƒè¯•æ—¥å¿—
            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] æˆåŠŸè·å– {len(columns_map)} å¼ è¡¨çš„åˆ—ä¿¡æ¯")
            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] è¡¨å: {list(columns_map.keys())}")
            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] åˆ—ä¿¡æ¯æ‘˜è¦: {columns_map}")
            self._logger.info(f"ğŸ“‹ [SchemaGetColumns] è¯¦ç»†å­—æ®µä¿¡æ¯: {len(details_map)} å¼ è¡¨æœ‰è¯¦æƒ…")

            return {
                "success": True,
                "tables": list(columns_map.keys()),
                "columns": columns_map,
                "column_details": details_map,
                "schema_summary": summary,
                "table_count": len(columns_map),
                "column_count": total_cols,
                "schema_descriptions": schema_descriptions,
                "message": f"åˆ—ä¿¡æ¯è·å–å®Œæˆï¼Œ{len(columns_map)}å¼ è¡¨ï¼Œ{total_cols}åˆ—"
            }
        except Exception as e:
            self._logger.error(f"è·å–åˆ—ä¿¡æ¯å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
