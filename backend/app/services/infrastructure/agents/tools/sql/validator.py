from __future__ import annotations

from loom.interfaces.tool import BaseTool
"""
SQL éªŒè¯å·¥å…·

éªŒè¯ SQL æŸ¥è¯¢çš„è¯­æ³•æ­£ç¡®æ€§å’Œé€»è¾‘åˆç†æ€§
æ”¯æŒå¤šç§æ•°æ®åº“çš„è¯­æ³•æ£€æŸ¥
"""


import logging
import re
from typing import Any, Dict, List, Optional, Union, Tuple, Literal
from dataclasses import dataclass
from enum import Enum
from pydantic import BaseModel, Field


from ...types import ToolCategory, ContextInfo

logger = logging.getLogger(__name__)


class ValidationLevel(str, Enum):
    """éªŒè¯çº§åˆ«"""
    BASIC = "basic"      # åŸºç¡€è¯­æ³•æ£€æŸ¥
    STRICT = "strict"    # ä¸¥æ ¼è¯­æ³•æ£€æŸ¥
    COMPREHENSIVE = "comprehensive"  # å…¨é¢æ£€æŸ¥


class ValidationResult(str, Enum):
    """éªŒè¯ç»“æœ"""
    VALID = "valid"
    INVALID = "invalid"
    WARNING = "warning"


@dataclass
class ValidationIssue:
    """éªŒè¯é—®é¢˜"""
    level: ValidationResult
    message: str
    line: Optional[int] = None
    column: Optional[int] = None
    suggestion: Optional[str] = None
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class ValidationReport:
    """éªŒè¯æŠ¥å‘Š"""
    is_valid: bool
    issues: List[ValidationIssue]
    warnings: List[ValidationIssue]
    errors: List[ValidationIssue]
    suggestions: List[str]
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class SQLValidatorTool(BaseTool):
    """SQL éªŒè¯å·¥å…·"""
    
    def __init__(self, container: Any, connection_config: Optional[Dict[str, Any]] = None):
        """
        Args:
            container: æœåŠ¡å®¹å™¨
            connection_config: æ•°æ®æºè¿æ¥é…ç½®ï¼ˆåœ¨åˆå§‹åŒ–æ—¶æ³¨å…¥ï¼Œä¼˜å…ˆä½¿ç”¨å†…éƒ¨çš„é…ç½®ï¼‰
        """
        super().__init__()
        self.name = "sql_validator"
        self.category = ToolCategory.SQL
        self.description = "éªŒè¯ SQL æŸ¥è¯¢çš„è¯­æ³•æ­£ç¡®æ€§å’Œé€»è¾‘åˆç†æ€§"
        self.container = container
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨åˆå§‹åŒ–æ—¶æ³¨å…¥ connection_config
        self._connection_config = connection_config
        
        # ä½¿ç”¨ Pydantic å®šä¹‰å‚æ•°æ¨¡å¼ï¼ˆargs_schemaï¼‰
        class SQLValidatorArgs(BaseModel):
            sql: str = Field(description="è¦éªŒè¯çš„ SQL æŸ¥è¯¢")
            validation_level: Literal["basic", "strict", "comprehensive"] = Field(
                default="comprehensive", description="éªŒè¯çº§åˆ«"
            )
            check_syntax: bool = Field(default=True, description="æ˜¯å¦æ£€æŸ¥è¯­æ³•")
            check_semantics: bool = Field(default=True, description="æ˜¯å¦æ£€æŸ¥è¯­ä¹‰")
            check_performance: bool = Field(default=False, description="æ˜¯å¦æ£€æŸ¥æ€§èƒ½")
            schema_info: Optional[Dict[str, Any]] = Field(default=None, description="Schema ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰")

        self.args_schema = SQLValidatorArgs
        
        # SQL å…³é”®å­—
        self.sql_keywords = {
            "SELECT", "FROM", "WHERE", "GROUP BY", "HAVING", "ORDER BY", "LIMIT",
            "INSERT", "UPDATE", "DELETE", "CREATE", "ALTER", "DROP",
            "JOIN", "INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "FULL JOIN",
            "UNION", "UNION ALL", "INTERSECT", "EXCEPT",
            "AND", "OR", "NOT", "IN", "EXISTS", "BETWEEN", "LIKE", "IS NULL", "IS NOT NULL",
            "COUNT", "SUM", "AVG", "MIN", "MAX", "DISTINCT"
        }
        
        # æ•°æ®ç±»å‹
        self.data_types = {
            "INT", "INTEGER", "BIGINT", "SMALLINT", "TINYINT",
            "DECIMAL", "NUMERIC", "FLOAT", "DOUBLE", "REAL",
            "VARCHAR", "CHAR", "TEXT", "LONGTEXT",
            "DATE", "DATETIME", "TIMESTAMP", "TIME",
            "BOOLEAN", "BOOL", "BLOB", "JSON"
        }
    
    def get_schema(self) -> Dict[str, Any]:
        """è·å–å·¥å…·å‚æ•°æ¨¡å¼ï¼ˆåŸºäº args_schema ç”Ÿæˆï¼‰"""
        try:
            parameters = self.args_schema.model_json_schema()
        except Exception:
            parameters = self.args_schema.schema()  # type: ignore[attr-defined]
        return {
            "type": "function",
            "function": {
                "name": "sql_validator",
                "description": "éªŒè¯ SQL æŸ¥è¯¢çš„è¯­æ³•æ­£ç¡®æ€§å’Œé€»è¾‘åˆç†æ€§",
                "parameters": parameters,
            },
        }
    
    async def run(
        self,
        sql: str,
        connection_config: Optional[Dict[str, Any]] = None,
        validation_level: str = "comprehensive",
        check_syntax: bool = True,
        check_semantics: bool = True,
        check_performance: bool = False,
        schema_info: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ SQL éªŒè¯
        
        Args:
            sql: è¦éªŒè¯çš„ SQL æŸ¥è¯¢
            connection_config: æ•°æ®æºè¿æ¥é…ç½®ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨åˆå§‹åŒ–æ—¶æ³¨å…¥çš„é…ç½®ï¼‰
            validation_level: éªŒè¯çº§åˆ«
            check_syntax: æ˜¯å¦æ£€æŸ¥è¯­æ³•
            check_semantics: æ˜¯å¦æ£€æŸ¥è¯­ä¹‰
            check_performance: æ˜¯å¦æ£€æŸ¥æ€§èƒ½
            schema_info: Schema ä¿¡æ¯
            
        Returns:
            Dict[str, Any]: éªŒè¯ç»“æœ
        """
        logger.info(f"ğŸ” [SQLValidatorTool] éªŒè¯ SQL")
        logger.info(f"   éªŒè¯çº§åˆ«: {validation_level}")
        logger.info(f"   SQL é•¿åº¦: {len(sql)} å­—ç¬¦")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨åˆå§‹åŒ–æ—¶æ³¨å…¥çš„ connection_configï¼Œå…è®¸ä» kwargs ä¸´æ—¶ä¼ å…¥ä»¥ä¾¿éªŒè¯/æµ‹è¯•
        connection_config = self._connection_config or connection_config or kwargs.get("connection_config")
        if not connection_config:
            return {
                "success": False,
                "error": "æœªé…ç½®æ•°æ®æºè¿æ¥ï¼Œè¯·åœ¨åˆå§‹åŒ–å·¥å…·æ—¶æä¾› connection_config",
                "report": None
            }
        
        try:
            # ğŸ”§ åœ¨éªŒè¯é˜¶æ®µå®‰å…¨æ›¿æ¢æ—¶é—´å ä½ç¬¦ï¼Œé¿å…è¯­æ³•æ ¡éªŒè¯¯æŠ¥
            resolved_sql, resolution_meta = self._resolve_time_placeholders(sql, kwargs)

            # è·å– Schema ä¿¡æ¯
            if schema_info is None:
                # ğŸ”¥ ä¿®å¤ï¼šä»SQLä¸­æå–è¡¨åï¼Œä¼ ç»™SchemaRetrievalTool
                table_names = self._extract_table_names(resolved_sql)
                schema_info = await self._get_schema_info(connection_config, table_names=table_names)
            
            # æ‰§è¡ŒéªŒè¯
            report = await self._validate_sql(
                resolved_sql, validation_level, check_syntax, check_semantics, 
                check_performance, schema_info
            )
            
            return {
                "success": True,
                "report": report,
                "metadata": {
                    "validation_level": validation_level,
                    "sql_length": len(sql),
                    "resolved_sql_length": len(resolved_sql),
                    "resolved_sql": resolved_sql,
                    "placeholder_resolution": resolution_meta,
                    "issues_count": len(report.issues),
                    "warnings_count": len(report.warnings),
                    "errors_count": len(report.errors)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ [SQLValidatorTool] éªŒè¯å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "report": None
            }

    def _resolve_time_placeholders(self, sql: str, kwargs: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """å°† {{start_date}} / {{end_date}} åœ¨éªŒè¯é˜¶æ®µæ›¿æ¢ä¸ºå®‰å…¨çš„å…·ä½“æ—¥æœŸã€‚

        ä¼˜å…ˆä» kwargs['context'] æˆ– kwargs['task_context'] æˆ– kwargs['template_context'] è·å–ï¼›
        å¯æ¥å—çš„é”®ï¼š('start_date','end_date') æˆ– ('time_window': {'start','end'})ã€‚
        è‹¥å‡ä¸å¯ç”¨ï¼Œä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼ï¼Œä¸å½±å“æœ€ç»ˆå­˜å‚¨ï¼ˆä»…æ ¡éªŒé˜¶æ®µä½¿ç”¨ï¼‰ã€‚
        """
        original_sql = sql
        meta: Dict[str, Any] = {"source": None, "used_defaults": False}

        # å¿«é€Ÿè·¯å¾„ï¼šæ— å ä½ç¬¦
        if "{{start_date}}" not in sql and "{{end_date}}" not in sql:
            return sql, {"changed": False}

        # æ”¶é›†ä¸Šä¸‹æ–‡
        ctx = kwargs.get("context") or {}
        task_ctx = kwargs.get("task_context") or {}
        tpl_ctx = kwargs.get("template_context") or {}

        def pick(k: str) -> Optional[str]:
            return (ctx.get(k) or task_ctx.get(k) or tpl_ctx.get(k)) if any([ctx, task_ctx, tpl_ctx]) else None

        start = pick("start_date")
        end = pick("end_date")

        # time_window ç»“æ„æ”¯æŒ
        tw = pick("time_window") if isinstance(pick("time_window"), dict) else None
        if isinstance(tw, dict):
            start = start or tw.get("start") or tw.get("from")
            end = end or tw.get("end") or tw.get("to")

        # é»˜è®¤å®‰å…¨å€¼ï¼ˆä»…ç”¨äºéªŒè¯é˜¶æ®µï¼‰
        if not start or not end:
            start = start or "2024-01-01"
            end = end or "2024-01-31"
            meta["used_defaults"] = True

        # æ‰§è¡Œæ›¿æ¢
        resolved = original_sql.replace("{{start_date}}", str(start)).replace("{{end_date}}", str(end))
        meta.update({"start_date": str(start), "end_date": str(end), "changed": resolved != original_sql})
        return resolved, meta
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """å‘åå…¼å®¹çš„executeæ–¹æ³•"""
        return await self.run(**kwargs)
    
    async def _get_schema_info(self, connection_config: Dict[str, Any], table_names: Optional[List[str]] = None) -> Dict[str, Any]:
        """è·å– Schema ä¿¡æ¯
        
        Args:
            connection_config: è¿æ¥é…ç½®
            table_names: å¯é€‰çš„è¡¨ååˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™åªè·å–è¿™äº›è¡¨çš„ç»“æ„ä¿¡æ¯
        """
        try:
            from ..schema.retrieval import create_schema_retrieval_tool

            # ğŸ”¥ ä¿®å¤ï¼šä¼ é€’ connection_config ä»¥ä¾¿å·¥å…·èƒ½æ­£ç¡®åˆå§‹åŒ–
            retrieval_tool = create_schema_retrieval_tool(
                self.container,
                connection_config=self._connection_config or connection_config
            )

            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœæä¾›äº†è¡¨åï¼Œä¼ å…¥SchemaRetrievalToolï¼›å¦åˆ™å°è¯•ä»ä¸Šä¸‹æ–‡è·å–
            logger.info(f"ğŸ” [SQLéªŒè¯] å¼€å§‹æ£€ç´¢ Schema ä¿¡æ¯")
            if table_names:
                logger.info(f"   è¡¨å: {table_names}")
            else:
                logger.info(f"   è¡¨å: None (å°†ä»ä¸Šä¸‹æ–‡è·å–)")

            result = await retrieval_tool.run(
                table_names=table_names,  # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼ å…¥ä»SQLä¸­æå–çš„è¡¨å
                include_relationships=True,
                include_constraints=True,
                format="detailed"
            )
            
            if result.get("success"):
                return result.get("result", {})
            else:
                logger.warning(f"âš ï¸ è·å– Schema ä¿¡æ¯å¤±è´¥: {result.get('error')}")
                # ğŸ”¥ å¦‚æœSchemaRetrievalToolå¤±è´¥ä¸”æ²¡æœ‰è¡¨åï¼Œå°è¯•è¿”å›ç©ºå­—å…¸è®©éªŒè¯ç»§ç»­è¿›è¡Œ
                if not table_names:
                    logger.warning(f"âš ï¸ SchemaRetrievalToolæ— æ³•ä»ä¸Šä¸‹æ–‡è·å–è¡¨åï¼Œå°†ä½¿ç”¨ç©ºSchemaä¿¡æ¯ç»§ç»­éªŒè¯")
                    return {}
                else:
                    logger.error(f"âŒ SchemaRetrievalToolå¤±è´¥ï¼Œå³ä½¿ä¼ å…¥äº†è¡¨å: {result.get('error')}")
                    return {}
                
        except Exception as e:
            logger.warning(f"âš ï¸ è·å– Schema ä¿¡æ¯å¤±è´¥: {e}")
            # ğŸ”¥ å³ä½¿å¤±è´¥ï¼Œä¹Ÿè¿”å›ç©ºå­—å…¸è®©éªŒè¯ç»§ç»­è¿›è¡Œï¼ˆä½¿ç”¨è¯­æ³•éªŒè¯ï¼‰
            return {}
    
    async def _validate_sql(
        self,
        sql: str,
        validation_level: str,
        check_syntax: bool,
        check_semantics: bool,
        check_performance: bool,
        schema_info: Dict[str, Any]
    ) -> ValidationReport:
        """éªŒè¯ SQL"""
        issues = []
        
        # è¯­æ³•æ£€æŸ¥
        if check_syntax:
            syntax_issues = self._check_syntax(sql)
            issues.extend(syntax_issues)
        
        # è¯­ä¹‰æ£€æŸ¥
        if check_semantics:
            semantic_issues = self._check_semantics(sql, schema_info)
            issues.extend(semantic_issues)
        
        # æ€§èƒ½æ£€æŸ¥
        if check_performance:
            performance_issues = self._check_performance(sql, schema_info)
            issues.extend(performance_issues)
        
        # åˆ†ç±»é—®é¢˜
        errors = [issue for issue in issues if issue.level == ValidationResult.INVALID]
        warnings = [issue for issue in issues if issue.level == ValidationResult.WARNING]
        
        # æå–å»ºè®®
        suggestions = [issue.suggestion for issue in issues if issue.suggestion]
        
        # åˆ¤æ–­æ•´ä½“æœ‰æ•ˆæ€§
        is_valid = len(errors) == 0
        
        return ValidationReport(
            is_valid=is_valid,
            issues=issues,
            warnings=warnings,
            errors=errors,
            suggestions=suggestions
        )
    
    def _check_syntax(self, sql: str) -> List[ValidationIssue]:
        """æ£€æŸ¥è¯­æ³•"""
        issues = []
        
        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
        sql_upper = sql.upper().strip()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if not sql.strip():
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="SQL æŸ¥è¯¢ä¸èƒ½ä¸ºç©º"
            ))
            return issues
        
        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        if not any(keyword in sql_upper for keyword in ["SELECT", "INSERT", "UPDATE", "DELETE", "CREATE", "ALTER", "DROP"]):
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="SQL æŸ¥è¯¢å¿…é¡»åŒ…å«æœ‰æ•ˆçš„ SQL è¯­å¥",
                suggestion="è¯·ç¡®ä¿æŸ¥è¯¢åŒ…å« SELECTã€INSERTã€UPDATEã€DELETEã€CREATEã€ALTER æˆ– DROP è¯­å¥"
            ))
        
        # æ£€æŸ¥æ‹¬å·åŒ¹é…
        if not self._check_parentheses(sql):
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="æ‹¬å·ä¸åŒ¹é…",
                suggestion="è¯·æ£€æŸ¥å¹¶ä¿®æ­£æ‹¬å·çš„åŒ¹é…"
            ))
        
        # æ£€æŸ¥å¼•å·åŒ¹é…
        if not self._check_quotes(sql):
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="å¼•å·ä¸åŒ¹é…",
                suggestion="è¯·æ£€æŸ¥å¹¶ä¿®æ­£å¼•å·çš„åŒ¹é…"
            ))
        
        # æ£€æŸ¥åˆ†å·
        if sql.strip().endswith(';'):
            issues.append(ValidationIssue(
                level=ValidationResult.WARNING,
                message="å»ºè®®ç§»é™¤æœ«å°¾çš„åˆ†å·",
                suggestion="åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæœ«å°¾çš„åˆ†å·æ˜¯ä¸å¿…è¦çš„"
            ))
        
        # æ£€æŸ¥ SELECT è¯­å¥ç»“æ„
        if sql_upper.startswith("SELECT"):
            select_issues = self._check_select_syntax(sql)
            issues.extend(select_issues)
        
        # æ£€æŸ¥ INSERT è¯­å¥ç»“æ„
        elif sql_upper.startswith("INSERT"):
            insert_issues = self._check_insert_syntax(sql)
            issues.extend(insert_issues)
        
        # æ£€æŸ¥ UPDATE è¯­å¥ç»“æ„
        elif sql_upper.startswith("UPDATE"):
            update_issues = self._check_update_syntax(sql)
            issues.extend(update_issues)
        
        # æ£€æŸ¥ DELETE è¯­å¥ç»“æ„
        elif sql_upper.startswith("DELETE"):
            delete_issues = self._check_delete_syntax(sql)
            issues.extend(delete_issues)
        
        return issues
    
    def _check_semantics(self, sql: str, schema_info: Dict[str, Any]) -> List[ValidationIssue]:
        """æ£€æŸ¥è¯­ä¹‰"""
        issues = []
        
        # æå–è¡¨å
        table_names = self._extract_table_names(sql)
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        available_tables = [table.get("name", "") for table in schema_info.get("tables", [])]
        for table_name in table_names:
            if table_name and table_name not in available_tables:
                issues.append(ValidationIssue(
                    level=ValidationResult.INVALID,
                    message=f"è¡¨ '{table_name}' ä¸å­˜åœ¨",
                    suggestion=f"è¯·æ£€æŸ¥è¡¨åæ˜¯å¦æ­£ç¡®ï¼Œå¯ç”¨è¡¨: {', '.join(available_tables[:5])}"
                ))
        
        # æå–åˆ—å
        column_names = self._extract_column_names(sql)
        
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        available_columns = schema_info.get("columns", [])
        for column_name in column_names:
            if column_name and not self._column_exists(column_name, available_columns):
                issues.append(ValidationIssue(
                    level=ValidationResult.INVALID,
                    message=f"åˆ— '{column_name}' ä¸å­˜åœ¨",
                    suggestion="è¯·æ£€æŸ¥åˆ—åæ˜¯å¦æ­£ç¡®"
                ))
        
        # æ£€æŸ¥ JOIN æ¡ä»¶
        join_issues = self._check_joins(sql, schema_info)
        issues.extend(join_issues)
        
        return issues
    
    def _check_performance(self, sql: str, schema_info: Dict[str, Any]) -> List[ValidationIssue]:
        """æ£€æŸ¥æ€§èƒ½"""
        issues = []
        
        sql_upper = sql.upper()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ LIMIT
        if "SELECT" in sql_upper and "LIMIT" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.WARNING,
                message="å»ºè®®æ·»åŠ  LIMIT å­å¥é™åˆ¶ç»“æœæ•°é‡",
                suggestion="æ·»åŠ  LIMIT å­å¥å¯ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½"
            ))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ WHERE æ¡ä»¶
        if "SELECT" in sql_upper and "WHERE" not in sql_upper and "JOIN" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.WARNING,
                message="å»ºè®®æ·»åŠ  WHERE æ¡ä»¶è¿‡æ»¤æ•°æ®",
                suggestion="æ·»åŠ é€‚å½“çš„ WHERE æ¡ä»¶å¯ä»¥å‡å°‘æ‰«æçš„æ•°æ®é‡"
            ))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç´¢å¼•
        indexes = schema_info.get("indexes", [])
        table_names = self._extract_table_names(sql)
        
        for table_name in table_names:
            table_indexes = [idx for idx in indexes if idx.get("table_name") == table_name]
            if not table_indexes:
                issues.append(ValidationIssue(
                    level=ValidationResult.WARNING,
                    message=f"è¡¨ '{table_name}' æ²¡æœ‰ç´¢å¼•",
                    suggestion=f"è€ƒè™‘ä¸ºè¡¨ '{table_name}' æ·»åŠ é€‚å½“çš„ç´¢å¼•"
                ))
        
        # æ£€æŸ¥å­æŸ¥è¯¢
        if "SELECT" in sql_upper and sql_upper.count("SELECT") > 1:
            issues.append(ValidationIssue(
                level=ValidationResult.WARNING,
                message="æŸ¥è¯¢åŒ…å«å­æŸ¥è¯¢ï¼Œå¯èƒ½å½±å“æ€§èƒ½",
                suggestion="è€ƒè™‘ä½¿ç”¨ JOIN æ›¿ä»£å­æŸ¥è¯¢ä»¥æé«˜æ€§èƒ½"
            ))
        
        return issues
    
    def _check_parentheses(self, sql: str) -> bool:
        """æ£€æŸ¥æ‹¬å·åŒ¹é…"""
        stack = []
        for char in sql:
            if char == '(':
                stack.append(char)
            elif char == ')':
                if not stack:
                    return False
                stack.pop()
        return len(stack) == 0
    
    def _check_quotes(self, sql: str) -> bool:
        """æ£€æŸ¥å¼•å·åŒ¹é…"""
        single_quotes = sql.count("'")
        double_quotes = sql.count('"')
        return single_quotes % 2 == 0 and double_quotes % 2 == 0
    
    def _check_select_syntax(self, sql: str) -> List[ValidationIssue]:
        """æ£€æŸ¥ SELECT è¯­å¥è¯­æ³•"""
        issues = []
        sql_upper = sql.upper()
        
        # æ£€æŸ¥ FROM å­å¥
        if "FROM" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="SELECT è¯­å¥ç¼ºå°‘ FROM å­å¥",
                suggestion="è¯·æ·»åŠ  FROM å­å¥æŒ‡å®šè¦æŸ¥è¯¢çš„è¡¨"
            ))
        
        # æ£€æŸ¥ GROUP BY å’Œ HAVING
        if "HAVING" in sql_upper and "GROUP BY" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="HAVING å­å¥éœ€è¦ GROUP BY å­å¥",
                suggestion="è¯·æ·»åŠ  GROUP BY å­å¥æˆ–ç§»é™¤ HAVING å­å¥"
            ))
        
        return issues
    
    def _check_insert_syntax(self, sql: str) -> List[ValidationIssue]:
        """æ£€æŸ¥ INSERT è¯­å¥è¯­æ³•"""
        issues = []
        sql_upper = sql.upper()
        
        # æ£€æŸ¥ INTO å…³é”®å­—
        if "INTO" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="INSERT è¯­å¥ç¼ºå°‘ INTO å…³é”®å­—",
                suggestion="è¯·æ·»åŠ  INTO å…³é”®å­—"
            ))
        
        # æ£€æŸ¥ VALUES æˆ– SELECT
        if "VALUES" not in sql_upper and "SELECT" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="INSERT è¯­å¥ç¼ºå°‘ VALUES æˆ– SELECT å­å¥",
                suggestion="è¯·æ·»åŠ  VALUES æˆ– SELECT å­å¥"
            ))
        
        return issues
    
    def _check_update_syntax(self, sql: str) -> List[ValidationIssue]:
        """æ£€æŸ¥ UPDATE è¯­å¥è¯­æ³•"""
        issues = []
        sql_upper = sql.upper()
        
        # æ£€æŸ¥ SET å­å¥
        if "SET" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="UPDATE è¯­å¥ç¼ºå°‘ SET å­å¥",
                suggestion="è¯·æ·»åŠ  SET å­å¥æŒ‡å®šè¦æ›´æ–°çš„åˆ—"
            ))
        
        return issues
    
    def _check_delete_syntax(self, sql: str) -> List[ValidationIssue]:
        """æ£€æŸ¥ DELETE è¯­å¥è¯­æ³•"""
        issues = []
        sql_upper = sql.upper()
        
        # æ£€æŸ¥ FROM å­å¥
        if "FROM" not in sql_upper:
            issues.append(ValidationIssue(
                level=ValidationResult.INVALID,
                message="DELETE è¯­å¥ç¼ºå°‘ FROM å­å¥",
                suggestion="è¯·æ·»åŠ  FROM å­å¥æŒ‡å®šè¦åˆ é™¤çš„è¡¨"
            ))
        
        return issues
    
    def _extract_table_names(self, sql: str) -> List[str]:
        """æå–è¡¨å"""
        table_names = []
        
        # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼æå–è¡¨å
        # FROM å­å¥
        from_pattern = r'FROM\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        from_matches = re.findall(from_pattern, sql, re.IGNORECASE)
        table_names.extend(from_matches)
        
        # JOIN å­å¥
        join_pattern = r'JOIN\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        join_matches = re.findall(join_pattern, sql, re.IGNORECASE)
        table_names.extend(join_matches)
        
        # UPDATE å­å¥
        update_pattern = r'UPDATE\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        update_matches = re.findall(update_pattern, sql, re.IGNORECASE)
        table_names.extend(update_matches)
        
        # DELETE å­å¥
        delete_pattern = r'DELETE\s+FROM\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        delete_matches = re.findall(delete_pattern, sql, re.IGNORECASE)
        table_names.extend(delete_matches)
        
        return list(set(table_names))  # å»é‡
    
    def _extract_column_names(self, sql: str) -> List[str]:
        """æå–åˆ—å"""
        column_names = []
        
        # SELECT å­å¥ä¸­çš„åˆ—
        select_pattern = r'SELECT\s+(.*?)\s+FROM'
        select_match = re.search(select_pattern, sql, re.IGNORECASE | re.DOTALL)
        if select_match:
            select_clause = select_match.group(1)
            # ç®€å•çš„åˆ—åæå–
            columns = [col.strip() for col in select_clause.split(',')]
            for col in columns:
                # ç§»é™¤åˆ«å
                if ' AS ' in col.upper():
                    col = col.split(' AS ')[0].strip()
                # ç§»é™¤å‡½æ•°
                if '(' in col and ')' in col:
                    continue
                column_names.append(col)
        
        # WHERE å­å¥ä¸­çš„åˆ—
        where_pattern = r'WHERE\s+(.*?)(?:\s+GROUP\s+BY|\s+ORDER\s+BY|\s+LIMIT|$)'
        where_match = re.search(where_pattern, sql, re.IGNORECASE | re.DOTALL)
        if where_match:
            where_clause = where_match.group(1)
            # ç®€å•çš„åˆ—åæå–
            where_columns = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)', where_clause)
            column_names.extend(where_columns)
        
        return list(set(column_names))  # å»é‡
    
    def _column_exists(self, column_name: str, available_columns: List[Dict[str, Any]]) -> bool:
        """æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨"""
        for col in available_columns:
            if col.get("name", "").lower() == column_name.lower():
                return True
        return False
    
    def _check_joins(self, sql: str, schema_info: Dict[str, Any]) -> List[ValidationIssue]:
        """æ£€æŸ¥ JOIN æ¡ä»¶"""
        issues = []
        
        # æå– JOIN æ¡ä»¶
        join_pattern = r'JOIN\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+ON\s+(.*?)(?:\s+JOIN|\s+WHERE|\s+GROUP|\s+ORDER|\s+LIMIT|$)'
        join_matches = re.findall(join_pattern, sql, re.IGNORECASE | re.DOTALL)
        
        relationships = schema_info.get("relationships", [])
        
        for table_name, join_condition in join_matches:
            # æ£€æŸ¥ JOIN æ¡ä»¶æ˜¯å¦åˆç†
            if '=' not in join_condition:
                issues.append(ValidationIssue(
                    level=ValidationResult.WARNING,
                    message=f"JOIN æ¡ä»¶ '{join_condition}' å¯èƒ½ä¸æ­£ç¡®",
                    suggestion="JOIN æ¡ä»¶é€šå¸¸ä½¿ç”¨ç­‰å· (=) è¿æ¥ä¸¤ä¸ªåˆ—"
                ))
        
        return issues


def create_sql_validator_tool(
    container: Any,
    connection_config: Optional[Dict[str, Any]] = None
) -> SQLValidatorTool:
    """
    åˆ›å»º SQL éªŒè¯å·¥å…·
    
    Args:
        container: æœåŠ¡å®¹å™¨
        connection_config: æ•°æ®æºè¿æ¥é…ç½®ï¼ˆåœ¨åˆå§‹åŒ–æ—¶æ³¨å…¥ï¼‰
        
    Returns:
        SQLValidatorTool å®ä¾‹
    """
    return SQLValidatorTool(container, connection_config=connection_config)


# å¯¼å‡º
__all__ = [
    "SQLValidatorTool",
    "ValidationLevel",
    "ValidationResult",
    "ValidationIssue",
    "ValidationReport",
    "create_sql_validator_tool",
]