"""
SQLç›¸å…³å·¥å…·é›†åˆ

æä¾›SQLç”Ÿæˆã€éªŒè¯ã€æ‰§è¡Œã€ç­–ç•¥æ£€æŸ¥ç­‰åŠŸèƒ½
é€‚é…backupç³»ç»Ÿçš„æ•°æ®æºå’ŒLLMæœåŠ¡
"""

import logging
from typing import Dict, Any
from ..auth_context import auth_manager
from ..config_context import config_manager
from ..llm_strategy_manager import llm_strategy_manager
from ..data_source_security_service import data_source_security_service

from .base import Tool


class SQLDraftTool(Tool):
    """SQLç”Ÿæˆå·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.draft"
        self.description = "æ ¹æ®æè¿°å’Œschemaç”ŸæˆSQLæŸ¥è¯¢"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆSQLæŸ¥è¯¢"""
        try:
            placeholder = input_data.get("placeholder", {})
            # æ”¯æŒä»ä¸Šä¸‹æ–‡ç›´æ¥è¯»å–schema
            schema = input_data.get("schema") or {
                "tables": input_data.get("tables", []),
                "columns": input_data.get("columns", {}),
            }
            description = placeholder.get("description", input_data.get("user_prompt", ""))

            # è¯­ä¹‰ä¸å¯é€‰å‚æ•°
            semantic_type = (input_data.get("semantic_type") or "").lower() or None
            top_n = input_data.get("top_n")
            window = input_data.get("window") or {}

            # æ„å»ºSQLç”Ÿæˆæç¤ºè¯ï¼ˆç±»å‹æ„ŸçŸ¥ï¼‰
            prompt = self._build_sql_prompt(description, schema, semantic_type=semantic_type, top_n=top_n, window=window)

            # ä»input_dataè·å–ç”¨æˆ·IDï¼Œä¼˜å…ˆä½¿ç”¨è®¤è¯ä¸Šä¸‹æ–‡
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"

            # è°ƒç”¨LLMæœåŠ¡
            llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
            if not llm_service:
                return {"success": False, "error": "LLM service not available"}

            # ä½¿ç”¨ç­–ç•¥ç®¡ç†å™¨æ„å»ºæ™ºèƒ½LLMç­–ç•¥
            base_complexity = "high" if (semantic_type or '').lower() in ("ranking", "compare", "chart") else "medium"

            llm_policy = llm_strategy_manager.build_llm_policy(
                user_id=user_id,
                stage="tool",
                complexity=base_complexity,
                tool_name="sql.draft",
                output_kind=input_data.get('output_kind', 'sql'),
                context={
                    "semantic_type": semantic_type,
                    "top_n": top_n,
                    "tables": schema.get("tables", []),
                    "columns": schema.get("columns", {}),
                    "window": window,
                    "output_kind": input_data.get('output_kind', 'sql')
                }
            )
            result = await self._call_llm(llm_service, prompt, llm_policy=llm_policy, user_id=user_id)

            # æ¸…ç†SQLæ ¼å¼ï¼ˆç§»é™¤markdownä»£ç å—ï¼‰
            cleaned_sql = self._clean_sql_response(result)

            return {
                "success": True,
                "sql": cleaned_sql,
                "description": description
            }

        except Exception as e:
            self._logger.error(f"SQLç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def _build_sql_prompt(self, description: str, schema: Dict[str, Any], *, semantic_type: str = None, top_n: int = None, window: Dict[str, Any] = None) -> str:
        """æ„å»ºSQLç”Ÿæˆæç¤ºè¯"""
        tables = schema.get("tables", [])
        columns = schema.get("columns", {})

        schema_info = []
        for table in tables:
            table_columns = columns.get(table, [])
            if table_columns:
                schema_info.append(f"è¡¨ {table}: {', '.join(table_columns)}")

        schema_str = "\n".join(schema_info) if schema_info else "æ— å…·ä½“è¡¨ç»“æ„ä¿¡æ¯"

        guidance = []
        # ç±»å‹æŒ‡å¯¼
        if semantic_type == "ranking":
            if top_n:
                guidance.append(f"æŒ‰åº¦é‡é™åºæ’åºå¹¶å–å‰{top_n}ï¼ˆå¯ç”¨ ORDER BY + LIMIT {top_n}ï¼Œæˆ–çª—å£å‡½æ•° RANK()ï¼‰")
            else:
                guidance.append("æŒ‰åº¦é‡é™åºæ’åºå¹¶å–å‰Nï¼ˆå¯ç”¨ ORDER BY + LIMIT Nï¼Œæˆ–çª—å£å‡½æ•° RANK()ï¼‰")
            guidance.append("é€‰æ‹©æ¸…æ™°çš„åˆ†ç»„ç»´åº¦ä¸åº¦é‡å­—æ®µï¼ˆSUM/COUNT/AVGç­‰ï¼‰")
        elif semantic_type == "compare":
            guidance.append("è¾“å‡ºåŸºå‡†å€¼ã€å¯¹æ¯”å€¼ã€å·®å€¼(diff)ä¸ç™¾åˆ†æ¯”å˜åŒ–(pct_change)åˆ—")
            guidance.append("ä¸¤ä¸ªæ—¶é—´èŒƒå›´/ç»„çš„è¿‡æ»¤æ¡ä»¶ä¸å£å¾„ä¿æŒä¸€è‡´")
        elif semantic_type == "period":
            guidance.append("ä½¿ç”¨åˆé€‚çš„æ—¶é—´ç²’åº¦ï¼ˆæ—¥/å‘¨/æœˆ/å­£åº¦ï¼‰åˆ†ç»„ï¼Œå­—æ®µå‘½åæ¸…æ™°")

        # æ—¶é—´æŒ‡ä»¤ï¼ˆå¯é€‰ï¼‰
        time_hint = ""
        try:
            tc = (window or {}).get("task_schedule", {})
            cron = tc.get("cron_expression")
            tz = tc.get("timezone")
            if cron or tz:
                time_hint = f"è°ƒåº¦: {cron or ''} {f'({tz})' if tz else ''}".strip()
        except Exception:
            pass

        guidance_lines = "\n".join([f"- {g}" for g in guidance]) if guidance else ""

        return f"""
æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”ŸæˆSQLæŸ¥è¯¢è¯­å¥:

éœ€æ±‚æè¿°: {description}

å¯ç”¨æ•°æ®ç»“æ„:
{schema_str}

{('æ—¶é—´ä¸Šä¸‹æ–‡: ' + time_hint) if time_hint else ''}

ç±»å‹æŒ‡å¯¼:
{guidance_lines}

è¦æ±‚:
1. ç”Ÿæˆæ ‡å‡†çš„SELECTè¯­å¥ï¼ˆå‘½åæ¸…æ™°ï¼Œå¿…è¦æ—¶æ·»åŠ åˆ«åï¼‰
2. ä½¿ç”¨é€‚å½“çš„WHERE/LIMITï¼ˆå¤§è¡¨ä¼˜å…ˆé™åˆ¶æ—¶é—´æˆ–è¿”å›è¡Œæ•°ï¼‰
3. è€ƒè™‘æ•°æ®ç±»å‹å’Œå­—æ®µå…³ç³»
4. åªè¿”å›SQLè¯­å¥ï¼Œä¸è¦åŒ…å«è§£é‡Šæ–‡å­—
"""

    async def _call_llm(self, llm_service, prompt: str, llm_policy: Dict[str, Any] = None, user_id: str = "system") -> str:
        """è°ƒç”¨LLMç”ŸæˆSQL"""
        try:
            if hasattr(llm_service, 'ask'):
                result = await llm_service.ask(user_id=user_id, prompt=prompt, llm_policy=llm_policy)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif hasattr(llm_service, 'generate_response'):
                result = await llm_service.generate_response(prompt=prompt, user_id=user_id)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif callable(llm_service):
                return await llm_service(prompt)
            else:
                raise ValueError("Unsupported LLM service interface")
        except Exception as e:
            self._logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return ""

    def _clean_sql_response(self, response: str) -> str:
        """æ¸…ç†LLMå“åº”ä¸­çš„SQLä»£ç ï¼Œç§»é™¤markdownæ ¼å¼"""
        if not response:
            return ""

        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        lines = response.strip().split('\n')
        cleaned_lines = []

        in_code_block = False
        for line in lines:
            line_stripped = line.strip()
            # è·³è¿‡ä»£ç å—å¼€å§‹æ ‡è®°
            if line_stripped.startswith('```'):
                in_code_block = not in_code_block
                continue
            # å¦‚æœåœ¨ä»£ç å—å†…æˆ–è€…çœ‹èµ·æ¥åƒSQLï¼Œä¿ç•™è¿™è¡Œ
            if in_code_block or line_stripped.upper().startswith(('SELECT', 'WITH', 'INSERT', 'UPDATE', 'DELETE')):
                cleaned_lines.append(line)

        result = '\n'.join(cleaned_lines).strip()

        # å¦‚æœæ¸…ç†åæ²¡æœ‰å†…å®¹ï¼Œè¿”å›åŸå§‹å“åº”
        if not result:
            return response.strip()

        return result


class SQLValidateTool(Tool):
    """SQLéªŒè¯å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.validate"
        self.description = "éªŒè¯SQLè¯­å¥çš„æ­£ç¡®æ€§"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

        # Compareå¼ºæ ¡éªŒé…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡é…ç½®ï¼‰
        import os
        self.compare_strict_validation = os.getenv('AGENT_COMPARE_STRICT_VALIDATION', 'true').lower() in ('true', '1', 'yes')
        self.compare_enforce_column_names = os.getenv('AGENT_COMPARE_ENFORCE_COLUMN_NAMES', 'false').lower() in ('true', '1', 'yes')
        self.required_compare_columns = ["baseline", "compare", "diff", "pct_change"]  # å¿…éœ€åˆ—å
        self.required_compare_concepts = ["baseline", "compare", "difference", "percentage"]  # å¿…éœ€æ¦‚å¿µ

        # SQLå®‰å…¨ç­–ç•¥é…ç½®
        self.enable_table_scan_protection = os.getenv('AGENT_ENABLE_TABLE_SCAN_PROTECTION', 'true').lower() in ('true', '1', 'yes')
        self.max_table_scan_size = int(os.getenv('AGENT_MAX_TABLE_SCAN_SIZE', '10000'))  # å…è®¸æ— WHEREæ¡ä»¶çš„æœ€å¤§è¡¨è¡Œæ•°
        self.scan_whitelist_tables = set(os.getenv('AGENT_SCAN_WHITELIST_TABLES', 'metadata,config,lookup').split(','))
        self.scan_exempt_patterns = ['LIMIT', 'TOP', 'ROWNUM', 'SAMPLE']  # è±å…æ¨¡å¼

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯SQLè¯­å¥"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # åŸºç¡€è¯­æ³•éªŒè¯
            validation_result = self._validate_sql_syntax(sql)

            # è¯­ä¹‰ç±»å‹ç‰¹å®šéªŒè¯
            semantic_type = (input_data.get("semantic_type") or "").lower() or None
            top_n = input_data.get("top_n")
            issues_extra = []
            warnings_extra = []

            # Compareå¼ºæ ¡éªŒ
            if semantic_type == "compare":
                compare_validation = self._validate_compare_sql(sql, input_data)
                if not compare_validation["valid"]:
                    issues_extra.extend(compare_validation["issues"])
                warnings_extra.extend(compare_validation.get("warnings", []))

            # RankingéªŒè¯
            elif semantic_type == "ranking" and top_n:
                ranking_validation = self._validate_ranking_sql(sql, top_n)
                if not ranking_validation["valid"]:
                    issues_extra.extend(ranking_validation["issues"])
                warnings_extra.extend(ranking_validation.get("warnings", []))

            # ChartéªŒè¯
            elif semantic_type == "chart":
                chart_validation = self._validate_chart_sql(sql, input_data)
                warnings_extra.extend(chart_validation.get("warnings", []))

            # SQLå®‰å…¨ç­–ç•¥éªŒè¯ï¼ˆè¡¨æ‰«æä¿æŠ¤ï¼‰
            if self.enable_table_scan_protection:
                security_validation = self._validate_table_scan_security(sql, input_data)
                if not security_validation["valid"]:
                    issues_extra.extend(security_validation["issues"])
                warnings_extra.extend(security_validation.get("warnings", []))

            # åˆå¹¶éªŒè¯ç»“æœ
            if issues_extra:
                validation_result["issues"] = (validation_result.get("issues") or []) + issues_extra
                validation_result["valid"] = False

            if warnings_extra:
                validation_result["warnings"] = (validation_result.get("warnings", [])) + warnings_extra

            return {
                "success": validation_result["valid"],
                "sql": sql,
                "issues": validation_result.get("issues", []),
                "warnings": validation_result.get("warnings", []),
                "error": validation_result.get("error") if not validation_result["valid"] else None
            }

        except Exception as e:
            self._logger.error(f"SQLéªŒè¯å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def _validate_sql_syntax(self, sql: str) -> Dict[str, Any]:
        """åŸºç¡€SQLè¯­æ³•éªŒè¯"""
        sql_upper = sql.upper().strip()
        issues = []

        # æ£€æŸ¥åŸºæœ¬SQLç»“æ„
        if not sql_upper.startswith("SELECT"):
            issues.append("SQLå¿…é¡»ä»¥SELECTå¼€å¤´")

        if "FROM" not in sql_upper:
            issues.append("SQLå¿…é¡»åŒ…å«FROMå­å¥")

        # æ£€æŸ¥å±é™©æ“ä½œ
        dangerous_keywords = ["DROP", "DELETE", "TRUNCATE", "UPDATE", "INSERT", "ALTER"]
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                issues.append(f"SQLåŒ…å«å±é™©å…³é”®è¯: {keyword}")

        return {
            "valid": len(issues) == 0,
            "issues": issues,
            "error": "; ".join(issues) if issues else None
        }

    def _validate_compare_sql(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """CompareæŸ¥è¯¢å¼ºæ ¡éªŒ"""
        issues = []
        warnings = []
        valid = True

        if not self.compare_strict_validation:
            self._logger.info("Compareå¼ºæ ¡éªŒå·²ç¦ç”¨ï¼Œè·³è¿‡éªŒè¯")
            return {"valid": True, "issues": [], "warnings": []}

        sql_upper = sql.upper()
        self._logger.info(f"ğŸ” [CompareValidation] å¼€å§‹Compareå¼ºæ ¡éªŒï¼Œenforce_column_names={self.compare_enforce_column_names}")

        # 1. å¼ºåˆ¶æ£€æŸ¥å¿…éœ€åˆ—åï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.compare_enforce_column_names:
            missing_columns = []
            for required_col in self.required_compare_columns:
                if required_col.upper() not in sql_upper:
                    missing_columns.append(required_col)

            if missing_columns:
                issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—å: {', '.join(missing_columns)}")
                valid = False
                self._logger.warning(f"âš ï¸ [CompareValidation] ç¼ºå°‘å¿…éœ€åˆ—å: {missing_columns}")

        # 2. å¿…é¡»åŒ…å«åŸºå‡†æœŸå’Œå¯¹æ¯”æœŸçš„æ¦‚å¿µï¼ˆæ›´ä¸¥æ ¼ï¼‰
        baseline_keywords = ["BASELINE", "BASE", "PREVIOUS", "LAST", "PRIOR", "BEFORE", "OLD"]
        compare_keywords = ["COMPARE", "CURRENT", "NEW", "NOW", "AFTER", "RECENT"]

        has_baseline = any(keyword in sql_upper for keyword in baseline_keywords)
        has_compare = any(keyword in sql_upper for keyword in compare_keywords)

        if not has_baseline:
            issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«åŸºå‡†æœŸæ¦‚å¿µ (å…³é”®è¯: {', '.join(baseline_keywords[:3])}...)")
            valid = False

        if not has_compare:
            issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«å¯¹æ¯”æœŸæ¦‚å¿µ (å…³é”®è¯: {', '.join(compare_keywords[:3])}...)")
            valid = False

        # 3. å¼ºåˆ¶è¦æ±‚åŒ…å«å·®å€¼è®¡ç®—ï¼ˆæ›´ç²¾ç¡®æ£€æŸ¥ï¼‰
        diff_patterns = ["DIFF", "DIFFERENCE", "CHANGE", "DELTA", "MINUS", "SUBTRACT", "VARIANCE"]
        has_diff = any(pattern in sql_upper for pattern in diff_patterns)
        has_arithmetic_diff = " - " in sql or "(-" in sql  # ç®—æœ¯å·®å€¼

        if not (has_diff or has_arithmetic_diff):
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«å·®å€¼è®¡ç®— (ä½¿ç”¨ DIFF/CHANGE åˆ—åæˆ–ç®—æœ¯è¿ç®— '-')")
            valid = False

        # 4. å¼ºåˆ¶è¦æ±‚åŒ…å«ç™¾åˆ†æ¯”å˜åŒ–ï¼ˆæ›´ç²¾ç¡®æ£€æŸ¥ï¼‰
        pct_patterns = ["PCT", "PERCENT", "PERCENTAGE", "RATE", "RATIO", "GROWTH"]
        has_pct = any(pattern in sql_upper for pattern in pct_patterns)
        has_pct_formula = "*100" in sql.replace(" ", "") or "/100" in sql.replace(" ", "")  # ç™¾åˆ†æ¯”å…¬å¼

        if not (has_pct or has_pct_formula):
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«ç™¾åˆ†æ¯”å˜åŒ– (ä½¿ç”¨ PCT_CHANGE/PERCENTAGE åˆ—åæˆ–ç™¾åˆ†æ¯”è®¡ç®—)")
            valid = False

        # 5. æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´ç»´åº¦ï¼ˆå‡çº§ä¸ºå¼ºåˆ¶è¦æ±‚ï¼‰
        time_keywords = ["DATE", "TIME", "YEAR", "MONTH", "DAY", "PERIOD", "WEEK", "QUARTER"]
        has_time_dimension = any(keyword in sql_upper for keyword in time_keywords)

        if not has_time_dimension:
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«æ—¶é—´ç»´åº¦ä»¥æ˜ç¡®å¯¹æ¯”æœŸé—´")
            valid = False

        # 6. æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„åˆ†ç»„å’Œæ’åº
        has_group_by = "GROUP BY" in sql_upper
        has_order_by = "ORDER BY" in sql_upper

        if not has_group_by:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®ä½¿ç”¨ GROUP BY è¿›è¡Œé€‚å½“åˆ†ç»„")

        if not has_order_by:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®ä½¿ç”¨ ORDER BY æŒ‰å˜åŒ–å¹…åº¦æ’åº")

        # 7. æ£€æŸ¥æ½œåœ¨çš„æ•°æ®è´¨é‡é—®é¢˜
        if "WHERE" not in sql_upper:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®æ·»åŠ  WHERE æ¡ä»¶é™åˆ¶æ•°æ®èŒƒå›´ï¼Œé¿å…å…¨è¡¨æ‰«æ")

        result = {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

        if valid:
            self._logger.info("âœ… [CompareValidation] CompareæŸ¥è¯¢é€šè¿‡å¼ºæ ¡éªŒ")
        else:
            self._logger.warning(f"ğŸš¨ [CompareValidation] CompareæŸ¥è¯¢æœªé€šè¿‡å¼ºæ ¡éªŒï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")

        return result

    def _validate_ranking_sql(self, sql: str, top_n: int) -> Dict[str, Any]:
        """æ’åæŸ¥è¯¢éªŒè¯"""
        issues = []
        warnings = []
        valid = True

        sql_upper = sql.upper()

        # æ£€æŸ¥æ˜¯å¦æœ‰æ’åºå’Œé™åˆ¶
        has_order_by = "ORDER BY" in sql_upper
        has_limit = "LIMIT" in sql_upper or f"LIMIT {top_n}" in sql_upper
        has_rank_function = any(func in sql_upper for func in [
            "RANK()", "DENSE_RANK()", "ROW_NUMBER()", "NTILE("
        ])

        if not has_order_by and not has_rank_function:
            issues.append("æ’åæŸ¥è¯¢å¿…é¡»åŒ…å« ORDER BY å­å¥æˆ–çª—å£æ’åå‡½æ•°")
            valid = False

        if not has_limit and not has_rank_function:
            warnings.append(f"æ’åæŸ¥è¯¢å»ºè®®ä½¿ç”¨ LIMIT {top_n} æˆ–çª—å£å‡½æ•°é™åˆ¶ç»“æœæ•°é‡")

        return {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

    def _validate_chart_sql(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å›¾è¡¨æŸ¥è¯¢éªŒè¯"""
        warnings = []

        chart_type = input_data.get("chart_type", "").lower()
        sql_upper = sql.upper()

        # æ ¹æ®å›¾è¡¨ç±»å‹ç»™å‡ºå»ºè®®
        if chart_type == "pie":
            if "GROUP BY" not in sql_upper:
                warnings.append("é¥¼å›¾å»ºè®®ä½¿ç”¨ GROUP BY å¯¹ç±»åˆ«è¿›è¡Œåˆ†ç»„")
        elif chart_type == "line":
            has_time = any(keyword in sql_upper for keyword in [
                "DATE", "TIME", "YEAR", "MONTH", "DAY"
            ])
            if not has_time:
                warnings.append("æŠ˜çº¿å›¾å»ºè®®åŒ…å«æ—¶é—´ç»´åº¦æ•°æ®")
        elif chart_type == "bar":
            if "ORDER BY" not in sql_upper:
                warnings.append("æŸ±çŠ¶å›¾å»ºè®®ä½¿ç”¨ ORDER BY å¯¹ç»“æœæ’åº")

        return {
            "valid": True,
            "warnings": warnings
        }

    def _validate_table_scan_security(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """SQLè¡¨æ‰«æå®‰å…¨éªŒè¯ - é˜²æ­¢æ— WHEREæ¡ä»¶çš„å¤§è¡¨æ‰«æ"""
        issues = []
        warnings = []
        valid = True

        if not self.enable_table_scan_protection:
            self._logger.info("è¡¨æ‰«æä¿æŠ¤å·²ç¦ç”¨ï¼Œè·³è¿‡éªŒè¯")
            return {"valid": True, "issues": [], "warnings": []}

        sql_upper = sql.upper()
        self._logger.info(f"ğŸ” [TableScanSecurity] å¼€å§‹è¡¨æ‰«æå®‰å…¨éªŒè¯")

        # æ£€æŸ¥æ˜¯å¦æœ‰WHEREæ¡ä»¶
        has_where = "WHERE" in sql_upper
        has_limit = any(pattern in sql_upper for pattern in self.scan_exempt_patterns)

        if not has_where and not has_limit:
            # æå–è¡¨åè¿›è¡Œç™½åå•æ£€æŸ¥
            tables = self._extract_table_names(sql)
            blocked_tables = []
            whitelisted_tables = []

            for table in tables:
                table_clean = table.lower().strip()
                if table_clean in self.scan_whitelist_tables:
                    whitelisted_tables.append(table)
                else:
                    blocked_tables.append(table)

            if blocked_tables:
                self._logger.warning(f"ğŸš¨ [TableScanSecurity] æ£€æµ‹åˆ°å¤§è¡¨æ‰«æé£é™©: {blocked_tables}")

                # å°è¯•è·å–è¡¨å¤§å°ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                table_size_info = self._get_table_size_info(blocked_tables, input_data)
                large_tables = []

                for table, size_info in table_size_info.items():
                    estimated_size = size_info.get("estimated_rows", 0)
                    if estimated_size > self.max_table_scan_size:
                        large_tables.append(f"{table}(~{estimated_size}è¡Œ)")

                if large_tables:
                    issues.append(
                        f"ç¦æ­¢æ— WHEREæ¡ä»¶æ‰«æå¤§è¡¨: {', '.join(large_tables)}ã€‚"
                        f"è¯·æ·»åŠ WHEREæ¡ä»¶é™åˆ¶æ•°æ®èŒƒå›´ï¼Œæˆ–ä½¿ç”¨LIMITé™åˆ¶è¿”å›è¡Œæ•°"
                    )
                    valid = False
                else:
                    warnings.append(
                        f"æ£€æµ‹åˆ°æ— WHEREæ¡ä»¶çš„è¡¨æ‰«æ: {', '.join(blocked_tables)}ã€‚"
                        f"å»ºè®®æ·»åŠ WHEREæ¡ä»¶æˆ–LIMITå­å¥ä»¥æå‡æ€§èƒ½"
                    )

            if whitelisted_tables:
                self._logger.info(f"âœ… [TableScanSecurity] ç™½åå•è¡¨å…è®¸æ‰«æ: {whitelisted_tables}")

        # æ£€æŸ¥JOINæ“ä½œçš„å®‰å…¨æ€§
        if "JOIN" in sql_upper and not has_where:
            warnings.append("å¤šè¡¨JOINæ“ä½œå»ºè®®ä½¿ç”¨WHEREæ¡ä»¶é™åˆ¶ç»“æœé›†å¤§å°")

        # æ£€æŸ¥èšåˆæ“ä½œ
        has_aggregation = any(func in sql_upper for func in ["COUNT", "SUM", "AVG", "MAX", "MIN", "GROUP BY"])
        if has_aggregation and not has_where and not has_limit:
            warnings.append("èšåˆæŸ¥è¯¢å»ºè®®æ·»åŠ WHEREæ¡ä»¶æˆ–æ—¶é—´èŒƒå›´é™åˆ¶")

        result = {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

        if valid:
            self._logger.info("âœ… [TableScanSecurity] SQLè¡¨æ‰«æå®‰å…¨éªŒè¯é€šè¿‡")
        else:
            self._logger.warning(f"ğŸš¨ [TableScanSecurity] SQLå­˜åœ¨å®‰å…¨é£é™©ï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")

        return result

    def _extract_table_names(self, sql: str) -> list:
        """ä»SQLä¸­æå–è¡¨å"""
        import re

        # ç®€åŒ–çš„è¡¨åæå–ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›ï¼‰
        sql_clean = re.sub(r'--.*', '', sql)  # ç§»é™¤æ³¨é‡Š
        sql_clean = re.sub(r'/\*.*?\*/', '', sql_clean, flags=re.DOTALL)  # ç§»é™¤å¤šè¡Œæ³¨é‡Š

        # æŸ¥æ‰¾FROMå’ŒJOINåçš„è¡¨å
        tables = set()

        # FROMå­å¥
        from_pattern = r'\bFROM\s+(\w+)'
        for match in re.finditer(from_pattern, sql_clean, re.IGNORECASE):
            tables.add(match.group(1))

        # JOINå­å¥
        join_pattern = r'\bJOIN\s+(\w+)'
        for match in re.finditer(join_pattern, sql_clean, re.IGNORECASE):
            tables.add(match.group(1))

        return list(tables)

    def _get_table_size_info(self, tables: list, input_data: Dict[str, Any]) -> Dict[str, Dict]:
        """è·å–è¡¨å¤§å°ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥ä»æ•°æ®æºæˆ–å…ƒæ•°æ®æœåŠ¡è·å–
        size_info = {}

        # é»˜è®¤è¡¨å¤§å°ä¼°ç®—ï¼ˆå®é™…åº”è¯¥ä»æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯è·å–ï¼‰
        default_estimates = {
            "users": {"estimated_rows": 50000},
            "orders": {"estimated_rows": 100000},
            "transactions": {"estimated_rows": 500000},
            "logs": {"estimated_rows": 1000000},
            "events": {"estimated_rows": 2000000},
        }

        for table in tables:
            table_lower = table.lower()
            if table_lower in default_estimates:
                size_info[table] = default_estimates[table_lower]
            else:
                # ä¿å®ˆä¼°è®¡
                size_info[table] = {"estimated_rows": self.max_table_scan_size + 1}

        return size_info


class SQLExecuteTool(Tool):
    """SQLæ‰§è¡Œå·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.execute"
        self.description = "æ‰§è¡ŒSQLæŸ¥è¯¢è·å–æ•°æ®"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # è·å–ç”¨æˆ·IDå’Œæ•°æ®æºID
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"
            data_source_config = input_data.get("data_source", {})
            data_source_id = data_source_config.get("id")

            # æ•°æ®æºæƒé™éªŒè¯
            if user_id != "system" and data_source_id:
                self._logger.info(f"éªŒè¯ç”¨æˆ· {user_id} å¯¹æ•°æ®æº {data_source_id} çš„è®¿é—®æƒé™")

                access_validation = data_source_security_service.validate_data_source_access(
                    user_id=user_id,
                    data_source_id=data_source_id
                )

                if not access_validation.get("allowed"):
                    self._logger.warning(f"æ•°æ®æºè®¿é—®è¢«æ‹’ç»: {access_validation}")
                    return {
                        "success": False,
                        "error": f"æ•°æ®æºè®¿é—®æƒé™éªŒè¯å¤±è´¥: {access_validation.get('reason', 'æœªçŸ¥é”™è¯¯')}",
                        "error_code": access_validation.get("error_code", "ACCESS_DENIED")
                    }

                self._logger.info("æ•°æ®æºæƒé™éªŒè¯é€šè¿‡")

            # è·å–æ•°æ®æºæœåŠ¡
            data_source_service = getattr(self.container, 'data_source_service', None) or getattr(self.container, 'data_source', None)
            if not data_source_service:
                return {"success": False, "error": "Data source service not available"}

            # æ‰§è¡ŒSQL (è¿™é‡Œéœ€è¦æ ¹æ®backupç³»ç»Ÿçš„å®é™…æ¥å£è°ƒæ•´)
            result = await self._execute_sql(data_source_service, sql, input_data)

            return {
                "success": True,
                "sql": sql,
                "rows": result.get("rows", []),
                "columns": result.get("columns", []),
                "row_count": len(result.get("rows", []))
            }

        except Exception as e:
            self._logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    async def _execute_sql(self, data_source_service, sql: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            # æ„å»ºæ•°æ®æºé…ç½®
            data_source_config = context.get("data_source", {}) or {}

            # è‹¥ data_source ä¸­ä»…æœ‰ id/type/database ç­‰ç®€è¦ä¿¡æ¯ï¼Œå°è¯•é€šè¿‡ user_data_source_service è·å–å®Œæ•´è¿æ¥é…ç½®
            container = getattr(self, 'container', None)
            user_id = context.get("user_id")
            ds_id = data_source_config.get("id")
            resolved_cfg = None

            if container and hasattr(container, 'user_data_source_service') and user_id and ds_id:
                try:
                    uds = await container.user_data_source_service.get_user_data_source(user_id=user_id, data_source_id=ds_id)
                    if uds and getattr(uds, 'connection_config', None):
                        resolved_cfg = uds.connection_config
                except Exception:
                    resolved_cfg = None

            final_cfg = resolved_cfg or data_source_config

            # å…¼å®¹ç±»å‹æ˜ å°„ï¼ˆmysql/postgres â†’ sqlï¼‰
            t = (final_cfg.get("source_type") or final_cfg.get("type") or "").lower()
            if t in ("mysql", "postgres", "postgresql", "mariadb"):
                final_cfg["source_type"] = "sql"

            # å°è¯•ä¸åŒçš„æ‰§è¡Œæ–¹æ³•
            if hasattr(data_source_service, 'execute_query'):
                result = await data_source_service.execute_query(sql, final_cfg)
            elif hasattr(data_source_service, 'run_query'):
                result = await data_source_service.run_query(final_cfg, sql)
            elif callable(data_source_service):
                result = await data_source_service(sql, final_cfg)
            else:
                raise ValueError("Unsupported data source service interface")

            return {
                "rows": result.get("rows", result.get("data", [])),
                "columns": result.get("columns", result.get("column_names", []))
            }

        except Exception as e:
            self._logger.error(f"SQLæ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return {"rows": [], "columns": []}


class SQLRefineTool(Tool):
    """SQLä¼˜åŒ–å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.refine"
        self.description = "åŸºäºé—®é¢˜åé¦ˆä¼˜åŒ–SQLè¯­å¥"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–SQLè¯­å¥"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            issues = input_data.get("issues", [])

            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # æ„å»ºä¼˜åŒ–æç¤ºè¯
            prompt = self._build_refine_prompt(sql, issues)

            # è°ƒç”¨LLMä¼˜åŒ–
            llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
            if not llm_service:
                return {"success": False, "error": "LLM service not available"}

            # ä»input_dataè·å–ç”¨æˆ·IDï¼Œä¼˜å…ˆä½¿ç”¨è®¤è¯ä¸Šä¸‹æ–‡
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"
            refined_sql = await self._call_llm(llm_service, prompt, user_id=user_id)

            return {
                "success": True,
                "sql": refined_sql,
                "original_sql": sql,
                "issues_addressed": issues
            }

        except Exception as e:
            self._logger.error(f"SQLä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def _build_refine_prompt(self, sql: str, issues: list) -> str:
        """æ„å»ºSQLä¼˜åŒ–æç¤ºè¯"""
        issues_str = "\n".join([f"- {issue}" for issue in issues])

        return f"""
è¯·ä¼˜åŒ–ä»¥ä¸‹SQLè¯­å¥ï¼Œè§£å†³å‘ç°çš„é—®é¢˜:

åŸå§‹SQL:
{sql}

å‘ç°çš„é—®é¢˜:
{issues_str}

è¦æ±‚:
1. ä¿æŒåŸæœ‰æŸ¥è¯¢é€»è¾‘
2. ä¿®å¤æ‰€æœ‰é—®é¢˜
3. ä¼˜åŒ–æ€§èƒ½
4. åªè¿”å›ä¼˜åŒ–åçš„SQLè¯­å¥
"""

    async def _call_llm(self, llm_service, prompt: str, user_id: str = "system") -> str:
        """è°ƒç”¨LLMä¼˜åŒ–SQL"""
        try:
            if hasattr(llm_service, 'ask'):
                result = await llm_service.ask(user_id=user_id, prompt=prompt)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif hasattr(llm_service, 'generate_response'):
                result = await llm_service.generate_response(prompt=prompt, user_id=user_id)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif callable(llm_service):
                return await llm_service(prompt)
            else:
                raise ValueError("Unsupported LLM service interface")
        except Exception as e:
            self._logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return ""


class SQLPolicyTool(Tool):
    """SQLç­–ç•¥æ£€æŸ¥å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.policy"
        self.description = "æ‰§è¡ŒSQLç­–ç•¥æ£€æŸ¥å¹¶æ·»åŠ LIMIT"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLç­–ç•¥æ£€æŸ¥"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"
            data_source_config = input_data.get("data_source", {})
            data_source_id = data_source_config.get("id")

            # ç¡®å®šç”¨æˆ·æ˜¯å¦ä¸ºè¶…çº§ç”¨æˆ·
            is_superuser = False
            if user_id != "system":
                auth_context = auth_manager.get_current_auth_context()
                is_superuser = auth_context.is_superuser if auth_context else False

            # ä½¿ç”¨DataSourceSecurityServiceè¿›è¡ŒSQLå®‰å…¨ç­–ç•¥æ£€æŸ¥
            security_result = data_source_security_service.apply_sql_security_policy(
                sql=sql,
                user_id=user_id,
                data_source_id=data_source_id,
                is_superuser=is_superuser
            )

            if not security_result.get("allowed"):
                self._logger.warning(f"SQLç­–ç•¥æ£€æŸ¥å¤±è´¥: {security_result}")
                return {
                    "success": False,
                    "error": f"SQLå®‰å…¨ç­–ç•¥æ£€æŸ¥å¤±è´¥: {'; '.join(security_result.get('issues', []))}",
                    "issues": security_result.get("issues", [])
                }

            # ä½¿ç”¨ç»è¿‡å®‰å…¨ç­–ç•¥å¤„ç†çš„SQL
            processed_sql = security_result.get("modified_sql", sql)

            return {
                "success": True,
                "sql": processed_sql,
                "original_sql": sql,
                "policies_applied": security_result.get("modifications", []),
                "warnings": security_result.get("warnings", []),
                "issues": security_result.get("issues", [])
            }

        except Exception as e:
            self._logger.error(f"SQLç­–ç•¥æ£€æŸ¥å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

