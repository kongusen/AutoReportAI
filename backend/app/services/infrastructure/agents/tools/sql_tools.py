"""
SQLç›¸å…³å·¥å…·é›†åˆ

æä¾›SQLç”Ÿæˆã€éªŒè¯ã€æ‰§è¡Œã€ç­–ç•¥æ£€æŸ¥ç­‰åŠŸèƒ½
é€‚é…backupç³»ç»Ÿçš„æ•°æ®æºå’ŒLLMæœåŠ¡
"""

import logging
from typing import Dict, Any, List, Optional
from ..auth_context import auth_manager
from ..config_context import config_manager
from ..llm_strategy_manager import llm_strategy_manager
from ..data_source_security_service import data_source_security_service

from .base import Tool


# SQLDraftTool å·²åˆ é™¤ - ç ´åå¼é‡æ„
# LLMåº”è¯¥ç›´æ¥ç”ŸæˆSQLï¼Œè€Œä¸æ˜¯é€šè¿‡å·¥å…·è°ƒç”¨å¦ä¸€ä¸ªLLM
# è¿™ä¸ªç±»çš„å­˜åœ¨è¿åäº†æ­£ç¡®çš„Agentæ¶æ„åŸåˆ™


class SQLValidateTool(Tool):
    """SQLéªŒè¯å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.validate"
        self.description = "éªŒè¯SQLè¯­å¥çš„æ­£ç¡®æ€§"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

        # Compareå¼ºæ ¡éªŒé…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡é…ç½®ï¼‰
        import os
        self.compare_strict_validation = os.getenv('AGENT_COMPARE_STRICT_VALIDATION', 'true').lower() in ('true', '1', 'yes')
        self.compare_enforce_column_names = os.getenv('AGENT_COMPARE_ENFORCE_COLUMN_NAMES', 'false').lower() in ('true', '1', 'yes')
        self.required_compare_columns = ["baseline", "compare", "diff", "pct_change"]  # å¿…éœ€åˆ—å
        self.required_compare_concepts = ["baseline", "compare", "difference", "percentage"]  # å¿…éœ€æ¦‚å¿µ

        # SQLå®‰å…¨ç­–ç•¥é…ç½®
        self.enable_table_scan_protection = os.getenv('AGENT_ENABLE_TABLE_SCAN_PROTECTION', 'true').lower() in ('true', '1', 'yes')
        self.max_table_scan_size = int(os.getenv('AGENT_MAX_TABLE_SCAN_SIZE', '10000'))  # å…è®¸æ— WHEREæ¡ä»¶çš„æœ€å¤§è¡¨è¡Œæ•°
        self.scan_whitelist_tables = set(os.getenv('AGENT_SCAN_WHITELIST_TABLES', 'metadata,config,lookup').split(','))
        self.scan_exempt_patterns = ['LIMIT', 'TOP', 'ROWNUM', 'SAMPLE']  # è±å…æ¨¡å¼

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½SQLéªŒè¯ - ç»“åˆè§„åˆ™éªŒè¯å’ŒAgentæ™ºèƒ½æ£€æŸ¥"""
        try:
            # è°ƒè¯•ï¼šæ£€æŸ¥è¾“å…¥æ•°æ®
            self._logger.debug(f"ğŸ”§ [SQLéªŒè¯] è¾“å…¥æ•°æ®é”®: {list(input_data.keys())}")

            sql = input_data.get("current_sql") or input_data.get("sql", "")
            self._logger.debug(f"ğŸ”§ [SQLéªŒè¯] æå–çš„SQL: '{sql}' (ç±»å‹: {type(sql)})")

            if not sql:
                self._logger.warning(f"ğŸ”§ [SQLéªŒè¯] SQLä¸ºç©ºï¼Œè¾“å…¥æ•°æ®: {input_data}")
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # ğŸš¨ é˜²æŠ¤ï¼šæ£€æŸ¥æ˜¯å¦æ”¶åˆ°äº†æè¿°æ–‡æœ¬è€Œä¸æ˜¯å®é™…SQL
            if self._is_description_text(sql):
                self._logger.error(f"ğŸš¨ [SQLéªŒè¯] æ”¶åˆ°æè¿°æ–‡æœ¬è€ŒéSQL: '{sql}'")
                return {
                    "success": False,
                    "error": "æ”¶åˆ°æè¿°æ–‡æœ¬è€ŒéSQLè¯­å¥",
                    "issues": ["ä¼ é€’ç»™éªŒè¯å™¨çš„ä¸æ˜¯SQLä»£ç ï¼Œè€Œæ˜¯æè¿°æ–‡æœ¬"],
                    "warnings": ["è¯·æ£€æŸ¥SQLç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿ä¼ é€’å®é™…çš„SQLè¯­å¥"]
                }

            # ğŸš€ å¿«é€Ÿé€šé“ï¼šå¯¹äºæ˜æ˜¾æ­£ç¡®çš„SQLï¼Œç›´æ¥é€šè¿‡éªŒè¯
            if self._is_obviously_valid_sql(sql):
                self._logger.info("âœ… SQLé€šè¿‡å¿«é€ŸéªŒè¯é€šé“")
                return {
                    "success": True,
                    "sql": sql,
                    "issues": [],
                    "warnings": [],
                    "error": None,
                    "agent_validated": False,
                    "validation_decision": "å¿«é€Ÿé€šé“éªŒè¯é€šè¿‡"
                }

            # ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è¯­æ³•éªŒè¯
            validation_result = self._validate_sql_syntax(sql)

            # ç¬¬äºŒé˜¶æ®µï¼šè¯­ä¹‰ç±»å‹ç‰¹å®šéªŒè¯
            semantic_type = (input_data.get("semantic_type") or "").lower() or None
            top_n = input_data.get("top_n")
            issues_extra = []
            warnings_extra = []

            # Compareå¼ºæ ¡éªŒ
            if semantic_type == "compare":
                compare_validation = self._validate_compare_sql(sql, input_data)
                if not compare_validation["valid"]:
                    issues_extra.extend(compare_validation["issues"])
                warnings_extra.extend(compare_validation.get("warnings", []))

            # RankingéªŒè¯
            elif semantic_type == "ranking" and top_n:
                ranking_validation = self._validate_ranking_sql(sql, top_n)
                if not ranking_validation["valid"]:
                    issues_extra.extend(ranking_validation["issues"])
                warnings_extra.extend(ranking_validation.get("warnings", []))

            # ChartéªŒè¯
            elif semantic_type == "chart":
                chart_validation = self._validate_chart_sql(sql, input_data)
                warnings_extra.extend(chart_validation.get("warnings", []))

            # SQLå®‰å…¨ç­–ç•¥éªŒè¯ï¼ˆè¡¨æ‰«æä¿æŠ¤ï¼‰
            if self.enable_table_scan_protection:
                security_validation = self._validate_table_scan_security(sql, input_data)
                if not security_validation["valid"]:
                    issues_extra.extend(security_validation["issues"])
                warnings_extra.extend(security_validation.get("warnings", []))

            # æ–°å¢ï¼šSchemaä¸€è‡´æ€§æ£€æŸ¥ä¸è‡ªåŠ¨ä¿®å¤ï¼ˆè¡¨/æ—¶é—´åˆ—ï¼‰
            schema_fix = self._check_and_fix_schema_consistency(sql, input_data)
            if not schema_fix["valid"]:
                issues_extra.extend(schema_fix.get("issues", []))
            if schema_fix.get("corrected_sql"):
                # å¦‚æœç”Ÿæˆäº†ä¿®æ­£SQLï¼Œæ”¾åˆ°éªŒè¯ç»“æœé‡Œï¼Œä¾›æ‰§è¡Œå™¨é‡‡ç”¨
                validation_result["corrected_sql"] = schema_fix["corrected_sql"]
                warnings_extra.extend(schema_fix.get("warnings", []))

            # åˆå¹¶è§„åˆ™éªŒè¯ç»“æœ
            if issues_extra:
                validation_result["issues"] = (validation_result.get("issues") or []) + issues_extra
                validation_result["valid"] = False

            if warnings_extra:
                validation_result["warnings"] = (validation_result.get("warnings", [])) + warnings_extra

            # ç¬¬ä¸‰é˜¶æ®µï¼šçœŸå®æ•°æ®æºéªŒè¯ï¼ˆæ ¸å¿ƒéªŒè¯ï¼‰
            database_validation_done = False
            database_validation = {"success": True, "issues": [], "warnings": []}
            validation_sql_with_dates = None  # ğŸ”§ åˆå§‹åŒ–å˜é‡

            # å¦‚æœåŸºç¡€éªŒè¯é€šè¿‡ï¼Œè¿›è¡ŒçœŸå®æ•°æ®åº“éªŒè¯
            if validation_result.get("valid", True):
                database_validation = await self._validate_sql_against_database(sql, input_data)
                database_validation_done = True
                # ğŸ”§ æå–éªŒè¯ç”¨çš„SQL
                validation_sql_with_dates = database_validation.get("validation_sql_with_dates")

                # æ•°æ®åº“éªŒè¯å¤±è´¥æ—¶ï¼Œæ›´æ–°æ•´ä½“éªŒè¯çŠ¶æ€
                if not database_validation.get("success", True):
                    validation_result["issues"] = (validation_result.get("issues", []) +
                                                 database_validation.get("issues", []))
                    validation_result["valid"] = False

                validation_result["warnings"] = (validation_result.get("warnings", []) +
                                               database_validation.get("warnings", []))

            # ç¬¬å››é˜¶æ®µï¼šAgentæ™ºèƒ½è¯­æ³•æ£€æŸ¥ï¼ˆä»…åœ¨æ•°æ®åº“éªŒè¯å¤±è´¥æˆ–éœ€è¦æ·±åº¦æ£€æŸ¥æ—¶ï¼‰
            agent_validation_done = False
            agent_correction_available = False
            if not validation_result["valid"] or self._should_do_deep_validation(sql):
                agent_validation = await self._agent_validate_sql(sql, input_data)
                agent_validation_done = True

                if not agent_validation.get("success", True):
                    validation_result["issues"] = (validation_result.get("issues", []) +
                                                 agent_validation.get("issues", []))
                    validation_result["valid"] = False

                validation_result["warnings"] = (validation_result.get("warnings", []) +
                                               agent_validation.get("warnings", []))

                # æ£€æŸ¥æ˜¯å¦æœ‰Agentæä¾›çš„ä¿®æ­£å»ºè®®
                agent_analysis = agent_validation.get("agent_analysis", {})
                if agent_analysis.get("corrected_sql"):
                    agent_correction_available = True

            # ğŸ”„ æ–°å¢ï¼šæ™ºèƒ½å®¹é”™å†³ç­–æœºåˆ¶
            final_decision = self._make_validation_decision(
                validation_result,
                sql,
                input_data,
                agent_correction_available
            )

            return {
                "success": final_decision["success"],
                "sql": sql,  # âš ï¸ å…³é”®ä¿®å¤ï¼šè¿”å›åŸå§‹å¸¦å ä½ç¬¦çš„SQLï¼Œä¸æ˜¯éªŒè¯ç”¨çš„SQL
                "validated_sql": validation_sql_with_dates if database_validation_done else None,  # æ–°å¢ï¼šå®é™…éªŒè¯æ‰§è¡Œçš„SQL
                "issues": final_decision.get("issues", []),
                "warnings": final_decision.get("warnings", []),
                "error": final_decision.get("error"),
                "agent_validated": agent_validation_done,
                "database_validated": database_validation_done,
                "validation_decision": final_decision.get("decision_reason"),
                "corrected_sql": final_decision.get("corrected_sql")  # å¦‚æœæœ‰ä¿®æ­£å»ºè®®
            }

        except Exception as e:
            self._logger.error(f"SQLéªŒè¯å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def _check_and_fix_schema_consistency(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥SQLæ˜¯å¦å¼•ç”¨äº†æœªçŸ¥è¡¨/ä¸åˆé€‚çš„æ—¶é—´åˆ—ï¼›å¿…è¦æ—¶ç»™å‡ºä¿®æ­£SQLã€‚

        - å…è®¸è¡¨é›†åˆå–è‡ª input_data['selected_tables'] ä¼˜å…ˆï¼Œå¦åˆ™ input_data['tables']ã€‚
        - è‹¥å‘ç°æœªçŸ¥è¡¨ï¼Œå°è¯•åŸºäºå…³é”®è¯/ç›¸ä¼¼åº¦åŒ¹é…åˆ°å…è®¸è¡¨å¹¶æ›¿æ¢ã€‚
        - è‹¥å‘ç°æ—¶é—´åˆ—ä¸åŒ¹é…ä¸”å­˜åœ¨ recommended_time_columnï¼Œåˆ™å°è¯•æ›¿æ¢å¸¸è§æ—¶é—´åˆ—åä¸ºæ¨èåˆ—ã€‚
        - è¿›ä¸€æ­¥ï¼šè‹¥SQLä¸­ä½¿ç”¨çš„æ—¶é—´åˆ—ä¸å±äºç›®æ ‡è¡¨ï¼Œä½†ç›®æ ‡è¡¨å­˜åœ¨ dt æˆ–å…¶ä»–å¸¸è§æ—¶é—´åˆ—ï¼Œåˆ™è‡ªåŠ¨æ›¿æ¢ä¸ºè¯¥å¯ç”¨åˆ—ã€‚
        """
        try:
            sql_text = sql or ""
            allowed = set()
            sel = input_data.get("selected_tables") or []
            if isinstance(sel, list):
                allowed.update(sel)
            tabs = input_data.get("tables") or []
            if isinstance(tabs, list):
                allowed.update(tabs)
            allowed = {str(t) for t in allowed if t}

            referenced = self._find_referenced_tables(sql_text)
            unknown = [t for t in referenced if t not in allowed and t]
            issues = []
            warnings = []
            corrected = sql_text

            # è¡¨ä¿®å¤
            replaced_any = False
            for unk in unknown:
                best = self._match_best_table(unk, list(allowed))
                if best:
                    # ç²—ç•¥æ›¿æ¢ï¼ˆè€ƒè™‘è¾¹ç•Œï¼‰
                    import re
                    pattern = rf"\b{re.escape(unk)}\b"
                    corrected_new = re.sub(pattern, best, corrected)
                    if corrected_new != corrected:
                        corrected = corrected_new
                        replaced_any = True
                        issues.append(f"è¡¨åä¸å­˜åœ¨: {unk} â†’ å·²æ›¿æ¢ä¸º {best}")
                else:
                    issues.append(f"è¡¨åä¸å­˜åœ¨ä¸”æ— æ³•ä¿®å¤: {unk}")

            # ä¸å†ç¡¬ç¼–ç æ—¶é—´åˆ—ä¿®å¤ï¼Œè®©Agenté‡æ–°ç”Ÿæˆæ›´å‡†ç¡®çš„SQL
            # å¦‚æœæ—¶é—´åˆ—æœ‰é—®é¢˜ï¼ŒAgentä¼šé€šè¿‡æŸ¥çœ‹è¡¨ç»“æ„é‡æ–°ç”Ÿæˆæ­£ç¡®çš„SQL
            self._logger.info("ğŸ“‹ [Schemaä¿®å¤] è·³è¿‡ç¡¬ç¼–ç æ—¶é—´åˆ—ä¿®å¤ï¼Œå»ºè®®Agenté‡æ–°ç”ŸæˆSQL")

                # ç¡¬ç¼–ç æ—¶é—´åˆ—æ›¿æ¢é€»è¾‘å·²ç§»é™¤ - è®©Agentæ™ºèƒ½åˆ¤æ–­æ—¶é—´å­—æ®µ
                # ä½¿ç”¨ SHOW FULL COLUMNS FROM table_name å’Œ Agent æ™ºèƒ½å†³ç­–ä»£æ›¿ç®—æ³•é€»è¾‘

            # è¿”å›ç»“æœ
            return {
                "valid": len(issues) == 0,
                "issues": issues,
                "warnings": warnings,
                "corrected_sql": corrected if (replaced_any or warnings) and corrected != sql_text else None
            }
        except Exception as e:
            return {"valid": True, "issues": [f"schema_check_error: {str(e)}"], "warnings": []}

    def _find_referenced_tables(self, sql: str) -> List[str]:
        """ç®€æ˜“SQLè§£æï¼šæå– FROM/JOIN åçš„è¡¨åï¼ˆä¸å«åˆ«å/åº“å‰ç¼€ï¼‰ã€‚"""
        import re
        up = sql
        tokens = []
        # åŒ¹é… FROM xxx æˆ– JOIN xxx
        for m in re.finditer(r"\b(FROM|JOIN)\s+([`\w\.]+)", up, flags=re.IGNORECASE):
            raw = m.group(2).strip('`')
            # å»æ‰åº“åå‰ç¼€
            if '.' in raw:
                raw = raw.split('.')[-1]
            # å»æ‰å°¾éƒ¨é€—å·
            raw = raw.rstrip(',')
            tokens.append(raw)
        return list(dict.fromkeys(tokens))

    def _match_best_table(self, unk: str, allowed: List[str]) -> Optional[str]:
        """åŸºäºå…³é”®è¯ä¸ç›¸ä¼¼åº¦é€‰æ‹©æœ€åŒ¹é…çš„å…è®¸è¡¨ã€‚"""
        import difflib
        target = (unk or "").lower()
        # å…ˆå…³é”®è¯å‘½ä¸­
        pri = ["refund", "return", "é€€è´§", "é€€æ¬¾"]
        candidates = []
        for a in allowed:
            la = a.lower()
            score = 0
            if any(k in la for k in pri):
                score += 5
            # ç®€å•ç›¸ä¼¼åº¦
            score += int(difflib.SequenceMatcher(None, target, la).ratio() * 10)
            candidates.append((score, a))
        candidates.sort(key=lambda x: (-x[0], x[1]))
        return candidates[0][1] if candidates else None

    def _validate_sql_syntax(self, sql: str) -> Dict[str, Any]:
        """å¢å¼ºçš„SQLè¯­æ³•éªŒè¯"""
        sql_upper = sql.upper().strip()
        issues = []

        self._logger.debug(f"[SQLéªŒè¯] éªŒè¯SQL: {sql[:100]}...")
        self._logger.debug(f"[SQLéªŒè¯] SQLé•¿åº¦: {len(sql)}, å¤§å†™å: {sql_upper[:100]}...")

        # æ£€æŸ¥åŸºæœ¬SQLç»“æ„
        if not sql_upper.startswith("SELECT"):
            issues.append("SQLå¿…é¡»ä»¥SELECTå¼€å¤´")
            self._logger.warning(f"[SQLéªŒè¯] SELECTæ£€æŸ¥å¤±è´¥ï¼ŒSQLå¼€å¤´: {sql_upper[:20]}")

        if "FROM" not in sql_upper:
            issues.append("SQLå¿…é¡»åŒ…å«FROMå­å¥")
            self._logger.warning(f"[SQLéªŒè¯] FROMæ£€æŸ¥å¤±è´¥ï¼ŒSQLå†…å®¹: {sql_upper}")

        # æ£€æŸ¥å±é™©æ“ä½œ - ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…è¯¯æŠ¥å­—æ®µå
        dangerous_keywords = ["DROP", "DELETE", "TRUNCATE", "INSERT", "ALTER"]
        import re
        for keyword in dangerous_keywords:
            # ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼Œç¡®ä¿åªåŒ¹é…å®Œæ•´çš„SQLå…³é”®è¯ï¼Œä¸åŒ¹é…å­—æ®µåä¸­çš„å­ä¸²
            # ä¾‹å¦‚ï¼šåŒ¹é… "DELETE FROM" ä½†ä¸åŒ¹é… "e_is_deleted"
            pattern = r'\b' + keyword + r'\b'
            if re.search(pattern, sql_upper):
                issues.append(f"SQLåŒ…å«å±é™©å…³é”®è¯: {keyword}")

        # ç‰¹æ®Šå¤„ç†UPDATE - æ£€æŸ¥æ˜¯å¦åœ¨åˆæ³•ä¸Šä¸‹æ–‡ä¸­ï¼ˆå¦‚å­—æ®µåupdate_timeï¼‰
        if "UPDATE" in sql_upper:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆæ³•çš„å­—æ®µåå¼•ç”¨
            import re
            # åŒ¹é…å¸¸è§çš„åˆæ³•UPDATEä½¿ç”¨åœºæ™¯
            legal_patterns = [
                r'\bupdate_time\b',
                r'\bupdate_date\b',
                r'\bupdated_at\b',
                r'\blast_update\b',
                r'DATE\(update_time\)',
                r'WHERE\s+.*update_time',
                r'ORDER\s+BY\s+.*update_time'
            ]

            is_legal_usage = any(re.search(pattern, sql_upper) for pattern in legal_patterns)

            if is_legal_usage:
                # ä»issuesä¸­ç§»é™¤UPDATEç›¸å…³çš„é”™è¯¯
                issues = [issue for issue in issues if "UPDATE" not in issue]
                self._logger.info("âœ… UPDATEæ£€æµ‹ï¼šå‘ç°åˆæ³•çš„update_timeå­—æ®µä½¿ç”¨ï¼Œç§»é™¤å±é™©å…³é”®è¯è­¦æŠ¥")

        # æ–°å¢ï¼šæ£€æŸ¥æ‹¬å·åŒ¹é…
        parentheses_issues = self._check_parentheses_balance(sql)
        issues.extend(parentheses_issues)

        # æ–°å¢ï¼šæ£€æŸ¥SQLè¯­å¥ç»“æŸï¼ˆè­¦å‘Šè€Œéé”™è¯¯ï¼‰
        # æ³¨é‡Šæ‰å¼ºåˆ¶åˆ†å·è¦æ±‚ï¼Œå› ä¸ºå¾ˆå¤šSQLæ‰§è¡Œç¯å¢ƒä¸éœ€è¦åˆ†å·
        # if not sql.strip().endswith(';'):
        #     issues.append("SQLè¯­å¥åº”ä»¥åˆ†å·(;)ç»“å°¾")

        # æ–°å¢ï¼šæ£€æŸ¥å¸¸è§è¯­æ³•é”™è¯¯
        syntax_issues = self._check_common_syntax_errors(sql)
        issues.extend(syntax_issues)

        return {
            "valid": len(issues) == 0,
            "issues": issues,
            "error": "; ".join(issues) if issues else None
        }

    def _check_parentheses_balance(self, sql: str) -> List[str]:
        """æ£€æŸ¥æ‹¬å·å¹³è¡¡ - SQLç‰¹å®šä¼˜åŒ–ç‰ˆæœ¬"""
        issues = []
        stack = []
        pairs = {'(': ')'}  # åªæ£€æŸ¥åœ†æ‹¬å·ï¼Œæ–¹æ‹¬å·åœ¨SQLä¸­ç”¨é€”ç‰¹æ®Š

        # å…ˆç§»é™¤SQLå­—ç¬¦ä¸²å­—é¢é‡ï¼Œé¿å…è¯¯æŠ¥
        import re
        sql_cleaned = re.sub(r"'[^']*'", "''", sql)  # ç§»é™¤å•å¼•å·å­—ç¬¦ä¸²
        sql_cleaned = re.sub(r'"[^"]*"', '""', sql_cleaned)  # ç§»é™¤åŒå¼•å·å­—ç¬¦ä¸²
        sql_cleaned = re.sub(r'`[^`]*`', '``', sql_cleaned)  # ç§»é™¤åå¼•å·æ ‡è¯†ç¬¦

        for i, char in enumerate(sql_cleaned):
            if char in pairs:
                stack.append((char, i))
            elif char in pairs.values():
                if not stack:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²æˆ–æ³¨é‡Šä¸­
                    context = sql[max(0, i-20):i+20]
                    if "'" in context or '"' in context or '--' in context:
                        continue  # å¯èƒ½åœ¨å­—ç¬¦ä¸²ä¸­ï¼Œè·³è¿‡
                    issues.append(f"å¤šä½™çš„å³æ‹¬å· '{char}' åœ¨ä½ç½® {i+1}")
                else:
                    left_char, left_pos = stack.pop()
                    expected = pairs[left_char]
                    if char != expected:
                        issues.append(f"æ‹¬å·ä¸åŒ¹é…: åœ¨ä½ç½® {left_pos+1} çš„ '{left_char}' åº”è¯¥ä¸ '{expected}' åŒ¹é…ï¼Œä½†æ‰¾åˆ°äº† '{char}'")

        # æ£€æŸ¥æœªåŒ¹é…çš„å·¦æ‹¬å· - æ›´æ™ºèƒ½çš„æ£€æŸ¥
        for left_char, left_pos in stack:
            # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯SQLå‡½æ•°è°ƒç”¨çš„ä¸€éƒ¨åˆ†
            preceding_context = sql[max(0, left_pos-10):left_pos].strip()
            if any(func in preceding_context.upper() for func in ['DATE_SUB', 'DATE_ADD', 'COUNT', 'SUM', 'AVG']):
                # å¯èƒ½æ˜¯SQLå‡½æ•°ï¼Œç»™å‡ºæ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
                issues.append(f"SQLå‡½æ•°è°ƒç”¨ç¼ºå°‘å³æ‹¬å·: åœ¨ä½ç½® {left_pos+1} çš„ '{left_char}' æ²¡æœ‰åŒ¹é…çš„å³æ‹¬å·")
            else:
                issues.append(f"ç¼ºå°‘å³æ‹¬å·: åœ¨ä½ç½® {left_pos+1} çš„ '{left_char}' æ²¡æœ‰åŒ¹é…çš„å³æ‹¬å·")

        return issues

    def _check_common_syntax_errors(self, sql: str) -> List[str]:
        """æ£€æŸ¥å¸¸è§SQLè¯­æ³•é”™è¯¯ - æ”¹è¿›ç‰ˆï¼Œå‡å°‘è¯¯æŠ¥"""
        issues = []
        sql_upper = sql.upper()

        # æ£€æŸ¥å¸¸è§çš„MySQLå‡½æ•°è¯­æ³• - æ›´ç²¾ç¡®çš„éªŒè¯
        if 'DATE_SUB' in sql_upper or 'DATE_ADD' in sql_upper:
            import re

            # æ›´ç²¾ç¡®çš„DATE_SUB/DATE_ADDæ£€æŸ¥
            date_func_pattern = r'(DATE_SUB|DATE_ADD)\s*\(\s*[^,]+\s*,\s*INTERVAL\s+\d+\s+\w+\s*\)'

            if 'INTERVAL' in sql_upper:
                if not re.search(date_func_pattern, sql_upper):
                    # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯æ­£ç¡®çš„ä½†æ ¼å¼ç¨æœ‰ä¸åŒ
                    loose_pattern = r'(DATE_SUB|DATE_ADD)\s*\([^)]+INTERVAL[^)]+\)'
                    if re.search(loose_pattern, sql_upper):
                        # æ ¼å¼å¯èƒ½æ­£ç¡®ä½†ä¸æ ‡å‡†ï¼Œç»™å‡ºå»ºè®®è€Œéé”™è¯¯
                        pass
                    else:
                        issues.append("DATE_SUB/DATE_ADDå‡½æ•°éœ€è¦æ­£ç¡®çš„å‚æ•°æ ¼å¼: DATE_SUB(date, INTERVAL value unit)")

        return issues

    def _should_do_deep_validation(self, sql: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ·±åº¦AgentéªŒè¯"""
        # æ£€æŸ¥å¤æ‚SQLæ¨¡å¼
        complex_patterns = ['JOIN', 'UNION', 'SUBQUERY', 'CASE', 'WINDOW', 'CTE', 'DATE_SUB', 'DATE_ADD']
        sql_upper = sql.upper()
        return any(pattern in sql_upper for pattern in complex_patterns)

    async def _validate_sql_against_database(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        é’ˆå¯¹çœŸå®æ•°æ®åº“æ‰§è¡ŒSQLéªŒè¯ - Plan-Tool-Active-Validateæ ¸å¿ƒæœºåˆ¶

        è¿™æ˜¯çœŸæ­£çš„éªŒè¯ï¼šé€šè¿‡å®é™…æ‰§è¡ŒSQLï¼ˆå¸¦LIMITä¿æŠ¤ï¼‰æ¥ç¡®è®¤SQLçš„æ­£ç¡®æ€§
        é‡è¦ï¼šéªŒè¯é˜¶æ®µå°†å ä½ç¬¦æ›¿æ¢ä¸ºçœŸå®æ—¥æœŸè¿›è¡Œæµ‹è¯•ï¼Œä½†è¿”å›ç»™å‰ç«¯çš„ä»æ˜¯å ä½ç¬¦ç‰ˆæœ¬
        """
        validation_sql_with_dates = None  # ğŸ”§ åˆå§‹åŒ–å˜é‡ï¼Œç¡®ä¿åœ¨æ‰€æœ‰è¿”å›è·¯å¾„ä¸­éƒ½å¯ç”¨

        try:
            self._logger.info(f"ğŸ” [æ•°æ®åº“éªŒè¯] å¼€å§‹éªŒè¯SQL: {sql[:100]}...")

            # è·å–æ•°æ®æºæ‰§è¡Œå™¨
            data_source = input_data.get("data_source")
            if not data_source:
                return {
                    "success": False,
                    "issues": ["æ•°æ®æºä¿¡æ¯ç¼ºå¤±ï¼Œæ— æ³•è¿›è¡Œæ•°æ®åº“éªŒè¯"],
                    "warnings": [],
                    "validation_sql_with_dates": None
                }

            # ğŸ”„ å…³é”®ä¿®å¤ï¼šéªŒè¯é˜¶æ®µéœ€è¦å°†å ä½ç¬¦æ›¿æ¢ä¸ºçœŸå®æ—¥æœŸè¿›è¡Œæµ‹è¯•
            validation_sql_with_dates = self._replace_placeholders_for_validation(sql, input_data)
            self._logger.info(f"ğŸ“… [å ä½ç¬¦æ›¿æ¢] éªŒè¯ç”¨SQL: {validation_sql_with_dates[:100]}...")

            # åˆ›å»ºå®‰å…¨çš„éªŒè¯SQL - æ·»åŠ LIMITä¿æŠ¤
            validation_sql = self._make_sql_safe_for_validation(validation_sql_with_dates)
            self._logger.info(f"ğŸ›¡ï¸ [å®‰å…¨SQL] {validation_sql}")

            # å°è¯•æ‰§è¡ŒSQLè¿›è¡ŒéªŒè¯
            try:
                # ä½¿ç”¨æ•°æ®æºçš„æŸ¥è¯¢æ–¹æ³•
                if hasattr(data_source, 'execute_query'):
                    result = await data_source.execute_query(validation_sql, max_rows=10)
                elif hasattr(data_source, 'query'):
                    result = await data_source.query(validation_sql, limit=10)
                else:
                    # é€‚é…ï¼šæ”¯æŒä¼ å…¥è¿æ¥é…ç½®å­—å…¸ï¼Œä½¿ç”¨å®¹å™¨æ•°æ®æºé€‚é…å™¨æ‰§è¡Œ
                    conn_cfg = None
                    if isinstance(data_source, dict):
                        if data_source.get("connection_config"):
                            conn_cfg = data_source.get("connection_config")
                        else:
                            # ç²—ç•¥åˆ¤æ–­æ˜¯å¦ä¸ºç›´æ¥çš„è¿æ¥é…ç½®
                            keys = {"source_type", "database", "connection_string", "fe_hosts", "http_port", "query_port", "username"}
                            if any(k in data_source for k in keys):
                                conn_cfg = data_source

                    if conn_cfg:
                        adapter = getattr(self.container, 'data_source', None)
                        if not adapter:
                            return {
                                "success": False,
                                "issues": ["æ•°æ®æºé€‚é…å™¨ä¸å¯ç”¨"],
                                "warnings": [],
                                "validation_sql_with_dates": validation_sql_with_dates  # ğŸ”§ æ·»åŠ éªŒè¯ç”¨çš„SQL
                            }
                        result = await adapter.run_query(conn_cfg, validation_sql, limit=10)
                    else:
                        # å°è¯•è°ƒç”¨å®¹å™¨ä¸­çš„æ—§å¼æ•°æ®åº“æœåŠ¡
                        db_service = getattr(self.container, 'db_service', None)
                        if not db_service:
                            return {
                                "success": False,
                                "issues": ["æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"],
                                "warnings": [],
                                "validation_sql_with_dates": validation_sql_with_dates  # ğŸ”§ æ·»åŠ éªŒè¯ç”¨çš„SQL
                            }

                        user_id = input_data.get("user_id", "system")
                        result = await db_service.execute_query(user_id, validation_sql, limit=10)

                # è§£ææ‰§è¡Œç»“æœ
                # ç»Ÿä¸€è§£æç»“æœ
                rows, columns = [], []
                if result:
                    try:
                        # å­—å…¸æ ¼å¼
                        if isinstance(result, dict):
                            rows = result.get("rows") or result.get("data") or []
                            columns = result.get("columns") or result.get("column_names") or []
                        else:
                            # å¯¹è±¡å±æ€§æ ¼å¼
                            if hasattr(result, 'rows'):
                                rows = getattr(result, 'rows', [])
                            elif hasattr(result, 'data'):
                                rows = getattr(result, 'data', [])
                            if hasattr(result, 'columns'):
                                columns = getattr(result, 'columns', [])
                            elif hasattr(result, 'column_names'):
                                columns = getattr(result, 'column_names', [])
                    except Exception:
                        rows, columns = [], []

                if rows is not None or columns is not None:
                    self._logger.info(f"âœ… [æ•°æ®åº“éªŒè¯æˆåŠŸ] è·å¾— {len(rows or [])} è¡Œæ•°æ®ï¼Œ{len(columns or [])} åˆ—")

                    # éªŒè¯æ•°æ®è´¨é‡
                    quality_issues = self._validate_result_quality(rows, columns, sql, input_data)

                    return {
                        "success": True,
                        "issues": [],
                        "warnings": quality_issues,  # è´¨é‡é—®é¢˜ä½œä¸ºè­¦å‘Šè€Œéé”™è¯¯
                        "validation_sql_with_dates": validation_sql_with_dates,  # ğŸ”§ æ·»åŠ éªŒè¯ç”¨çš„SQL
                        "validation_result": {
                            "row_count": len(rows or []),
                            "column_count": len(columns or []),
                            "columns": columns or [],
                            "sample_data": (rows or [])[:3]  # è¿”å›å‰3è¡Œä½œä¸ºæ ·æœ¬
                        }
                    }
                else:
                    # SQLæ‰§è¡ŒæˆåŠŸä½†æ— ç»“æœ
                    self._logger.warning("âš ï¸ [æ•°æ®åº“éªŒè¯] SQLæ‰§è¡ŒæˆåŠŸä½†æ— æ•°æ®è¿”å›")
                    return {
                        "success": True,
                        "issues": [],
                        "warnings": ["SQLæ‰§è¡ŒæˆåŠŸä½†æœªè¿”å›æ•°æ®ï¼Œè¯·æ£€æŸ¥æŸ¥è¯¢æ¡ä»¶"],
                        "validation_sql_with_dates": validation_sql_with_dates,  # ğŸ”§ æ·»åŠ éªŒè¯ç”¨çš„SQL
                        "validation_result": {
                            "row_count": 0,
                            "column_count": 0,
                            "columns": [],
                            "sample_data": []
                        }
                    }

            except Exception as exec_error:
                # æ•°æ®åº“æ‰§è¡Œé”™è¯¯ - è¿™æ˜¯çœŸæ­£çš„SQLé—®é¢˜
                error_msg = str(exec_error).lower()
                self._logger.error(f"âŒ [æ•°æ®åº“éªŒè¯å¤±è´¥] {exec_error}")

                # åˆ†æé”™è¯¯ç±»å‹å¹¶æä¾›å…·ä½“å»ºè®®
                error_analysis = self._analyze_database_error(error_msg, sql, input_data)

                return {
                    "success": False,
                    "issues": [f"æ•°æ®åº“æ‰§è¡Œé”™è¯¯: {error_analysis['error_message']}"],
                    "warnings": error_analysis.get("suggestions", []),
                    "validation_sql_with_dates": validation_sql_with_dates,  # ğŸ”§ æ·»åŠ éªŒè¯ç”¨çš„SQL
                    "database_error": {
                        "original_error": str(exec_error),
                        "error_type": error_analysis["error_type"],
                        "recommendations": error_analysis.get("suggestions", [])
                    }
                }

        except Exception as e:
            self._logger.error(f"ğŸš¨ [æ•°æ®åº“éªŒè¯å¼‚å¸¸] {e}")
            return {
                "success": False,
                "issues": [f"æ•°æ®åº“éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}"],
                "warnings": [],
                "validation_sql_with_dates": validation_sql_with_dates  # ğŸ”§ å³ä½¿å¼‚å¸¸ä¹Ÿè¿”å›ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
            }

    def _replace_placeholders_for_validation(self, sql: str, input_data: Dict[str, Any]) -> str:
        """
        ä¸ºéªŒè¯ç›®çš„å°†å ä½ç¬¦æ›¿æ¢ä¸ºçœŸå®æ—¥æœŸ

        éªŒè¯é˜¶æ®µéœ€è¦æ‰§è¡ŒçœŸå®çš„SQLæŸ¥è¯¢ï¼Œæ‰€ä»¥è¦å°†{{start_date}}å’Œ{{end_date}}æ›¿æ¢ä¸ºå…·ä½“æ—¥æœŸ
        ä½†æœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„ä»ç„¶æ˜¯å¸¦å ä½ç¬¦çš„ç‰ˆæœ¬
        """
        try:
            validation_sql = sql

            # ä»input_dataä¸­è·å–æ—¶é—´çª—å£ä¿¡æ¯
            window = input_data.get("window") or input_data.get("time_window")
            if window and isinstance(window, dict):
                start_date = window.get("start_date")
                end_date = window.get("end_date")

                if start_date:
                    validation_sql = validation_sql.replace("{{start_date}}", f"'{start_date}'")
                    self._logger.info(f"ğŸ”„ æ›¿æ¢ {{{{start_date}}}} -> '{start_date}'")

                if end_date:
                    validation_sql = validation_sql.replace("{{end_date}}", f"'{end_date}'")
                    self._logger.info(f"ğŸ”„ æ›¿æ¢ {{{{end_date}}}} -> '{end_date}'")

            # å¦‚æœæ²¡æœ‰ä»windowè·å–åˆ°æ—¥æœŸï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
            if "{{start_date}}" in validation_sql or "{{end_date}}" in validation_sql:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„æ—¥æœŸå­—æ®µ
                start_date = input_data.get("start_date")
                end_date = input_data.get("end_date")

                if start_date and "{{start_date}}" in validation_sql:
                    validation_sql = validation_sql.replace("{{start_date}}", f"'{start_date}'")
                    self._logger.info(f"ğŸ”„ å¤‡ç”¨æ›¿æ¢ {{{{start_date}}}} -> '{start_date}'")

                if end_date and "{{end_date}}" in validation_sql:
                    validation_sql = validation_sql.replace("{{end_date}}", f"'{end_date}'")
                    self._logger.info(f"ğŸ”„ å¤‡ç”¨æ›¿æ¢ {{{{end_date}}}} -> '{end_date}'")

            # å¦‚æœä»æœ‰å ä½ç¬¦æœªæ›¿æ¢ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•æ—¥æœŸ
            if "{{start_date}}" in validation_sql or "{{end_date}}" in validation_sql:
                from datetime import datetime, timedelta
                today = datetime.now().date()
                yesterday = today - timedelta(days=1)

                default_date = yesterday.strftime('%Y-%m-%d')

                if "{{start_date}}" in validation_sql:
                    validation_sql = validation_sql.replace("{{start_date}}", f"'{default_date}'")
                    self._logger.info(f"ğŸ”„ é»˜è®¤æ›¿æ¢ {{{{start_date}}}} -> '{default_date}'")

                if "{{end_date}}" in validation_sql:
                    validation_sql = validation_sql.replace("{{end_date}}", f"'{default_date}'")
                    self._logger.info(f"ğŸ”„ é»˜è®¤æ›¿æ¢ {{{{end_date}}}} -> '{default_date}'")

            return validation_sql

        except Exception as e:
            self._logger.error(f"âŒ å ä½ç¬¦æ›¿æ¢å¤±è´¥: {e}")
            return sql  # å¤±è´¥æ—¶è¿”å›åŸå§‹SQL

    def _make_sql_safe_for_validation(self, sql: str) -> str:
        """ä¸ºéªŒè¯ç›®çš„åˆ¶ä½œå®‰å…¨çš„SQLã€‚

        ç­–ç•¥ï¼š
        - å·²åŒ…å« LIMIT/TOP/ROWNUM/SAMPLEï¼šä¸æ”¹åŠ¨ã€‚
        - æ˜ç¡®èšåˆ/åˆ†ç»„ï¼ˆGROUP BY æˆ–å« COUNT/SUM/AVG/MIN/MAXï¼‰ï¼šä¸åŠ  LIMITï¼Œé¿å…è¯¯ä¼¤å£å¾„ä¸ç±»åˆ«å®Œæ•´æ€§ã€‚
        - å…¶ä½™æŸ¥è¯¢ï¼šæœ«å°¾æ·»åŠ  LIMIT 10ï¼ˆéªŒè¯å°æ ·æœ¬ï¼‰ã€‚
        """
        original = sql or ""
        sql = (original.strip() or "")

        # ç§»é™¤æœ«å°¾åˆ†å·
        if sql.endswith(';'):
            sql = sql[:-1]

        up = sql.upper()
        # å·²æœ‰æ ·æœ¬é™åˆ¶
        if any(tok in up for tok in [" LIMIT ", " TOP ", "ROWNUM", " SAMPLE "]):
            return sql

        # èšåˆ/åˆ†ç»„æŸ¥è¯¢ä¸è¿‡åº¦åŠ  LIMITï¼ˆä»¥å…è¯¯ä¼¤æ¯”ä¾‹/ç±»åˆ«å®Œæ•´æ€§ï¼‰
        has_group_by = " GROUP BY " in up
        has_agg = any(fn in up for fn in ["COUNT(", "SUM(", "AVG(", "MIN(", "MAX("])
        if has_group_by or has_agg:
            return sql

        # å…¶ä»–æƒ…å†µåŠ å…¥LIMIT 10
        return f"{sql} LIMIT 10"

    def _validate_result_quality(self, rows: List, columns: List, sql: str, input_data: Dict[str, Any]) -> List[str]:
        """éªŒè¯æŸ¥è¯¢ç»“æœçš„æ•°æ®è´¨é‡"""
        warnings = []

        # æ£€æŸ¥åˆ—æ•°å’Œæ•°æ®å®Œæ•´æ€§
        if not columns:
            warnings.append("æŸ¥è¯¢ç»“æœç¼ºå°‘åˆ—ä¿¡æ¯")

        if not rows:
            warnings.append("æŸ¥è¯¢æœªè¿”å›æ•°æ®è¡Œï¼Œè¯·æ£€æŸ¥æ—¶é—´èŒƒå›´æˆ–è¿‡æ»¤æ¡ä»¶")
        elif len(rows) < 3:
            warnings.append(f"æŸ¥è¯¢ç»“æœè¾ƒå°‘ï¼ˆä»…{len(rows)}è¡Œï¼‰ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æŸ¥è¯¢æ¡ä»¶")

        # æ£€æŸ¥è¯­ä¹‰ç±»å‹ç‰¹å®šçš„è´¨é‡è¦æ±‚
        semantic_type = input_data.get("semantic_type", "").lower()

        if semantic_type == "compare":
            # å¯¹æ¯”æŸ¥è¯¢åº”è¯¥æœ‰baseline, compare, diff, pct_changeç­‰åˆ—
            required_concepts = ["åŸºå‡†", "å¯¹æ¯”", "å·®å€¼", "ç™¾åˆ†æ¯”", "baseline", "compare", "diff", "pct", "change"]
            has_compare_structure = any(any(concept in str(col).lower() for concept in required_concepts)
                                      for col in columns)
            if not has_compare_structure:
                warnings.append("å¯¹æ¯”æŸ¥è¯¢ç»“æœä¸­æœªå‘ç°å¯¹æ¯”ç»“æ„ï¼ˆåŸºå‡†å€¼ã€å¯¹æ¯”å€¼ã€å·®å€¼ã€å˜åŒ–ç‡ï¼‰")

        elif semantic_type == "ranking":
            # æ’åæŸ¥è¯¢åº”è¯¥æœ‰æ’åºç»“æ„
            if len(rows) > 1:
                # ç®€å•æ£€æŸ¥ï¼šå¦‚æœæœ‰æ•°å€¼åˆ—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ’åºè¶‹åŠ¿
                numeric_cols = []
                for i, col in enumerate(columns):
                    try:
                        if rows[0] and i < len(rows[0]) and isinstance(rows[0][i], (int, float)):
                            numeric_cols.append(i)
                    except:
                        pass

                if not numeric_cols:
                    warnings.append("æ’åæŸ¥è¯¢ç»“æœä¸­æœªå‘ç°æ•°å€¼åˆ—ç”¨äºæ’åº")

        return warnings

    def _analyze_database_error(self, error_msg: str, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ•°æ®åº“é”™è¯¯å¹¶æä¾›ä¿®å¤å»ºè®®"""
        error_analysis = {
            "error_type": "unknown",
            "error_message": error_msg,
            "suggestions": []
        }

        # è¡¨/åˆ—ä¸å­˜åœ¨é”™è¯¯
        if any(keyword in error_msg for keyword in ["table", "column", "field", "doesn't exist", "not found", "unknown"]):
            error_analysis["error_type"] = "schema_mismatch"
            error_analysis["suggestions"] = [
                "æ£€æŸ¥è¡¨åå’Œåˆ—åæ˜¯å¦æ­£ç¡®",
                "ç¡®è®¤ä½¿ç”¨çš„è¡¨å’Œåˆ—åœ¨æ•°æ®åº“schemaä¸­å­˜åœ¨",
                "å»ºè®®é‡æ–°è·å–schemaä¿¡æ¯"
            ]

        # è¯­æ³•é”™è¯¯
        elif any(keyword in error_msg for keyword in ["syntax", "parse", "grammar", "invalid"]):
            error_analysis["error_type"] = "syntax_error"
            error_analysis["suggestions"] = [
                "æ£€æŸ¥SQLè¯­æ³•æ˜¯å¦æ­£ç¡®",
                "ç¡®è®¤æ‹¬å·ã€å¼•å·æ˜¯å¦åŒ¹é…",
                "æ£€æŸ¥å…³é”®å­—æ‹¼å†™æ˜¯å¦æ­£ç¡®"
            ]

        # æƒé™é”™è¯¯
        elif any(keyword in error_msg for keyword in ["permission", "access", "denied", "unauthorized"]):
            error_analysis["error_type"] = "permission_error"
            error_analysis["suggestions"] = [
                "æ£€æŸ¥æ•°æ®åº“è®¿é—®æƒé™",
                "ç¡®è®¤ç”¨æˆ·æœ‰æŸ¥è¯¢ç›¸å…³è¡¨çš„æƒé™"
            ]

        # æ•°æ®ç±»å‹é”™è¯¯
        elif any(keyword in error_msg for keyword in ["type", "conversion", "cast", "format"]):
            error_analysis["error_type"] = "data_type_error"
            error_analysis["suggestions"] = [
                "æ£€æŸ¥æ•°æ®ç±»å‹è½¬æ¢æ˜¯å¦æ­£ç¡®",
                "ç¡®è®¤æ—¥æœŸã€æ•°å€¼æ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚"
            ]

        return error_analysis

    async def _agent_validate_sql(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨Agentè¿›è¡Œæ™ºèƒ½SQLè¯­æ³•éªŒè¯"""
        try:
            # æ„å»ºæ™ºèƒ½éªŒè¯æç¤ºè¯
            prompt = self._build_agent_validation_prompt(sql, input_data)

            # è°ƒç”¨LLMè¿›è¡ŒéªŒè¯
            llm_service = getattr(self.container, 'llm_service', None) or getattr(self.container, 'llm', None)
            if not llm_service:
                self._logger.warning("LLM service not available for agent validation")
                return {"success": True, "issues": [], "warnings": []}

            # è·å–ç”¨æˆ·ID
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"

            # è®¾ç½®LLMç­–ç•¥ï¼Œè¦æ±‚è¿”å›JSONæ ¼å¼
            llm_policy = {
                "stage": "tool",
                "step": "sql.validate",
                "complexity": "medium",
                "output_kind": "sql_validation"
            }

            # è¯·æ±‚JSONæ ¼å¼å“åº”
            response_format = {"type": "json_object"}

            # è°ƒç”¨LLM
            response = await llm_service.ask(
                user_id=user_id,
                prompt=prompt,
                response_format=response_format,
                llm_policy=llm_policy
            )

            # è§£æLLMå“åº”
            import json
            try:
                validation_response = json.loads(response.get("response", "{}"))
            except json.JSONDecodeError:
                self._logger.warning("LLMè¿”å›éJSONæ ¼å¼ï¼Œä½¿ç”¨åŸºç¡€éªŒè¯")
                return {"success": True, "issues": [], "warnings": []}

            # æå–éªŒè¯ç»“æœ
            is_valid = validation_response.get("is_valid", True)
            syntax_errors = validation_response.get("syntax_errors", [])
            suggestions = validation_response.get("suggestions", [])

            self._logger.info(f"ğŸ¤– Agent SQLéªŒè¯å®Œæˆ: valid={is_valid}, errors={len(syntax_errors)}, suggestions={len(suggestions)}")

            return {
                "success": is_valid,
                "issues": syntax_errors if not is_valid else [],
                "warnings": suggestions,
                "agent_analysis": validation_response
            }

        except Exception as e:
            self._logger.error(f"Agent SQLéªŒè¯å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä¸å½±å“ä¸»æµç¨‹
            return {"success": True, "issues": [], "warnings": []}

    def _build_agent_validation_prompt(self, sql: str, input_data: Dict[str, Any]) -> str:
        """æ„å»ºAgentéªŒè¯æç¤ºè¯"""
        semantic_type = input_data.get("semantic_type", "")
        user_prompt = input_data.get("user_prompt", "")

        # é¢„æ£€æŸ¥ï¼šå¦‚æœSQLçœ‹èµ·æ¥æ˜¯æ­£ç¡®çš„ï¼Œç»™Agentä¸€ä¸ªæç¤º
        confidence_hint = ""
        if self._is_likely_valid_sql(sql):
            confidence_hint = "\nâš ï¸ æç¤ºï¼šæ­¤SQLè¯­å¥é€šè¿‡äº†åŸºç¡€æ¨¡å¼åŒ¹é…éªŒè¯ï¼Œè¯·è°¨æ…åˆ¤æ–­æ˜¯å¦å­˜åœ¨çœŸæ­£çš„è¯­æ³•é”™è¯¯ã€‚"

        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLè¯­æ³•æ£€æŸ¥ä¸“å®¶ã€‚è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹SQLè¯­å¥çš„è¯­æ³•æ­£ç¡®æ€§ã€‚

åŸå§‹éœ€æ±‚: {user_prompt}
å ä½ç¬¦ç±»å‹: {semantic_type}
SQLè¯­å¥:
```sql
{sql}
```
{confidence_hint}

è¯·æ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š
1. è¯­æ³•æ­£ç¡®æ€§ï¼ˆæ‹¬å·åŒ¹é…ã€å…³é”®å­—æ‹¼å†™ã€å‡½æ•°è°ƒç”¨æ ¼å¼ï¼‰
2. æŸ¥è¯¢é€»è¾‘åˆç†æ€§
3. æ½œåœ¨çš„æ€§èƒ½é—®é¢˜
4. æ•°æ®ç±»å‹å…¼å®¹æ€§

âš ï¸ é‡è¦æç¤ºï¼š
- å¯¹äºDATE_SUB(CURDATE(), INTERVAL 1 YEAR)è¿™æ ·çš„æ ‡å‡†MySQLå‡½æ•°è°ƒç”¨ï¼Œå¦‚æœæ‹¬å·åŒ¹é…æ­£ç¡®ï¼Œåº”åˆ¤å®šä¸ºæœ‰æ•ˆ
- è¯·åŒºåˆ†çœŸæ­£çš„è¯­æ³•é”™è¯¯å’Œæ ¼å¼åå¥½é—®é¢˜
- åªæœ‰ç¡®å®æ— æ³•æ‰§è¡Œçš„SQLæ‰åº”æ ‡è®°ä¸ºæ— æ•ˆ
- ğŸ• æµ‹è¯•ç¯å¢ƒè¯´æ˜ï¼šå…è®¸ä½¿ç”¨æœªæ¥æ—¥æœŸè¿›è¡Œæµ‹è¯•ï¼Œä¸è¦å› ä¸ºæ—¥æœŸè¶…å‡ºå½“å‰èŒƒå›´è€Œåˆ¤å®šä¸ºæ— æ•ˆ
- æ—¥æœŸèŒƒå›´æ£€æŸ¥ä¸æ˜¯è¯­æ³•é”™è¯¯ï¼Œå³ä½¿æŸ¥è¯¢ç»“æœå¯èƒ½ä¸ºç©ºä¹Ÿåº”è¯¥å…è®¸æ‰§è¡Œ
- âœ… åŒä¸€æ—¥æœŸçš„BETWEENæŸ¥è¯¢ï¼ˆå¦‚ BETWEEN '2025-09-26' AND '2025-09-26'ï¼‰æ˜¯å®Œå…¨æœ‰æ•ˆçš„è¯­æ³•
- âœ… DATE()å‡½æ•°æŸ¥è¯¢ï¼ˆå¦‚ WHERE DATE(column) = '2025-09-26'ï¼‰ä¹Ÿæ˜¯æœ‰æ•ˆçš„

è¿”å›JSONæ ¼å¼ç»“æœï¼š
{{
    "is_valid": true/false,
    "syntax_errors": ["å…·ä½“çš„è¯­æ³•é”™è¯¯æè¿°"],
    "suggestions": ["æ”¹è¿›å»ºè®®"],
    "confidence": 0.95,
    "corrected_sql": "å¦‚æœæœ‰é”™è¯¯ï¼Œæä¾›ä¿®æ­£åçš„SQL"
}}
"""

    def _validate_compare_sql(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """CompareæŸ¥è¯¢å¼ºæ ¡éªŒ"""
        issues = []
        warnings = []
        valid = True

        if not self.compare_strict_validation:
            self._logger.info("Compareå¼ºæ ¡éªŒå·²ç¦ç”¨ï¼Œè·³è¿‡éªŒè¯")
            return {"valid": True, "issues": [], "warnings": []}

        sql_upper = sql.upper()
        self._logger.info(f"ğŸ” [CompareValidation] å¼€å§‹Compareå¼ºæ ¡éªŒï¼Œenforce_column_names={self.compare_enforce_column_names}")

        # 1. å¼ºåˆ¶æ£€æŸ¥å¿…éœ€åˆ—åï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.compare_enforce_column_names:
            missing_columns = []
            for required_col in self.required_compare_columns:
                if required_col.upper() not in sql_upper:
                    missing_columns.append(required_col)

            if missing_columns:
                issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—å: {', '.join(missing_columns)}")
                valid = False
                self._logger.warning(f"âš ï¸ [CompareValidation] ç¼ºå°‘å¿…éœ€åˆ—å: {missing_columns}")

        # 2. å¿…é¡»åŒ…å«åŸºå‡†æœŸå’Œå¯¹æ¯”æœŸçš„æ¦‚å¿µï¼ˆæ›´ä¸¥æ ¼ï¼‰
        baseline_keywords = ["BASELINE", "BASE", "PREVIOUS", "LAST", "PRIOR", "BEFORE", "OLD"]
        compare_keywords = ["COMPARE", "CURRENT", "NEW", "NOW", "AFTER", "RECENT"]

        has_baseline = any(keyword in sql_upper for keyword in baseline_keywords)
        has_compare = any(keyword in sql_upper for keyword in compare_keywords)

        if not has_baseline:
            issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«åŸºå‡†æœŸæ¦‚å¿µ (å…³é”®è¯: {', '.join(baseline_keywords[:3])}...)")
            valid = False

        if not has_compare:
            issues.append(f"CompareæŸ¥è¯¢å¿…é¡»åŒ…å«å¯¹æ¯”æœŸæ¦‚å¿µ (å…³é”®è¯: {', '.join(compare_keywords[:3])}...)")
            valid = False

        # 3. å¼ºåˆ¶è¦æ±‚åŒ…å«å·®å€¼è®¡ç®—ï¼ˆæ›´ç²¾ç¡®æ£€æŸ¥ï¼‰
        diff_patterns = ["DIFF", "DIFFERENCE", "CHANGE", "DELTA", "MINUS", "SUBTRACT", "VARIANCE"]
        has_diff = any(pattern in sql_upper for pattern in diff_patterns)
        has_arithmetic_diff = " - " in sql or "(-" in sql  # ç®—æœ¯å·®å€¼

        if not (has_diff or has_arithmetic_diff):
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«å·®å€¼è®¡ç®— (ä½¿ç”¨ DIFF/CHANGE åˆ—åæˆ–ç®—æœ¯è¿ç®— '-')")
            valid = False

        # 4. å¼ºåˆ¶è¦æ±‚åŒ…å«ç™¾åˆ†æ¯”å˜åŒ–ï¼ˆæ›´ç²¾ç¡®æ£€æŸ¥ï¼‰
        pct_patterns = ["PCT", "PERCENT", "PERCENTAGE", "RATE", "RATIO", "GROWTH"]
        has_pct = any(pattern in sql_upper for pattern in pct_patterns)
        has_pct_formula = "*100" in sql.replace(" ", "") or "/100" in sql.replace(" ", "")  # ç™¾åˆ†æ¯”å…¬å¼

        if not (has_pct or has_pct_formula):
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«ç™¾åˆ†æ¯”å˜åŒ– (ä½¿ç”¨ PCT_CHANGE/PERCENTAGE åˆ—åæˆ–ç™¾åˆ†æ¯”è®¡ç®—)")
            valid = False

        # 5. æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´ç»´åº¦ï¼ˆå‡çº§ä¸ºå¼ºåˆ¶è¦æ±‚ï¼‰
        time_keywords = ["DATE", "TIME", "YEAR", "MONTH", "DAY", "PERIOD", "WEEK", "QUARTER"]
        has_time_dimension = any(keyword in sql_upper for keyword in time_keywords)

        if not has_time_dimension:
            issues.append("CompareæŸ¥è¯¢å¿…é¡»åŒ…å«æ—¶é—´ç»´åº¦ä»¥æ˜ç¡®å¯¹æ¯”æœŸé—´")
            valid = False

        # 6. æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„åˆ†ç»„å’Œæ’åº
        has_group_by = "GROUP BY" in sql_upper
        has_order_by = "ORDER BY" in sql_upper

        if not has_group_by:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®ä½¿ç”¨ GROUP BY è¿›è¡Œé€‚å½“åˆ†ç»„")

        if not has_order_by:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®ä½¿ç”¨ ORDER BY æŒ‰å˜åŒ–å¹…åº¦æ’åº")

        # 7. æ£€æŸ¥æ½œåœ¨çš„æ•°æ®è´¨é‡é—®é¢˜
        if "WHERE" not in sql_upper:
            warnings.append("CompareæŸ¥è¯¢å»ºè®®æ·»åŠ  WHERE æ¡ä»¶é™åˆ¶æ•°æ®èŒƒå›´ï¼Œé¿å…å…¨è¡¨æ‰«æ")

        result = {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

        if valid:
            self._logger.info("âœ… [CompareValidation] CompareæŸ¥è¯¢é€šè¿‡å¼ºæ ¡éªŒ")
        else:
            self._logger.warning(f"ğŸš¨ [CompareValidation] CompareæŸ¥è¯¢æœªé€šè¿‡å¼ºæ ¡éªŒï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")

        return result

    def _validate_ranking_sql(self, sql: str, top_n: int) -> Dict[str, Any]:
        """æ’åæŸ¥è¯¢éªŒè¯"""
        issues = []
        warnings = []
        valid = True

        sql_upper = sql.upper()

        # æ£€æŸ¥æ˜¯å¦æœ‰æ’åºå’Œé™åˆ¶
        has_order_by = "ORDER BY" in sql_upper
        has_limit = "LIMIT" in sql_upper or f"LIMIT {top_n}" in sql_upper
        has_rank_function = any(func in sql_upper for func in [
            "RANK()", "DENSE_RANK()", "ROW_NUMBER()", "NTILE("
        ])

        if not has_order_by and not has_rank_function:
            issues.append("æ’åæŸ¥è¯¢å¿…é¡»åŒ…å« ORDER BY å­å¥æˆ–çª—å£æ’åå‡½æ•°")
            valid = False

        if not has_limit and not has_rank_function:
            warnings.append(f"æ’åæŸ¥è¯¢å»ºè®®ä½¿ç”¨ LIMIT {top_n} æˆ–çª—å£å‡½æ•°é™åˆ¶ç»“æœæ•°é‡")

        return {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

    def _validate_chart_sql(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å›¾è¡¨æŸ¥è¯¢éªŒè¯"""
        warnings = []

        chart_type = input_data.get("chart_type", "").lower()
        sql_upper = sql.upper()

        # æ ¹æ®å›¾è¡¨ç±»å‹ç»™å‡ºå»ºè®®
        if chart_type == "pie":
            if "GROUP BY" not in sql_upper:
                warnings.append("é¥¼å›¾å»ºè®®ä½¿ç”¨ GROUP BY å¯¹ç±»åˆ«è¿›è¡Œåˆ†ç»„")
        elif chart_type == "line":
            has_time = any(keyword in sql_upper for keyword in [
                "DATE", "TIME", "YEAR", "MONTH", "DAY"
            ])
            if not has_time:
                warnings.append("æŠ˜çº¿å›¾å»ºè®®åŒ…å«æ—¶é—´ç»´åº¦æ•°æ®")
        elif chart_type == "bar":
            if "ORDER BY" not in sql_upper:
                warnings.append("æŸ±çŠ¶å›¾å»ºè®®ä½¿ç”¨ ORDER BY å¯¹ç»“æœæ’åº")

        return {
            "valid": True,
            "warnings": warnings
        }

    def _validate_table_scan_security(self, sql: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """SQLè¡¨æ‰«æå®‰å…¨éªŒè¯ - é˜²æ­¢æ— WHEREæ¡ä»¶çš„å¤§è¡¨æ‰«æ"""
        issues = []
        warnings = []
        valid = True

        if not self.enable_table_scan_protection:
            self._logger.info("è¡¨æ‰«æä¿æŠ¤å·²ç¦ç”¨ï¼Œè·³è¿‡éªŒè¯")
            return {"valid": True, "issues": [], "warnings": []}

        sql_upper = sql.upper()
        self._logger.info(f"ğŸ” [TableScanSecurity] å¼€å§‹è¡¨æ‰«æå®‰å…¨éªŒè¯")

        # æ£€æŸ¥æ˜¯å¦æœ‰WHEREæ¡ä»¶
        has_where = "WHERE" in sql_upper
        has_limit = any(pattern in sql_upper for pattern in self.scan_exempt_patterns)

        if not has_where and not has_limit:
            # æå–è¡¨åè¿›è¡Œç™½åå•æ£€æŸ¥
            tables = self._extract_table_names(sql)
            blocked_tables = []
            whitelisted_tables = []

            for table in tables:
                table_clean = table.lower().strip()
                if table_clean in self.scan_whitelist_tables:
                    whitelisted_tables.append(table)
                else:
                    blocked_tables.append(table)

            if blocked_tables:
                self._logger.warning(f"ğŸš¨ [TableScanSecurity] æ£€æµ‹åˆ°å¤§è¡¨æ‰«æé£é™©: {blocked_tables}")

                # å°è¯•è·å–è¡¨å¤§å°ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                table_size_info = self._get_table_size_info(blocked_tables, input_data)
                large_tables = []

                for table, size_info in table_size_info.items():
                    estimated_size = size_info.get("estimated_rows", 0)
                    if estimated_size > self.max_table_scan_size:
                        large_tables.append(f"{table}(~{estimated_size}è¡Œ)")

                if large_tables:
                    issues.append(
                        f"ç¦æ­¢æ— WHEREæ¡ä»¶æ‰«æå¤§è¡¨: {', '.join(large_tables)}ã€‚"
                        f"è¯·æ·»åŠ WHEREæ¡ä»¶é™åˆ¶æ•°æ®èŒƒå›´ï¼Œæˆ–ä½¿ç”¨LIMITé™åˆ¶è¿”å›è¡Œæ•°"
                    )
                    valid = False
                else:
                    warnings.append(
                        f"æ£€æµ‹åˆ°æ— WHEREæ¡ä»¶çš„è¡¨æ‰«æ: {', '.join(blocked_tables)}ã€‚"
                        f"å»ºè®®æ·»åŠ WHEREæ¡ä»¶æˆ–LIMITå­å¥ä»¥æå‡æ€§èƒ½"
                    )

            if whitelisted_tables:
                self._logger.info(f"âœ… [TableScanSecurity] ç™½åå•è¡¨å…è®¸æ‰«æ: {whitelisted_tables}")

        # æ£€æŸ¥JOINæ“ä½œçš„å®‰å…¨æ€§
        if "JOIN" in sql_upper and not has_where:
            warnings.append("å¤šè¡¨JOINæ“ä½œå»ºè®®ä½¿ç”¨WHEREæ¡ä»¶é™åˆ¶ç»“æœé›†å¤§å°")

        # æ£€æŸ¥èšåˆæ“ä½œ
        has_aggregation = any(func in sql_upper for func in ["COUNT", "SUM", "AVG", "MAX", "MIN", "GROUP BY"])
        if has_aggregation and not has_where and not has_limit:
            warnings.append("èšåˆæŸ¥è¯¢å»ºè®®æ·»åŠ WHEREæ¡ä»¶æˆ–æ—¶é—´èŒƒå›´é™åˆ¶")

        result = {
            "valid": valid,
            "issues": issues,
            "warnings": warnings
        }

        if valid:
            self._logger.info("âœ… [TableScanSecurity] SQLè¡¨æ‰«æå®‰å…¨éªŒè¯é€šè¿‡")
        else:
            self._logger.warning(f"ğŸš¨ [TableScanSecurity] SQLå­˜åœ¨å®‰å…¨é£é™©ï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")

        return result

    def _extract_table_names(self, sql: str) -> list:
        """ä»SQLä¸­æå–è¡¨å"""
        import re

        # ç®€åŒ–çš„è¡¨åæå–ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›ï¼‰
        sql_clean = re.sub(r'--.*', '', sql)  # ç§»é™¤æ³¨é‡Š
        sql_clean = re.sub(r'/\*.*?\*/', '', sql_clean, flags=re.DOTALL)  # ç§»é™¤å¤šè¡Œæ³¨é‡Š

        # æŸ¥æ‰¾FROMå’ŒJOINåçš„è¡¨å
        tables = set()

        # FROMå­å¥
        from_pattern = r'\bFROM\s+(\w+)'
        for match in re.finditer(from_pattern, sql_clean, re.IGNORECASE):
            tables.add(match.group(1))

        # JOINå­å¥
        join_pattern = r'\bJOIN\s+(\w+)'
        for match in re.finditer(join_pattern, sql_clean, re.IGNORECASE):
            tables.add(match.group(1))

        return list(tables)

    def _get_table_size_info(self, tables: list, input_data: Dict[str, Any]) -> Dict[str, Dict]:
        """è·å–è¡¨å¤§å°ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥ä»æ•°æ®æºæˆ–å…ƒæ•°æ®æœåŠ¡è·å–
        size_info = {}

        # é»˜è®¤è¡¨å¤§å°ä¼°ç®—ï¼ˆå®é™…åº”è¯¥ä»æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯è·å–ï¼‰
        default_estimates = {
            "users": {"estimated_rows": 50000},
            "orders": {"estimated_rows": 100000},
            "transactions": {"estimated_rows": 500000},
            "logs": {"estimated_rows": 1000000},
            "events": {"estimated_rows": 2000000},
        }

        for table in tables:
            table_lower = table.lower()
            if table_lower in default_estimates:
                size_info[table] = default_estimates[table_lower]
            else:
                # ä¿å®ˆä¼°è®¡
                size_info[table] = {"estimated_rows": self.max_table_scan_size + 1}

        return size_info

    def _make_validation_decision(self, validation_result: Dict[str, Any], sql: str, input_data: Dict[str, Any], agent_correction_available: bool = False) -> Dict[str, Any]:
        """æ™ºèƒ½å®¹é”™å†³ç­–æœºåˆ¶ - åˆ¤æ–­æ˜¯å¦åº”è¯¥é€šè¿‡éªŒè¯"""
        issues = validation_result.get("issues", [])
        warnings = validation_result.get("warnings", [])
        original_valid = validation_result.get("valid", True)

        # ğŸš¨ ä¸¥é‡é”™è¯¯ï¼šå¿…é¡»é˜»æ­¢é€šè¿‡
        critical_keywords = [
            "DROP", "DELETE", "TRUNCATE", "INSERT", "UPDATE", "ALTER",
            "å¤šä½™çš„å³æ‹¬å·", "SQLå‡½æ•°è°ƒç”¨ç¼ºå°‘å³æ‹¬å·"
        ]

        has_critical_issues = any(
            any(keyword in issue for keyword in critical_keywords)
            for issue in issues
        )

        if has_critical_issues:
            return {
                "success": False,
                "issues": issues,
                "warnings": warnings,
                "error": "; ".join(issues),
                "decision_reason": "å‘ç°ä¸¥é‡è¯­æ³•é”™è¯¯ï¼Œå¿…é¡»ä¿®å¤"
            }

        # ğŸŸ¡ è½»å¾®é—®é¢˜ï¼šå¯ä»¥å®¹å¿çš„é”™è¯¯ç±»å‹
        tolerable_issues = [
            "ç¼ºå°‘å³æ‹¬å·",  # ä½†ä¸æ˜¯å‡½æ•°è°ƒç”¨çš„
            "DATE_SUB/DATE_ADDå‡½æ•°éœ€è¦æ­£ç¡®çš„å‚æ•°æ ¼å¼",
            "SQLè¯­å¥åº”ä»¥åˆ†å·(;)ç»“å°¾"
        ]

        # åˆ†ç¦»ä¸¥é‡å’Œè½»å¾®é—®é¢˜
        serious_issues = []
        minor_issues = []

        for issue in issues:
            is_tolerable = any(tolerable in issue for tolerable in tolerable_issues)

            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯å‡½æ•°è°ƒç”¨çš„æ‹¬å·é—®é¢˜ï¼Œè§†ä¸ºä¸¥é‡
            if "ç¼ºå°‘å³æ‹¬å·" in issue and any(func in issue for func in ['DATE_SUB', 'DATE_ADD', 'COUNT', 'SUM']):
                serious_issues.append(issue)
            elif is_tolerable:
                minor_issues.append(issue)
            else:
                serious_issues.append(issue)

        # ğŸ” æ–°å¢ï¼šæ™ºèƒ½SQLè¯­æ³•æ£€æŸ¥ - å¯¹äºå¸¸è§çš„æ­£ç¡®SQLæ¨¡å¼è¿›è¡Œç™½åå•éªŒè¯
        if not serious_issues and self._is_likely_valid_sql(sql):
            # ä½¿ç”¨SQLæ¨¡å¼åŒ¹é…è¿›è¡Œæœ€åéªŒè¯
            return {
                "success": True,
                "issues": [],
                "warnings": warnings + minor_issues,  # è½»å¾®é—®é¢˜è½¬ä¸ºè­¦å‘Š
                "error": None,
                "decision_reason": f"é€šè¿‡æ™ºèƒ½æ¨¡å¼éªŒè¯ï¼Œ{len(minor_issues)}ä¸ªè½»å¾®é—®é¢˜è½¬ä¸ºè­¦å‘Š"
            }

        # å†³ç­–é€»è¾‘
        if not serious_issues:
            # æ²¡æœ‰ä¸¥é‡é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ï¼Œä½†ä¿ç•™è­¦å‘Š
            return {
                "success": True,
                "issues": [],
                "warnings": warnings + minor_issues,  # è½»å¾®é—®é¢˜è½¬ä¸ºè­¦å‘Š
                "error": None,
                "decision_reason": f"é€šè¿‡å®¹é”™éªŒè¯ï¼Œ{len(minor_issues)}ä¸ªè½»å¾®é—®é¢˜è½¬ä¸ºè­¦å‘Š"
            }

        elif len(serious_issues) == 1 and agent_correction_available:
            # åªæœ‰ä¸€ä¸ªä¸¥é‡é—®é¢˜ä¸”æœ‰Agentä¿®æ­£å»ºè®®ï¼Œå¯ä»¥æä¾›ä¿®æ­£å»ºè®®
            return {
                "success": False,
                "issues": serious_issues,
                "warnings": warnings + minor_issues,
                "error": "; ".join(serious_issues),
                "decision_reason": "å‘ç°å¯ä¿®å¤çš„è¯­æ³•é”™è¯¯ï¼Œå·²æä¾›ä¿®æ­£å»ºè®®"
            }

        else:
            # å¤šä¸ªä¸¥é‡é—®é¢˜ï¼Œå¿…é¡»ä¿®å¤
            return {
                "success": False,
                "issues": serious_issues + minor_issues,
                "warnings": warnings,
                "error": "; ".join(serious_issues + minor_issues),
                "decision_reason": f"å‘ç°{len(serious_issues)}ä¸ªä¸¥é‡é”™è¯¯ï¼Œéœ€è¦ä¿®å¤"
            }

    def _is_likely_valid_sql(self, sql: str) -> bool:
        """æ™ºèƒ½SQLæ¨¡å¼æ£€æŸ¥ - è¯†åˆ«å¸¸è§çš„æ­£ç¡®SQLæ¨¡å¼"""
        sql_clean = sql.strip().upper()

        # æ£€æŸ¥å¸¸è§çš„æ­£ç¡®SQLæ¨¡å¼
        valid_patterns = [
            # æ ‡å‡†COUNTæŸ¥è¯¢æ¨¡å¼
            r'^SELECT\s+COUNT\(\*\)\s+AS\s+\w+\s+FROM\s+\w+\s+WHERE\s+.+;?$',
            # å¸¦DATE_SUBçš„æŸ¥è¯¢æ¨¡å¼
            r'^SELECT\s+.+\s+FROM\s+\w+\s+WHERE\s+.+DATE_SUB\(CURDATE\(\),\s*INTERVAL\s+\d+\s+\w+\)\s*;?$',
            # åŸºæœ¬SELECTæ¨¡å¼
            r'^SELECT\s+.+\s+FROM\s+\w+(\s+WHERE\s+.+)?(\s+ORDER\s+BY\s+.+)?(\s+LIMIT\s+\d+)?\s*;?$'
        ]

        import re
        for pattern in valid_patterns:
            if re.match(pattern, sql_clean, re.DOTALL):
                self._logger.info(f"âœ… SQLåŒ¹é…æœ‰æ•ˆæ¨¡å¼: {pattern[:50]}...")
                return True

        # é¢å¤–æ£€æŸ¥ï¼šDATE_SUBå‡½æ•°æ ¼å¼
        if 'DATE_SUB' in sql_clean:
            # éªŒè¯DATE_SUBå‡½æ•°æ˜¯å¦æ ¼å¼æ­£ç¡®
            date_sub_pattern = r'DATE_SUB\s*\(\s*CURDATE\s*\(\s*\)\s*,\s*INTERVAL\s+\d+\s+\w+\s*\)'
            if re.search(date_sub_pattern, sql_clean):
                self._logger.info("âœ… DATE_SUBå‡½æ•°æ ¼å¼éªŒè¯é€šè¿‡")
                return True

        # ç®€å•æ‹¬å·å¹³è¡¡æ£€æŸ¥
        if self._simple_parentheses_check(sql):
            self._logger.info("âœ… ç®€å•æ‹¬å·å¹³è¡¡æ£€æŸ¥é€šè¿‡")
            return True

        return False

    def _simple_parentheses_check(self, sql: str) -> bool:
        """ç®€å•çš„æ‹¬å·å¹³è¡¡æ£€æŸ¥ - æ›´å®½æ¾çš„éªŒè¯"""
        count = 0
        in_string = False
        quote_char = None

        for i, char in enumerate(sql):
            # å¤„ç†å­—ç¬¦ä¸²
            if char in ('"', "'", '`') and not in_string:
                in_string = True
                quote_char = char
            elif char == quote_char and in_string:
                in_string = False
                quote_char = None
            elif in_string:
                continue

            # è®¡ç®—æ‹¬å·
            if char == '(':
                count += 1
            elif char == ')':
                count -= 1

            # å¦‚æœæ‹¬å·æ•°é‡ä¸ºè´Ÿï¼Œè¯´æ˜æœ‰å¤šä½™çš„å³æ‹¬å·
            if count < 0:
                return False

        # æœ€ç»ˆæ‹¬å·æ•°é‡åº”è¯¥ä¸º0
        return count == 0

    def _is_description_text(self, sql: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºæè¿°æ–‡æœ¬è€ŒéSQL"""
        if not sql or not isinstance(sql, str):
            return False

        sql_lower = sql.lower().strip()

        # æ˜æ˜¾çš„æè¿°æ€§å…³é”®è¯
        description_keywords = [
            "å½“å‰å€™é€‰", "å€™é€‰sql", "sqlå†…å®¹", "å·²æœ‰sql", "ç°æœ‰sql",
            "å¾…éªŒè¯", "ç­‰å¾…", "è¯·", "éœ€è¦", "å»ºè®®", "åº”è¯¥",
            "å€™é€‰çš„", "å½“å‰çš„", "ç”Ÿæˆçš„", "æä¾›çš„", "è¿”å›çš„"
        ]

        # å¦‚æœåŒ…å«æè¿°æ€§å…³é”®è¯ä½†ä¸åŒ…å«SQLå…³é”®è¯ï¼Œå¯èƒ½æ˜¯æè¿°æ–‡æœ¬
        has_description = any(keyword in sql_lower for keyword in description_keywords)
        has_sql_keywords = any(keyword in sql_lower for keyword in ["select", "from", "where", "insert", "update", "delete"])

        if has_description and not has_sql_keywords:
            self._logger.warning(f"ğŸ” [æè¿°æ£€æµ‹] å‘ç°æè¿°æ€§å…³é”®è¯ä½†æ— SQLå…³é”®è¯: {sql[:50]}")
            return True

        # å¦‚æœæ˜¯å¾ˆçŸ­çš„æ–‡æœ¬ä¸”ä¸åŒ…å«SQLå…³é”®è¯ï¼Œå¯èƒ½æ˜¯æè¿°
        if len(sql.strip()) < 50 and not has_sql_keywords:
            self._logger.warning(f"ğŸ” [æè¿°æ£€æµ‹] æ–‡æœ¬è¿‡çŸ­ä¸”æ— SQLå…³é”®è¯: {sql}")
            return True

        # å¦‚æœåŒ…å«ä¸­æ–‡æè¿°æ€§è¯è¯­
        chinese_description = ["å½“å‰", "å€™é€‰", "å†…å®¹", "æè¿°", "ä¿¡æ¯", "æ•°æ®", "ç»“æœ"]
        has_chinese_desc = any(keyword in sql for keyword in chinese_description)
        if has_chinese_desc and not has_sql_keywords:
            self._logger.warning(f"ğŸ” [æè¿°æ£€æµ‹] å‘ç°ä¸­æ–‡æè¿°ä½†æ— SQLå…³é”®è¯: {sql[:50]}")
            return True

        return False

    def _is_obviously_valid_sql(self, sql: str) -> bool:
        """å¿«é€Ÿæ£€æŸ¥æ˜æ˜¾æ­£ç¡®çš„SQL - ç”¨äºç»•è¿‡å¤æ‚éªŒè¯"""
        sql_clean = sql.strip()
        sql_upper = sql_clean.upper()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©æ“ä½œ
        dangerous_keywords = ["DROP", "DELETE", "TRUNCATE", "UPDATE", "INSERT", "ALTER"]
        if any(keyword in sql_upper for keyword in dangerous_keywords):
            return False

        # å¿…é¡»æ˜¯SELECTæŸ¥è¯¢
        if not sql_upper.startswith("SELECT"):
            return False

        # å¿…é¡»æœ‰FROMå­å¥
        if "FROM" not in sql_upper:
            return False

        # ç‰¹æ®Šæ¨¡å¼ï¼šæ ‡å‡†çš„COUNTæŸ¥è¯¢ä¸DATE_SUB
        count_date_sub_pattern = (
            sql_upper.startswith("SELECT COUNT(*) AS") and
            "FROM" in sql_upper and
            "WHERE" in sql_upper and
            "DATE_SUB(CURDATE(), INTERVAL" in sql_upper
        )

        if count_date_sub_pattern:
            # è¿›è¡Œç®€å•çš„æ‹¬å·æ£€æŸ¥
            if self._simple_parentheses_check(sql_clean):
                self._logger.info("âœ… è¯†åˆ«ä¸ºæ ‡å‡†COUNT+DATE_SUBæ¨¡å¼ï¼Œå¿«é€Ÿé€šè¿‡")
                return True

        # å…¶ä»–æ˜æ˜¾æ­£ç¡®çš„ç®€å•æ¨¡å¼
        simple_patterns = [
            # ç®€å•çš„SELECT * FROM table;
            r'^SELECT\s+\*\s+FROM\s+\w+\s*;?$',
            # SELECT column FROM table WHERE condition;
            r'^SELECT\s+\w+\s+FROM\s+\w+\s+WHERE\s+.+\s*;?$',
        ]

        import re
        for pattern in simple_patterns:
            if re.match(pattern, sql_upper):
                if self._simple_parentheses_check(sql_clean):
                    self._logger.info(f"âœ… åŒ¹é…ç®€å•SQLæ¨¡å¼ï¼Œå¿«é€Ÿé€šè¿‡")
                    return True

        return False


class SQLExecuteTool(Tool):
    """SQLæ‰§è¡Œå·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.execute"
        self.description = "æ‰§è¡ŒSQLæŸ¥è¯¢è·å–æ•°æ®"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # ğŸ”„ å…³é”®ä¿®å¤ï¼šæ‰§è¡Œå‰éœ€è¦å°†å ä½ç¬¦æ›¿æ¢ä¸ºçœŸå®æ—¥æœŸ
            executable_sql = self._replace_placeholders_for_execution(sql, input_data)
            self._logger.info(f"ğŸš€ [SQLæ‰§è¡Œ] åŸå§‹SQL: {sql[:100]}...")
            self._logger.info(f"ğŸ“… [SQLæ‰§è¡Œ] æ‰§è¡ŒSQL: {executable_sql[:100]}...")

            # è·å–ç”¨æˆ·IDå’Œæ•°æ®æºID
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"
            data_source_config = input_data.get("data_source", {})
            data_source_id = data_source_config.get("id")

            # æ•°æ®æºæƒé™éªŒè¯
            if user_id != "system" and data_source_id:
                self._logger.info(f"éªŒè¯ç”¨æˆ· {user_id} å¯¹æ•°æ®æº {data_source_id} çš„è®¿é—®æƒé™")

                access_validation = data_source_security_service.validate_data_source_access(
                    user_id=user_id,
                    data_source_id=data_source_id
                )

                if not access_validation.get("allowed"):
                    self._logger.warning(f"æ•°æ®æºè®¿é—®è¢«æ‹’ç»: {access_validation}")
                    return {
                        "success": False,
                        "error": f"æ•°æ®æºè®¿é—®æƒé™éªŒè¯å¤±è´¥: {access_validation.get('reason', 'æœªçŸ¥é”™è¯¯')}",
                        "error_code": access_validation.get("error_code", "ACCESS_DENIED")
                    }

                self._logger.info("æ•°æ®æºæƒé™éªŒè¯é€šè¿‡")

            # è·å–æ•°æ®æºæœåŠ¡
            data_source_service = getattr(self.container, 'data_source_service', None) or getattr(self.container, 'data_source', None)
            if not data_source_service:
                return {"success": False, "error": "Data source service not available"}

            # æ‰§è¡ŒSQL (ä½¿ç”¨æ›¿æ¢åçš„å¯æ‰§è¡ŒSQL)
            result = await self._execute_sql(data_source_service, executable_sql, input_data)

            return {
                "success": True,
                "sql": sql,
                "rows": result.get("rows", []),
                "columns": result.get("columns", []),
                "row_count": len(result.get("rows", []))
            }

        except Exception as e:
            self._logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    async def _execute_sql(self, data_source_service, sql: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            # æ„å»ºæ•°æ®æºé…ç½®
            data_source_config = context.get("data_source", {}) or {}

            # è‹¥ data_source ä¸­ä»…æœ‰ id/type/database ç­‰ç®€è¦ä¿¡æ¯ï¼Œå°è¯•é€šè¿‡ user_data_source_service è·å–å®Œæ•´è¿æ¥é…ç½®
            container = getattr(self, 'container', None)
            user_id = context.get("user_id")
            ds_id = data_source_config.get("id")
            resolved_cfg = None

            if container and hasattr(container, 'user_data_source_service') and user_id and ds_id:
                try:
                    uds = await container.user_data_source_service.get_user_data_source(user_id=user_id, data_source_id=ds_id)
                    if uds and getattr(uds, 'connection_config', None):
                        resolved_cfg = uds.connection_config
                except Exception:
                    resolved_cfg = None

            final_cfg = resolved_cfg or data_source_config

            # å…¼å®¹ç±»å‹æ˜ å°„ï¼ˆmysql/postgres â†’ sqlï¼‰
            t = (final_cfg.get("source_type") or final_cfg.get("type") or "").lower()
            if t in ("mysql", "postgres", "postgresql", "mariadb"):
                final_cfg["source_type"] = "sql"

            # å°è¯•ä¸åŒçš„æ‰§è¡Œæ–¹æ³•
            if hasattr(data_source_service, 'execute_query'):
                result = await data_source_service.execute_query(sql, final_cfg)
            elif hasattr(data_source_service, 'run_query'):
                result = await data_source_service.run_query(final_cfg, sql)
            elif callable(data_source_service):
                result = await data_source_service(sql, final_cfg)
            else:
                raise ValueError("Unsupported data source service interface")

            return {
                "rows": result.get("rows", result.get("data", [])),
                "columns": result.get("columns", result.get("column_names", []))
            }

        except Exception as e:
            self._logger.error(f"SQLæ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return {"rows": [], "columns": []}

    def _replace_placeholders_for_execution(self, sql: str, input_data: Dict[str, Any]) -> str:
        """
        ä¸ºæ‰§è¡Œç›®çš„å°†å ä½ç¬¦æ›¿æ¢ä¸ºçœŸå®æ—¥æœŸ

        æ‰§è¡Œé˜¶æ®µéœ€è¦è¿è¡ŒçœŸå®çš„SQLæŸ¥è¯¢ï¼Œæ‰€ä»¥è¦å°†{{start_date}}å’Œ{{end_date}}æ›¿æ¢ä¸ºå…·ä½“æ—¥æœŸ
        """
        try:
            executable_sql = sql

            # ä»input_dataä¸­è·å–æ—¶é—´çª—å£ä¿¡æ¯
            window = input_data.get("window") or input_data.get("time_window")
            if window and isinstance(window, dict):
                start_date = window.get("start_date")
                end_date = window.get("end_date")

                if start_date:
                    executable_sql = executable_sql.replace("{{start_date}}", f"'{start_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢] {{{{start_date}}}} -> '{start_date}'")

                if end_date:
                    executable_sql = executable_sql.replace("{{end_date}}", f"'{end_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢] {{{{end_date}}}} -> '{end_date}'")

            # å¦‚æœæ²¡æœ‰ä»windowè·å–åˆ°æ—¥æœŸï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
            if "{{start_date}}" in executable_sql or "{{end_date}}" in executable_sql:
                start_date = input_data.get("start_date")
                end_date = input_data.get("end_date")

                if start_date and "{{start_date}}" in executable_sql:
                    executable_sql = executable_sql.replace("{{start_date}}", f"'{start_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢-å¤‡ç”¨] {{{{start_date}}}} -> '{start_date}'")

                if end_date and "{{end_date}}" in executable_sql:
                    executable_sql = executable_sql.replace("{{end_date}}", f"'{end_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢-å¤‡ç”¨] {{{{end_date}}}} -> '{end_date}'")

            # å¦‚æœä»æœ‰å ä½ç¬¦æœªæ›¿æ¢ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•æ—¥æœŸ
            if "{{start_date}}" in executable_sql or "{{end_date}}" in executable_sql:
                from datetime import datetime, timedelta
                today = datetime.now().date()
                yesterday = today - timedelta(days=1)

                default_date = yesterday.strftime('%Y-%m-%d')

                if "{{start_date}}" in executable_sql:
                    executable_sql = executable_sql.replace("{{start_date}}", f"'{default_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢-é»˜è®¤] {{{{start_date}}}} -> '{default_date}'")

                if "{{end_date}}" in executable_sql:
                    executable_sql = executable_sql.replace("{{end_date}}", f"'{default_date}'")
                    self._logger.info(f"ğŸ”„ [æ‰§è¡Œæ›¿æ¢-é»˜è®¤] {{{{end_date}}}} -> '{default_date}'")

            return executable_sql

        except Exception as e:
            self._logger.error(f"âŒ [æ‰§è¡Œ] å ä½ç¬¦æ›¿æ¢å¤±è´¥: {e}")
            return sql  # å¤±è´¥æ—¶è¿”å›åŸå§‹SQL


class SQLRefineTool(Tool):
    """
    SQLä¿®æ­£å·¥å…· - ç®€åŒ–èŒè´£ç‰ˆæœ¬

    å•ä¸€èŒè´£ï¼šåº”ç”¨Agentæä¾›çš„SQLä¿®æ­£å»ºè®®
    ä¸å†è°ƒç”¨LLMï¼Œåªæ‰§è¡ŒAgentæŒ‡å®šçš„ä¿®æ­£æ“ä½œ
    éµå¾ªAgentæ¶æ„åŸåˆ™ï¼šAgentæ€è€ƒå†³ç­–ï¼Œå·¥å…·æ‰§è¡Œæ“ä½œ
    """

    def __init__(self, container):
        super().__init__()
        self.name = "sql.refine"
        self.description = "åº”ç”¨Agentæä¾›çš„SQLä¿®æ­£å»ºè®®"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åº”ç”¨SQLä¿®æ­£ - æ”¯æŒæ™ºèƒ½ä¿®å¤å’ŒAgentä¿®æ­£ä¸¤ç§æ¨¡å¼

        æœŸæœ›è¾“å…¥ï¼š
        - current_sql: å½“å‰çš„SQL
        - corrected_sql: Agentæä¾›çš„ä¿®æ­£SQLï¼ˆå¯é€‰ï¼‰
        - issues: è¦è§£å†³çš„é—®é¢˜åˆ—è¡¨

        å¦‚æœæ²¡æœ‰Agentæä¾›çš„ä¿®æ­£SQLï¼Œä¼šåŸºäºé—®é¢˜æ™ºèƒ½ç”Ÿæˆä¿®æ­£
        """
        try:
            current_sql = input_data.get("current_sql") or input_data.get("sql", "")
            corrected_sql = input_data.get("corrected_sql", "")
            issues = input_data.get("issues", [])

            if not current_sql:
                return {"success": False, "error": "å½“å‰SQLè¯­å¥ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œä¿®æ­£"}

            # å¦‚æœæ²¡æœ‰Agentæä¾›çš„ä¿®æ­£SQLï¼Œå°è¯•æ™ºèƒ½ä¿®å¤
            if not corrected_sql and issues:
                self._logger.info(f"ğŸ¤– [æ™ºèƒ½ä¿®å¤] åŸºäº{len(issues)}ä¸ªé—®é¢˜ç”Ÿæˆä¿®æ­£SQL")
                corrected_sql = self._apply_intelligent_fixes(current_sql, issues)

            if not corrected_sql:
                # æ—¢æ²¡æœ‰Agentä¿®æ­£ä¹Ÿæ— æ³•æ™ºèƒ½ä¿®å¤
                return {
                    "success": False,
                    "error": "æ— æ³•ç”Ÿæˆä¿®æ­£SQL",
                    "suggestion": "éœ€è¦Agentæä¾›corrected_sqlæˆ–æä¾›æ›´å…·ä½“çš„é—®é¢˜æè¿°",
                    "current_sql": current_sql,
                    "issues": issues
                }

            # ç®€å•éªŒè¯ä¿®æ­£SQLçš„åŸºæœ¬åˆæ³•æ€§
            if not self._basic_sql_validation(corrected_sql):
                return {
                    "success": False,
                    "error": "ä¿®æ­£SQLä¸ç¬¦åˆåŸºæœ¬æ ¼å¼è¦æ±‚",
                    "current_sql": current_sql,
                    "attempted_correction": corrected_sql
                }

            self._logger.info(f"ğŸ”§ [SQLä¿®æ­£] åº”ç”¨ä¿®æ­£: {len(corrected_sql)} å­—ç¬¦")
            self._logger.info(f"ğŸ“‹ [ä¿®æ­£é—®é¢˜] è§£å†³ {len(issues)} ä¸ªé—®é¢˜: {', '.join(issues[:3])}...")

            return {
                "success": True,
                "current_sql": corrected_sql,  # æ–°çš„å½“å‰SQL
                "sql": corrected_sql,  # å…¼å®¹æ€§å­—æ®µ
                "original_sql": current_sql,
                "issues_addressed": issues,
                "refinement_applied": True,
                "message": f"å·²åº”ç”¨ä¿®æ­£ï¼Œè§£å†³{len(issues)}ä¸ªé—®é¢˜"
            }

        except Exception as e:
            self._logger.error(f"SQLä¿®æ­£å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"success": False, "error": f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}"}

    def _basic_sql_validation(self, sql: str) -> bool:
        """åŸºæœ¬SQLæ ¼å¼éªŒè¯ - ä¸æ·±å…¥è¯­ä¹‰ï¼Œåªæ£€æŸ¥æœ€åŸºæœ¬çš„æ ¼å¼"""
        if not sql or not isinstance(sql, str):
            return False

        sql_upper = sql.strip().upper()

        # å¿…é¡»ä»¥SELECTå¼€å¤´
        if not sql_upper.startswith('SELECT'):
            return False

        # å¿…é¡»åŒ…å«FROM
        if 'FROM' not in sql_upper:
            return False

        # ä¸èƒ½åŒ…å«å±é™©æ“ä½œ
        dangerous_ops = ['DROP', 'DELETE', 'TRUNCATE', 'UPDATE', 'INSERT', 'ALTER']
        if any(op in sql_upper for op in dangerous_ops):
            return False

        return True

    def _apply_intelligent_fixes(self, sql: str, issues: List[str]) -> str:
        """åŸºäºé—®é¢˜åˆ—è¡¨æ™ºèƒ½ä¿®å¤SQL"""
        try:
            fixed_sql = sql

            for issue in issues:
                issue_lower = issue.lower()

                # ä¿®å¤å±é™©å…³é”®è¯è¯¯æŠ¥ï¼ˆUPDATEå­—æ®µåï¼‰
                if "sqlåŒ…å«å±é™©å…³é”®è¯: update" in issue_lower:
                    # è¿™é€šå¸¸æ˜¯update_timeå­—æ®µå¯¼è‡´çš„è¯¯æŠ¥ï¼Œæ— éœ€ä¿®æ”¹SQL
                    continue

                # ä¿®å¤æ‹¬å·ä¸åŒ¹é…
                elif "æ‹¬å·" in issue_lower and "åŒ¹é…" in issue_lower:
                    fixed_sql = self._fix_parentheses_mismatch(fixed_sql)

                # ä¿®å¤DATE_SUBå‡½æ•°æ ¼å¼
                elif "date_sub" in issue_lower and "å‚æ•°æ ¼å¼" in issue_lower:
                    fixed_sql = self._fix_date_sub_format(fixed_sql)

                # ä¿®å¤åˆ†å·é—®é¢˜
                elif "åˆ†å·" in issue_lower:
                    if not fixed_sql.strip().endswith(';'):
                        fixed_sql = fixed_sql.strip() + ';'

            return fixed_sql

        except Exception as e:
            self._logger.error(f"æ™ºèƒ½ä¿®å¤å¤±è´¥: {e}")
            return sql

    def _fix_parentheses_mismatch(self, sql: str) -> str:
        """ä¿®å¤æ‹¬å·ä¸åŒ¹é…é—®é¢˜"""
        try:
            # ç®€å•çš„æ‹¬å·ä¿®å¤ï¼šç¡®ä¿æ¯ä¸ªå·¦æ‹¬å·éƒ½æœ‰å¯¹åº”çš„å³æ‹¬å·
            count = 0
            for char in sql:
                if char == '(':
                    count += 1
                elif char == ')':
                    count -= 1

            # å¦‚æœç¼ºå°‘å³æ‹¬å·ï¼Œåœ¨æœ«å°¾æ·»åŠ 
            if count > 0:
                sql += ')' * count
                self._logger.info(f"ğŸ”§ æ‹¬å·ä¿®å¤ï¼šæ·»åŠ äº†{count}ä¸ªå³æ‹¬å·")

            return sql
        except Exception:
            return sql

    def _fix_date_sub_format(self, sql: str) -> str:
        """ä¿®å¤DATE_SUBå‡½æ•°æ ¼å¼"""
        try:
            import re
            # æŸ¥æ‰¾å¹¶ä¿®å¤DATE_SUBå‡½æ•°è°ƒç”¨
            pattern = r'DATE_SUB\s*\(\s*([^,]+)\s*,\s*INTERVAL\s+(\d+)\s+(\w+)\s*\)'

            def replace_date_sub(match):
                date_expr = match.group(1).strip()
                interval_num = match.group(2)
                interval_unit = match.group(3)
                return f'DATE_SUB({date_expr}, INTERVAL {interval_num} {interval_unit})'

            fixed_sql = re.sub(pattern, replace_date_sub, sql, flags=re.IGNORECASE)

            if fixed_sql != sql:
                self._logger.info("ğŸ”§ DATE_SUBæ ¼å¼ä¿®å¤ï¼šè§„èŒƒåŒ–å‡½æ•°è°ƒç”¨æ ¼å¼")

            return fixed_sql
        except Exception:
            return sql

    def _build_refine_prompt(self, sql: str, issues: list, input_data: Dict[str, Any] = None) -> str:
        """æ„å»ºæ™ºèƒ½SQLä¼˜åŒ–æç¤ºè¯"""
        issues_str = "\n".join([f"- {issue}" for issue in issues])

        # è·å–ç”¨æˆ·åŸå§‹éœ€æ±‚å’Œè¯­ä¹‰ç±»å‹
        user_prompt = input_data.get("user_prompt", "") if input_data else ""
        semantic_type = input_data.get("semantic_type", "") if input_data else ""

        # è·å–schemaä¿¡æ¯ - å…³é”®ä¿®å¤ï¼
        schema_summary = input_data.get("schema_summary", "") if input_data else ""
        tables = input_data.get("tables", []) if input_data else []
        columns = input_data.get("columns", {}) if input_data else {}

        # å¦‚æœæ²¡æœ‰schema_summaryä½†æœ‰tableså’Œcolumnsï¼Œæ„å»ºåŸºæœ¬schemaæè¿°
        if not schema_summary and (tables or columns):
            schema_parts = []
            for table in tables:
                table_columns = columns.get(table, [])
                if table_columns:
                    schema_parts.append(f"**{table}**: {', '.join(table_columns[:10])}{'...' if len(table_columns) > 10 else ''}")
                else:
                    schema_parts.append(f"**{table}**: (åˆ—ä¿¡æ¯å¾…æŸ¥è¯¢)")
            schema_summary = f"å¯ç”¨æ•°æ®è¡¨:\n" + "\n".join(schema_parts)

        # æ£€æŸ¥æ˜¯å¦æœ‰AgentéªŒè¯ç»“æœ
        agent_analysis = input_data.get("agent_analysis") if input_data else None
        corrected_sql = ""
        if agent_analysis and agent_analysis.get("corrected_sql"):
            corrected_sql = f"\næ™ºèƒ½ä¿®æ­£å»ºè®®:\n{agent_analysis.get('corrected_sql')}\n"

        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLä¼˜åŒ–ä¸“å®¶ã€‚è¯·ä¿®å¤ä»¥ä¸‹SQLè¯­å¥ä¸­çš„é—®é¢˜ã€‚

ç”¨æˆ·åŸå§‹éœ€æ±‚: {user_prompt}
å ä½ç¬¦ç±»å‹: {semantic_type}

**æ•°æ®åº“ç»“æ„**:
{schema_summary}

é—®é¢˜SQL:
```sql
{sql}
```

å‘ç°çš„é—®é¢˜:
{issues_str}
{corrected_sql}
è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜å¹¶è¿”å›ä¼˜åŒ–åçš„SQLè¯­å¥ã€‚

è¦æ±‚:
1. **å¿…é¡»ä½¿ç”¨ä¸Šè¿°æ•°æ®åº“ç»“æ„ä¸­çš„çœŸå®è¡¨åå’Œåˆ—å**
2. ä¿æŒåŸæœ‰æŸ¥è¯¢é€»è¾‘ä¸å˜
3. ä¿®å¤æ‰€æœ‰è¯­æ³•é”™è¯¯ï¼ˆç‰¹åˆ«æ³¨æ„æ‹¬å·åŒ¹é…ï¼‰
4. ç¡®ä¿å‡½æ•°è°ƒç”¨æ ¼å¼æ­£ç¡®
5. ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
6. åªè¿”å›ä¿®å¤åçš„å®Œæ•´SQLè¯­å¥ï¼Œä¸è¦å…¶ä»–å†…å®¹

ç‰¹åˆ«æ³¨æ„:
- **ä¸¥æ ¼åŒ¹é…æ•°æ®åº“ç»“æ„ä¸­çš„è¡¨åï¼ˆå¦‚ods_complain, ods_refundç­‰ï¼‰**
- **ä¸è¦è™šæ„ä¸å­˜åœ¨çš„è¡¨åï¼ˆå¦‚return_requestsç­‰ï¼‰**
- æ£€æŸ¥æ‰€æœ‰æ‹¬å·æ˜¯å¦æ­£ç¡®åŒ¹é…
- ç¡®ä¿DATE_SUBã€DATE_ADDç­‰å‡½æ•°çš„INTERVALè¯­æ³•å®Œæ•´
- éªŒè¯SQLè¯­å¥ä»¥åˆ†å·ç»“å°¾
"""

    async def _call_llm(self, llm_service, prompt: str, user_id: str = "system") -> str:
        """è°ƒç”¨LLMä¼˜åŒ–SQL"""
        try:
            if hasattr(llm_service, 'ask'):
                result = await llm_service.ask(user_id=user_id, prompt=prompt)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif hasattr(llm_service, 'generate_response'):
                result = await llm_service.generate_response(prompt=prompt, user_id=user_id)
                return result.get("response", "") if isinstance(result, dict) else str(result)
            elif callable(llm_service):
                return await llm_service(prompt)
            else:
                raise ValueError("Unsupported LLM service interface")
        except Exception as e:
            self._logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return ""


class SQLPolicyTool(Tool):
    """SQLç­–ç•¥æ£€æŸ¥å·¥å…·"""

    def __init__(self, container):
        super().__init__()
        self.name = "sql.policy"
        self.description = "æ‰§è¡ŒSQLç­–ç•¥æ£€æŸ¥å¹¶æ·»åŠ LIMIT"
        self.container = container
        self._logger = logging.getLogger(self.__class__.__name__)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLç­–ç•¥æ£€æŸ¥"""
        try:
            sql = input_data.get("current_sql") or input_data.get("sql", "")
            if not sql:
                return {"success": False, "error": "SQLè¯­å¥ä¸ºç©º"}

            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_id = input_data.get("user_id") or auth_manager.get_current_user_id() or "system"
            data_source_config = input_data.get("data_source", {})
            data_source_id = data_source_config.get("id")

            # ç¡®å®šç”¨æˆ·æ˜¯å¦ä¸ºè¶…çº§ç”¨æˆ·
            is_superuser = False
            if user_id != "system":
                auth_context = auth_manager.get_context()
                is_superuser = auth_context.is_superuser if auth_context else False

            # ä½¿ç”¨DataSourceSecurityServiceè¿›è¡ŒSQLå®‰å…¨ç­–ç•¥æ£€æŸ¥
            security_result = data_source_security_service.apply_sql_security_policy(
                sql=sql,
                user_id=user_id,
                data_source_id=data_source_id,
                is_superuser=is_superuser
            )

            if not security_result.get("allowed"):
                self._logger.warning(f"SQLç­–ç•¥æ£€æŸ¥å¤±è´¥: {security_result}")
                return {
                    "success": False,
                    "error": f"SQLå®‰å…¨ç­–ç•¥æ£€æŸ¥å¤±è´¥: {'; '.join(security_result.get('issues', []))}",
                    "issues": security_result.get("issues", [])
                }

            # ä½¿ç”¨ç»è¿‡å®‰å…¨ç­–ç•¥å¤„ç†çš„SQL
            processed_sql = security_result.get("modified_sql", sql)

            return {
                "success": True,
                "sql": processed_sql,
                "original_sql": sql,
                "policies_applied": security_result.get("modifications", []),
                "warnings": security_result.get("warnings", []),
                "issues": security_result.get("issues", [])
            }

        except Exception as e:
            self._logger.error(f"SQLç­–ç•¥æ£€æŸ¥å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}
