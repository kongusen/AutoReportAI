"""
çº¯æ•°æ®åº“é©±åŠ¨çš„Reactæ™ºèƒ½ä»£ç†

å®Œå…¨ç§»é™¤é…ç½®æ–‡ä»¶ä¾èµ–ï¼Œçº¯ç²¹åŸºäºæ•°æ®åº“çš„ç”¨æˆ·é…ç½®
ç”¨æˆ·å¿…é¡»æä¾›user_idæ‰èƒ½ä½¿ç”¨AgentæœåŠ¡
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class PureDatabaseReactAgent:
    """
    çº¯æ•°æ®åº“é©±åŠ¨çš„Reactæ™ºèƒ½ä»£ç†
    
    æ ¸å¿ƒå˜åŒ–:
    1. å®Œå…¨ç§»é™¤é…ç½®æ–‡ä»¶ä¾èµ–
    2. ç”¨æˆ·å¿…é¡»æä¾›user_idæ‰èƒ½ä½¿ç”¨
    3. æ‰€æœ‰æ¨¡å‹é€‰æ‹©åŸºäºç”¨æˆ·çš„æ•°æ®åº“é…ç½®
    4. Agentä¸ªæ€§åŒ–å­¦ä¹ å’Œåå¥½è®°å½•
    """
    
    def __init__(
        self,
        user_id: str,  # ğŸ”‘ å¿…éœ€å‚æ•°ï¼šç”¨æˆ·ID
        tools: Optional[List] = None,
        memory_token_limit: int = 4000,
        max_iterations: int = 15,
        verbose: bool = True,
        system_prompt: Optional[str] = None
    ):
        if not user_id:
            raise ValueError("user_idæ˜¯å¿…éœ€å‚æ•°ï¼Œçº¯æ•°æ®åº“é©±åŠ¨Agentå¿…é¡»æŒ‡å®šç”¨æˆ·ID")
        
        self.user_id = user_id
        self.tools = tools or []
        self.memory_token_limit = memory_token_limit
        self.max_iterations = max_iterations
        self.verbose = verbose
        self.system_prompt = system_prompt
        
        self.agent: Optional[Any] = None
        self.initialized = False
        self.llm_manager = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_conversations = 0
        self.successful_conversations = 0
        self.total_tool_calls = 0
        self.start_time = datetime.utcnow()
        
        logger.info(f"ä¸ºç”¨æˆ· {user_id} åˆå§‹åŒ–çº¯æ•°æ®åº“é©±åŠ¨Reactä»£ç†")
    
    async def initialize(self):
        """åˆå§‹åŒ–Reactä»£ç† - çº¯æ•°æ®åº“é©±åŠ¨"""
        if self.initialized:
            return
        
        logger.info(f"åˆå§‹åŒ–ç”¨æˆ· {self.user_id} çš„Reactä»£ç†...")
        
        try:
            # 1. è·å–æ•°æ®åº“é©±åŠ¨çš„LLMç®¡ç†å™¨
            from ..llm import get_llm_manager
            self.llm_manager = await get_llm_manager()
            
            # 2. ä¸ºReact Agenté€‰æ‹©æœ€ä½³æ¨¡å‹ - åŸºäºç”¨æˆ·é…ç½®
            try:
                best_model = await self.llm_manager.select_best_model_for_user(
                    user_id=self.user_id,
                    task_type="reasoning",  # Reactéœ€è¦æ¨ç†èƒ½åŠ›
                    complexity="medium",
                    constraints={
                        "max_cost": 0.02,  # åˆç†çš„æˆæœ¬æ§åˆ¶
                        "preferred_providers": ["anthropic", "openai"]  # æ¨ç†ä»»åŠ¡åå¥½
                    },
                    agent_id="react_agent"
                )
                
                logger.info(f"React Agentä¸ºç”¨æˆ· {self.user_id} é€‰æ‹©æ¨¡å‹: {best_model['provider']}:{best_model['model']} (ç½®ä¿¡åº¦: {best_model['confidence']:.1%})")
                
                # è®°å½•æ¨¡å‹é€‰æ‹©ä¿¡æ¯
                self.selected_model = best_model
                
            except Exception as e:
                logger.error(f"ä¸ºç”¨æˆ· {self.user_id} é€‰æ‹©æ¨¡å‹å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸ºç”¨æˆ·é€‰æ‹©åˆé€‚çš„æ¨¡å‹: {str(e)}")
            
            # 3. åˆ›å»ºå·¥å…·é›†åˆï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if not self.tools:
                try:
                    from ..tools import get_ai_tools_factory
                    tools_factory = await get_ai_tools_factory()
                    self.tools = await tools_factory.create_all_tools()
                except Exception as e:
                    logger.warning(f"åˆ›å»ºå·¥å…·å¤±è´¥: {e}")
                    self.tools = []
            
            # 4. åˆ›å»ºReactä»£ç†ï¼ˆä¼˜å…ˆä½¿ç”¨LlamaIndexï¼Œé™çº§åˆ°æ¨¡æ‹Ÿï¼‰
            try:
                from llama_index.core.agent import ReActAgent
                from llama_index.core.memory import ChatMemoryBuffer
                
                # è¿™é‡Œåº”è¯¥ä½¿ç”¨å®é™…çš„LlamaIndex LLMå®ä¾‹
                # ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿï¼Œå®é™…å®ç°ä¸­éœ€è¦ä»selected_modelåˆ›å»ºLLMå®ä¾‹
                self.agent = ReActAgent.from_tools(
                    tools=self.tools,
                    llm=None,  # å®é™…å®ç°ä¸­ä»selected_modelåˆ›å»º
                    memory=ChatMemoryBuffer.from_defaults(token_limit=self.memory_token_limit),
                    verbose=self.verbose,
                    max_iterations=self.max_iterations,
                    system_prompt=self.system_prompt or self._get_react_system_prompt()
                )
                
            except (ImportError, Exception) as e:
                logger.warning(f"LlamaIndex React Agentåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿä»£ç†: {e}")
                self.agent = self._create_mock_agent()
            
            self.initialized = True
            logger.info(f"ç”¨æˆ· {self.user_id} çš„Reactä»£ç†åˆå§‹åŒ–å®Œæˆ - å·¥å…·: {len(self.tools)}, æ¨¡å‹: {self.selected_model['provider']}:{self.selected_model['model']}")
            
        except Exception as e:
            logger.error(f"Reactä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºå¤‡ç”¨æ¨¡æ‹Ÿä»£ç†
            self.agent = self._create_mock_agent()
            self.initialized = True
            raise
    
    def _create_mock_agent(self):
        """åˆ›å»ºæ¨¡æ‹ŸReactä»£ç†"""
        class MockReactAgent:
            def __init__(self, parent):
                self.parent = parent
            
            async def achat(self, message: str) -> Any:
                """æ¨¡æ‹Ÿå¼‚æ­¥èŠå¤©ï¼Œä½¿ç”¨æ•°æ®åº“é©±åŠ¨çš„LLMé€‰æ‹©"""
                try:
                    from app.services.infrastructure.ai.llm import ask_agent_for_user
                    
                    response = await ask_agent_for_user(
                        user_id=self.parent.user_id,
                        question=message,
                        agent_type="react_agent",
                        context="Reactä»£ç†æ¨ç†æ¨¡å¼",
                        task_type="reasoning",
                        complexity="medium"
                    )
                    
                    return MockAgentResponse(response)
                    
                except Exception as e:
                    logger.error(f"æ¨¡æ‹ŸAgentè°ƒç”¨å¤±è´¥: {e}")
                    return MockAgentResponse(f"æ¨¡æ‹ŸReactä»£ç†å“åº”ï¼š{message}")
            
            def chat(self, message: str) -> Any:
                """æ¨¡æ‹ŸåŒæ­¥èŠå¤©"""
                return MockAgentResponse(f"æ¨¡æ‹ŸReactä»£ç†å“åº”ï¼š{message}")
            
            def reset(self):
                """é‡ç½®å¯¹è¯å†å²"""
                pass
                
        class MockAgentResponse:
            def __init__(self, response: str):
                self.response = response
                self.source_nodes = []
                self.sources = []
            
            def __str__(self):
                return self.response
        
        return MockReactAgent(self)
    
    def _get_react_system_prompt(self) -> str:
        """è·å–Reactç³»ç»Ÿæç¤ºè¯"""
        tools_info = self._get_tools_description()
        
        return f"""
ä½ æ˜¯ç”¨æˆ· {self.user_id} çš„ä¸“å±AIæ™ºèƒ½ä»£ç†ï¼ŒåŸºäºReActï¼ˆReasoning + Actingï¼‰æ¡†æ¶å·¥ä½œã€‚

ä½ çš„å·¥ä½œæµç¨‹ï¼š
1. **Thoughtï¼ˆæ€è€ƒï¼‰**: åˆ†æå½“å‰é—®é¢˜ï¼Œåˆ¶å®šè§£å†³ç­–ç•¥
2. **Actionï¼ˆè¡ŒåŠ¨ï¼‰**: é€‰æ‹©åˆé€‚çš„å·¥å…·æ‰§è¡Œå…·ä½“æ“ä½œ
3. **Observationï¼ˆè§‚å¯Ÿï¼‰**: åˆ†æå·¥å…·æ‰§è¡Œç»“æœ
4. **åå¤è¿­ä»£**: ç›´åˆ°é—®é¢˜å®Œå…¨è§£å†³

å¯ç”¨å·¥å…·ï¼š
{tools_info}

å·¥ä½œåŸåˆ™ï¼š
- å§‹ç»ˆå…ˆæ€è€ƒå†è¡ŒåŠ¨
- é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡
- åŸºäºè§‚å¯Ÿç»“æœè°ƒæ•´ç­–ç•¥
- ç¡®ä¿æœ€ç»ˆç­”æ¡ˆå‡†ç¡®å®Œæ•´
- å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå°è¯•ä¸åŒçš„æ–¹æ³•
- è®°ä½ä½ æœåŠ¡çš„ç”¨æˆ·IDæ˜¯ {self.user_id}

è¯·æŒ‰ç…§ Thought -> Action -> Observation çš„å¾ªç¯æ¥å¤„ç†ç”¨æˆ·è¯·æ±‚ã€‚
"""
    
    def _get_tools_description(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        if not self.tools:
            return "æš‚æ— å¯ç”¨å·¥å…·"
        
        descriptions = []
        for i, tool in enumerate(self.tools, 1):
            if hasattr(tool, 'metadata'):
                name = getattr(tool.metadata, 'name', f'å·¥å…·{i}')
                desc = getattr(tool.metadata, 'description', 'æ— æè¿°')
                descriptions.append(f"- {name}: {desc}")
            else:
                descriptions.append(f"- å·¥å…·{i}: æ— æè¿°ä¿¡æ¯")
        
        return "\n".join(descriptions)
    
    async def chat(
        self, 
        message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        è¿›è¡Œå¯¹è¯ - çº¯æ•°æ®åº“é©±åŠ¨
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¯¹è¯ç»“æœï¼ŒåŒ…å«æ¨¡å‹é€‰æ‹©å’Œä½¿ç”¨ç»Ÿè®¡
        """
        if not self.initialized:
            await self.initialize()
        
        conversation_start = time.time()
        
        try:
            logger.info(f"Reactä»£ç†(ç”¨æˆ·:{self.user_id})å¼€å§‹å¤„ç†: {message[:100]}{'...' if len(message) > 100 else ''}")
            
            # æ„å»ºå®Œæ•´çš„è¾“å…¥æ¶ˆæ¯
            full_message = message
            if context:
                context_str = "\n".join([f"{k}: {v}" for k, v in context.items()])
                full_message = f"ä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context_str}\n\nç”¨æˆ·è¯·æ±‚: {message}"
            
            # è°ƒç”¨ä»£ç†
            if hasattr(self.agent, 'achat'):
                response = await self.agent.achat(full_message)
            else:
                response = self.agent.chat(full_message)
            
            conversation_time = time.time() - conversation_start
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.total_conversations += 1
            self.successful_conversations += 1
            
            # è®°å½•ä½¿ç”¨åé¦ˆåˆ°æ•°æ®åº“
            if hasattr(self, 'selected_model') and self.llm_manager:
                from ..llm import record_usage_feedback
                
                record_usage_feedback(
                    user_id=self.user_id,
                    model=self.selected_model['model'],
                    provider=self.selected_model['provider'],
                    success=True,
                    satisfaction_score=0.9,  # åŸºäºæˆåŠŸå®Œæˆä»»åŠ¡çš„æ»¡æ„åº¦
                    actual_cost=self.selected_model.get('expected_cost'),
                    actual_latency=int(conversation_time * 1000),
                    agent_id="react_agent",
                    task_type="reasoning"
                )
            
            # æ„å»ºç»“æœ
            result = {
                "status": "success",
                "response": str(response),
                "conversation_time": conversation_time,
                "reasoning_steps": self._extract_reasoning_steps(response),
                "tool_calls": self._extract_tool_calls(response),
                "sources": getattr(response, 'sources', []),
                "metadata": {
                    "user_id": self.user_id,
                    "agent_type": "react",
                    "model_used": f"{self.selected_model['provider']}:{self.selected_model['model']}" if hasattr(self, 'selected_model') else 'unknown',
                    "model_confidence": self.selected_model.get('confidence') if hasattr(self, 'selected_model') else None,
                    "tools_available": len(self.tools),
                    "max_iterations": self.max_iterations,
                    "database_driven": True
                }
            }
            
            logger.info(f"Reactä»£ç†(ç”¨æˆ·:{self.user_id})å¤„ç†å®Œæˆï¼Œç”¨æ—¶: {conversation_time:.2f}s")
            
            return result
            
        except Exception as e:
            conversation_time = time.time() - conversation_start
            logger.error(f"Reactä»£ç†(ç”¨æˆ·:{self.user_id})å¤„ç†å¤±è´¥: {e}")
            
            # è®°å½•å¤±è´¥åé¦ˆ
            if hasattr(self, 'selected_model') and self.llm_manager:
                from ..llm import record_usage_feedback
                
                record_usage_feedback(
                    user_id=self.user_id,
                    model=self.selected_model['model'],
                    provider=self.selected_model['provider'],
                    success=False,
                    satisfaction_score=0.3,
                    actual_latency=int(conversation_time * 1000),
                    agent_id="react_agent",
                    task_type="reasoning"
                )
            
            return {
                "status": "error",
                "error": str(e),
                "conversation_time": conversation_time,
                "response": f"å¤„ç†å‡ºç°é”™è¯¯ï¼š{str(e)}",
                "reasoning_steps": [],
                "tool_calls": [],
                "sources": [],
                "metadata": {
                    "user_id": self.user_id,
                    "agent_type": "react",
                    "error_type": type(e).__name__,
                    "database_driven": True
                }
            }
    
    def _extract_reasoning_steps(self, response: Any) -> List[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–æ¨ç†æ­¥éª¤"""
        steps = []
        response_text = str(response)
        
        if "Thought:" in response_text:
            parts = response_text.split("Thought:")
            for i, part in enumerate(parts[1:], 1):
                thought_end = part.find("Action:") if "Action:" in part else len(part)
                thought = part[:thought_end].strip()
                
                step = {
                    "step_number": i,
                    "type": "thought",
                    "content": thought
                }
                
                if "Action:" in part:
                    action_start = part.find("Action:") + 7
                    action_end = part.find("Observation:") if "Observation:" in part else len(part)
                    action = part[action_start:action_end].strip()
                    step["action"] = action
                    
                    if "Observation:" in part:
                        obs_start = part.find("Observation:") + 12
                        observation = part[obs_start:].strip()
                        step["observation"] = observation
                
                steps.append(step)
        
        return steps
    
    def _extract_tool_calls(self, response: Any) -> List[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        tool_calls = []
        
        if hasattr(response, 'source_nodes'):
            for node in response.source_nodes:
                if hasattr(node, 'metadata'):
                    tool_calls.append({
                        "tool_name": node.metadata.get("tool_name", "unknown"),
                        "result": node.text if hasattr(node, 'text') else str(node)
                    })
        
        self.total_tool_calls += len(tool_calls)
        return tool_calls
    
    def reset_conversation(self):
        """é‡ç½®å¯¹è¯å†å²"""
        if self.agent and hasattr(self.agent, 'reset'):
            self.agent.reset()
        logger.info(f"Reactä»£ç†(ç”¨æˆ·:{self.user_id})å¯¹è¯å†å²å·²é‡ç½®")
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        uptime = (datetime.utcnow() - self.start_time).total_seconds()
        
        return {
            "user_id": self.user_id,
            "total_conversations": self.total_conversations,
            "successful_conversations": self.successful_conversations,
            "success_rate": self.successful_conversations / max(self.total_conversations, 1),
            "total_tool_calls": self.total_tool_calls,
            "average_tool_calls_per_conversation": self.total_tool_calls / max(self.total_conversations, 1),
            "uptime_seconds": uptime,
            "agent_config": {
                "max_iterations": self.max_iterations,
                "memory_token_limit": self.memory_token_limit,
                "tools_count": len(self.tools),
                "verbose": self.verbose,
                "database_driven": True
            },
            "selected_model": getattr(self, 'selected_model', None)
        }
    
    def get_service_info(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ä¿¡æ¯"""
        return {
            "service_name": "Pure Database Driven React Agent",
            "version": "2.0.0",
            "architecture": "Database-First User-Specific Agent",
            "user_id": self.user_id,
            "status": "initialized" if self.initialized else "uninitialized",
            "capabilities": [
                "ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©",
                "ReActæ¨ç†å¾ªç¯",
                "å¤šè½®å¯¹è¯æ”¯æŒ",
                "å·¥å…·è°ƒç”¨ç¼–æ’",
                "ä½¿ç”¨åé¦ˆå­¦ä¹ ",
                "ä¸ªæ€§åŒ–Agentåå¥½"
            ],
            "data_sources": [
                "ç”¨æˆ·LLMåå¥½é…ç½®",
                "æ•°æ®åº“é©±åŠ¨æ¨¡å‹é€‰æ‹©",
                "ç”¨æˆ·ä½¿ç”¨å†å²è®°å½•"
            ],
            "configuration": {
                "max_iterations": self.max_iterations,
                "memory_token_limit": self.memory_token_limit,
                "tools_count": len(self.tools),
                "verbose": self.verbose
            },
            "statistics": self.get_conversation_stats(),
            "selected_model": getattr(self, 'selected_model', None)
        }


# ä¾¿æ·å‡½æ•°
async def create_react_agent_for_user(
    user_id: str,
    tools: Optional[List] = None,
    memory_token_limit: int = 4000,
    max_iterations: int = 15,
    verbose: bool = True,
    system_prompt: Optional[str] = None
) -> PureDatabaseReactAgent:
    """ä¸ºæŒ‡å®šç”¨æˆ·åˆ›å»ºReactä»£ç†"""
    
    agent = PureDatabaseReactAgent(
        user_id=user_id,
        tools=tools,
        memory_token_limit=memory_token_limit,
        max_iterations=max_iterations,
        verbose=verbose,
        system_prompt=system_prompt
    )
    
    await agent.initialize()
    return agent