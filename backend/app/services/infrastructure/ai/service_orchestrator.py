"""
æœåŠ¡ç¼–æ’å™¨ - åŸºäºæ–°çš„BaseToolæ¶æ„
æ•´åˆå·¥å…·å·¥å‚å’ŒReActç¼–æ’å™¨ï¼Œæä¾›ç»Ÿä¸€çš„å ä½ç¬¦åˆ†ææœåŠ¡
"""

import logging
import uuid
from datetime import datetime
from typing import Dict, Any, AsyncGenerator, Optional, List

from .core.tools import ToolContext, ToolChain, ToolResult, ToolResultType
from .core.unified_controller import get_unified_controller, tt
from .tools import (
    AdvancedSQLGenerator,
    SmartDataAnalyzer,
    IntelligentReportGenerator,
    PromptAwareOrchestrator
)
from .llm import ask_agent_for_user

logger = logging.getLogger(__name__)


class ServiceOrchestrator:
    """æœåŠ¡ç¼–æ’å™¨ - åŸºäºå¢å¼ºçš„BaseToolæ¶æ„v3.0"""
    
    def __init__(self):
        self.tool_chain = self._create_tool_chain()
        self.unified_controller = get_unified_controller()
        
        # æ–°çš„ç»Ÿä¸€æ§åˆ¶å™¨å·²è‡ªåŠ¨åˆå§‹åŒ–
        
        logger.info("æœåŠ¡ç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"å·²åŠ è½½å·¥å…·: {self.tool_chain.list_tools()}")
    
    def _create_tool_chain(self) -> ToolChain:
        """åˆ›å»ºå¢å¼ºçš„å·¥å…·é“¾"""
        tool_chain = ToolChain()
        
        # æ³¨å†Œæ–°çš„å·¥å…·é›†åˆ
        try:
            # SQLç”Ÿæˆå·¥å…·
            sql_generator = AdvancedSQLGenerator()
            tool_chain.register_tool(sql_generator)
            
            # æ•°æ®åˆ†æå·¥å…·  
            data_analyzer = SmartDataAnalyzer()
            tool_chain.register_tool(data_analyzer)
            
            # æŠ¥å‘Šç”Ÿæˆå·¥å…·
            report_generator = IntelligentReportGenerator()
            tool_chain.register_tool(report_generator)
            
            # ç¼–æ’å™¨å·¥å…·
            orchestrator_tool = PromptAwareOrchestrator()
            tool_chain.register_tool(orchestrator_tool)
            
            # ğŸ”§ æ³¨å†ŒReActæ¡¥æ¥å·¥å…·ï¼ˆä¿®å¤å·¥å…·åç§°ä¸åŒ¹é…é—®é¢˜ï¼‰
            from .tools.bridge_tools import register_bridge_tools
            try:
                register_bridge_tools(tool_chain)
                logger.info("âœ… ReActæ¡¥æ¥å·¥å…·æ³¨å†ŒæˆåŠŸ")
            except Exception as bridge_error:
                logger.error(f"âŒ ReActæ¡¥æ¥å·¥å…·æ³¨å†Œå¤±è´¥: {bridge_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä½¿ç”¨åŸæœ‰å·¥å…·
            
            logger.info("å¢å¼ºå·¥å…·é“¾åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å·¥å…·é“¾åˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºåŸºç¡€å·¥å…·é“¾ä½œä¸ºåå¤‡
            tool_chain = self._create_fallback_tool_chain()
        
        return tool_chain
    
    def _create_fallback_tool_chain(self) -> ToolChain:
        """åˆ›å»ºåå¤‡å·¥å…·é“¾"""
        from .core.tools import BaseTool
        
        class FallbackTool(BaseTool):
            def __init__(self, name):
                super().__init__(name)
            
            async def execute(self, input_data, context):
                yield self.create_success_result(
                    f"åå¤‡å·¥å…· {self.tool_name} æ‰§è¡Œå®Œæˆ",
                    metadata={"fallback": True}
                )
        
        tool_chain = ToolChain()
        # ğŸ”§ ä½¿ç”¨ReAct orchestratoræœŸæœ›çš„å·¥å…·åç§°
        tool_chain.register_tool(FallbackTool("sql_generator_tool"))
        tool_chain.register_tool(FallbackTool("template_info_tool"))
        tool_chain.register_tool(FallbackTool("data_analyzer_tool"))
        tool_chain.register_tool(FallbackTool("data_source_info_tool"))
        
        return tool_chain
        
    async def analyze_template_streaming(
        self,
        user_id: str,
        template_id: str,
        template_content: str,
        data_source_info: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼æ¨¡æ¿åˆ†æ - ä½¿ç”¨æ–°æ¶æ„
        """
        
        # æ„å»ºå¢å¼ºçš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
        context = ToolContext(
            user_id=user_id,
            task_id=f"template_analysis_{uuid.uuid4().hex[:8]}",
            session_id=template_id,
            template_id=template_id,
            template_content=template_content,
            data_source_info=data_source_info,
            context_data={
                "analysis_type": "template_streaming",
                "request_time": datetime.utcnow().isoformat()
            }
        )
        
        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = {
            "template_content": template_content,
            "template_id": template_id,
            "data_source_info": data_source_info or {},
            "analysis_mode": "streaming"
        }
        
        logger.info(f"å¼€å§‹å¢å¼ºæµå¼æ¨¡æ¿åˆ†æ: {context.task_id}")
        
        # æ‰§è¡Œæ¨¡æ¿åˆ†æå·¥å…·
        try:
            async for result in self.tool_chain.execute_tool("template_analysis_tool", input_data, context):
                yield {
                    "type": result.type.value,
                    "uuid": str(uuid.uuid4()),
                    "timestamp": result.timestamp.isoformat() if hasattr(result, 'timestamp') else datetime.utcnow().isoformat(),
                    "user_id": user_id,
                    "task_id": context.task_id,
                    "tool_name": result.tool_name or "template_analysis_tool",
                    "data": result.data,
                    "confidence": getattr(result, 'confidence', None),
                    "validation_passed": getattr(result, 'validation_passed', True),
                    "insights": getattr(result, 'insights', []),
                    "iteration": getattr(result, 'iteration', None)
                }
        except Exception as e:
            yield {
                "type": "error",
                "uuid": str(uuid.uuid4()),
                "timestamp": datetime.utcnow().isoformat(),
                "user_id": user_id,
                "task_id": context.task_id,
                "tool_name": "template_analysis_tool",
                "error": {
                    "error_message": str(e),
                    "error_type": "execution_error",
                    "recoverable": True
                }
            }
    
    async def generate_sql_streaming(
        self,
        user_id: str,
        placeholders: list,
        data_source_info: Optional[Dict[str, Any]] = None,
        template_context: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼SQLç”Ÿæˆ - ä½¿ç”¨æ–°æ¶æ„
        """
        
        # æ„å»ºå¢å¼ºçš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
        context = ToolContext(
            user_id=user_id,
            task_id=f"sql_generation_{uuid.uuid4().hex[:8]}",
            session_id="sql_gen",
            placeholders=placeholders,
            data_source_info=data_source_info,
            context_data={
                "generation_type": "sql_streaming",
                "template_context": template_context,
                "request_time": datetime.utcnow().isoformat()
            }
        )
        
        input_data = {
            "placeholders": placeholders,
            "data_source_info": data_source_info or {},
            "template_context": template_context or "",
            "generation_mode": "streaming"
        }
        
        logger.info(f"å¼€å§‹å¢å¼ºæµå¼SQLç”Ÿæˆ: {context.task_id}")
        
        try:
            # ä½¿ç”¨AdvancedSQLGeneratorå·¥å…·åç§°
            tool_name = "advanced_sql_generator"
            async for result in self.tool_chain.execute_tool(tool_name, input_data, context):
                yield {
                    "type": result.type.value,
                    "uuid": str(uuid.uuid4()),
                    "timestamp": result.timestamp.isoformat() if hasattr(result, 'timestamp') else datetime.utcnow().isoformat(),
                    "user_id": user_id,
                    "task_id": context.task_id,
                    "tool_name": result.tool_name or tool_name,
                    "data": result.data,
                    "confidence": getattr(result, 'confidence', None),
                    "validation_passed": getattr(result, 'validation_passed', True),
                    "insights": getattr(result, 'insights', []),
                    "optimization_suggestions": getattr(result, 'optimization_suggestions', []),
                    "iteration": getattr(result, 'iteration', None),
                    "retry_count": getattr(result, 'retry_count', 0)
                }
        except Exception as e:
            yield {
                "type": "error",
                "uuid": str(uuid.uuid4()),
                "timestamp": datetime.utcnow().isoformat(),
                "user_id": user_id,
                "task_id": context.task_id,
                "tool_name": "advanced_sql_generator",
                "error": {
                    "error_message": str(e),
                    "error_type": "execution_error",
                    "recoverable": True
                }
            }
    
    async def analyze_single_placeholder_simple(
        self,
        user_id: str,
        placeholder_name: str,
        placeholder_text: str,
        template_id: str,
        template_context: Optional[str] = None,
        data_source_info: Optional[Dict[str, Any]] = None,
        task_params: Optional[Dict[str, Any]] = None,
        cron_expression: Optional[str] = None,
        execution_time: Optional[datetime] = None,
        task_type: str = "manual"
    ) -> Dict[str, Any]:
        """
        å•ä¸ªå ä½ç¬¦åˆ†æ - ä½¿ç”¨æ–°çš„BaseToolæ¶æ„
        """
        
        logger.info(f"å¼€å§‹å•ä¸ªå ä½ç¬¦åˆ†æ: {placeholder_name}")
        
        try:
            # æ„å»ºå¢å¼ºçš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
            context = ToolContext(
                user_id=user_id,
                task_id=f"placeholder_analysis_{uuid.uuid4().hex[:8]}",
                session_id=template_id,
                template_id=template_id,
                template_content=template_context,
                data_source_info=data_source_info,
                placeholders=[{
                    "name": placeholder_name,
                    "text": placeholder_text,
                    "params": task_params or {}
                }],
                context_data={
                    "template_id": template_id,
                    "template_context": template_context,
                    "task_params": task_params or {},
                    "cron_expression": cron_expression,
                    "execution_time": execution_time,
                    "task_type": task_type,
                    "analysis_mode": "single_placeholder"
                },
                # å¯ç”¨å­¦ä¹ å’Œä¼˜åŒ–
                enable_learning=True,
                enable_optimization=True,
                # è®¾ç½®è´¨é‡é˜ˆå€¼
                confidence_threshold=0.8,
                validation_required=True
            )
            
            # æ„å»ºåˆ†æç›®æ ‡
            goal = f"""åˆ†æå ä½ç¬¦ '{placeholder_name}' å¹¶ç”Ÿæˆç›¸åº”çš„SQLæŸ¥è¯¢ã€‚

å ä½ç¬¦è¯¦æƒ…ï¼š
- åç§°ï¼š{placeholder_name}
- æ–‡æœ¬ï¼š{placeholder_text}
- æ¨¡æ¿IDï¼š{template_id}
- ä¸Šä¸‹æ–‡ï¼š{template_context or 'æ— '}

è¦æ±‚ï¼š
1. ç†è§£å ä½ç¬¦çš„ä¸šåŠ¡å«ä¹‰
2. æ ¹æ®æ•°æ®æºç»“æ„ç”Ÿæˆåˆé€‚çš„SQLæŸ¥è¯¢
3. ç¡®ä¿SQLè¯­æ³•æ­£ç¡®ä¸”èƒ½æ‰§è¡Œ
4. æä¾›SQLçš„ç½®ä¿¡åº¦è¯„ä¼°

æ•°æ®æºä¿¡æ¯ï¼š
{data_source_info if data_source_info else 'æœªæä¾›'}"""

            # ä½¿ç”¨å¢å¼ºçš„ReActç¼–æ’å™¨æ‰§è¡Œåˆ†æ - é›†æˆæç¤ºè¯ç³»ç»Ÿ
            from .core.prompts import prompt_manager, PromptComplexity
            from .core.prompt_monitor import get_prompt_monitor
            
            # æ ¹æ®ä¸Šä¸‹æ–‡è¯„ä¼°å¤æ‚åº¦
            prompt_complexity = self._assess_task_complexity(context, placeholder_text)
            context.context_data["prompt_complexity"] = prompt_complexity.value
            
            # è·å–æç¤ºè¯ç›‘æ§å™¨
            monitor = get_prompt_monitor()
            execution_start = datetime.utcnow()
            
            try:
                # ä½¿ç”¨ReActç¼–æ’å™¨æ‰§è¡Œåˆ†æ - ä½¿ç”¨æ¡¥æ¥åçš„å·¥å…·é›†
                # ğŸ”§ ä¿®å¤å·¥å…·åç§°ä¸åŒ¹é…é—®é¢˜ï¼šä½¿ç”¨ReAct orchestratoræœŸæœ›çš„å·¥å…·åç§°
                react_tools = ["template_info_tool", "data_analyzer_tool", "sql_generator_tool", "data_source_info_tool"]
                
                result = await self.react_orchestrator.tt(
                    goal=goal,
                    context=context,
                    available_tools=react_tools,
                    max_iterations=context.max_iterations,
                    prompt_complexity=prompt_complexity
                )
                
                # è®°å½•æˆåŠŸçš„æç¤ºè¯ä½¿ç”¨
                execution_time = (datetime.utcnow() - execution_start).total_seconds() * 1000
                monitor.record_usage(
                    category="placeholder_analysis",
                    prompt_type="react_orchestration",
                    complexity=prompt_complexity.value,
                    success=result.get("status") in ["success", "partial_success"],
                    execution_time_ms=execution_time,
                    prompt_length=len(goal),
                    user_id=user_id,
                    context_size=len(str(context.context_data)),
                    iterations=result.get("iterations_used", 1)
                )
                
            except Exception as e:
                # è®°å½•å¤±è´¥çš„æç¤ºè¯ä½¿ç”¨
                execution_time = (datetime.utcnow() - execution_start).total_seconds() * 1000
                monitor.record_usage(
                    category="placeholder_analysis", 
                    prompt_type="react_orchestration",
                    complexity=prompt_complexity.value,
                    success=False,
                    execution_time_ms=execution_time,
                    prompt_length=len(goal),
                    error_message=str(e),
                    user_id=user_id,
                    context_size=len(str(context.context_data)),
                    iterations=0
                )
                raise
            
            # è½¬æ¢ç»“æœæ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹
            if result["status"] in ["success", "partial_success"]:
                # ä»tool_resultsä¸­æå–SQLç”Ÿæˆç»“æœ
                tool_results = result.get("tool_results", [])
                generated_sql = result.get("generated_sql", "")
                
                # æŸ¥æ‰¾SQLç”Ÿæˆå·¥å…·çš„ç»“æœ
                sql_result = None
                for tool_result in tool_results:
                    if tool_result.get("tool") == "sql_generation_tool":
                        sql_result = tool_result.get("result", {})
                        if isinstance(sql_result, dict) and "generated_sql" in sql_result:
                            generated_sql = sql_result["generated_sql"]
                        break
                
                # æ„å»ºç»Ÿä¸€çš„å“åº”æ ¼å¼
                confidence_score = result.get("confidence_score", 0.7)
                if result["status"] == "partial_success":
                    confidence_score *= 0.8  # éƒ¨åˆ†æˆåŠŸçš„ç½®ä¿¡åº¦é™ä½
                
                return {
                    "status": "success",
                    "placeholder_name": placeholder_name,
                    "analysis_result": f"ReActåˆ†æå®Œæˆ - ç›®æ ‡: {goal[:100]}...",
                    "generated_sql": generated_sql,
                    "confidence_score": confidence_score,
                    "sql_validated": bool(generated_sql and "online_retail" in generated_sql.lower()),
                    "react_insights": result.get("react_insights", []),
                    "iterations_used": result.get("iterations_used", 1),
                    "execution_summary": result.get("execution_summary", {}),
                    "tool_results": tool_results
                }
            else:
                # é”™è¯¯æƒ…å†µ
                return {
                    "status": "error",
                    "error": {
                        "error_type": "react_execution_failed",
                        "error_message": result.get("error", "ReActæ‰§è¡Œå¤±è´¥"),
                        "recoverable": True
                    },
                    "placeholder_name": placeholder_name,
                    "iterations_used": result.get("iterations_used", 0),
                    "step_history": result.get("step_history", [])
                }
                
        except Exception as e:
            logger.error(f"å ä½ç¬¦åˆ†æå¼‚å¸¸: {e}", exc_info=True)
            return {
                "status": "error",
                "error": {
                    "error_type": "service_orchestrator_error",
                    "error_message": str(e),
                    "recoverable": False
                },
                "placeholder_name": placeholder_name
            }

    # å‘åå…¼å®¹æ–¹æ³• - æ”¯æŒç°æœ‰çš„éæµå¼è°ƒç”¨
    
    async def analyze_template_simple(
        self,
        user_id: str,
        template_id: str,
        template_content: str,
        data_source_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ç®€å•æ¨¡æ¿åˆ†æ - éæµå¼ï¼Œå‘åå…¼å®¹
        """
        
        result = None
        error = None
        
        async for message_data in self.analyze_template_streaming(
            user_id=user_id,
            template_id=template_id,
            template_content=template_content,
            data_source_info=data_source_info
        ):
            if message_data["type"] == "result":
                result = message_data["result"]
            elif message_data["type"] == "error":
                error = message_data["error"]
        
        if error:
            return {
                "status": "error",
                "error": error,
                "template_id": template_id
            }
        
        return result or {
            "status": "completed",
            "template_id": template_id,
            "placeholder_analysis": {
                "total_count": 0,
                "placeholders": [],
                "processing_status": "no_result"
            }
        }
    
    def _assess_task_complexity(self, context: ToolContext, placeholder_text: str) -> 'PromptComplexity':
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        from .core.prompts import PromptComplexity
        
        # åŸºäºå¤šä¸ªå› ç´ è¯„ä¼°å¤æ‚åº¦
        complexity_score = 0
        
        # 1. é”™è¯¯å†å²
        error_count = len(context.error_history)
        if error_count >= 3:
            complexity_score += 3
        elif error_count >= 1:
            complexity_score += 2
        
        # 2. å ä½ç¬¦å¤æ‚åº¦
        if len(placeholder_text) > 100:
            complexity_score += 2
        elif len(placeholder_text) > 50:
            complexity_score += 1
        
        # 3. æ•°æ®æºå¤æ‚åº¦
        if context.data_source_info:
            table_count = len(context.data_source_info.get("tables", []))
            if table_count > 20:
                complexity_score += 2
            elif table_count > 10:
                complexity_score += 1
        
        # 4. æ¨¡æ¿å¤æ‚åº¦
        if context.template_content and len(context.template_content) > 500:
            complexity_score += 1
        
        # 5. å­¦ä¹ å†å²
        if len(context.learned_insights) >= 5:
            complexity_score += 1
        
        # æ˜ å°„åˆ°å¤æ‚åº¦çº§åˆ«
        if complexity_score >= 6:
            return PromptComplexity.CRITICAL
        elif complexity_score >= 4:
            return PromptComplexity.HIGH
        elif complexity_score >= 2:
            return PromptComplexity.MEDIUM
        else:
            return PromptComplexity.SIMPLE
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        try:
            return self.controller.get_task_status(task_id)
        except AttributeError:
            # å¦‚æœcontrollerä¸å­˜åœ¨ï¼Œè¿”å›åŸºæœ¬çŠ¶æ€
            return {
                "task_id": task_id,
                "status": "unknown",
                "message": "æ§åˆ¶å™¨æœªåˆå§‹åŒ–"
            }
    
    def list_active_tasks(self) -> list:
        """åˆ—å‡ºæ´»è·ƒä»»åŠ¡"""
        try:
            return self.controller.list_active_tasks()
        except AttributeError:
            return []
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        try:
            return await self.controller.cancel_task(task_id)
        except AttributeError:
            logger.warning(f"æ— æ³•å–æ¶ˆä»»åŠ¡ {task_id}: æ§åˆ¶å™¨æœªåˆå§‹åŒ–")
            return False
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç¼–æ’å™¨æ€§èƒ½æŒ‡æ ‡"""
        from .core.prompt_monitor import get_prompt_monitor
        
        monitor = get_prompt_monitor()
        
        return {
            "tool_chain": {
                "registered_tools": self.tool_chain.list_tools(),
                "execution_history": self.tool_chain.get_execution_history(limit=10),
                "tool_metrics": {
                    tool_name: self.tool_chain.get_tool_metrics(tool_name).__dict__ 
                    if self.tool_chain.get_tool_metrics(tool_name) else None
                    for tool_name in self.tool_chain.list_tools()
                }
            },
            "prompt_performance": monitor.get_performance_summary(
                category="placeholder_analysis",
                time_window_hours=24
            ),
            "system_status": {
                "orchestrator_initialized": True,
                "react_orchestrator_available": self.react_orchestrator is not None,
                "tools_count": len(self.tool_chain.list_tools())
            }
        }


# å…¨å±€å®ä¾‹
_orchestrator: Optional[ServiceOrchestrator] = None


def get_service_orchestrator() -> ServiceOrchestrator:
    """è·å–æœåŠ¡ç¼–æ’å™¨å•ä¾‹"""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = ServiceOrchestrator()
    return _orchestrator


# å‘åå…¼å®¹çš„ä¾¿æ·å‡½æ•°

async def analyze_template_with_new_architecture(
    user_id: str,
    template_id: str,
    template_content: str,
    data_source_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """ä½¿ç”¨æ–°æ¶æ„åˆ†ææ¨¡æ¿ - ä¾¿æ·å‡½æ•°"""
    orchestrator = get_service_orchestrator()
    return await orchestrator.analyze_template_simple(
        user_id=user_id,
        template_id=template_id,
        template_content=template_content,
        data_source_info=data_source_info
    )