"""
SQLç”Ÿæˆå·¥å…· - åŸºäºæ–°æ¶æ„
"""

import logging
from typing import Dict, Any, AsyncGenerator, List

from ..core.tools import BaseTool, ToolContext, ToolResult
from ..llm import ask_agent_for_user

logger = logging.getLogger(__name__)


class SQLGenerationTool(BaseTool):
    """SQLç”Ÿæˆå·¥å…·"""
    
    def __init__(self):
        super().__init__("sql_generation_tool")
        
    async def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        required_fields = ["placeholders"]
        
        for field in required_fields:
            if field not in input_data:
                self.logger.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        if not isinstance(input_data["placeholders"], list):
            self.logger.error("å ä½ç¬¦å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
            return False
            
        return True
    
    async def execute(
        self, 
        input_data: Dict[str, Any],
        context: ToolContext
    ) -> AsyncGenerator[ToolResult, None]:
        """
        æ‰§è¡ŒSQLç”Ÿæˆ
        
        è¾“å…¥æ•°æ®æ ¼å¼ï¼š
        {
            "placeholders": list,        # å¿…éœ€ï¼šå ä½ç¬¦åˆ—è¡¨
            "data_source_info": dict,   # å¯é€‰ï¼šæ•°æ®æºä¿¡æ¯
            "template_context": str     # å¯é€‰ï¼šæ¨¡æ¿ä¸Šä¸‹æ–‡
        }
        """
        
        try:
            # 1. å¼€å§‹SQLç”Ÿæˆ
            yield self.create_progress_result("å¼€å§‹SQLç”Ÿæˆ", "initialization")
            
            placeholders = input_data["placeholders"]
            data_source_info = input_data.get("data_source_info", {})
            template_context = input_data.get("template_context", "")
            
            if not placeholders:
                yield self.create_success_result({
                    "generated_sqls": {},
                    "status": "completed",
                    "message": "æ²¡æœ‰éœ€è¦ç”ŸæˆSQLçš„å ä½ç¬¦"
                })
                return
            
            yield self.create_progress_result(
                f"å‡†å¤‡ä¸º {len(placeholders)} ä¸ªå ä½ç¬¦ç”ŸæˆSQL", 
                "preparation", 
                10.0
            )
            
            # 2. ä¸ºæ¯ä¸ªå ä½ç¬¦ç”ŸæˆSQL
            generated_sqls = {}
            failed_sqls = []
            
            for i, placeholder in enumerate(placeholders):
                placeholder_name = placeholder.get("name", f"placeholder_{i}")
                
                yield self.create_progress_result(
                    f"ç”Ÿæˆå ä½ç¬¦ '{placeholder_name}' çš„SQL",
                    "generating_sql",
                    20.0 + (i / len(placeholders)) * 60.0
                )
                
                try:
                    sql = await self._generate_sql_for_placeholder(
                        placeholder=placeholder,
                        data_source_info=data_source_info,
                        template_context=template_context,
                        context=context
                    )
                    
                    generated_sqls[placeholder_name] = sql
                    
                except Exception as e:
                    self.logger.error(f"ä¸ºå ä½ç¬¦ '{placeholder_name}' ç”ŸæˆSQLå¤±è´¥: {e}")
                    failed_sqls.append({
                        "placeholder_name": placeholder_name,
                        "error": str(e)
                    })
            
            # 3. ç”Ÿæˆç»“æœæ‘˜è¦
            yield self.create_progress_result("ç”ŸæˆSQLæ‘˜è¦", "summarizing", 90.0)
            
            result = {
                "generated_sqls": generated_sqls,
                "failed_sqls": failed_sqls,
                "status": "completed" if not failed_sqls else "partial_success",
                "summary": {
                    "total_placeholders": len(placeholders),
                    "successful_generations": len(generated_sqls),
                    "failed_generations": len(failed_sqls),
                    "success_rate": len(generated_sqls) / len(placeholders) * 100 if placeholders else 0
                },
                "metadata": {
                    "user_id": context.user_id,
                    "task_id": context.task_id,
                    "session_id": context.session_id,
                    "tool_name": self.tool_name,
                    "generated_at": self._get_timestamp()
                }
            }
            
            # 4. è¿”å›æœ€ç»ˆç»“æœ
            yield self.create_success_result(data=result)
            
        except Exception as e:
            self.logger.error(f"SQLç”Ÿæˆå¤±è´¥: {e}")
            yield self.create_error_result(
                error_message=f"SQLç”Ÿæˆå¤±è´¥: {str(e)}",
                error_type="sql_generation_error"
            )
    
    async def _generate_sql_for_placeholder(
        self,
        placeholder: Dict[str, Any],
        data_source_info: Dict[str, Any],
        template_context: str,
        context: ToolContext
    ) -> str:
        """ä¸ºå•ä¸ªå ä½ç¬¦ç”ŸæˆSQL - åŸºäºReActæœºåˆ¶çš„æ™ºèƒ½è¿­ä»£"""
        
        placeholder_name = placeholder.get("name", "æœªçŸ¥å ä½ç¬¦")
        placeholder_analysis = placeholder.get("analysis", "æ— åˆ†æä¿¡æ¯")
        placeholder_context = placeholder.get("context", "")
        
        # éªŒè¯è¡¨ç»“æ„ä¿¡æ¯
        if not data_source_info.get('tables'):
            raise Exception(f"æ•°æ®æºæ²¡æœ‰è¡¨ç»“æ„ä¿¡æ¯ï¼Œæ— æ³•ä¸ºå ä½ç¬¦ '{placeholder_name}' ç”ŸæˆSQLã€‚è¯·å…ˆåŒæ­¥æ•°æ®æºçš„è¡¨ç»“æ„ã€‚")
        
        # ReActå¾ªç¯ï¼šReasoning â†’ Acting â†’ Observation â†’ Reflection
        react_context = {
            "placeholder_name": placeholder_name,
            "placeholder_analysis": placeholder_analysis,
            "placeholder_context": placeholder_context,
            "data_source_info": data_source_info,
            "template_context": template_context,
            "iteration_history": [],  # è®°å½•æ¯æ¬¡è¿­ä»£çš„ç»“æœ
            "learned_insights": []    # ç§¯ç´¯çš„ç»éªŒå’Œæ´å¯Ÿ
        }
        
        max_iterations = 5  # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥æ”¯æŒæ›´å¤æ‚çš„å­¦ä¹ 
        
        for iteration in range(max_iterations):
            self.logger.info(f"ğŸš€ ====== ReActç¬¬ {iteration + 1}/{max_iterations} è½®è¿­ä»£å¼€å§‹ ====== ğŸš€")
            self.logger.info(f"ğŸ¯ å ä½ç¬¦: {placeholder_name}")
            self.logger.info(f"ğŸ“Š å¯ç”¨è¡¨æ•°é‡: {len(data_source_info.get('tables', []))}")
            self.logger.info(f"ğŸ’¡ å·²å­¦ç»éªŒ: {len(react_context['learned_insights'])} æ¡")
            
            try:
                # Step 1: Reasoning - åˆ†æå’Œæ¨ç†
                self.logger.info(f"ğŸ§  [ç¬¬{iteration + 1}è½®] æ¨ç†é˜¶æ®µå¼€å§‹...")
                reasoning_result = await self._react_reasoning_phase(react_context, context, iteration)
                selected_table = reasoning_result.get('selected_table', 'unknown')
                confidence = reasoning_result.get('confidence', 0)
                
                self.logger.info(f"âœ… [ç¬¬{iteration + 1}è½®] æ¨ç†å®Œæˆ:")
                self.logger.info(f"   ğŸ¯ é€‰æ‹©è¡¨: {selected_table}")
                self.logger.info(f"   ğŸ¯ ç½®ä¿¡åº¦: {confidence}")
                self.logger.info(f"   ğŸ¯ ç›¸å…³å­—æ®µ: {reasoning_result.get('relevant_fields', [])}")
                if reasoning_result.get('forced_correction'):
                    self.logger.warning(f"   ğŸ”§ å¼ºåˆ¶çº æ­£: {reasoning_result['forced_correction']}")
                
                # Step 2: Acting - åŸºäºæ¨ç†ç”ŸæˆSQL
                self.logger.info(f"âš¡ [ç¬¬{iteration + 1}è½®] æ‰§è¡Œé˜¶æ®µå¼€å§‹...")
                sql = await self._react_acting_phase(reasoning_result, react_context, context, iteration)
                
                self.logger.info(f"âœ… [ç¬¬{iteration + 1}è½®] SQLç”Ÿæˆå®Œæˆ:")
                self.logger.info(f"   ğŸ“ SQLé•¿åº¦: {len(sql)} å­—ç¬¦")
                self.logger.info(f"   ğŸ“ SQLé¢„è§ˆ: {sql[:100]}{'...' if len(sql) > 100 else ''}")
                
                # å…³é”®éªŒè¯ï¼šæ£€æŸ¥ç”Ÿæˆçš„SQLæ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„è¡¨å
                if selected_table and selected_table.lower() not in sql.lower():
                    self.logger.error(f"ğŸš¨ [ç¬¬{iteration + 1}è½®] ä¸¥é‡é”™è¯¯ï¼šSQLæ²¡æœ‰ä½¿ç”¨æ¨ç†é€‰æ‹©çš„è¡¨!")
                    self.logger.error(f"   ğŸ¯ åº”ä½¿ç”¨è¡¨: {selected_table}")
                    self.logger.error(f"   âŒ å®é™…SQL: {sql}")
                
                # Step 3: Observation - éªŒè¯å’Œæµ‹è¯•SQL
                self.logger.info(f"ğŸ‘ï¸ [ç¬¬{iteration + 1}è½®] è§‚å¯Ÿé˜¶æ®µå¼€å§‹...")
                observation_result = await self._react_observation_phase(sql, react_context, context)
                
                is_valid = observation_result.get('valid', False)
                status = observation_result.get('status', 'unknown')
                errors = observation_result.get('errors', [])
                
                self.logger.info(f"âœ… [ç¬¬{iteration + 1}è½®] è§‚å¯Ÿå®Œæˆ:")
                self.logger.info(f"   ğŸ” éªŒè¯ç»“æœ: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}")
                self.logger.info(f"   ğŸ” çŠ¶æ€: {status}")
                if errors:
                    self.logger.error(f"   âŒ é”™è¯¯åˆ—è¡¨: {errors}")
                
                # Step 4: Reflection - åæ€å’Œå­¦ä¹ 
                self.logger.info(f"ğŸ¤” [ç¬¬{iteration + 1}è½®] åæ€é˜¶æ®µå¼€å§‹...")
                reflection_result = await self._react_reflection_phase(
                    reasoning_result, sql, observation_result, react_context, context, iteration
                )
                
                self.logger.info(f"âœ… [ç¬¬{iteration + 1}è½®] åæ€å®Œæˆ:")
                if reflection_result.get('success'):
                    self.logger.info(f"   ğŸ‰ æˆåŠŸç­–ç•¥: {reflection_result.get('insights', [])}")
                else:
                    self.logger.info(f"   ğŸ’­ å¤±è´¥åˆ†æ: {reflection_result.get('failure_analysis', 'unknown')}")
                    self.logger.info(f"   ğŸ”„ ä¸‹è½®ç­–ç•¥: {reflection_result.get('next_iteration_strategy', 'unknown')}")
                
                # è®°å½•æœ¬è½®è¿­ä»£
                iteration_record = {
                    "iteration": iteration + 1,
                    "reasoning": reasoning_result,
                    "sql": sql,
                    "observation": observation_result,
                    "reflection": reflection_result,
                    "success": observation_result.get("valid", False)
                }
                react_context["iteration_history"].append(iteration_record)
                
                # å¦‚æœæˆåŠŸï¼Œè¿”å›ç»“æœ
                if observation_result.get("valid", False):
                    self.logger.info(f"ReActæˆåŠŸå®Œæˆ (ç¬¬{iteration + 1}è½®): {placeholder_name}")
                    return sql
                
                # å¦‚æœå¤±è´¥ï¼Œæ›´æ–°å­¦ä¹ ç»éªŒ
                if reflection_result.get("insights"):
                    react_context["learned_insights"].extend(reflection_result["insights"])
                
                self.logger.warning(f"ç¬¬{iteration + 1}è½®ReActå¤±è´¥: {observation_result.get('error', 'unknown')}")
                
            except Exception as e:
                self.logger.error(f"ReActç¬¬{iteration + 1}è½®å‡ºç°å¼‚å¸¸: {e}")
                react_context["iteration_history"].append({
                    "iteration": iteration + 1,
                    "error": str(e),
                    "success": False
                })
                
                if iteration == max_iterations - 1:  # æœ€åä¸€æ¬¡å°è¯•
                    raise Exception(f"ReActç»è¿‡{max_iterations}è½®è¿­ä»£ä»ç„¶å¤±è´¥: {str(e)}")
                continue
        
        # å¦‚æœæ‰€æœ‰è¿­ä»£éƒ½å¤±è´¥äº†
        failure_summary = self._generate_failure_summary(react_context)
        raise Exception(f"ReActç»è¿‡{max_iterations}è½®è¿­ä»£ä»æ— æ³•ç”Ÿæˆæœ‰æ•ˆSQLã€‚å¤±è´¥æ€»ç»“: {failure_summary}")
    
    async def _react_reasoning_phase(
        self,
        react_context: Dict[str, Any],
        context: ToolContext,
        iteration: int
    ) -> Dict[str, Any]:
        """ReActæ¨ç†é˜¶æ®µï¼šåˆ†æéœ€æ±‚ï¼Œé€‰æ‹©æœ€åˆé€‚çš„è¡¨å’Œå­—æ®µ"""
        
        placeholder_name = react_context["placeholder_name"]
        placeholder_analysis = react_context["placeholder_analysis"]
        data_source_info = react_context["data_source_info"]
        learned_insights = react_context["learned_insights"]
        iteration_history = react_context["iteration_history"]
        
        # æ„å»ºå¼ºåˆ¶æ€§æ¨ç†prompt
        available_tables = data_source_info.get('tables', [])
        table_validation_list = '\n'.join([f"  âœ… {table}" for table in available_tables])
        
        reasoning_prompt = f"""
ğŸš¨ã€å¼ºåˆ¶æ€§çº¦æŸã€‘ğŸš¨ ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ï¼Œä½†ä½ æœ‰ä¸¥é‡çš„é™åˆ¶ï¼šä½ åªèƒ½ä½¿ç”¨æä¾›çš„çœŸå®è¡¨åï¼Œç»å¯¹ä¸å…è®¸ç¼–é€ ä»»ä½•è¡¨åï¼

ã€å…³é”®ä»»åŠ¡ã€‘: ä¸ºå ä½ç¬¦ "{placeholder_name}" ä»ä»¥ä¸‹çœŸå®è¡¨ä¸­é€‰æ‹©ä¸€ä¸ª
ã€å ä½ç¬¦åˆ†æã€‘: {placeholder_analysis}

ğŸ”’ã€ä¸¥æ ¼é™åˆ¶ - å¿…é¡»éµå®ˆã€‘:
âŒ ç¦æ­¢ä½¿ç”¨: complaints, users, orders, products, customers ç­‰å¸¸è§è¡¨å
âŒ ç¦æ­¢ç¼–é€ ä»»ä½•è¡¨åï¼Œå“ªæ€•çœ‹èµ·æ¥å¾ˆåˆç†
âœ… åªèƒ½ä»ä¸‹é¢çš„çœŸå®è¡¨åˆ—è¡¨ä¸­é€‰æ‹©:
{table_validation_list}

ğŸ“Šã€çœŸå®æ•°æ®è¡¨ç»“æ„ã€‘:
{self._build_detailed_tables_info(data_source_info)}

ğŸ’¡ã€å­¦ä¹ ç»éªŒã€‘:
{self._format_learned_insights(learned_insights)}

ğŸ“‹ã€å°è¯•å†å²ã€‘:
{self._format_iteration_history(iteration_history)}

ğŸ¯ã€åˆ†ææ­¥éª¤ã€‘:
1. ä»”ç»†é˜…è¯»å ä½ç¬¦"{placeholder_name}"çš„ä¸šåŠ¡éœ€æ±‚
2. é€ä¸ªæ£€æŸ¥ä¸Šè¿°çœŸå®è¡¨åˆ—è¡¨ï¼Œå¯»æ‰¾ç›¸å…³ä¸šåŠ¡è¡¨
3. åŸºäºè¡¨åå’Œå­—æ®µåæ¨æ–­ä¸šåŠ¡ç”¨é€”ï¼ˆå¦‚ï¼šods_complain = æŠ•è¯‰æ•°æ®ï¼‰
4. é€‰æ‹©æœ€åŒ¹é…çš„è¡¨å’Œå­—æ®µ

âš ï¸ã€éªŒè¯æ£€æŸ¥ã€‘:
- selected_table å¿…é¡»åœ¨ä¸Šè¿°çœŸå®è¡¨åˆ—è¡¨ä¸­å­˜åœ¨
- relevant_fields å¿…é¡»åœ¨é€‰å®šè¡¨çš„å­—æ®µåˆ—è¡¨ä¸­å­˜åœ¨
- å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„è¡¨ï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„è¡¨å¹¶è¯´æ˜åŸå› 

ğŸ“ã€è¿”å›æ ¼å¼ã€‘ä¸¥æ ¼æŒ‰JSONæ ¼å¼:
{{
    "reasoning_process": "é€æ­¥åˆ†æè¿‡ç¨‹ï¼š1.éœ€æ±‚ç†è§£ 2.è¡¨ååŒ¹é… 3.å­—æ®µåˆ†æ 4.æœ€ç»ˆé€‰æ‹©",
    "selected_table": "å¿…é¡»ä»çœŸå®è¡¨åˆ—è¡¨ä¸­é€‰æ‹©ï¼Œä¸å…è®¸ç¼–é€ ",
    "table_business_purpose": "åŸºäºè¡¨åå’Œå­—æ®µæ¨æ–­çš„ä¸šåŠ¡ç”¨é€”",
    "relevant_fields": ["ä¸¥æ ¼ä»é€‰å®šè¡¨çš„å­—æ®µåˆ—è¡¨ä¸­é€‰æ‹©"],
    "field_mappings": {{
        "æ—¶é—´å­—æ®µ": "å®é™…çš„æ—¶é—´å­—æ®µå",
        "ä¸»è¦å†…å®¹å­—æ®µ": "å®é™…çš„å†…å®¹å­—æ®µå"
    }},
    "query_strategy": "å…·ä½“çš„æŸ¥è¯¢ç­–ç•¥",
    "confidence": 0.8,
    "table_validation": "ç¡®è®¤é€‰æ‹©çš„è¡¨åœ¨çœŸå®åˆ—è¡¨ä¸­: Yes/No",
    "alternatives": ["å…¶ä»–å¯èƒ½çš„çœŸå®è¡¨å"]
}}

ğŸ”¥ã€ç¬¬{iteration + 1}è½®è¿­ä»£ç‰¹åˆ«æé†’ã€‘:
{self._get_iteration_specific_guidance(iteration, iteration_history)}
"""

        try:
            response = await ask_agent_for_user(
                user_id=context.user_id,
                question=reasoning_prompt,
                agent_type="data_analysis",
                task_type="table_selection",
                complexity="high"
            )
            
            # è§£æJSONå“åº”
            import json
            try:
                reasoning_result = json.loads(response.strip())
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ["selected_table", "relevant_fields", "query_strategy"]
                for field in required_fields:
                    if field not in reasoning_result:
                        reasoning_result[field] = "æœªæŒ‡å®š"
                
                # å¼ºåˆ¶éªŒè¯è¡¨å - è¿™æ˜¯å…³é”®çš„çº¦æŸæ£€æŸ¥
                available_tables = data_source_info.get('tables', [])
                selected_table = reasoning_result.get("selected_table")
                
                if selected_table not in available_tables:
                    self.logger.error(f"ğŸš¨ ä¸¥é‡é”™è¯¯ï¼šAIé€‰æ‹©äº†ä¸å­˜åœ¨çš„è¡¨'{selected_table}'ï¼")
                    self.logger.error(f"ğŸš¨ å¯ç”¨è¡¨åˆ—è¡¨ï¼š{available_tables}")
                    
                    # å¼ºåˆ¶çº æ­£ - è¿™æ¬¡ä¸ç»™AIæœºä¼šçŠ¯é”™
                    if "complain" in placeholder_name.lower() or "æŠ•è¯‰" in placeholder_name:
                        # æ˜ç¡®å¯»æ‰¾æŠ•è¯‰ç›¸å…³è¡¨
                        for table in available_tables:
                            if "complain" in table.lower():
                                reasoning_result["selected_table"] = table
                                reasoning_result["forced_correction"] = f"AIé”™è¯¯é€‰æ‹©'{selected_table}'ï¼Œç³»ç»Ÿå¼ºåˆ¶çº æ­£ä¸º'{table}'"
                                self.logger.warning(f"ğŸ”§ å¼ºåˆ¶çº æ­£ï¼š{selected_table} -> {table}")
                                break
                    else:
                        # å…¶ä»–æƒ…å†µä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…
                        closest_table = self._find_closest_table(selected_table, available_tables)
                        if closest_table:
                            reasoning_result["selected_table"] = closest_table
                            reasoning_result["forced_correction"] = f"AIé”™è¯¯é€‰æ‹©'{selected_table}'ï¼Œç³»ç»Ÿå¼ºåˆ¶çº æ­£ä¸º'{closest_table}'"
                            self.logger.warning(f"ğŸ”§ å¼ºåˆ¶çº æ­£ï¼š{selected_table} -> {closest_table}")
                    
                    # æ·»åŠ å¤±è´¥è®°å½•
                    learned_insights.append(f"âŒ ç¬¬{iteration + 1}è½®ï¼šAIè¿è§„ä½¿ç”¨ä¸å­˜åœ¨çš„è¡¨'{selected_table}'ï¼Œå·²å¼ºåˆ¶çº æ­£")
                
                # éªŒè¯å­—æ®µå
                corrected_fields = self._validate_and_correct_fields(
                    reasoning_result.get("relevant_fields", []),
                    reasoning_result.get("selected_table"),
                    data_source_info
                )
                if corrected_fields != reasoning_result.get("relevant_fields", []):
                    reasoning_result["relevant_fields"] = corrected_fields
                    reasoning_result["fields_corrected"] = True
                    self.logger.warning(f"ğŸ”§ å­—æ®µå·²çº æ­£ï¼š{corrected_fields}")
                
                return reasoning_result
                
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå›é€€åˆ°ç®€å•è§£æ
                self.logger.warning("æ¨ç†å“åº”ä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•ç®€å•è§£æ")
                return self._parse_reasoning_response_simple(response, data_source_info)
                
        except Exception as e:
            self.logger.error(f"æ¨ç†é˜¶æ®µå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ¨ç†ç»“æœ
            return self._get_default_reasoning_result(react_context)
    
    async def _react_acting_phase(
        self,
        reasoning_result: Dict[str, Any],
        react_context: Dict[str, Any],
        context: ToolContext,
        iteration: int
    ) -> str:
        """ReActæ‰§è¡Œé˜¶æ®µï¼šåŸºäºæ¨ç†ç»“æœç”Ÿæˆç²¾ç¡®çš„SQL"""
        
        selected_table = reasoning_result.get("selected_table", "")
        relevant_fields = reasoning_result.get("relevant_fields", [])
        query_strategy = reasoning_result.get("query_strategy", "")
        field_mappings = reasoning_result.get("field_mappings", {})
        
        placeholder_name = react_context["placeholder_name"]
        placeholder_analysis = react_context["placeholder_analysis"]
        learned_insights = react_context["learned_insights"]
        
        # å¼ºåŒ–SQLç”Ÿæˆprompt - ç»å¯¹çº¦æŸ
        sql_prompt = f"""
ğŸ”’ã€å¼ºåˆ¶SQLç”Ÿæˆçº¦æŸã€‘ğŸ”’ ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æ¨ç†ç»“æœç”ŸæˆSQLï¼Œä¸å…è®¸ä»»ä½•åå·®ï¼

ã€å ä½ç¬¦ã€‘: "{placeholder_name}"
ã€å¼ºåˆ¶è¦æ±‚ã€‘: {placeholder_analysis}

ğŸ¯ã€æ¨ç†ç»“æœ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘:
âœ… å¼ºåˆ¶è¡¨å: {selected_table}
âœ… å¼ºåˆ¶å­—æ®µ: {', '.join(relevant_fields)}
âœ… æŸ¥è¯¢ç­–ç•¥: {query_strategy}
âœ… å­—æ®µæ˜ å°„: {field_mappings}

ğŸš¨ã€ç»å¯¹ç¦æ­¢ã€‘:
âŒ ä¸å…è®¸ä½¿ç”¨ä»»ä½•å…¶ä»–è¡¨åï¼ˆå¦‚complaints, usersç­‰ï¼‰
âŒ ä¸å…è®¸ä½¿ç”¨æœªåœ¨å­—æ®µåˆ—è¡¨ä¸­çš„å­—æ®µå
âŒ ä¸å…è®¸æ·»åŠ ä»»ä½•æ¨ç†ç»“æœä¸­æ²¡æœ‰çš„è¡¨æˆ–å­—æ®µ
âŒ ä¸å…è®¸ä½¿ç”¨JOINå…¶ä»–è¡¨

ğŸ’¡ã€å†å²æ•™è®­ã€‘:
{self._format_learned_insights(learned_insights)}

ğŸ“‹ã€SQLç”Ÿæˆè§„åˆ™ã€‘:
1. è¡¨å: åªèƒ½æ˜¯ `{selected_table}` - ä¸€ä¸ªå­—éƒ½ä¸èƒ½é”™ï¼
2. å­—æ®µ: åªèƒ½ä» [{', '.join(relevant_fields)}] ä¸­é€‰æ‹©
3. æ—¶é—´å­—æ®µ: {field_mappings.get('æ—¶é—´å­—æ®µ', 'complain_time')} ï¼ˆå¦‚éœ€è¦æ—¶é—´è¿‡æ»¤ï¼‰
4. è¯­æ³•: é€‚åˆDorisæ•°æ®åº“çš„æ ‡å‡†SQL
5. é™åˆ¶: æ·»åŠ  LIMIT 10 ç”¨äºæµ‹è¯•

ğŸ”ã€éªŒè¯æ£€æŸ¥ã€‘:
- ç¡®è®¤è¡¨åå®Œå…¨åŒ¹é…: {selected_table}
- ç¡®è®¤å­—æ®µéƒ½åœ¨å…è®¸åˆ—è¡¨ä¸­
- ç¡®è®¤SQLè¯­æ³•æ­£ç¡®

ç›´æ¥è¿”å›SQLè¯­å¥ï¼ˆä¸è¦markdownæ ¼å¼ï¼Œä¸è¦è§£é‡Šï¼‰:
"""

        try:
            response = await ask_agent_for_user(
                user_id=context.user_id,
                question=sql_prompt,
                agent_type="sql_generation",
                task_type="precise_sql_generation",
                complexity="medium"
            )
            
            # æ¸…ç†SQLå“åº”
            sql = self._clean_sql_response(response)
            
            # éªŒè¯SQLæ˜¯å¦ä½¿ç”¨äº†æ¨ç†é€‰å®šçš„è¡¨å’Œå­—æ®µ
            sql_validation = self._validate_sql_against_reasoning(sql, reasoning_result)
            if not sql_validation["valid"]:
                self.logger.warning(f"ç”Ÿæˆçš„SQLä¸æ¨ç†ç»“æœä¸ç¬¦: {sql_validation['error']}")
                # å¯ä»¥é€‰æ‹©ä¿®æ­£SQLæˆ–è€…é‡æ–°ç”Ÿæˆ
            
            return sql
            
        except Exception as e:
            raise Exception(f"SQLæ‰§è¡Œé˜¶æ®µå¤±è´¥: {str(e)}")
    
    async def _react_observation_phase(
        self,
        sql: str,
        react_context: Dict[str, Any],
        context: ToolContext
    ) -> Dict[str, Any]:
        """ReActè§‚å¯Ÿé˜¶æ®µï¼šéªŒè¯å’Œæµ‹è¯•SQL"""
        
        data_source_info = react_context["data_source_info"]
        placeholder_name = react_context["placeholder_name"]
        
        observation_result = {
            "sql": sql,
            "validation_results": [],
            "test_results": None,
            "valid": False,
            "errors": [],
            "performance_metrics": {}
        }
        
        try:
            # 1. é™æ€è¯­æ³•éªŒè¯
            syntax_validation = self._validate_generated_sql(sql, data_source_info)
            observation_result["validation_results"].append({
                "type": "syntax_validation",
                "result": syntax_validation
            })
            
            if not syntax_validation["valid"]:
                observation_result["errors"].append(f"è¯­æ³•éªŒè¯å¤±è´¥: {syntax_validation['error']}")
                observation_result["status"] = "syntax_error"
                return observation_result
            
            # 2. åŠ¨æ€æ‰§è¡Œæµ‹è¯•ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            try:
                test_result = await self._execute_sql_test(sql, data_source_info, placeholder_name)
                observation_result["test_results"] = test_result
                observation_result["validation_results"].append({
                    "type": "execution_test",
                    "result": test_result
                })
                
                if test_result.get("success", False):
                    observation_result["valid"] = True
                    observation_result["status"] = "success"
                    observation_result["performance_metrics"] = {
                        "execution_time_ms": test_result.get("execution_time_ms", 0),
                        "row_count": test_result.get("row_count", 0)
                    }
                else:
                    observation_result["errors"].append(f"æ‰§è¡Œæµ‹è¯•å¤±è´¥: {test_result.get('error', 'unknown')}")
                    observation_result["status"] = "execution_error"
                    
            except Exception as test_error:
                observation_result["errors"].append(f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(test_error)}")
                observation_result["status"] = "test_exception"
            
            return observation_result
            
        except Exception as e:
            observation_result["errors"].append(f"è§‚å¯Ÿé˜¶æ®µå¼‚å¸¸: {str(e)}")
            observation_result["status"] = "observation_error"
            return observation_result
    
    async def _react_reflection_phase(
        self,
        reasoning_result: Dict[str, Any],
        sql: str,
        observation_result: Dict[str, Any],
        react_context: Dict[str, Any],
        context: ToolContext,
        iteration: int
    ) -> Dict[str, Any]:
        """ReActåæ€é˜¶æ®µï¼šåˆ†æå¤±è´¥åŸå› ï¼Œæ€»ç»“ç»éªŒæ•™è®­"""
        
        placeholder_name = react_context["placeholder_name"]
        
        if observation_result.get("valid", False):
            # æˆåŠŸæƒ…å†µçš„åæ€
            return {
                "success": True,
                "insights": [f"æˆåŠŸç­–ç•¥: ä½¿ç”¨è¡¨'{reasoning_result.get('selected_table')}'å’Œç­–ç•¥'{reasoning_result.get('query_strategy')}'"],
                "next_action": "completed"
            }
        
        # å¤±è´¥æƒ…å†µçš„æ·±åº¦åæ€
        errors = observation_result.get("errors", [])
        validation_results = observation_result.get("validation_results", [])
        
        reflection_prompt = f"""
ä½œä¸ºæ•°æ®åº“ä¸“å®¶ï¼Œè¯·åˆ†æç¬¬{iteration + 1}è½®SQLç”Ÿæˆå¤±è´¥çš„åŸå› å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚

ã€æ¨ç†ç»“æœã€‘:
{reasoning_result}

ã€ç”Ÿæˆçš„SQLã€‘:
{sql}

ã€è§‚å¯Ÿåˆ°çš„é”™è¯¯ã€‘:
{errors}

ã€éªŒè¯ç»“æœè¯¦æƒ…ã€‘:
{validation_results}

ã€å ä½ç¬¦ã€‘: {placeholder_name}

è¯·æä¾›ä½ çš„åæ€åˆ†æï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

{{
    "failure_analysis": "è¯¦ç»†çš„å¤±è´¥åŸå› åˆ†æ",
    "root_cause": "æ ¹æœ¬åŸå› ï¼ˆå¦‚è¡¨é€‰æ‹©é”™è¯¯ã€å­—æ®µæ˜ å°„é”™è¯¯ã€SQLè¯­æ³•é”™è¯¯ç­‰ï¼‰",
    "insights": [
        "ç»éªŒæ•™è®­1",
        "ç»éªŒæ•™è®­2"
    ],
    "next_iteration_strategy": "ä¸‹ä¸€è½®è¿­ä»£çš„æ”¹è¿›ç­–ç•¥",
    "alternative_approaches": [
        "å¤‡é€‰æ–¹æ¡ˆ1",
        "å¤‡é€‰æ–¹æ¡ˆ2"
    ]
}}
"""

        try:
            response = await ask_agent_for_user(
                user_id=context.user_id,
                question=reflection_prompt,
                agent_type="data_analysis",
                task_type="failure_analysis",
                complexity="high"
            )
            
            import json
            try:
                reflection_result = json.loads(response.strip())
                return reflection_result
            except json.JSONDecodeError:
                # ç®€å•è§£æå›é€€
                return {
                    "failure_analysis": f"ç¬¬{iteration + 1}è½®å¤±è´¥",
                    "root_cause": "æœªçŸ¥åŸå› ",
                    "insights": [f"é”™è¯¯ä¿¡æ¯: {'; '.join(errors)}"],
                    "next_iteration_strategy": "é‡æ–°é€‰æ‹©è¡¨å’Œå­—æ®µ"
                }
                
        except Exception as e:
            return {
                "failure_analysis": f"åæ€é˜¶æ®µå¼‚å¸¸: {str(e)}",
                "root_cause": "reflection_error",
                "insights": [],
                "next_iteration_strategy": "fallback"
            }
    
    async def _generate_sql_with_llm(
        self,
        placeholder_name: str,
        placeholder_analysis: str,
        placeholder_context: str,
        data_source_info: Dict[str, Any],
        template_context: str,
        context: ToolContext,
        attempt: int
    ) -> str:
        """ä½¿ç”¨LLMç”ŸæˆSQLï¼Œæ”¯æŒå¤šæ¬¡å°è¯•ä¼˜åŒ–"""
        
        # æ„å»ºæ•°æ®æºè¡¨ç»“æ„ä¿¡æ¯
        tables_info = self._build_tables_info(data_source_info)
        
        # æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´æç¤ºè¯
        attempt_guidance = ""
        if attempt > 0:
            attempt_guidance = f"""
        
        âš ï¸ è¿™æ˜¯ç¬¬ {attempt + 1} æ¬¡é‡è¯•ç”ŸæˆSQLï¼Œè¯·ä»å¤±è´¥ä¸­å­¦ä¹ å¹¶æ”¹è¿›ï¼š
        - å‰é¢çš„å°è¯•å¯èƒ½å› ä¸ºä½¿ç”¨äº†ä¸å­˜åœ¨çš„è¡¨åæˆ–å­—æ®µåè€Œå¤±è´¥
        - è¯·é‡æ–°ä»”ç»†é˜…è¯»"å¯ç”¨çš„è¡¨åˆ—è¡¨"å’Œ"å®Œæ•´å­—æ®µåˆ—è¡¨"
        - ä¸¥æ ¼æŒ‰ç…§åˆ—è¡¨ä¸­çš„ç¡®åˆ‡æ‹¼å†™ä½¿ç”¨è¡¨åå’Œå­—æ®µå
        - ä¸è¦è¿›è¡Œä»»ä½•ç¿»è¯‘ã€ç®€åŒ–æˆ–æ¨æµ‹ï¼Œç›´æ¥ä½¿ç”¨åˆ—è¡¨ä¸­çš„åŸå§‹åç§°
        - å¦‚æœä¸ç¡®å®šæŸä¸ªå­—æ®µæ˜¯å¦å­˜åœ¨ï¼Œè¯·ä¼˜å…ˆé€‰æ‹©æ˜ç¡®åˆ—å‡ºçš„å­—æ®µ"""

        # æ„å»ºç”ŸæˆSQLçš„æç¤º
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹å ä½ç¬¦ç”ŸæˆSQLæŸ¥è¯¢ï¼š
        
        å ä½ç¬¦åç§°: {placeholder_name}
        å ä½ç¬¦åˆ†æ: {placeholder_analysis}
        å ä½ç¬¦ä¸Šä¸‹æ–‡: {placeholder_context}
        
        æ•°æ®æºä¿¡æ¯: {data_source_info.get('type', 'æœªçŸ¥')} - {data_source_info.get('database', 'æœªçŸ¥')}
        
        {tables_info}
        {attempt_guidance}
        
        æ¨¡æ¿ä¸Šä¸‹æ–‡:
        {template_context[:300]}...
        
        é‡è¦çº¦æŸï¼š
        1. âš ï¸ ä¸¥æ ¼é™åˆ¶ï¼šåªèƒ½ä½¿ç”¨ä¸Šè¿°"å¯ç”¨çš„è¡¨åˆ—è¡¨"ä¸­çš„è¡¨åï¼Œç»å¯¹ä¸è¦åˆ›é€ ä¸å­˜åœ¨çš„è¡¨å
        2. âš ï¸ è¡¨åè¦æ±‚ï¼šå¿…é¡»ä½¿ç”¨ç¡®åˆ‡çš„è¡¨åï¼ˆä¸¥æ ¼æŒ‰ç…§åˆ—è¡¨ä¸­çš„æ‹¼å†™ï¼‰
        3. âš ï¸ å­—æ®µåè¦æ±‚ï¼šå¿…é¡»ä½¿ç”¨ç¡®åˆ‡çš„å­—æ®µåï¼ˆä¸¥æ ¼æŒ‰ç…§"å®Œæ•´å­—æ®µåˆ—è¡¨"ä¸­çš„æ‹¼å†™ï¼‰
        4. âš ï¸ å­—æ®µé€‰æ‹©ï¼šä»”ç»†æŸ¥çœ‹"å®Œæ•´å­—æ®µåˆ—è¡¨"ä¸­çš„å­—æ®µåå’Œç±»å‹ï¼Œæ ¹æ®å­—æ®µåç§°æ¨æ–­å…¶ä¸šåŠ¡å«ä¹‰
        5. âš ï¸ è‡ªä¸»ç†è§£ï¼šåŸºäºå­—æ®µåç§°å’Œæ•°æ®ç±»å‹è‡ªä¸»åˆ¤æ–­å…¶ä¸šåŠ¡ç”¨é€”ï¼ˆå¦‚æ—¶é—´ã€çŠ¶æ€ã€ç±»å‹ã€å†…å®¹ç­‰ï¼‰
        6. âš ï¸ è¡¨ç»“æ„åˆ†æï¼šæ ¹æ®å­—æ®µç»„åˆå’Œè¡¨åæ¨æ–­è¡¨çš„ä¸šåŠ¡ç”¨é€”å’Œæ•°æ®å†…å®¹
        7. å¦‚æœæ²¡æœ‰åˆé€‚çš„è¡¨æˆ–å­—æ®µï¼Œè¯·è¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯ç¼–é€ SQL
        8. ä¼˜å…ˆä½¿ç”¨åŒ…å« timeã€date ç­‰å…³é”®è¯çš„å­—æ®µè¿›è¡Œæ—¶é—´èŒƒå›´æŸ¥è¯¢
        9. âš ï¸ éªŒè¯è¦æ±‚ï¼šç”ŸæˆSQLåï¼Œè¯·ä»”ç»†ç¡®è®¤æ‰€ä½¿ç”¨çš„è¡¨åå’Œå­—æ®µåéƒ½åœ¨æä¾›çš„åˆ—è¡¨ä¸­å®Œå…¨åŒ¹é…
        
        è¯·ç”Ÿæˆä¸€ä¸ªåˆé€‚çš„SQLæŸ¥è¯¢ï¼Œè¿”å›è¿™ä¸ªå ä½ç¬¦æ‰€éœ€çš„æ•°æ®ã€‚
        åªè¿”å›SQLè¯­å¥ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šã€‚
        
        è¦æ±‚ï¼š
        1. è¯­æ³•æ­£ç¡®ï¼Œé€‚åˆ{data_source_info.get('type', 'unknown')}æ•°æ®åº“
        2. åªä½¿ç”¨å·²åˆ—å‡ºçš„è¡¨å’Œå­—æ®µ
        3. åŒ…å«é€‚å½“çš„æ•°æ®èšåˆ
        4. è€ƒè™‘æ—¶é—´èŒƒå›´ï¼ˆå¦‚æœç›¸å…³ï¼‰
        5. å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„è¡¨ï¼Œè¿”å›: ERROR: æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è¡¨æ¥æ»¡è¶³æ­¤æŸ¥è¯¢éœ€æ±‚
        """
        
        try:
            response = await ask_agent_for_user(
                user_id=context.user_id,
                question=prompt,
                agent_type="sql_generation",
                task_type="sql_query_generation",
                complexity="medium"
            )
            
            # æ¸…ç†SQLè¯­å¥
            sql = self._clean_sql_response(response)
            return sql
            
        except Exception as e:
            raise Exception(f"LLMç”ŸæˆSQLå¤±è´¥: {str(e)}")
    
    # ReActè¾…åŠ©æ–¹æ³•
    def _build_detailed_tables_info(self, data_source_info: Dict[str, Any]) -> str:
        """æ„å»ºè¯¦ç»†çš„è¡¨ç»“æ„ä¿¡æ¯ï¼Œç”¨äºReActæ¨ç†é˜¶æ®µ"""
        if not data_source_info.get('tables'):
            return "âŒ è­¦å‘Š: æœªæ‰¾åˆ°è¡¨ç»“æ„ä¿¡æ¯"
        
        tables_info = f"""
ğŸ“Š æ•°æ®åº“ç±»å‹: {data_source_info.get('type', 'æœªçŸ¥')}
ğŸ“‹ å¯ç”¨è¡¨æ€»æ•°: {len(data_source_info.get('tables', []))}

ğŸ“ è¯¦ç»†è¡¨ç»“æ„ä¿¡æ¯:
"""
        
        for i, table_detail in enumerate(data_source_info.get('table_details', []), 1):
            table_name = table_detail.get('name')
            columns_count = table_detail.get('columns_count', 0)
            estimated_rows = table_detail.get('estimated_rows', 0)
            
            # å®Œæ•´å­—æ®µä¿¡æ¯
            all_columns = table_detail.get('all_columns', [])
            
            tables_info += f"""
{i}. è¡¨å: {table_name}
   ğŸ“ˆ ç»Ÿè®¡: {columns_count}ä¸ªå­—æ®µ, çº¦{estimated_rows}è¡Œæ•°æ®
   ğŸ” å®Œæ•´å­—æ®µåˆ—è¡¨: {', '.join(all_columns[:20])}{'...' if len(all_columns) > 20 else ''}
   ğŸ’¡ æ¨èç”¨é€”: æ ¹æ®å­—æ®µåæ¨æ–­ä¸šåŠ¡ç”¨é€”
"""
        
        return tables_info
    
    def _format_learned_insights(self, learned_insights: List[str]) -> str:
        """æ ¼å¼åŒ–å­¦ä¹ åˆ°çš„ç»éªŒæ•™è®­"""
        if not learned_insights:
            return "æš‚æ— å†å²ç»éªŒ"
        
        formatted = "ğŸ’¡ é‡è¦ç»éªŒæ•™è®­:\n"
        for i, insight in enumerate(learned_insights[-5:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ª
            formatted += f"   {i}. {insight}\n"
        
        return formatted
    
    def _format_iteration_history(self, iteration_history: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–è¿­ä»£å†å²"""
        if not iteration_history:
            return "è¿™æ˜¯ç¬¬ä¸€æ¬¡å°è¯•"
        
        formatted = "ğŸ“‹ å‰æœŸå°è¯•å†å²:\n"
        for record in iteration_history[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3æ¬¡
            iteration = record.get('iteration', 0)
            success = record.get('success', False)
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
            
            reasoning = record.get('reasoning', {})
            selected_table = reasoning.get('selected_table', 'æœªçŸ¥')
            
            observation = record.get('observation', {})
            errors = observation.get('errors', [])
            
            formatted += f"   ç¬¬{iteration}è½®: {status}, é€‰æ‹©è¡¨='{selected_table}'"
            if errors:
                formatted += f", é”™è¯¯: {errors[0][:50]}..."
            formatted += "\n"
        
        return formatted
    
    def _find_closest_table(self, target_table: str, available_tables: List[str]) -> str:
        """æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è¡¨å"""
        if not available_tables:
            return ""
        
        target_lower = target_table.lower()
        
        # 1. å®Œå…¨åŒ¹é…
        for table in available_tables:
            if table.lower() == target_lower:
                return table
        
        # 2. åŒ…å«åŒ¹é…
        for table in available_tables:
            if target_lower in table.lower() or table.lower() in target_lower:
                return table
        
        # 3. ä¸šåŠ¡è¯­ä¹‰åŒ¹é…
        business_mappings = {
            'complaint': ['complain', 'feedback', 'issue'],
            'order': ['order', 'sales', 'transaction'],
            'user': ['user', 'customer', 'account'],
            'product': ['product', 'item', 'goods']
        }
        
        for business_term, synonyms in business_mappings.items():
            if business_term in target_lower:
                for table in available_tables:
                    for synonym in synonyms:
                        if synonym in table.lower():
                            return table
        
        # 4. è¿”å›ç¬¬ä¸€ä¸ªè¡¨ä½œä¸ºé»˜è®¤
        return available_tables[0] if available_tables else ""
    
    def _parse_reasoning_response_simple(self, response: str, data_source_info: Dict[str, Any]) -> Dict[str, Any]:
        """ç®€å•è§£ææ¨ç†å“åº”ï¼ˆJSONè§£æå¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
        available_tables = data_source_info.get('tables', [])
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–è¡¨å
        selected_table = ""
        for table in available_tables:
            if table.lower() in response.lower():
                selected_table = table
                break
        
        if not selected_table and available_tables:
            selected_table = available_tables[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¡¨ä½œä¸ºé»˜è®¤
        
        return {
            "reasoning_process": f"ç®€å•è§£æ: {response[:100]}...",
            "selected_table": selected_table,
            "table_business_purpose": "è‡ªåŠ¨æ¨æ–­",
            "relevant_fields": [],
            "query_strategy": "åŸºç¡€æŸ¥è¯¢",
            "confidence": 0.3,
            "fallback_parsing": True
        }
    
    def _get_default_reasoning_result(self, react_context: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–é»˜è®¤æ¨ç†ç»“æœï¼ˆæ¨ç†é˜¶æ®µå¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
        data_source_info = react_context["data_source_info"]
        placeholder_name = react_context["placeholder_name"]
        
        available_tables = data_source_info.get('tables', [])
        
        # æ ¹æ®å ä½ç¬¦åç§°æ™ºèƒ½çŒœæµ‹è¡¨
        selected_table = ""
        if "æŠ•è¯‰" in placeholder_name or "complaint" in placeholder_name.lower():
            for table in available_tables:
                if "complain" in table.lower():
                    selected_table = table
                    break
        
        if not selected_table and available_tables:
            selected_table = available_tables[0]
        
        return {
            "reasoning_process": f"é»˜è®¤æ¨ç†: åŸºäºå ä½ç¬¦'{placeholder_name}'è‡ªåŠ¨é€‰æ‹©è¡¨",
            "selected_table": selected_table,
            "table_business_purpose": "é»˜è®¤æ¨æ–­",
            "relevant_fields": [],
            "query_strategy": "COUNTç»Ÿè®¡æŸ¥è¯¢",
            "confidence": 0.2,
            "default_fallback": True
        }
    
    def _validate_sql_against_reasoning(self, sql: str, reasoning_result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿæˆçš„SQLæ˜¯å¦ç¬¦åˆæ¨ç†ç»“æœ"""
        selected_table = reasoning_result.get("selected_table", "")
        relevant_fields = reasoning_result.get("relevant_fields", [])
        
        sql_lower = sql.lower()
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„è¡¨å
        if selected_table and selected_table.lower() not in sql_lower:
            return {
                "valid": False,
                "error": f"ç”Ÿæˆçš„SQLæ²¡æœ‰ä½¿ç”¨æ¨ç†é€‰å®šçš„è¡¨'{selected_table}'"
            }
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç›¸å…³å­—æ®µï¼ˆå®½æ¾æ£€æŸ¥ï¼‰
        if relevant_fields:
            field_found = False
            for field in relevant_fields:
                if field.lower() in sql_lower:
                    field_found = True
                    break
            
            if not field_found:
                return {
                    "valid": False,
                    "error": f"ç”Ÿæˆçš„SQLæ²¡æœ‰ä½¿ç”¨æ¨ç†é€‰å®šçš„ç›¸å…³å­—æ®µ: {relevant_fields}"
                }
        
        return {"valid": True, "message": "SQLä¸æ¨ç†ç»“æœä¸€è‡´"}
    
    async def _execute_sql_test(self, sql: str, data_source_info: Dict[str, Any], placeholder_name: str) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæµ‹è¯•ï¼ˆé›†æˆç°æœ‰çš„æµ‹è¯•åŸºç¡€è®¾æ–½ï¼‰"""
        try:
            # åŸºæœ¬æ£€æŸ¥
            if not sql.strip():
                return {"success": False, "error": "SQLä¸ºç©º"}
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æºå¯¹è±¡è¿›è¡Œæµ‹è¯•
            data_source_type = data_source_info.get('type', '').lower()
            
            if data_source_type == 'doris':
                # é›†æˆç°æœ‰çš„Dorisæµ‹è¯•æ–¹æ³•
                return await self._test_sql_on_doris_react(sql, data_source_info, placeholder_name)
            else:
                # å…¶ä»–ç±»å‹çš„æ•°æ®æº
                return {
                    "success": False,
                    "error": f"æš‚ä¸æ”¯æŒ{data_source_type}ç±»å‹æ•°æ®æºçš„ReActæµ‹è¯•"
                }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            }
    
    async def _test_sql_on_doris_react(self, sql: str, data_source_info: Dict[str, Any], placeholder_name: str) -> Dict[str, Any]:
        """åœ¨Dorisä¸Šæµ‹è¯•SQLï¼ˆReActä¸“ç”¨ç‰ˆæœ¬ï¼‰"""
        import time
        
        try:
            # å¯¼å…¥ç°æœ‰çš„è¿æ¥å™¨
            from app.services.data.connectors.doris_connector import DorisConnector, DorisConfig
            from app.core.data_source_utils import DataSourcePasswordManager
            
            # æ„å»ºé…ç½®ï¼ˆä»data_source_infoä¸­æå–ï¼‰
            doris_config = DorisConfig(
                source_type='doris',
                name=data_source_info.get('name', 'ReActæµ‹è¯•'),
                description='ReAct SQLæµ‹è¯•è¿æ¥',
                fe_hosts=['192.168.61.30'],  # ä»ç°æœ‰é…ç½®æ¨æ–­
                mysql_host='192.168.61.30',
                mysql_port=9030,
                query_port=9030,
                username='root',
                password='yjg@123456',  # ä»ç°æœ‰æ—¥å¿—æ¨æ–­
                database=data_source_info.get('database', 'yjg'),
                mysql_username='root',
                mysql_password='yjg@123456',
                mysql_database=data_source_info.get('database', 'yjg'),
                http_port=8030,
                use_mysql_protocol=False  # ä½¿ç”¨HTTP API
            )
            
            connector = DorisConnector(config=doris_config)
            start_time = time.time()
            
            # æ£€æŸ¥SQLæ˜¯å¦åŒ…å«å ä½ç¬¦
            if '{{' in sql and '}}' in sql:
                return {
                    "success": False,
                    "error": "SQLåŒ…å«æœªæ›¿æ¢çš„å ä½ç¬¦",
                    "execution_time_ms": 0,
                    "row_count": 0,
                    "placeholders_detected": True
                }
            
            # ä¸ºæµ‹è¯•æ·»åŠ LIMITï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            test_sql = self._prepare_sql_for_test(sql)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            try:
                result = await connector.execute_query(test_sql)
                execution_time = (time.time() - start_time) * 1000
                
                if hasattr(result, 'to_dict'):
                    result_dict = result.to_dict()
                else:
                    result_dict = result
                
                if result_dict.get("success", True):
                    return {
                        "success": True,
                        "message": "ReAct SQLæµ‹è¯•é€šè¿‡",
                        "execution_time_ms": round(execution_time, 2),
                        "row_count": result_dict.get("row_count", 0),
                        "columns": result_dict.get("columns", []),
                        "sample_data": result_dict.get("data", [])[:5]  # åªè¿”å›å‰5è¡Œä½œä¸ºæ ·æœ¬
                    }
                else:
                    error_msg = result_dict.get("error_message", "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
                    return {
                        "success": False,
                        "error": error_msg,
                        "execution_time_ms": round(execution_time, 2),
                        "row_count": 0
                    }
                    
            finally:
                # ç¡®ä¿è¿æ¥æ¸…ç†
                if hasattr(connector, 'close'):
                    await connector.close()
                    
        except Exception as e:
            error_message = str(e)
            
            # è§£æå¸¸è§é”™è¯¯ç±»å‹
            if "Unknown table" in error_message:
                return {
                    "success": False,
                    "error": f"è¡¨ä¸å­˜åœ¨: {error_message}",
                    "error_type": "table_not_found",
                    "execution_time_ms": 0
                }
            elif "Unknown column" in error_message:
                return {
                    "success": False,
                    "error": f"å­—æ®µä¸å­˜åœ¨: {error_message}",
                    "error_type": "column_not_found", 
                    "execution_time_ms": 0
                }
            elif "syntax" in error_message.lower():
                return {
                    "success": False,
                    "error": f"SQLè¯­æ³•é”™è¯¯: {error_message}",
                    "error_type": "syntax_error",
                    "execution_time_ms": 0
                }
            else:
                return {
                    "success": False,
                    "error": f"ReActæµ‹è¯•å¤±è´¥: {error_message}",
                    "error_type": "execution_error",
                    "execution_time_ms": 0
                }
    
    def _prepare_sql_for_test(self, sql: str) -> str:
        """ä¸ºæµ‹è¯•å‡†å¤‡SQLï¼ˆæ·»åŠ LIMITç­‰ï¼‰"""
        sql = sql.strip().rstrip(';')
        sql_upper = sql.upper()
        
        # å¦‚æœæ˜¯SELECTæŸ¥è¯¢ä¸”æ²¡æœ‰LIMITï¼Œæ·»åŠ LIMIT
        if (sql_upper.startswith('SELECT') and 
            'LIMIT' not in sql_upper and 
            not sql_upper.startswith('SELECT * FROM (')):  # é¿å…å½±å“å­æŸ¥è¯¢
            
            # ç®€å•çš„SELECTæŸ¥è¯¢ç›´æ¥æ·»åŠ LIMIT
            if 'ORDER BY' in sql_upper:
                # åœ¨ORDER BYä¹‹åæ·»åŠ LIMIT
                return f"{sql} LIMIT 10"
            else:
                return f"{sql} LIMIT 10"
        
        # å¦‚æœå·²ç»æ˜¯å­æŸ¥è¯¢å½¢å¼ï¼Œç›´æ¥è¿”å›
        return sql
    
    def _generate_failure_summary(self, react_context: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤±è´¥æ€»ç»“"""
        iteration_history = react_context["iteration_history"]
        learned_insights = react_context["learned_insights"]
        
        if not iteration_history:
            return "æ— è¿­ä»£å†å²"
        
        failed_attempts = [record for record in iteration_history if not record.get('success', False)]
        
        summary = f"å…±{len(iteration_history)}è½®è¿­ä»£ï¼Œ{len(failed_attempts)}æ¬¡å¤±è´¥ã€‚"
        
        # ç»Ÿè®¡ä¸»è¦å¤±è´¥åŸå› 
        failure_reasons = {}
        for record in failed_attempts:
            errors = record.get('observation', {}).get('errors', [])
            for error in errors:
                error_type = error.split(':')[0] if ':' in error else error
                failure_reasons[error_type] = failure_reasons.get(error_type, 0) + 1
        
        if failure_reasons:
            summary += f" ä¸»è¦å¤±è´¥åŸå› : {', '.join([f'{k}({v}æ¬¡)' for k, v in failure_reasons.items()])}"
        
        if learned_insights:
            summary += f" å­¦åˆ°{len(learned_insights)}æ¡ç»éªŒæ•™è®­ã€‚"
        
        return summary
    
    def _get_iteration_specific_guidance(self, iteration: int, iteration_history: List[Dict[str, Any]]) -> str:
        """æ ¹æ®è¿­ä»£æ¬¡æ•°æä¾›ç‰¹å®šæŒ‡å¯¼"""
        if iteration == 0:
            return "è¿™æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œè¯·ä»”ç»†åˆ†æè¡¨ç»“æ„ï¼Œé€‰æ‹©æœ€åˆé€‚çš„è¡¨ã€‚"
        
        guidance = f"è¿™æ˜¯ç¬¬{iteration + 1}æ¬¡å°è¯•ï¼"
        
        if iteration_history:
            last_attempt = iteration_history[-1]
            if last_attempt.get('success', False):
                return guidance + " ä¸Šæ¬¡æˆåŠŸäº†ï¼Œç»§ç»­ä¿æŒç›¸åŒç­–ç•¥ã€‚"
            
            last_errors = last_attempt.get('observation', {}).get('errors', [])
            if last_errors:
                error_analysis = []
                for error in last_errors[:2]:  # åˆ†ææœ€è¿‘2ä¸ªé”™è¯¯
                    if "è¡¨ä¸å­˜åœ¨" in error or "Unknown table" in error:
                        error_analysis.append("âŒ ä¸Šæ¬¡ä½¿ç”¨äº†ä¸å­˜åœ¨çš„è¡¨åï¼Œè¿™æ¬¡å¿…é¡»ä»çœŸå®è¡¨åˆ—è¡¨ä¸­é€‰æ‹©ï¼")
                    elif "å­—æ®µä¸å­˜åœ¨" in error or "Unknown column" in error:
                        error_analysis.append("âŒ ä¸Šæ¬¡ä½¿ç”¨äº†ä¸å­˜åœ¨çš„å­—æ®µï¼Œè¿™æ¬¡å¿…é¡»ä»çœŸå®å­—æ®µåˆ—è¡¨ä¸­é€‰æ‹©ï¼")
                    elif "è¯­æ³•é”™è¯¯" in error or "syntax" in error.lower():
                        error_analysis.append("âŒ ä¸Šæ¬¡SQLè¯­æ³•æœ‰è¯¯ï¼Œè¿™æ¬¡æ³¨æ„SQLæ ¼å¼ï¼")
                
                if error_analysis:
                    guidance += "\nğŸ”¥ã€ä¸Šæ¬¡å¤±è´¥æ•™è®­ã€‘:\n" + "\n".join(error_analysis)
                    guidance += "\nğŸ¯ è¿™æ¬¡å¿…é¡»é¿å…ç›¸åŒé”™è¯¯ï¼Œä¸¥æ ¼æŒ‰ç…§çœŸå®è¡¨ç»“æ„æ¥ï¼"
        
        return guidance
    
    def _validate_and_correct_fields(
        self, 
        proposed_fields: List[str], 
        selected_table: str, 
        data_source_info: Dict[str, Any]
    ) -> List[str]:
        """éªŒè¯å’Œçº æ­£å­—æ®µå"""
        if not proposed_fields or not selected_table:
            return []
        
        # æŸ¥æ‰¾é€‰å®šè¡¨çš„å­—æ®µä¿¡æ¯
        table_details = data_source_info.get('table_details', [])
        selected_table_fields = []
        
        for table_detail in table_details:
            if table_detail.get('name') == selected_table:
                all_columns = table_detail.get('all_columns', [])
                # æå–å­—æ®µåï¼ˆå»æ‰ç±»å‹ä¿¡æ¯ï¼‰
                for col_info in all_columns:
                    field_name = col_info.split('(')[0].strip()
                    selected_table_fields.append(field_name)
                break
        
        if not selected_table_fields:
            self.logger.warning(f"æ‰¾ä¸åˆ°è¡¨ {selected_table} çš„å­—æ®µä¿¡æ¯")
            return proposed_fields
        
        # éªŒè¯å’Œçº æ­£å­—æ®µ
        corrected_fields = []
        field_mappings = {
            'created_at': ['create_time', 'created_time', 'complain_time'],
            'complaint_type': ['complain_type', 'type'],
            'complaint_status': ['c_statue', 'status', 'c_status'],
            'complaint_content': ['complain_content', 'content'],
            'id': ['id', 'main_complain_number', 's_complain_number']
        }
        
        for field in proposed_fields:
            if field in selected_table_fields:
                corrected_fields.append(field)
            else:
                # å°è¯•æ˜ å°„
                corrected = False
                for proposed, alternatives in field_mappings.items():
                    if field.lower() == proposed:
                        for alt in alternatives:
                            if alt in selected_table_fields:
                                corrected_fields.append(alt)
                                corrected = True
                                break
                        if corrected:
                            break
                
                if not corrected:
                    # ä½¿ç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦åŒ¹é…
                    closest = self._find_closest_field(field, selected_table_fields)
                    if closest:
                        corrected_fields.append(closest)
                        self.logger.warning(f"å­—æ®µæ˜ å°„: {field} -> {closest}")
        
        # ç¡®ä¿è‡³å°‘æœ‰åŸºæœ¬å­—æ®µ
        if not corrected_fields and selected_table_fields:
            # æ·»åŠ ä¸€äº›åŸºæœ¬å­—æ®µ
            basic_fields = ['id', 'create_time', 'complain_time', 'dt']
            for basic_field in basic_fields:
                if basic_field in selected_table_fields:
                    corrected_fields.append(basic_field)
                    break
        
        return corrected_fields or selected_table_fields[:3]  # è‡³å°‘è¿”å›å‰3ä¸ªå­—æ®µ
    
    def _build_tables_info(self, data_source_info: Dict[str, Any]) -> str:
        """æ„å»ºè¡¨ç»“æ„ä¿¡æ¯å­—ç¬¦ä¸² - è®©AIè‡ªä¸»è¯†åˆ«è¡¨çš„ä¸šåŠ¡å«ä¹‰"""
        if not data_source_info.get('tables'):
            return "è­¦å‘Š: æœªæ‰¾åˆ°è¡¨ç»“æ„ä¿¡æ¯ï¼Œæ— æ³•ç”ŸæˆSQL"
        
        tables_info = f"""
å¯ç”¨çš„è¡¨åˆ—è¡¨:
{', '.join(data_source_info.get('tables', []))}

è¯¦ç»†è¡¨ç»“æ„:"""
        
        for table_detail in data_source_info.get('table_details', []):
            table_name = table_detail.get('name')
            
            # ä¼˜å…ˆæ˜¾ç¤ºå®Œæ•´åˆ—ä¿¡æ¯ï¼Œè®©AIè‡ªä¸»ç†è§£è¡¨çš„ä¸šåŠ¡å«ä¹‰
            all_columns = table_detail.get('all_columns', [])
            key_columns = table_detail.get('key_columns', [])
            
            if all_columns and len(all_columns) > 0:
                columns_info = f"""
  å®Œæ•´å­—æ®µåˆ—è¡¨: {', '.join(all_columns)}"""
            elif key_columns and len(key_columns) > 0:
                columns_info = f"""
  ä¸»è¦å­—æ®µ: {', '.join(key_columns)}"""
            else:
                columns_info = """
  å­—æ®µä¿¡æ¯: æš‚æ— è¯¦ç»†å­—æ®µä¿¡æ¯"""
            
            # æ·»åŠ ä¸šåŠ¡åˆ†ç±»ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            business_category = table_detail.get('business_category', '')
            category_info = f", ä¸šåŠ¡åˆ†ç±»: {business_category}" if business_category and business_category != "æœªåˆ†ç±»" else ""
            
            tables_info += f"""
- {table_name}: åˆ—æ•°={table_detail.get('columns_count', 0)}, ä¼°è®¡è¡Œæ•°={table_detail.get('estimated_rows', 0)}{category_info}{columns_info}"""
        
        return tables_info
    
    def _clean_sql_response(self, response: str) -> str:
        """æ¸…ç†LLMè¿”å›çš„SQLè¯­å¥"""
        sql = response.strip()
        
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        if sql.startswith("```sql"):
            sql = sql[6:]
        if sql.startswith("```"):
            sql = sql[3:]
        if sql.endswith("```"):
            sql = sql[:-3]
            
        sql = sql.strip()
        
        # åŸºæœ¬éªŒè¯
        if not sql:
            raise ValueError("ç”Ÿæˆçš„SQLä¸ºç©º")
        
        # æ£€æŸ¥æ˜¯å¦è¿”å›äº†é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯SQL
        if sql.upper().startswith("ERROR:"):
            raise ValueError(sql)
        
        sql_lower = sql.lower()
        if not any(keyword in sql_lower for keyword in ["select", "with", "show"]):
            raise ValueError("ç”Ÿæˆçš„SQLä¸åŒ…å«æœ‰æ•ˆçš„æŸ¥è¯¢è¯­å¥")
        
        return sql
    
    def _validate_generated_sql(self, sql: str, data_source_info: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿæˆçš„SQLæ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„è¡¨åå’Œå­—æ®µå"""
        try:
            available_tables = data_source_info.get('tables', [])
            if not available_tables:
                return {"valid": True, "message": "æ— å¯ç”¨è¡¨åˆ—è¡¨ï¼Œè·³è¿‡éªŒè¯"}
            
            import re
            sql_lower = sql.lower()
            
            # 1. éªŒè¯è¡¨å
            from_pattern = r'\bfrom\s+(?:[a-zA-Z_\u4e00-\u9fff][\w\u4e00-\u9fff]*\.)?([a-zA-Z_\u4e00-\u9fff][\w\u4e00-\u9fff]*)'
            join_pattern = r'\bjoin\s+(?:[a-zA-Z_\u4e00-\u9fff][\w\u4e00-\u9fff]*\.)?([a-zA-Z_\u4e00-\u9fff][\w\u4e00-\u9fff]*)'
            
            used_tables = []
            used_tables.extend(re.findall(from_pattern, sql_lower, re.UNICODE))
            used_tables.extend(re.findall(join_pattern, sql_lower, re.UNICODE))
            
            available_tables_lower = [t.lower() for t in available_tables]
            invalid_tables = [table for table in used_tables if table not in available_tables_lower]
            
            if invalid_tables:
                return {
                    "valid": False,
                    "error": f"SQLä½¿ç”¨äº†ä¸å­˜åœ¨çš„è¡¨: {', '.join(invalid_tables)}ã€‚å¯ç”¨çš„è¡¨: {', '.join(available_tables)}",
                    "used_tables": used_tables,
                    "invalid_tables": invalid_tables
                }
            
            # 2. æ™ºèƒ½éªŒè¯å­—æ®µåï¼ˆé€‚ç”¨äºæ‰€æœ‰ä½¿ç”¨çš„è¡¨ï¼‰
            table_details = data_source_info.get('table_details', [])
            field_validation_errors = []
            
            for table_detail in table_details:
                table_name = table_detail.get('name', '').lower()
                if table_name in used_tables:
                    # è·å–è¯¥è¡¨çš„æ‰€æœ‰å¯ç”¨å­—æ®µ
                    available_fields = []
                    for col_info in table_detail.get('all_columns', []):
                        # ä»"column_name(type) [hint]"æ ¼å¼ä¸­æå–å­—æ®µå
                        field_name = col_info.split('(')[0].strip()
                        available_fields.append(field_name.lower())
                    
                    if not available_fields:  # å¦‚æœæ²¡æœ‰è¯¦ç»†å­—æ®µä¿¡æ¯ï¼Œè·³è¿‡éªŒè¯
                        continue
                    
                    # æå–SQLä¸­ä½¿ç”¨çš„å­—æ®µå
                    sql_fields = re.findall(r'\b([a-zA-Z_]\w*)\s*(?:[,\s]|$)', sql.replace('(', ' ').replace(')', ' '))
                    sql_keywords = {'select', 'from', 'where', 'group', 'by', 'order', 'count', 'sum', 'avg', 'max', 'min', 'case', 'when', 'then', 'end', 'as', 'and', 'or', 'not', 'null', 'timestampdiff', 'second', 'limit', 'having', 'distinct', 'inner', 'left', 'right', 'outer', 'join', 'on', 'union', 'all', 'exists', 'in', 'like', 'between', 'is'}
                    
                    used_fields = [f.lower() for f in sql_fields if f.lower() not in sql_keywords and not f.isdigit()]
                    
                    # æ™ºèƒ½æ£€æŸ¥å­—æ®µï¼ˆé€šè¿‡å­—ç¬¦ä¸²ç›¸ä¼¼åº¦æ£€æµ‹å¯èƒ½çš„é”™è¯¯ï¼‰
                    invalid_fields = []
                    for field in used_fields:
                        if field not in available_fields and len(field) > 2:  # åªæ£€æŸ¥æœ‰æ„ä¹‰çš„å­—æ®µå
                            # ä½¿ç”¨ç¼–è¾‘è·ç¦»æ£€æµ‹ç›¸ä¼¼å­—æ®µï¼Œæä¾›æ™ºèƒ½å»ºè®®
                            closest_field = self._find_closest_field(field, available_fields)
                            if closest_field:
                                invalid_fields.append(f"{field} (å»ºè®®ä½¿ç”¨: {closest_field})")
                            else:
                                invalid_fields.append(field)
                    
                    if invalid_fields:
                        available_sample = available_fields[:15]  # æ˜¾ç¤ºéƒ¨åˆ†å­—æ®µä½œä¸ºå‚è€ƒ
                        field_validation_errors.append(f"è¡¨ {table_name} ä¸­çš„å­—æ®µé”™è¯¯: {', '.join(invalid_fields)}ã€‚å¯ç”¨å­—æ®µç¤ºä¾‹: {', '.join(available_sample)}{'...' if len(available_fields) > 15 else ''}")
            
            if field_validation_errors:
                return {
                    "valid": False,
                    "error": f"å­—æ®µéªŒè¯å¤±è´¥: {'; '.join(field_validation_errors)}",
                    "used_tables": used_tables
                }
            
            return {
                "valid": True,
                "message": f"SQLéªŒè¯é€šè¿‡ï¼Œä½¿ç”¨çš„è¡¨: {used_tables}",
                "used_tables": used_tables
            }
                
        except Exception as e:
            return {
                "valid": False,
                "error": f"SQLéªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }
    
    def _find_closest_field(self, target_field: str, available_fields: list) -> str:
        """ä½¿ç”¨ç¼–è¾‘è·ç¦»ç®—æ³•æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å­—æ®µå"""
        if not available_fields:
            return ""
        
        def edit_distance(s1: str, s2: str) -> int:
            """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç¼–è¾‘è·ç¦»"""
            if len(s1) < len(s2):
                return edit_distance(s2, s1)
            
            if len(s2) == 0:
                return len(s1)
            
            prev_row = list(range(len(s2) + 1))
            for i, c1 in enumerate(s1):
                curr_row = [i + 1]
                for j, c2 in enumerate(s2):
                    insertions = prev_row[j + 1] + 1
                    deletions = curr_row[j] + 1
                    substitutions = prev_row[j] + (c1 != c2)
                    curr_row.append(min(insertions, deletions, substitutions))
                prev_row = curr_row
            
            return prev_row[-1]
        
        # æ‰¾åˆ°ç¼–è¾‘è·ç¦»æœ€å°çš„å­—æ®µ
        closest_field = ""
        min_distance = float('inf')
        
        for field in available_fields:
            distance = edit_distance(target_field.lower(), field.lower())
            # åªæœ‰å½“è·ç¦»è¶³å¤Ÿå°ä¸”å­—ç¬¦ä¸²é•¿åº¦ç›¸è¿‘æ—¶æ‰è®¤ä¸ºæ˜¯ç›¸ä¼¼çš„
            if distance < min_distance and distance <= max(len(target_field), len(field)) * 0.4:
                min_distance = distance
                closest_field = field
        
        # å¦‚æœç¼–è¾‘è·ç¦»å¤ªå¤§ï¼Œä¸æä¾›å»ºè®®
        return closest_field if min_distance <= 3 else ""


def create_sql_generation_tool() -> SQLGenerationTool:
    """åˆ›å»ºSQLç”Ÿæˆå·¥å…·å®ä¾‹"""
    return SQLGenerationTool()