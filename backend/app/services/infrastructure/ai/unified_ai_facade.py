"""
ç»Ÿä¸€AIé—¨é¢æœåŠ¡ - é›†ä¸­ç®¡ç†æ‰€æœ‰AIè°ƒç”¨
Unified AI Facade - Centralized AI call management

æä¾›ç»Ÿä¸€çš„AIè°ƒç”¨æ¥å£ï¼Œéšè—åº•å±‚ServiceOrchestratorçš„å¤æ‚æ€§
å„ä¸šåŠ¡å±‚é€šè¿‡è¿™ä¸ªé—¨é¢è¿›è¡ŒAIè°ƒç”¨ï¼Œå®ç°æ ‡å‡†åŒ–å’Œé›†ä¸­ç®¡ç†
"""

import logging
import uuid
from typing import Dict, Any, Optional, List, AsyncGenerator
from datetime import datetime
from enum import Enum

from .service_orchestrator import get_service_orchestrator
from .core import TaskType
from .core.prompts import prompt_manager, PromptComplexity
from .tools.sql_generator import AdvancedSQLGenerator

logger = logging.getLogger(__name__)


class AITaskCategory(Enum):
    """AIä»»åŠ¡åˆ†ç±» - ç”¨äºç»Ÿä¸€ç®¡ç†ä¸åŒä¸šåŠ¡åœºæ™¯"""
    
    # æ¨¡æ¿ç›¸å…³
    TEMPLATE_ANALYSIS = "template_analysis"
    PLACEHOLDER_ANALYSIS = "placeholder_analysis"
    TEMPLATE_PARSING = "template_parsing"
    
    # æ•°æ®ç›¸å…³  
    SCHEMA_ANALYSIS = "schema_analysis"
    DATA_ANALYSIS = "data_analysis"
    QUERY_OPTIMIZATION = "query_optimization"
    
    # SQLç›¸å…³
    SQL_GENERATION = "sql_generation"
    SQL_REPAIR = "sql_repair"
    SQL_OPTIMIZATION = "sql_optimization"
    
    # ETLç›¸å…³
    ETL_PLANNING = "etl_planning"
    ETL_EXECUTION = "etl_execution"
    DATA_TRANSFORMATION = "data_transformation"
    
    # æŠ¥å‘Šç›¸å…³
    CONTENT_GENERATION = "content_generation"
    BUSINESS_EXPLANATION = "business_explanation"
    DATA_INTERPRETATION = "data_interpretation"
    
    # å·¥ä½œæµç›¸å…³
    WORKFLOW_ORCHESTRATION = "workflow_orchestration"
    STEP_EXECUTION = "step_execution"
    TASK_COORDINATION = "task_coordination"


class UnifiedAIFacade:
    """
    ç»Ÿä¸€AIé—¨é¢æœåŠ¡
    
    èŒè´£ï¼š
    1. æä¾›ç»Ÿä¸€çš„AIè°ƒç”¨æ¥å£
    2. éšè—ServiceOrchestratorçš„å¤æ‚æ€§  
    3. æ ‡å‡†åŒ–è¾“å…¥è¾“å‡ºæ ¼å¼
    4. é›†ä¸­ç®¡ç†AIä»»åŠ¡ç±»å‹
    5. æä¾›ä¸šåŠ¡å‹å¥½çš„API
    """
    
    def __init__(self):
        self.orchestrator = get_service_orchestrator()
        self.prompt_manager = prompt_manager
        self.enhanced_sql_tool = AdvancedSQLGenerator()
        logger.info("ç»Ÿä¸€AIé—¨é¢æœåŠ¡åˆå§‹åŒ–å®Œæˆ - å·²é›†æˆä¼ä¸šçº§æç¤ºè¯ç³»ç»Ÿ")
    
    # === æ¨¡æ¿ç›¸å…³AIæœåŠ¡ ===
    
    async def analyze_template(
        self,
        user_id: str,
        template_id: str,
        template_content: str,
        data_source_info: Optional[Dict[str, Any]] = None,
        streaming: bool = False
    ) -> Dict[str, Any]:
        """æ¨¡æ¿æ™ºèƒ½åˆ†æ"""
        
        if streaming:
            # æµå¼å¤„ç† - è¿”å›AsyncGenerator
            return self.orchestrator.analyze_template_streaming(
                user_id=user_id,
                template_id=template_id,
                template_content=template_content,
                data_source_info=data_source_info
            )
        else:
            # ç®€å•è°ƒç”¨
            return await self.orchestrator.analyze_template_simple(
                user_id=user_id,
                template_id=template_id,
                template_content=template_content,
                data_source_info=data_source_info
            )
    
    async def analyze_placeholder(
        self,
        user_id: str,
        placeholder_name: str,
        placeholder_text: str,
        template_id: str,
        template_context: Optional[str] = None,
        data_source_info: Optional[Dict[str, Any]] = None,
        task_params: Optional[Dict[str, Any]] = None,
        streaming: bool = False
    ) -> Dict[str, Any]:
        """å•ä¸ªå ä½ç¬¦æ™ºèƒ½åˆ†æ"""
        
        if streaming:
            return self.orchestrator.analyze_single_placeholder_streaming(
                user_id=user_id,
                placeholder_name=placeholder_name,
                placeholder_text=placeholder_text,
                template_id=template_id,
                template_context=template_context,
                data_source_info=data_source_info,
                task_params=task_params
            )
        else:
            return await self.orchestrator.analyze_single_placeholder_simple(
                user_id=user_id,
                placeholder_name=placeholder_name,
                placeholder_text=placeholder_text,
                template_id=template_id,
                template_context=template_context,
                data_source_info=data_source_info,
                task_params=task_params
            )
    
    async def batch_analyze_placeholders(
        self,
        user_id: str,
        placeholders: List[Dict[str, Any]],
        template_id: str,
        template_context: str,
        data_source_info: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡å ä½ç¬¦åˆ†æ"""
        
        results = []
        for placeholder in placeholders:
            result = await self.analyze_placeholder(
                user_id=user_id,
                placeholder_name=placeholder.get("name"),
                placeholder_text=placeholder.get("text"),
                template_id=template_id,
                template_context=template_context,
                data_source_info=data_source_info,
                task_params=placeholder.get("params", {})
            )
            results.append(result)
        
        return results
    
    # === SQLç›¸å…³AIæœåŠ¡ ===
    
    async def generate_sql(
        self,
        user_id: str,
        placeholders: List[Dict[str, Any]],
        data_source_info: Optional[Dict[str, Any]] = None,
        template_context: Optional[str] = None,
        streaming: bool = False
    ) -> Dict[str, Any]:
        """SQLæ™ºèƒ½ç”Ÿæˆ"""
        
        if streaming:
            return self.orchestrator.generate_sql_streaming(
                user_id=user_id,
                placeholders=placeholders,
                data_source_info=data_source_info,
                template_context=template_context
            )
        else:
            # åˆ›å»ºç®€å•çš„SQLç”Ÿæˆæ–¹æ³•
            result = None
            async for message_data in self.orchestrator.generate_sql_streaming(
                user_id=user_id,
                placeholders=placeholders,
                data_source_info=data_source_info,
                template_context=template_context
            ):
                if message_data["type"] == "result":
                    result = message_data["result"]
                elif message_data["type"] == "error":
                    return {
                        "status": "error",
                        "error": message_data["error"]
                    }
            
            return result or {
                "status": "completed",
                "generated_sql": {},
                "placeholders": placeholders
            }
    
    async def generate_sql_enhanced(
        self,
        user_id: str,
        placeholders: List[Dict[str, Any]],
        data_source_info: Optional[Dict[str, Any]] = None,
        template_context: Optional[str] = None,
        use_enterprise_prompts: bool = True
    ) -> Dict[str, Any]:
        """å¢å¼ºçš„SQLç”Ÿæˆ - ä½¿ç”¨ä¼ä¸šçº§æç¤ºè¯ç³»ç»Ÿ"""
        
        try:
            if use_enterprise_prompts and self.enhanced_sql_tool:
                self.logger.info(f"ğŸš€ ä½¿ç”¨ä¼ä¸šçº§æç¤ºè¯ç³»ç»Ÿç”ŸæˆSQL: {len(placeholders)} ä¸ªå ä½ç¬¦")
                
                # æ„å»ºå·¥å…·ä¸Šä¸‹æ–‡
                from ..core.context import ToolContext
                
                tool_context = ToolContext(
                    user_id=user_id,
                    task_id=str(uuid.uuid4()),
                    session_id=str(uuid.uuid4()),
                    timestamp=datetime.now()
                )
                
                # å‡†å¤‡è¾“å…¥æ•°æ®
                input_data = {
                    "placeholders": placeholders,
                    "data_source_info": data_source_info or {},
                    "template_context": template_context or ""
                }
                
                # æ‰§è¡Œå¢å¼ºçš„SQLç”Ÿæˆ
                results = []
                async for result in self.enhanced_sql_tool.execute(input_data, tool_context):
                    if result.result_type == "success":
                        return {
                            "status": "success",
                            "data": result.data,
                            "message": "ä½¿ç”¨ä¼ä¸šçº§æç¤ºè¯ç³»ç»ŸæˆåŠŸç”ŸæˆSQL",
                            "enhanced": True,
                            "tool_version": "enhanced_v2.0"
                        }
                    elif result.result_type == "error":
                        self.logger.error(f"å¢å¼ºSQLç”Ÿæˆå¤±è´¥: {result.error_message}")
                        # å›é€€åˆ°æ ‡å‡†æ–¹æ³•
                        break
                    else:
                        # è¿›åº¦ç»“æœ
                        results.append({
                            "type": "progress", 
                            "message": result.message,
                            "progress": result.progress
                        })
                
                # å¦‚æœå¢å¼ºæ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•
                self.logger.warning("å¢å¼ºSQLç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•")
            
            # ä½¿ç”¨æ ‡å‡†æ–¹æ³•ä½œä¸ºå›é€€
            return await self.generate_sql(
                user_id=user_id,
                placeholders=placeholders,
                data_source_info=data_source_info,
                template_context=template_context,
                streaming=False
            )
            
        except Exception as e:
            self.logger.error(f"SQLç”Ÿæˆå¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e),
                "fallback_attempted": True
            }
    
    async def optimize_query(
        self,
        user_id: str,
        sql_query: str,
        schema_info: Dict[str, Any],
        performance_requirements: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """æŸ¥è¯¢ä¼˜åŒ–å»ºè®®"""
        
        # ä½¿ç”¨é€šç”¨AIè°ƒç”¨
        return await self._execute_ai_task(
            category=AITaskCategory.QUERY_OPTIMIZATION,
            user_id=user_id,
            task_data={
                "sql_query": sql_query,
                "schema_info": schema_info,
                "performance_requirements": performance_requirements or {}
            }
        )
    
    # === æ•°æ®åˆ†æAIæœåŠ¡ ===
    
    async def analyze_schema(
        self,
        user_id: str,
        schema_data: Dict[str, Any],
        analysis_depth: str = "standard"
    ) -> Dict[str, Any]:
        """Schemaç»“æ„æ™ºèƒ½åˆ†æ"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.SCHEMA_ANALYSIS,
            user_id=user_id,
            task_data={
                "schema_data": schema_data,
                "analysis_depth": analysis_depth
            }
        )
    
    async def analyze_data_quality(
        self,
        user_id: str,
        data_sample: Dict[str, Any],
        quality_metrics: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """æ•°æ®è´¨é‡æ™ºèƒ½åˆ†æ"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.DATA_ANALYSIS,
            user_id=user_id,
            task_data={
                "data_sample": data_sample,
                "quality_metrics": quality_metrics or ["completeness", "accuracy", "consistency"]
            }
        )
    
    # === ETLç›¸å…³AIæœåŠ¡ ===
    
    async def plan_etl_workflow(
        self,
        user_id: str,
        source_schema: Dict[str, Any],
        target_schema: Dict[str, Any],
        business_requirements: Optional[str] = None
    ) -> Dict[str, Any]:
        """ETLå·¥ä½œæµæ™ºèƒ½è§„åˆ’"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.ETL_PLANNING,
            user_id=user_id,
            task_data={
                "source_schema": source_schema,
                "target_schema": target_schema,
                "business_requirements": business_requirements or ""
            }
        )
    
    async def execute_data_transformation(
        self,
        user_id: str,
        transformation_rules: List[Dict[str, Any]],
        source_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ•°æ®è½¬æ¢æ™ºèƒ½æ‰§è¡Œ"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.DATA_TRANSFORMATION,
            user_id=user_id,
            task_data={
                "transformation_rules": transformation_rules,
                "source_data": source_data
            }
        )
    
    # === æŠ¥å‘Šç”ŸæˆAIæœåŠ¡ ===
    
    async def generate_content(
        self,
        user_id: str,
        template_parts: List[Dict[str, Any]],
        data_context: Dict[str, Any],
        style_requirements: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """æŠ¥å‘Šå†…å®¹æ™ºèƒ½ç”Ÿæˆ"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.CONTENT_GENERATION,
            user_id=user_id,
            task_data={
                "template_parts": template_parts,
                "data_context": data_context,
                "style_requirements": style_requirements or {}
            }
        )
    
    async def explain_business_insights(
        self,
        user_id: str,
        data_analysis_results: Dict[str, Any],
        business_context: str,
        target_audience: str = "business"
    ) -> Dict[str, Any]:
        """ä¸šåŠ¡æ´å¯Ÿæ™ºèƒ½è§£é‡Š"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.BUSINESS_EXPLANATION,
            user_id=user_id,
            task_data={
                "analysis_results": data_analysis_results,
                "business_context": business_context,
                "target_audience": target_audience
            }
        )
    
    # === å·¥ä½œæµç›¸å…³AIæœåŠ¡ ===
    
    async def orchestrate_workflow_step(
        self,
        user_id: str,
        step_definition: Dict[str, Any],
        workflow_context: Dict[str, Any],
        previous_results: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """å·¥ä½œæµæ­¥éª¤æ™ºèƒ½ç¼–æ’"""
        
        return await self._execute_ai_task(
            category=AITaskCategory.WORKFLOW_ORCHESTRATION,
            user_id=user_id,
            task_data={
                "step_definition": step_definition,
                "workflow_context": workflow_context,
                "previous_results": previous_results or []
            }
        )
    
    # === æ ¸å¿ƒæ‰§è¡Œæ–¹æ³• ===
    
    async def _execute_ai_task(
        self,
        category: AITaskCategory,
        user_id: str,
        task_data: Dict[str, Any],
        task_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        é€šç”¨AIä»»åŠ¡æ‰§è¡Œæ–¹æ³•
        æ‰€æœ‰ä¸šåŠ¡å±‚éƒ½é€šè¿‡è¿™ä¸ªæ–¹æ³•è¿›è¡ŒAIè°ƒç”¨ï¼Œç¡®ä¿ç»Ÿä¸€æ€§
        """
        
        # æ ¹æ®åˆ†ç±»æ˜ å°„åˆ°å…·ä½“çš„ä»»åŠ¡ç±»å‹
        task_type_mapping = {
            AITaskCategory.TEMPLATE_ANALYSIS: TaskType.TEMPLATE_ANALYSIS,
            AITaskCategory.PLACEHOLDER_ANALYSIS: TaskType.PLACEHOLDER_ANALYSIS,
            AITaskCategory.SQL_GENERATION: TaskType.SQL_GENERATION,
            AITaskCategory.SQL_REPAIR: TaskType.SQL_REPAIR,
            AITaskCategory.DATA_TRANSFORMATION: TaskType.DATA_TRANSFORMATION,
            # å…¶ä»–ä»»åŠ¡ç±»å‹å¯ä»¥æ‰©å±•
        }
        
        task_type = task_type_mapping.get(category)
        if not task_type:
            # å¯¹äºä¸ç›´æ¥æ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼Œä½¿ç”¨é€šç”¨å¤„ç†
            return await self._execute_generic_ai_task(category, user_id, task_data)
        
        # ä½¿ç”¨ç°æœ‰çš„ServiceOrchestratoræ¶æ„
        from .core import AgentTask
        
        task = AgentTask(
            type=task_type,
            task_id=f"{category.value}_{uuid.uuid4().hex[:8]}",
            user_id=user_id,
            data=task_data,
            config=task_config,
            created_at=datetime.utcnow().isoformat()
        )
        
        # æ‰§è¡Œå¹¶æ”¶é›†ç»“æœ
        result = None
        error = None
        
        async for message in self.orchestrator.controller.execute_task(task):
            if message.type.value == "result":
                result = message.content
            elif message.type.value == "error":
                error = message.error
        
        if error:
            return {
                "status": "error",
                "category": category.value,
                "error": {
                    "type": error.error_type,
                    "message": error.error_message,
                    "recoverable": error.recoverable
                }
            }
        
        return result or {
            "status": "completed",
            "category": category.value,
            "message": "AIä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œä½†æœªè¿”å›å…·ä½“ç»“æœ"
        }
    
    async def _execute_generic_ai_task(
        self,
        category: AITaskCategory,
        user_id: str,
        task_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        é€šç”¨AIä»»åŠ¡å¤„ç† - ç”¨äºå¤„ç†å°šæœªæ˜ å°„åˆ°å…·ä½“TaskTypeçš„ä»»åŠ¡
        """
        
        # ä½¿ç”¨åº•å±‚çš„LLMæœåŠ¡
        from .llm import ask_agent_for_user
        
        # æ ¹æ®ä»»åŠ¡åˆ†ç±»æ„å»ºæç¤ºè¯
        prompt = self._build_prompt_for_category(category, task_data)
        
        try:
            # å¤„ç†UUIDæ ¼å¼é—®é¢˜ - å¦‚æœuser_idä¸æ˜¯æœ‰æ•ˆUUIDï¼Œåˆ›å»ºä¸€ä¸ªç³»ç»Ÿé»˜è®¤UUID
            import uuid
            try:
                if user_id in ["test-user", "system", "test-user-001", "test-user-002", "test-user-003", "test-user-004", "test-user-005", "test-user-006", "test-user-007"]:
                    # ä¸ºæµ‹è¯•ç”¨æˆ·åˆ›å»ºå›ºå®šUUID
                    test_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, user_id))
                else:
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆUUID
                    uuid.UUID(user_id)
                    test_uuid = user_id
            except ValueError:
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆUUIDï¼Œåˆ›å»ºä¸€ä¸ªåŸºäºå­—ç¬¦ä¸²çš„UUID
                test_uuid = str(uuid.uuid5(uuid.NAMESPACE_DNS, user_id))
                
            response = await ask_agent_for_user(
                user_id=test_uuid,
                question=prompt,
                agent_type=category.value,
                task_type=category.value,
                complexity="medium"
            )
            
            # ç¡®ä¿å“åº”ä¸ä¸ºNone
            if response is None:
                response = f"AIæœåŠ¡è¿”å›ç©ºç»“æœï¼Œä»»åŠ¡ç±»åˆ«: {category.value}"
                
            return {
                "status": "completed",
                "category": category.value,
                "result": response,
                "processed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "status": "error",
                "category": category.value,
                "error": {
                    "type": "generic_ai_error",
                    "message": str(e),
                    "recoverable": True
                }
            }
    
    def _build_prompt_for_category(
        self,
        category: AITaskCategory,
        task_data: Dict[str, Any]
    ) -> str:
        """æ ¹æ®ä»»åŠ¡åˆ†ç±»æ„å»ºæç¤ºè¯"""
        
        base_prompts = {
            AITaskCategory.SCHEMA_ANALYSIS: f"""
            è¯·åˆ†æä»¥ä¸‹æ•°æ®åº“Schemaç»“æ„ï¼š
            {task_data.get('schema_data', {})}
            
            åˆ†æè¦æ±‚ï¼š
            1. è¡¨ç»“æ„ç‰¹å¾åˆ†æ
            2. å­—æ®µç±»å‹åˆ†å¸ƒ
            3. å…³ç³»åˆ†æ
            4. ä¼˜åŒ–å»ºè®®
            """,
            
            AITaskCategory.QUERY_OPTIMIZATION: f"""
            è¯·åˆ†æå¹¶ä¼˜åŒ–ä»¥ä¸‹SQLæŸ¥è¯¢ï¼š
            SQL: {task_data.get('sql_query', '')}
            Schema: {task_data.get('schema_info', {})}
            
            ä¼˜åŒ–è¦æ±‚ï¼š
            1. ç´¢å¼•ä¼˜åŒ–å»ºè®®
            2. æŸ¥è¯¢é‡å†™å»ºè®®
            3. æ€§èƒ½æå‡é¢„ä¼°
            """,
            
            AITaskCategory.DATA_ANALYSIS: f"""
            è¯·åˆ†æä»¥ä¸‹æ•°æ®è´¨é‡ï¼š
            æ•°æ®æ ·æœ¬: {task_data.get('data_sample', {})}
            è´¨é‡æŒ‡æ ‡: {task_data.get('quality_metrics', [])}
            
            åˆ†æè¦æ±‚ï¼š
            1. æ•°æ®å®Œæ•´æ€§è¯„ä¼°
            2. æ•°æ®å‡†ç¡®æ€§æ£€æŸ¥
            3. å¼‚å¸¸å€¼æ£€æµ‹
            4. è´¨é‡æ”¹è¿›å»ºè®®
            """,
            
            AITaskCategory.ETL_PLANNING: f"""
            è¯·è§„åˆ’ETLå·¥ä½œæµï¼š
            æºSchema: {task_data.get('source_schema', {})}
            ç›®æ ‡Schema: {task_data.get('target_schema', {})}
            ä¸šåŠ¡éœ€æ±‚: {task_data.get('business_requirements', '')}
            
            è§„åˆ’è¦æ±‚ï¼š
            1. æ•°æ®æ˜ å°„è§„åˆ™
            2. è½¬æ¢æ­¥éª¤è®¾è®¡
            3. æ•°æ®éªŒè¯è§„åˆ™
            4. æ€§èƒ½ä¼˜åŒ–å»ºè®®
            """,
            
            AITaskCategory.CONTENT_GENERATION: f"""
            è¯·ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼š
            æ¨¡æ¿éƒ¨åˆ†: {task_data.get('template_parts', [])}
            æ•°æ®ä¸Šä¸‹æ–‡: {task_data.get('data_context', {})}
            é£æ ¼è¦æ±‚: {task_data.get('style_requirements', {})}
            
            ç”Ÿæˆè¦æ±‚ï¼š
            1. å†…å®¹é€»è¾‘æ¸…æ™°
            2. æ•°æ®å¼•ç”¨å‡†ç¡®
            3. è¯­è¨€è¡¨è¾¾ä¸“ä¸š
            4. ç¬¦åˆé£æ ¼è¦æ±‚
            """,
            
            AITaskCategory.BUSINESS_EXPLANATION: f"""
            è¯·è§£é‡Šä¸šåŠ¡æ´å¯Ÿï¼š
            åˆ†æç»“æœ: {task_data.get('analysis_results', {})}
            ä¸šåŠ¡èƒŒæ™¯: {task_data.get('business_context', '')}
            ç›®æ ‡å—ä¼—: {task_data.get('target_audience', 'business')}
            
            è§£é‡Šè¦æ±‚ï¼š
            1. é€šä¿—æ˜“æ‡‚çš„è¯­è¨€
            2. çªå‡ºå…³é”®æ´å¯Ÿ
            3. æä¾›è¡ŒåŠ¨å»ºè®®
            4. ç¬¦åˆå—ä¼—ç‰¹ç‚¹
            """
        }
        
        return base_prompts.get(category, f"è¯·å¤„ç†{category.value}ä»»åŠ¡ï¼š{task_data}")
    
    # === å¥åº·æ£€æŸ¥å’ŒçŠ¶æ€ç®¡ç† ===
    
    async def health_check(self) -> Dict[str, Any]:
        """AIæœåŠ¡å¥åº·æ£€æŸ¥"""
        try:
            orchestrator_health = {
                "orchestrator_status": "healthy",
                "active_tasks": len(self.orchestrator.list_active_tasks())
            }
            
            # æ£€æŸ¥LLMæœåŠ¡å¥åº·çŠ¶æ€
            from .llm import health_check
            llm_health = await health_check()
            
            return {
                "status": "healthy",
                "unified_facade": "operational",
                "orchestrator": orchestrator_health,
                "llm_services": llm_health,
                "supported_categories": [cat.value for cat in AITaskCategory],
                "checked_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "checked_at": datetime.now().isoformat()
            }
    
    def get_supported_categories(self) -> List[str]:
        """è·å–æ”¯æŒçš„AIä»»åŠ¡åˆ†ç±»"""
        return [category.value for category in AITaskCategory]


    # === ä¼ä¸šçº§æç¤ºè¯ç®¡ç† ===
    
    def get_optimized_prompt(
        self,
        category: str,
        prompt_type: str,
        context: Dict[str, Any],
        complexity: Optional[PromptComplexity] = None
    ) -> str:
        """è·å–ä¼˜åŒ–çš„æç¤ºè¯"""
        try:
            return self.prompt_manager.get_prompt(
                category=category,
                prompt_type=prompt_type,
                context=context,
                complexity=complexity
            )
        except Exception as e:
            self.logger.error(f"è·å–æç¤ºè¯å¤±è´¥: {category}.{prompt_type} - {e}")
            raise
    
    def assess_prompt_complexity(self, context: Dict[str, Any]) -> PromptComplexity:
        """è¯„ä¼°æç¤ºè¯å¤æ‚åº¦éœ€æ±‚"""
        return self.prompt_manager._assess_complexity(context)
    
    async def analyze_prompt_performance(
        self,
        category: str,
        prompt_type: str,
        usage_stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†ææç¤ºè¯æ€§èƒ½è¡¨ç°"""
        
        try:
            # åŸºäºä½¿ç”¨ç»Ÿè®¡åˆ†ææç¤ºè¯æ•ˆæœ
            performance_metrics = {
                "success_rate": usage_stats.get("success_count", 0) / max(usage_stats.get("total_count", 1), 1),
                "average_complexity": usage_stats.get("avg_complexity", "medium"),
                "error_patterns": usage_stats.get("common_errors", []),
                "optimization_suggestions": []
            }
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            if performance_metrics["success_rate"] < 0.8:
                performance_metrics["optimization_suggestions"].append(
                    "å»ºè®®å¢åŠ æç¤ºè¯å¤æ‚åº¦æˆ–æ·»åŠ æ›´å¤šçº¦æŸ"
                )
            
            if len(performance_metrics["error_patterns"]) > 3:
                performance_metrics["optimization_suggestions"].append(
                    "å»ºè®®åˆ†æé”™è¯¯æ¨¡å¼ï¼Œä¼˜åŒ–é”™è¯¯æ¢å¤æœºåˆ¶"
                )
            
            return {
                "status": "success",
                "performance_metrics": performance_metrics,
                "category": category,
                "prompt_type": prompt_type
            }
            
        except Exception as e:
            self.logger.error(f"æç¤ºè¯æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e)
            }


# === å…¨å±€å®ä¾‹ç®¡ç† ===

_unified_facade: Optional[UnifiedAIFacade] = None


def get_unified_ai_facade() -> UnifiedAIFacade:
    """è·å–ç»Ÿä¸€AIé—¨é¢æœåŠ¡å•ä¾‹"""
    global _unified_facade
    if _unified_facade is None:
        _unified_facade = UnifiedAIFacade()
    return _unified_facade


# === ä¾¿æ·å¯¼å…¥ ===

__all__ = [
    "UnifiedAIFacade",
    "AITaskCategory", 
    "get_unified_ai_facade"
]