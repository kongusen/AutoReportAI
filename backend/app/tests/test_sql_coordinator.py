"""
SQLç”Ÿæˆåè°ƒå™¨æµ‹è¯•

æµ‹è¯•SQL-Firstæ¶æ„çš„æ ¸å¿ƒç»„ä»¶
"""

import pytest
from typing import Dict, Any

from app.services.infrastructure.agents.sql_generation import (
    SQLGenerationCoordinator,
    SQLGenerationConfig,
)
from app.core.container import Container


class TestSQLGenerationCoordinator:
    """SQLç”Ÿæˆåè°ƒå™¨æµ‹è¯•å¥—ä»¶"""

    @pytest.fixture
    def container(self):
        """è·å–å®¹å™¨å®ä¾‹"""
        return Container()

    @pytest.fixture
    def coordinator(self, container):
        """åˆ›å»ºåè°ƒå™¨å®ä¾‹"""
        return SQLGenerationCoordinator(
            container=container,
            llm_client=container.llm_service,
            db_connector=container.data_source,
            config=SQLGenerationConfig(
                max_generation_attempts=3,
                max_fix_attempts=2,
                enable_dry_run_validation=True,
            ),
        )

    @pytest.fixture
    def base_context(self) -> Dict[str, Any]:
        """åŸºç¡€contextå¿«ç…§"""
        return {
            "time_window": {"start_date": "2024-01-01", "end_date": "2024-01-31"},
            "column_details": {
                "ods_sales": {
                    "sale_date": {"type": "DATE", "comment": "é”€å”®æ—¥æœŸ"},
                    "amount": {"type": "DECIMAL", "comment": "é”€å”®é‡‘é¢"},
                    "product_id": {"type": "VARCHAR", "comment": "äº§å“ID"},
                    "region": {"type": "VARCHAR", "comment": "é”€å”®åŒºåŸŸ"},
                },
                "ods_products": {
                    "product_id": {"type": "VARCHAR", "comment": "äº§å“ID"},
                    "product_name": {"type": "VARCHAR", "comment": "äº§å“åç§°"},
                    "category": {"type": "VARCHAR", "comment": "äº§å“ç±»åˆ«"},
                },
            },
            "data_source": {
                "id": "test_ds_001",
                "source_type": "doris",
                "host": "localhost",
                "port": 9030,
                "database": "test_db",
            },
            "user_id": "test_user",
        }

    @pytest.mark.asyncio
    async def test_simple_query_success(self, coordinator, base_context):
        """æµ‹è¯•ç®€å•æŸ¥è¯¢æˆåŠŸåœºæ™¯"""
        result = await coordinator.generate(
            query="ç»Ÿè®¡1æœˆä»½çš„é”€å”®æ€»é¢",
            context_snapshot=base_context,
        )

        # éªŒè¯ç»“æœ
        assert result.success, f"ç”Ÿæˆå¤±è´¥: {result.error}"
        assert result.sql, "SQLä¸åº”ä¸ºç©º"
        assert "SELECT" in result.sql.upper()
        assert "{{start_date}}" in result.sql, "åº”ä½¿ç”¨æ—¶é—´å ä½ç¬¦"
        assert "{{end_date}}" in result.sql, "åº”ä½¿ç”¨æ—¶é—´å ä½ç¬¦"
        assert "ods_sales" in result.sql, "åº”ä½¿ç”¨æ­£ç¡®çš„è¡¨å"

        # éªŒè¯å…ƒæ•°æ®
        assert result.metadata.get("attempt") <= 3
        assert result.metadata.get("confidence", 0) > 0.5

        print(f"\nâœ… æˆåŠŸç”ŸæˆSQL:\n{result.sql}")
        print(f"ğŸ“Š å…ƒæ•°æ®: {result.metadata}")

    @pytest.mark.asyncio
    async def test_complex_query_with_join(self, coordinator, base_context):
        """æµ‹è¯•å¤æ‚æŸ¥è¯¢ï¼ˆå¸¦JOINï¼‰"""
        result = await coordinator.generate(
            query="ç»Ÿè®¡æ¯ä¸ªäº§å“ç±»åˆ«çš„é”€å”®é‡‘é¢æ€»å’Œ",
            context_snapshot=base_context,
        )

        assert result.success
        assert "JOIN" in result.sql.upper() or "ods_products" in result.sql
        print(f"\nâœ… å¤æ‚æŸ¥è¯¢SQL:\n{result.sql}")

    @pytest.mark.asyncio
    async def test_missing_time_dependency(self, coordinator, base_context):
        """æµ‹è¯•ç¼ºå°‘æ—¶é—´ä¾èµ–"""
        # ç§»é™¤æ—¶é—´çª—å£
        context = {**base_context}
        del context["time_window"]

        result = await coordinator.generate(
            query="ç»Ÿè®¡é”€å”®é¢",
            context_snapshot=context,
        )

        # åº”è¯¥å¤±è´¥å¹¶æç¤ºç¼ºå°‘æ—¶é—´ä¿¡æ¯
        assert not result.success
        assert result.needs_user_input
        assert "æ—¶é—´" in result.error
        print(f"\nâš ï¸ é¢„æœŸå¤±è´¥: {result.error}")
        print(f"ğŸ’¡ å»ºè®®: {result.suggestions}")

    @pytest.mark.asyncio
    async def test_missing_schema_dependency(self, coordinator, base_context):
        """æµ‹è¯•ç¼ºå°‘Schemaä¾èµ–"""
        # ç§»é™¤schema
        context = {**base_context}
        del context["column_details"]

        result = await coordinator.generate(
            query="ç»Ÿè®¡é”€å”®é¢",
            context_snapshot=context,
        )

        # åº”è¯¥å¤±è´¥å¹¶æç¤ºç¼ºå°‘Schema
        assert not result.success
        assert "Schema" in result.error
        print(f"\nâš ï¸ é¢„æœŸå¤±è´¥: {result.error}")

    @pytest.mark.asyncio
    async def test_invalid_table_name_fix(self, coordinator, base_context):
        """æµ‹è¯•è¡¨åé”™è¯¯è‡ªåŠ¨ä¿®å¤"""
        # è¿™ä¸ªæµ‹è¯•å‡è®¾LLMå¯èƒ½ç”Ÿæˆé”™è¯¯çš„è¡¨å
        # Coordinatoråº”è¯¥èƒ½é€šè¿‡SchemaéªŒè¯å‘ç°å¹¶å°è¯•ä¿®å¤
        result = await coordinator.generate(
            query="ç»Ÿè®¡salesè¡¨çš„æ•°æ®",  # æ•…æ„ä½¿ç”¨ä¸å­˜åœ¨çš„è¡¨å
            context_snapshot=base_context,
        )

        # å³ä½¿ç”¨æˆ·è¯´äº†é”™è¯¯çš„è¡¨åï¼Œä¹Ÿåº”è¯¥ç”Ÿæˆæ­£ç¡®çš„SQL
        if result.success:
            assert "ods_sales" in result.sql
            print(f"\nâœ… è‡ªåŠ¨ä¿®æ­£è¡¨å:\n{result.sql}")
        else:
            # æˆ–è€…æ˜ç¡®æŠ¥é”™
            assert "è¡¨å" in result.error or "table" in result.error.lower()
            print(f"\nâš ï¸ æ£€æµ‹åˆ°è¡¨åé”™è¯¯: {result.error}")

    @pytest.mark.asyncio
    async def test_multiple_attempts(self, coordinator, base_context):
        """æµ‹è¯•å¤šæ¬¡å°è¯•æœºåˆ¶"""
        result = await coordinator.generate(
            query="ç”¨éå¸¸æ¨¡ç³Šçš„æ–¹å¼ç»Ÿè®¡ä¸€äº›æ•°æ®",  # æ•…æ„æ¨¡ç³Š
            context_snapshot=base_context,
        )

        # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½åº”è¯¥æœ‰å°è¯•è®°å½•
        if result.success:
            attempts = result.metadata.get("attempt", 1)
            print(f"\nâœ… {attempts}æ¬¡å°è¯•åæˆåŠŸ")
        else:
            debug_info = result.debug_info or []
            print(f"\nâŒ {len(debug_info)}æ¬¡å°è¯•åå¤±è´¥")
            print(f"å¤±è´¥åŸå› : {result.metadata.get('failure_reasons')}")
            print(f"å»ºè®®: {result.metadata.get('suggestions')}")

    @pytest.mark.asyncio
    async def test_error_summary(self, coordinator):
        """æµ‹è¯•é”™è¯¯æ‘˜è¦åŠŸèƒ½"""
        # åˆ›å»ºä¸€ä¸ªå¿…ç„¶å¤±è´¥çš„åœºæ™¯
        result = await coordinator.generate(
            query="æ— æ„ä¹‰çš„æŸ¥è¯¢",
            context_snapshot={},  # å®Œå…¨ç©ºçš„context
        )

        assert not result.success
        assert result.error
        assert result.metadata.get("suggestions")

        print(f"\nâŒ é”™è¯¯ä¿¡æ¯: {result.error}")
        print(f"ğŸ’¡ å»ºè®®:")
        for suggestion in result.metadata.get("suggestions", []):
            print(f"  - {suggestion}")


class TestSQLGenerationConfig:
    """æµ‹è¯•é…ç½®ç±»"""

    def test_default_config(self):
        """æµ‹è¯•é»˜è®¤é…ç½®"""
        config = SQLGenerationConfig()

        assert config.max_generation_attempts == 3
        assert config.max_fix_attempts == 2
        assert config.enable_dry_run_validation is True
        assert config.feature_flag_key == "enable_sql_generation_coordinator"

    def test_custom_config(self):
        """æµ‹è¯•è‡ªå®šä¹‰é…ç½®"""
        config = SQLGenerationConfig(
            max_generation_attempts=5,
            max_fix_attempts=3,
            enable_dry_run_validation=False,
        )

        assert config.max_generation_attempts == 5
        assert config.max_fix_attempts == 3
        assert config.enable_dry_run_validation is False


# ===== æ€§èƒ½æµ‹è¯• =====


@pytest.mark.benchmark
@pytest.mark.asyncio
async def test_performance_benchmark():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    import time

    container = Container()
    coordinator = SQLGenerationCoordinator(
        container=container,
        llm_client=container.llm_service,
        db_connector=container.data_source,
        config=SQLGenerationConfig(),
    )

    context = {
        "time_window": {"start_date": "2024-01-01", "end_date": "2024-01-31"},
        "column_details": {
            "ods_sales": {
                "sale_date": {"type": "DATE"},
                "amount": {"type": "DECIMAL"},
            }
        },
        "data_source": {"id": "test", "source_type": "doris"},
    }

    queries = [
        "ç»Ÿè®¡é”€å”®æ€»é¢",
        "ç»Ÿè®¡æ¯æ—¥é”€å”®è¶‹åŠ¿",
        "æŸ¥è¯¢é”€å”®é¢TOP10çš„æ—¥æœŸ",
    ]

    total_time = 0
    success_count = 0

    for query in queries:
        start = time.time()
        result = await coordinator.generate(query, context)
        elapsed = time.time() - start

        total_time += elapsed
        if result.success:
            success_count += 1

        print(f"\næŸ¥è¯¢: {query}")
        print(f"è€—æ—¶: {elapsed:.2f}s")
        print(f"ç»“æœ: {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥'}")

    avg_time = total_time / len(queries)
    success_rate = success_count / len(queries) * 100

    print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
    print(f"  å¹³å‡è€—æ—¶: {avg_time:.2f}s")
    print(f"  æˆåŠŸç‡: {success_rate:.1f}%")

    # æ€§èƒ½æ–­è¨€ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
    assert avg_time < 15, f"å¹³å‡è€—æ—¶è¿‡é•¿: {avg_time:.2f}s"
    assert success_rate >= 60, f"æˆåŠŸç‡è¿‡ä½: {success_rate:.1f}%"


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "-s", "--tb=short"])
