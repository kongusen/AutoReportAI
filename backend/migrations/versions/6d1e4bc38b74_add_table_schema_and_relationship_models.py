"""Add table schema and relationship models

Revision ID: 6d1e4bc38b74
Revises: f2de3ebc898b
Create Date: 2025-08-15 15:27:45.312241

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6d1e4bc38b74'
down_revision: Union[str, Sequence[str], None] = 'f2de3ebc898b'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('table_schemas',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('data_source_id', sa.UUID(), nullable=False),
    sa.Column('table_name', sa.String(), nullable=False),
    sa.Column('table_schema', sa.String(), nullable=True),
    sa.Column('table_catalog', sa.String(), nullable=True),
    sa.Column('columns_info', sa.JSON(), nullable=False),
    sa.Column('primary_keys', sa.JSON(), nullable=True),
    sa.Column('indexes', sa.JSON(), nullable=True),
    sa.Column('constraints', sa.JSON(), nullable=True),
    sa.Column('estimated_row_count', sa.BigInteger(), nullable=True),
    sa.Column('table_size_bytes', sa.BigInteger(), nullable=True),
    sa.Column('last_analyzed', sa.DateTime(timezone=True), nullable=True),
    sa.Column('business_category', sa.String(), nullable=True),
    sa.Column('data_freshness', sa.String(), nullable=True),
    sa.Column('update_frequency', sa.String(), nullable=True),
    sa.Column('data_quality_score', sa.Float(), nullable=True),
    sa.Column('completeness_rate', sa.Float(), nullable=True),
    sa.Column('accuracy_rate', sa.Float(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('is_analyzed', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['data_source_id'], ['data_sources.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_table_schemas_table_name'), 'table_schemas', ['table_name'], unique=False)
    op.create_table('column_schemas',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('table_schema_id', sa.UUID(), nullable=False),
    sa.Column('column_name', sa.String(), nullable=False),
    sa.Column('column_type', sa.String(), nullable=False),
    sa.Column('normalized_type', sa.Enum('INT', 'BIGINT', 'FLOAT', 'DOUBLE', 'DECIMAL', 'VARCHAR', 'CHAR', 'TEXT', 'DATE', 'DATETIME', 'TIMESTAMP', 'BOOLEAN', 'JSON', 'ARRAY', 'UNKNOWN', name='columntype'), nullable=False),
    sa.Column('column_size', sa.Integer(), nullable=True),
    sa.Column('precision', sa.Integer(), nullable=True),
    sa.Column('scale', sa.Integer(), nullable=True),
    sa.Column('is_nullable', sa.Boolean(), nullable=True),
    sa.Column('is_primary_key', sa.Boolean(), nullable=True),
    sa.Column('is_unique', sa.Boolean(), nullable=True),
    sa.Column('is_indexed', sa.Boolean(), nullable=True),
    sa.Column('default_value', sa.String(), nullable=True),
    sa.Column('business_name', sa.String(), nullable=True),
    sa.Column('business_description', sa.Text(), nullable=True),
    sa.Column('semantic_category', sa.String(), nullable=True),
    sa.Column('null_count', sa.BigInteger(), nullable=True),
    sa.Column('unique_count', sa.BigInteger(), nullable=True),
    sa.Column('distinct_count', sa.BigInteger(), nullable=True),
    sa.Column('min_value', sa.String(), nullable=True),
    sa.Column('max_value', sa.String(), nullable=True),
    sa.Column('avg_value', sa.String(), nullable=True),
    sa.Column('data_patterns', sa.JSON(), nullable=True),
    sa.Column('sample_values', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['table_schema_id'], ['table_schemas.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_column_schemas_column_name'), 'column_schemas', ['column_name'], unique=False)
    op.create_table('table_relationships',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('data_source_id', sa.UUID(), nullable=False),
    sa.Column('source_table_id', sa.UUID(), nullable=False),
    sa.Column('target_table_id', sa.UUID(), nullable=False),
    sa.Column('relationship_type', sa.String(), nullable=False),
    sa.Column('source_column', sa.String(), nullable=False),
    sa.Column('target_column', sa.String(), nullable=False),
    sa.Column('confidence_score', sa.Float(), nullable=True),
    sa.Column('business_description', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['data_source_id'], ['data_sources.id'], ),
    sa.ForeignKeyConstraint(['source_table_id'], ['table_schemas.id'], ),
    sa.ForeignKeyConstraint(['target_table_id'], ['table_schemas.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.alter_column('task_executions', 'workflow_definition',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'agent_execution_plan',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'execution_context',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'input_parameters',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'processing_config',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'execution_result',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'output_artifacts',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'agent_execution_times',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('task_executions', 'progress_details',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('task_executions', 'progress_details',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'agent_execution_times',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'output_artifacts',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'execution_result',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'processing_config',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'input_parameters',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'execution_context',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'agent_execution_plan',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('task_executions', 'workflow_definition',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_table('table_relationships')
    op.drop_index(op.f('ix_column_schemas_column_name'), table_name='column_schemas')
    op.drop_table('column_schemas')
    op.drop_index(op.f('ix_table_schemas_table_name'), table_name='table_schemas')
    op.drop_table('table_schemas')
    # ### end Alembic commands ###
