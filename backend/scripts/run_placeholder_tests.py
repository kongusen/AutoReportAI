#!/usr/bin/env python3
"""
æ™ºèƒ½å ä½ç¬¦ç³»ç»Ÿæµ‹è¯•è¿è¡Œè„šæœ¬

ç”¨äºè¿è¡Œå®Œæ•´çš„å ä½ç¬¦ç³»ç»Ÿæµ‹è¯•å¥—ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•  
- æ€§èƒ½æµ‹è¯•
- åŠŸèƒ½æµ‹è¯•
- éªŒæ”¶æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    python scripts/run_placeholder_tests.py [é€‰é¡¹]
    
é€‰é¡¹:
    --all           è¿è¡Œæ‰€æœ‰æµ‹è¯• (é»˜è®¤)
    --unit          åªè¿è¡Œå•å…ƒæµ‹è¯•
    --integration   åªè¿è¡Œé›†æˆæµ‹è¯•
    --performance   åªè¿è¡Œæ€§èƒ½æµ‹è¯•
    --functional    åªè¿è¡ŒåŠŸèƒ½æµ‹è¯•
    --acceptance    åªè¿è¡ŒéªŒæ”¶æµ‹è¯•
    --coverage      ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
    --verbose       è¯¦ç»†è¾“å‡ºæ¨¡å¼
    --parallel      å¹¶è¡Œè¿è¡Œæµ‹è¯•
    --html          ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from datetime import datetime


class PlaceholderTestRunner:
    """å ä½ç¬¦æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.test_dir = project_root / "tests" / "services" / "domain" / "placeholder"
        self.reports_dir = project_root / "test_reports"
        self.reports_dir.mkdir(exist_ok=True)
        
    def run_tests(self, test_type: str = "all", options: dict = None):
        """è¿è¡ŒæŒ‡å®šç±»å‹çš„æµ‹è¯•"""
        options = options or {}
        
        # æ„å»ºpytestå‘½ä»¤
        cmd = ["python3.11", "-m", "pytest"]
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„
        if test_type == "all":
            cmd.append(str(self.test_dir))
        elif test_type == "unit":
            cmd.extend([
                str(self.test_dir / "test_parsers.py"),
                str(self.test_dir / "test_context_analysis.py")
            ])
        elif test_type == "integration":
            cmd.append(str(self.test_dir / "test_integration.py"))
        elif test_type == "performance":
            cmd.append(str(self.test_dir / "test_performance.py"))
        elif test_type == "functional":
            cmd.append(str(self.test_dir / "test_functional.py"))
        elif test_type == "acceptance":
            cmd.append(str(self.test_dir / "test_acceptance.py"))
        else:
            raise ValueError(f"æœªçŸ¥çš„æµ‹è¯•ç±»å‹: {test_type}")
        
        # æ·»åŠ é€‰é¡¹
        if options.get("verbose"):
            cmd.extend(["-v", "-s"])
        
        if options.get("parallel"):
            cmd.extend(["-n", "auto"])
        
        # æµ‹è¯•è¦†ç›–ç‡
        if options.get("coverage"):
            cmd.extend([
                "--cov=app.services.domain.placeholder",
                "--cov-report=term-missing",
                f"--cov-report=html:{self.reports_dir}/coverage_html",
                f"--cov-report=xml:{self.reports_dir}/coverage.xml"
            ])
        
        # HTMLæŠ¥å‘Š
        if options.get("html"):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            html_report = self.reports_dir / f"test_report_{test_type}_{timestamp}.html"
            cmd.extend([f"--html={html_report}", "--self-contained-html"])
        
        # JUnit XMLæŠ¥å‘Š
        junit_report = self.reports_dir / f"junit_{test_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xml"
        cmd.extend([f"--junit-xml={junit_report}"])
        
        # æ‰§è¡Œæµ‹è¯•
        print(f"ğŸš€ å¼€å§‹è¿è¡Œ {test_type} æµ‹è¯•...")
        print(f"å‘½ä»¤: {' '.join(cmd)}")
        print("-" * 80)
        
        try:
            result = subprocess.run(cmd, cwd=self.project_root, check=False)
            return result.returncode == 0
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def run_test_suite(self, options: dict = None):
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•å¥—ä»¶"""
        options = options or {}
        
        print("ğŸ§ª æ™ºèƒ½å ä½ç¬¦ç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
        print("=" * 80)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")
        print(f"æŠ¥å‘Šç›®å½•: {self.reports_dir}")
        print("=" * 80)
        
        test_results = {}
        test_sequence = [
            ("unit", "å•å…ƒæµ‹è¯•"),
            ("integration", "é›†æˆæµ‹è¯•"),
            ("performance", "æ€§èƒ½æµ‹è¯•"),
            ("functional", "åŠŸèƒ½æµ‹è¯•"),
            ("acceptance", "éªŒæ”¶æµ‹è¯•")
        ]
        
        for test_type, test_name in test_sequence:
            print(f"\nğŸ“‹ æ­£åœ¨æ‰§è¡Œ {test_name}...")
            success = self.run_tests(test_type, options)
            test_results[test_type] = success
            
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
            
            if not success and not options.get("continue_on_failure", True):
                print("âš ï¸  æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œåç»­æµ‹è¯•")
                break
        
        # æµ‹è¯•ç»“æœæ€»ç»“
        self.print_summary(test_results)
        
        # è¿”å›æ•´ä½“æµ‹è¯•ç»“æœ
        return all(test_results.values())
    
    def print_summary(self, test_results: dict):
        """æ‰“å°æµ‹è¯•ç»“æœæ€»ç»“"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 80)
        
        total_tests = len(test_results)
        passed_tests = sum(1 for result in test_results.values() if result)
        failed_tests = total_tests - passed_tests
        
        print(f"æ€»æµ‹è¯•å¥—ä»¶æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•æ•°: {passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•æ•°: {failed_tests}")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for test_type, success in test_results.items():
            status = "âœ… PASS" if success else "âŒ FAIL"
            test_name = {
                "unit": "å•å…ƒæµ‹è¯•",
                "integration": "é›†æˆæµ‹è¯•", 
                "performance": "æ€§èƒ½æµ‹è¯•",
                "functional": "åŠŸèƒ½æµ‹è¯•",
                "acceptance": "éªŒæ”¶æµ‹è¯•"
            }.get(test_type, test_type)
            print(f"  {test_name}: {status}")
        
        if all(test_results.values()):
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ™ºèƒ½å ä½ç¬¦ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
        else:
            print(f"\nâš ï¸  æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¥—ä»¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜ã€‚")
        
        print(f"\nğŸ“ æµ‹è¯•æŠ¥å‘Šä¿å­˜åœ¨: {self.reports_dir}")
        print("=" * 80)
    
    def check_environment(self):
        """æ£€æŸ¥æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•ç¯å¢ƒ...")
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = sys.version_info
        if python_version < (3, 8):
            print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦Python 3.8+")
            return False
        print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
        
        # æ£€æŸ¥æµ‹è¯•ç›®å½•
        if not self.test_dir.exists():
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {self.test_dir}")
            return False
        print(f"âœ… æµ‹è¯•ç›®å½•: {self.test_dir}")
        
        # æ£€æŸ¥å¿…è¦çš„æµ‹è¯•æ–‡ä»¶
        required_files = [
            "test_parsers.py",
            "test_context_analysis.py",
            "test_integration.py", 
            "test_performance.py",
            "test_functional.py",
            "test_acceptance.py"
        ]
        
        missing_files = []
        for file_name in required_files:
            file_path = self.test_dir / file_name
            if not file_path.exists():
                missing_files.append(file_name)
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘æµ‹è¯•æ–‡ä»¶: {', '.join(missing_files)}")
            return False
        print(f"âœ… æ‰€æœ‰æµ‹è¯•æ–‡ä»¶å­˜åœ¨")
        
        # æ£€æŸ¥ä¾èµ–åŒ…
        try:
            import pytest
            import asyncio
            print(f"âœ… pytestç‰ˆæœ¬: {pytest.__version__}")
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
            return False
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½å ä½ç¬¦ç³»ç»Ÿæµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # æµ‹è¯•ç±»å‹å‚æ•°
    test_group = parser.add_mutually_exclusive_group()
    test_group.add_argument("--all", action="store_true", default=True,
                          help="è¿è¡Œæ‰€æœ‰æµ‹è¯• (é»˜è®¤)")
    test_group.add_argument("--unit", action="store_true",
                          help="åªè¿è¡Œå•å…ƒæµ‹è¯•")
    test_group.add_argument("--integration", action="store_true", 
                          help="åªè¿è¡Œé›†æˆæµ‹è¯•")
    test_group.add_argument("--performance", action="store_true",
                          help="åªè¿è¡Œæ€§èƒ½æµ‹è¯•")
    test_group.add_argument("--functional", action="store_true",
                          help="åªè¿è¡ŒåŠŸèƒ½æµ‹è¯•")
    test_group.add_argument("--acceptance", action="store_true",
                          help="åªè¿è¡ŒéªŒæ”¶æµ‹è¯•")
    
    # è¾“å‡ºé€‰é¡¹
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è¯¦ç»†è¾“å‡ºæ¨¡å¼")
    parser.add_argument("--coverage", action="store_true",
                       help="ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š")
    parser.add_argument("--html", action="store_true",
                       help="ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š")
    parser.add_argument("--parallel", action="store_true",
                       help="å¹¶è¡Œè¿è¡Œæµ‹è¯•")
    parser.add_argument("--continue-on-failure", action="store_true",
                       help="æµ‹è¯•å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œåç»­æµ‹è¯•")
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument("--project-root", type=Path,
                       default=Path(__file__).parent.parent,
                       help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
    
    args = parser.parse_args()
    
    # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
    project_root = args.project_root.resolve()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = PlaceholderTestRunner(project_root)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not runner.check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return 1
    
    # ç¡®å®šæµ‹è¯•ç±»å‹
    if args.unit:
        test_type = "unit"
    elif args.integration:
        test_type = "integration"
    elif args.performance:
        test_type = "performance"
    elif args.functional:
        test_type = "functional"
    elif args.acceptance:
        test_type = "acceptance"
    else:
        test_type = "all"
    
    # å‡†å¤‡é€‰é¡¹
    options = {
        "verbose": args.verbose,
        "coverage": args.coverage,
        "html": args.html,
        "parallel": args.parallel,
        "continue_on_failure": args.continue_on_failure
    }
    
    # è¿è¡Œæµ‹è¯•
    try:
        if test_type == "all":
            success = runner.run_test_suite(options)
        else:
            success = runner.run_tests(test_type, options)
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())