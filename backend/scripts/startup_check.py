#!/usr/bin/env python3
"""
AutoReportAI Backend å¯åŠ¨æ£€æŸ¥å’Œåˆå§‹åŒ–è„šæœ¬
åœ¨åç«¯å¯åŠ¨å‰æ£€æŸ¥å¹¶è‡ªåŠ¨ä¿®å¤å¸¸è§çš„é…ç½®é—®é¢˜
"""
import sys
import os
import time
import subprocess
import logging
from urllib.parse import urlparse

import psycopg2
import redis
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# æ·»åŠ appç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class StartupChecker:
    """å¯åŠ¨æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.db_url = str(settings.DATABASE_URL)
        self.redis_url = str(settings.REDIS_URL)
        self.max_retries = 30  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 2   # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰

    def wait_for_service(self, service_name: str, check_func, max_retries=None):
        """ç­‰å¾…æœåŠ¡å¯ç”¨"""
        max_retries = max_retries or self.max_retries
        
        logger.info(f"ğŸ” ç­‰å¾… {service_name} æœåŠ¡...")
        
        for attempt in range(1, max_retries + 1):
            try:
                if check_func():
                    logger.info(f"âœ… {service_name} æœåŠ¡å·²å°±ç»ª")
                    return True
            except Exception as e:
                logger.debug(f"  ç¬¬ {attempt}/{max_retries} æ¬¡æ£€æŸ¥å¤±è´¥: {e}")
            
            if attempt < max_retries:
                logger.info(f"  {service_name} æœªå°±ç»ªï¼Œ{self.retry_delay}ç§’åé‡è¯•... ({attempt}/{max_retries})")
                time.sleep(self.retry_delay)
        
        logger.error(f"âŒ {service_name} æœåŠ¡åœ¨ {max_retries} æ¬¡é‡è¯•åä»ä¸å¯ç”¨")
        return False

    def check_database(self):
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
        try:
            parsed_url = urlparse(self.db_url)
            conn = psycopg2.connect(
                host=parsed_url.hostname,
                port=parsed_url.port or 5432,
                user=parsed_url.username,
                password=parsed_url.password,
                database=parsed_url.path.lstrip('/'),
                connect_timeout=5
            )
            conn.close()
            return True
        except Exception as e:
            logger.debug(f"æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def check_redis(self):
        """æ£€æŸ¥Redisè¿æ¥"""
        try:
            parsed_url = urlparse(self.redis_url)
            r = redis.Redis(
                host=parsed_url.hostname or 'localhost',
                port=parsed_url.port or 6379,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            r.ping()
            return True
        except Exception as e:
            logger.debug(f"Redisæ£€æŸ¥å¤±è´¥: {e}")
            return False

    def check_migrations_needed(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡Œè¿ç§»"""
        try:
            engine = create_engine(self.db_url)
            with engine.connect() as conn:
                # æ£€æŸ¥alembic_versionè¡¨æ˜¯å¦å­˜åœ¨
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = 'alembic_version'
                    );
                """))
                
                has_alembic_table = result.scalar()
                
                if not has_alembic_table:
                    logger.info("ğŸ“‹ æ£€æµ‹åˆ°æ–°æ•°æ®åº“ï¼Œéœ€è¦è¿è¡Œåˆå§‹è¿ç§»")
                    return True
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åº”ç”¨çš„è¿ç§»
                result = conn.execute(text("SELECT version_num FROM alembic_version"))
                current_version = result.scalar()
                
                if not current_version:
                    logger.info("ğŸ“‹ æ•°æ®åº“ç‰ˆæœ¬ä¸ºç©ºï¼Œéœ€è¦è¿è¡Œè¿ç§»")
                    return True
                
                logger.info(f"ğŸ“‹ å½“å‰æ•°æ®åº“ç‰ˆæœ¬: {current_version}")
                
                # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨ï¼ˆåŸºæœ¬è¡¨æ£€æŸ¥ï¼‰
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = 'users'
                    );
                """))
                
                has_users_table = result.scalar()
                if not has_users_table:
                    logger.info("ğŸ“‹ æ ¸å¿ƒè¡¨ä¸å­˜åœ¨ï¼Œéœ€è¦è¿è¡Œè¿ç§»")
                    return True
                
                return False
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥è¿ç§»çŠ¶æ€æ—¶å‡ºé”™ï¼Œå°†å°è¯•è¿è¡Œè¿ç§»: {e}")
            return True

    def run_migrations(self):
        """è¿è¡Œæ•°æ®åº“è¿ç§»"""
        logger.info("ğŸ”„ è¿è¡Œæ•°æ®åº“è¿ç§»...")
        try:
            # åˆ‡æ¢åˆ°æ­£ç¡®çš„ç›®å½•
            os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            
            result = subprocess.run(
                ["alembic", "upgrade", "head"],
                capture_output=True,
                text=True,
                timeout=120  # 2åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode == 0:
                logger.info("âœ… æ•°æ®åº“è¿ç§»å®Œæˆ")
                return True
            else:
                logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ æ•°æ®åº“è¿ç§»è¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œè¿ç§»æ—¶å‡ºé”™: {e}")
            return False

    def check_default_data_needed(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–é»˜è®¤æ•°æ®"""
        try:
            engine = create_engine(self.db_url)
            with engine.connect() as conn:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç®¡ç†å‘˜ç”¨æˆ·
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT 1 FROM users 
                        WHERE username = 'admin' AND is_superuser = true
                    );
                """))
                
                has_admin = result.scalar()
                
                if not has_admin:
                    logger.info("ğŸ‘¤ æœªæ‰¾åˆ°ç®¡ç†å‘˜ç”¨æˆ·ï¼Œéœ€è¦åˆå§‹åŒ–é»˜è®¤æ•°æ®")
                    return True
                
                # æ£€æŸ¥æ˜¯å¦æœ‰AIæä¾›è€…é…ç½®
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT 1 FROM ai_providers 
                        WHERE provider_type = 'openai' AND is_active = true
                    );
                """))
                
                has_ai_provider = result.scalar()
                
                if not has_ai_provider:
                    logger.info("ğŸ¤– æœªæ‰¾åˆ°AIæä¾›è€…é…ç½®ï¼Œéœ€è¦åˆå§‹åŒ–é»˜è®¤æ•°æ®")
                    return True
                
                logger.info("âœ… é»˜è®¤æ•°æ®å·²å­˜åœ¨")
                return False
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥é»˜è®¤æ•°æ®æ—¶å‡ºé”™ï¼Œå°†å°è¯•åˆå§‹åŒ–: {e}")
            return True

    def initialize_default_data(self):
        """åˆå§‹åŒ–é»˜è®¤æ•°æ®"""
        logger.info("ğŸ”„ åˆå§‹åŒ–é»˜è®¤æ•°æ®...")
        try:
            result = subprocess.run(
                ["python", "scripts/init_db.py"],
                capture_output=True,
                text=True,
                timeout=60  # 1åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode == 0:
                logger.info("âœ… é»˜è®¤æ•°æ®åˆå§‹åŒ–å®Œæˆ")
                return True
            else:
                logger.error(f"âŒ é»˜è®¤æ•°æ®åˆå§‹åŒ–å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ é»˜è®¤æ•°æ®åˆå§‹åŒ–è¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–é»˜è®¤æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def run_full_check(self):
        """è¿è¡Œå®Œæ•´çš„å¯åŠ¨æ£€æŸ¥"""
        logger.info("ğŸš€ å¼€å§‹å¯åŠ¨æ£€æŸ¥...")
        
        # 1. ç­‰å¾…æ•°æ®åº“æœåŠ¡
        if not self.wait_for_service("æ•°æ®åº“", self.check_database):
            logger.error("âŒ æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨")
            return False
        
        # 2. ç­‰å¾…RedisæœåŠ¡
        if not self.wait_for_service("Redis", self.check_redis):
            logger.error("âŒ RedisæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨")
            return False
        
        # 3. æ£€æŸ¥å¹¶è¿è¡Œè¿ç§»
        if self.check_migrations_needed():
            if not self.run_migrations():
                logger.error("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨")
                return False
        
        # 4. æ£€æŸ¥å¹¶åˆå§‹åŒ–é»˜è®¤æ•°æ®
        if self.check_default_data_needed():
            if not self.initialize_default_data():
                logger.warning("âš ï¸ é»˜è®¤æ•°æ®åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ç»§ç»­å¯åŠ¨")
        
        logger.info("âœ… å¯åŠ¨æ£€æŸ¥å®Œæˆï¼Œç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª")
        return True

def main():
    """ä¸»å‡½æ•°"""
    checker = StartupChecker()
    
    if checker.run_full_check():
        logger.info("ğŸ‰ å¯åŠ¨æ£€æŸ¥æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ å¯åŠ¨æ£€æŸ¥å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()