#!/usr/bin/env python3
"""
æµ‹è¯• Schema å·¥å…·æ›¿æ¢çš„å®Œæ•´æµç¨‹

éªŒè¯ï¼š
1. Schema Context åˆå§‹åŒ–
2. è¡¨ç»“æ„ç¼“å­˜
3. ä¸Šä¸‹æ–‡æ£€ç´¢
4. åˆ—éªŒè¯å·¥å…·
5. åˆ—è‡ªåŠ¨ä¿®å¤å·¥å…·
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
backend_dir = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(backend_dir))

import logging
from typing import Dict, Any

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MockDataSourceService:
    """æ¨¡æ‹Ÿæ•°æ®æºæœåŠ¡"""

    def __init__(self):
        # æ¨¡æ‹Ÿè¡¨ç»“æ„æ•°æ®
        self.mock_tables = {
            "orders": {
                "columns": [
                    {"name": "order_id", "type": "bigint", "comment": "è®¢å•ID", "key": "PRI"},
                    {"name": "user_id", "type": "bigint", "comment": "ç”¨æˆ·ID", "key": ""},
                    {"name": "created_at", "type": "datetime", "comment": "åˆ›å»ºæ—¶é—´", "key": ""},
                    {"name": "status", "type": "varchar(50)", "comment": "è®¢å•çŠ¶æ€", "key": ""},
                    {"name": "total_amount", "type": "decimal(10,2)", "comment": "è®¢å•æ€»é¢", "key": ""},
                    {"name": "dt", "type": "date", "comment": "åˆ†åŒºæ—¥æœŸ", "key": ""},
                ]
            },
            "return_orders": {
                "columns": [
                    {"name": "return_id", "type": "bigint", "comment": "é€€è´§ID", "key": "PRI"},
                    {"name": "order_id", "type": "bigint", "comment": "åŸè®¢å•ID", "key": ""},
                    {"name": "return_date", "type": "datetime", "comment": "é€€è´§æ—¥æœŸ", "key": ""},
                    {"name": "return_amount", "type": "decimal(10,2)", "comment": "é€€è´§é‡‘é¢", "key": ""},
                    {"name": "reason", "type": "varchar(200)", "comment": "é€€è´§åŸå› ", "key": ""},
                    {"name": "dt", "type": "date", "comment": "åˆ†åŒºæ—¥æœŸ", "key": ""},
                ]
            },
            "order_items": {
                "columns": [
                    {"name": "item_id", "type": "bigint", "comment": "è®¢å•æ˜ç»†ID", "key": "PRI"},
                    {"name": "order_id", "type": "bigint", "comment": "è®¢å•ID", "key": ""},
                    {"name": "product_id", "type": "bigint", "comment": "å•†å“ID", "key": ""},
                    {"name": "quantity", "type": "int", "comment": "æ•°é‡", "key": ""},
                    {"name": "price", "type": "decimal(10,2)", "comment": "å•ä»·", "key": ""},
                    {"name": "dt", "type": "date", "comment": "åˆ†åŒºæ—¥æœŸ", "key": ""},
                ]
            },
            "users": {
                "columns": [
                    {"name": "user_id", "type": "bigint", "comment": "ç”¨æˆ·ID", "key": "PRI"},
                    {"name": "username", "type": "varchar(100)", "comment": "ç”¨æˆ·å", "key": ""},
                    {"name": "email", "type": "varchar(200)", "comment": "é‚®ç®±", "key": ""},
                    {"name": "created_at", "type": "datetime", "comment": "æ³¨å†Œæ—¶é—´", "key": ""},
                ]
            },
        }

    async def run_query(self, config: Dict[str, Any], sql: str, limit: int = 1000) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ‰§è¡Œ SQL æŸ¥è¯¢"""
        sql_upper = sql.upper()

        # å¤„ç† SHOW TABLES
        if "SHOW TABLES" in sql_upper:
            return {
                "success": True,
                "rows": [{"Tables_in_db": table_name} for table_name in self.mock_tables.keys()],
                "columns": ["Tables_in_db"],
            }

        # å¤„ç† SHOW FULL COLUMNS
        if "SHOW FULL COLUMNS" in sql_upper:
            # æå–è¡¨å
            for table_name in self.mock_tables.keys():
                if table_name in sql:
                    columns = self.mock_tables[table_name]["columns"]
                    rows = []
                    for col in columns:
                        rows.append({
                            "Field": col["name"],
                            "Type": col["type"],
                            "Null": "YES",
                            "Key": col["key"],
                            "Default": None,
                            "Comment": col["comment"],
                        })
                    return {
                        "success": True,
                        "rows": rows,
                        "columns": ["Field", "Type", "Null", "Key", "Default", "Comment"],
                    }

        # é»˜è®¤è¿”å›æˆåŠŸ
        return {
            "success": True,
            "rows": [],
            "columns": [],
        }


class MockContainer:
    """æ¨¡æ‹Ÿä¾èµ–æ³¨å…¥å®¹å™¨"""

    def __init__(self):
        self.data_source = MockDataSourceService()


async def test_schema_context_initialization():
    """æµ‹è¯• 1: Schema Context åˆå§‹åŒ–"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 1: Schema Context åˆå§‹åŒ–")
    logger.info("=" * 60)

    try:
        from app.services.infrastructure.agents.context_retriever import create_schema_context_retriever

        container = MockContainer()

        # åˆ›å»º Schema Context Retriever
        retriever = create_schema_context_retriever(
            data_source_id="test_ds_001",
            container=container,
            top_k=5,
            inject_as="system"
        )

        logger.info("âœ… Schema Context Retriever åˆ›å»ºæˆåŠŸ")

        # åˆå§‹åŒ–ï¼ˆåŠ è½½æ‰€æœ‰è¡¨ç»“æ„ï¼‰
        await retriever.retriever.initialize()

        # éªŒè¯ç¼“å­˜
        cache_size = len(retriever.retriever.schema_cache)
        logger.info(f"âœ… Schema ç¼“å­˜åˆå§‹åŒ–å®Œæˆï¼Œç¼“å­˜äº† {cache_size} ä¸ªè¡¨")

        # éªŒè¯æ¯ä¸ªè¡¨çš„ç¼“å­˜å†…å®¹
        for table_name, table_info in retriever.retriever.schema_cache.items():
            column_count = len(table_info["columns"])
            logger.info(f"   - {table_name}: {column_count} åˆ—")

        assert cache_size == 4, f"æœŸæœ›ç¼“å­˜ 4 ä¸ªè¡¨ï¼Œå®é™…ç¼“å­˜äº† {cache_size} ä¸ªè¡¨"
        logger.info("âœ… æµ‹è¯• 1 é€šè¿‡")

        return retriever

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 1 å¤±è´¥: {e}", exc_info=True)
        raise


async def test_context_retrieval(retriever):
    """æµ‹è¯• 2: ä¸Šä¸‹æ–‡æ£€ç´¢"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 2: ä¸Šä¸‹æ–‡æ£€ç´¢")
    logger.info("=" * 60)

    try:
        # æµ‹è¯•åœºæ™¯ 1: æŸ¥è¯¢é€€è´§ç›¸å…³çš„è¡¨
        query = "åˆ†æé€€è´§è¶‹åŠ¿ï¼Œç»Ÿè®¡æ¯å¤©çš„é€€è´§è®¢å•æ•°é‡å’Œé€€è´§é‡‘é¢"
        documents = await retriever.retriever.retrieve(query, top_k=3)

        logger.info(f"æŸ¥è¯¢: {query}")
        logger.info(f"æ£€ç´¢åˆ° {len(documents)} ä¸ªç›¸å…³è¡¨:")

        retrieved_tables = set()
        for doc in documents:
            table_name = doc.metadata.get("table_name")
            retrieved_tables.add(table_name)
            logger.info(f"   - {table_name}")
            logger.info(f"     å†…å®¹é¢„è§ˆ: {doc.content[:150]}...")

        # éªŒè¯ï¼šåº”è¯¥åŒ…å« return_orders è¡¨
        assert "return_orders" in retrieved_tables, "æœŸæœ›æ£€ç´¢åˆ° return_orders è¡¨"
        logger.info("âœ… æµ‹è¯•åœºæ™¯ 1 é€šè¿‡ï¼ˆé€€è´§åˆ†æï¼‰")

        # æµ‹è¯•åœºæ™¯ 2: æŸ¥è¯¢è®¢å•ç›¸å…³çš„è¡¨
        query = "ç»Ÿè®¡æœ€è¿‘ä¸€å‘¨çš„è®¢å•æ€»é¢å’Œè®¢å•æ•°é‡"
        documents = await retriever.retriever.retrieve(query, top_k=3)

        logger.info(f"æŸ¥è¯¢: {query}")
        logger.info(f"æ£€ç´¢åˆ° {len(documents)} ä¸ªç›¸å…³è¡¨:")

        retrieved_tables = set()
        for doc in documents:
            table_name = doc.metadata.get("table_name")
            retrieved_tables.add(table_name)
            logger.info(f"   - {table_name}")

        # éªŒè¯ï¼šåº”è¯¥åŒ…å« orders è¡¨
        assert "orders" in retrieved_tables, "æœŸæœ›æ£€ç´¢åˆ° orders è¡¨"
        logger.info("âœ… æµ‹è¯•åœºæ™¯ 2 é€šè¿‡ï¼ˆè®¢å•åˆ†æï¼‰")

        logger.info("âœ… æµ‹è¯• 2 é€šè¿‡")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 2 å¤±è´¥: {e}", exc_info=True)
        raise


async def test_column_validator():
    """æµ‹è¯• 3: åˆ—éªŒè¯å·¥å…·"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 3: åˆ—éªŒè¯å·¥å…·")
    logger.info("=" * 60)

    try:
        from app.services.infrastructure.agents.tools.validation_tools import SQLColumnValidatorTool

        container = MockContainer()
        validator = SQLColumnValidatorTool(container=container)

        # å‡†å¤‡ schema_contextï¼ˆæ¨¡æ‹Ÿå·²ç¼“å­˜çš„è¡¨ç»“æ„ï¼‰
        schema_context = {
            "return_orders": {
                "columns": ["return_id", "order_id", "return_date", "return_amount", "reason", "dt"]
            }
        }

        # æµ‹è¯•åœºæ™¯ 1: æ­£ç¡®çš„ SQLï¼ˆæ‰€æœ‰åˆ—éƒ½å­˜åœ¨ï¼‰
        sql_correct = """
        SELECT return_id, order_id, return_date, return_amount
        FROM return_orders
        WHERE dt BETWEEN {{start_date}} AND {{end_date}}
        """

        result = await validator.run(sql=sql_correct, schema_context=schema_context)
        logger.info(f"æµ‹è¯•åœºæ™¯ 1: æ­£ç¡®çš„ SQL")
        logger.info(f"   éªŒè¯ç»“æœ: {result.get('valid')}")
        logger.info(f"   æ¶ˆæ¯: {result.get('message')}")

        assert result.get("valid") is True, "æœŸæœ› SQL éªŒè¯é€šè¿‡"
        logger.info("âœ… æµ‹è¯•åœºæ™¯ 1 é€šè¿‡ï¼ˆæ­£ç¡®çš„ SQLï¼‰")

        # æµ‹è¯•åœºæ™¯ 2: é”™è¯¯çš„åˆ—å
        sql_wrong = """
        SELECT return_id, order_id, return_date, return_total_amount
        FROM return_orders
        WHERE dt BETWEEN {{start_date}} AND {{end_date}}
        """

        result = await validator.run(sql=sql_wrong, schema_context=schema_context)
        logger.info(f"æµ‹è¯•åœºæ™¯ 2: é”™è¯¯çš„åˆ—å")
        logger.info(f"   éªŒè¯ç»“æœ: {result.get('valid')}")
        logger.info(f"   æ— æ•ˆåˆ—: {result.get('invalid_columns')}")
        logger.info(f"   ä¿®å¤å»ºè®®: {result.get('suggestions')}")

        assert result.get("valid") is False, "æœŸæœ› SQL éªŒè¯å¤±è´¥"
        assert "return_total_amount" in result.get("invalid_columns", []), "æœŸæœ›æ£€æµ‹åˆ°æ— æ•ˆåˆ—"
        logger.info("âœ… æµ‹è¯•åœºæ™¯ 2 é€šè¿‡ï¼ˆé”™è¯¯çš„åˆ—åï¼‰")

        logger.info("âœ… æµ‹è¯• 3 é€šè¿‡")

        return result.get("suggestions")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 3 å¤±è´¥: {e}", exc_info=True)
        raise


async def test_column_auto_fix(suggestions):
    """æµ‹è¯• 4: åˆ—è‡ªåŠ¨ä¿®å¤å·¥å…·"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 4: åˆ—è‡ªåŠ¨ä¿®å¤å·¥å…·")
    logger.info("=" * 60)

    try:
        from app.services.infrastructure.agents.tools.validation_tools import SQLColumnAutoFixTool

        container = MockContainer()
        auto_fix = SQLColumnAutoFixTool(container=container)

        # æµ‹è¯•ï¼šä¿®å¤é”™è¯¯çš„åˆ—å
        sql_wrong = """
        SELECT return_id, order_id, return_date, return_total_amount
        FROM return_orders
        WHERE dt BETWEEN {{start_date}} AND {{end_date}}
        """

        # ä½¿ç”¨å‰é¢éªŒè¯å·¥å…·è¿”å›çš„å»ºè®®
        result = await auto_fix.run(sql=sql_wrong, suggestions=suggestions)

        logger.info(f"åŸå§‹ SQL:\n{sql_wrong}")
        logger.info(f"ä¿®å¤åçš„ SQL:\n{result.get('fixed_sql')}")
        logger.info(f"å˜æ›´åˆ—è¡¨: {result.get('changes')}")

        fixed_sql = result.get("fixed_sql")

        # éªŒè¯ï¼šä¿®å¤åçš„ SQL åº”è¯¥åŒ…å«æ­£ç¡®çš„åˆ—å
        if suggestions and "return_total_amount" in suggestions:
            correct_column = suggestions["return_total_amount"]
            assert correct_column in fixed_sql, f"æœŸæœ›ä¿®å¤åçš„ SQL åŒ…å« {correct_column}"
            assert "return_total_amount" not in fixed_sql, "æœŸæœ›ä¿®å¤åçš„ SQL ä¸åŒ…å«é”™è¯¯çš„åˆ—å"
            logger.info("âœ… åˆ—åå·²æ­£ç¡®ä¿®å¤")

        logger.info("âœ… æµ‹è¯• 4 é€šè¿‡")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 4 å¤±è´¥: {e}", exc_info=True)
        raise


async def test_tools_removed():
    """æµ‹è¯• 5: éªŒè¯æ—§å·¥å…·å·²ç§»é™¤"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 5: éªŒè¯æ—§å·¥å…·å·²ç§»é™¤")
    logger.info("=" * 60)

    try:
        from app.services.infrastructure.agents.tools import build_default_tool_factories

        # è·å–æ‰€æœ‰å·¥å…·
        factories = build_default_tool_factories()

        # æ„å»ºå·¥å…·å®ä¾‹
        container = MockContainer()
        tools = [factory(container) for factory in factories]

        # è·å–å·¥å…·åç§°åˆ—è¡¨
        tool_names = []
        for tool in tools:
            # å°è¯•ä»ä¸åŒçš„å±æ€§è·å–å·¥å…·åç§°
            name = getattr(tool, 'name', None) or getattr(tool, '__name__', None)
            if name:
                tool_names.append(name)

        logger.info(f"å½“å‰å¯ç”¨çš„å·¥å…· ({len(tool_names)} ä¸ª):")
        for name in tool_names:
            logger.info(f"   - {name}")

        # éªŒè¯ï¼šschema å·¥å…·åº”è¯¥å·²è¢«ç§»é™¤
        schema_tools = [name for name in tool_names if name and "schema." in name]
        assert len(schema_tools) == 0, f"æœŸæœ›æ²¡æœ‰ schema å·¥å…·ï¼Œä½†å‘ç°: {schema_tools}"
        logger.info("âœ… ç¡®è®¤ï¼šschema.* å·¥å…·å·²ç§»é™¤")

        # éªŒè¯ï¼šéªŒè¯å·¥å…·åº”è¯¥å·²æ·»åŠ 
        validation_tools = [name for name in tool_names if name and "sql." in name and "validate" in name.lower()]
        assert len(validation_tools) > 0, "æœŸæœ›è‡³å°‘æœ‰ä¸€ä¸ªéªŒè¯å·¥å…·"
        logger.info("âœ… ç¡®è®¤ï¼šsql.validate_* å·¥å…·å·²æ·»åŠ ")

        logger.info("âœ… æµ‹è¯• 5 é€šè¿‡")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 5 å¤±è´¥: {e}", exc_info=True)
        raise


async def test_schema_tools_deprecated():
    """æµ‹è¯• 6: éªŒè¯ schema_tools.py å·²æ ‡è®°ä¸º DEPRECATED"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 6: éªŒè¯ schema_tools.py å·²æ ‡è®°ä¸º DEPRECATED")
    logger.info("=" * 60)

    try:
        import importlib.util

        schema_tools_path = backend_dir / "app" / "services" / "infrastructure" / "agents" / "tools" / "schema_tools.py"

        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(schema_tools_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # éªŒè¯ï¼šæ–‡ä»¶å¼€å¤´åº”è¯¥åŒ…å« DEPRECATED è­¦å‘Š
        assert "DEPRECATED" in content[:500], "æœŸæœ›æ–‡ä»¶å¼€å¤´åŒ…å« DEPRECATED æ ‡è®°"
        logger.info("âœ… ç¡®è®¤ï¼šschema_tools.py å·²æ ‡è®°ä¸º DEPRECATED")

        # éªŒè¯ï¼šåº”è¯¥åŒ…å«æ›¿ä»£æ–¹æ¡ˆè¯´æ˜
        assert "context_retriever" in content.lower(), "æœŸæœ›æ–‡ä»¶åŒ…å« context_retriever æ›¿ä»£æ–¹æ¡ˆè¯´æ˜"
        logger.info("âœ… ç¡®è®¤ï¼šåŒ…å«æ›¿ä»£æ–¹æ¡ˆè¯´æ˜")

        # éªŒè¯ï¼šåº”è¯¥åŒ…å«åºŸå¼ƒæ—¥æœŸ
        assert "2025-10-24" in content, "æœŸæœ›æ–‡ä»¶åŒ…å«åºŸå¼ƒæ—¥æœŸ"
        logger.info("âœ… ç¡®è®¤ï¼šåŒ…å«åºŸå¼ƒæ—¥æœŸ")

        logger.info("âœ… æµ‹è¯• 6 é€šè¿‡")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯• 6 å¤±è´¥: {e}", exc_info=True)
        raise


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("\n")
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯• Schema å·¥å…·æ›¿æ¢")
    logger.info("\n")

    try:
        # æµ‹è¯• 1: Schema Context åˆå§‹åŒ–
        retriever = await test_schema_context_initialization()

        # æµ‹è¯• 2: ä¸Šä¸‹æ–‡æ£€ç´¢
        await test_context_retrieval(retriever)

        # æµ‹è¯• 3: åˆ—éªŒè¯å·¥å…·
        suggestions = await test_column_validator()

        # æµ‹è¯• 4: åˆ—è‡ªåŠ¨ä¿®å¤å·¥å…·
        await test_column_auto_fix(suggestions)

        # æµ‹è¯• 5: éªŒè¯æ—§å·¥å…·å·²ç§»é™¤
        await test_tools_removed()

        # æµ‹è¯• 6: éªŒè¯ schema_tools.py å·²æ ‡è®°ä¸º DEPRECATED
        await test_schema_tools_deprecated()

        logger.info("\n")
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("=" * 60)
        logger.info("\n")
        logger.info("æ›¿æ¢æ€»ç»“ï¼š")
        logger.info("  âœ… Schema Context æœºåˆ¶æ­£å¸¸å·¥ä½œ")
        logger.info("  âœ… è¡¨ç»“æ„ç¼“å­˜åŠŸèƒ½æ­£å¸¸")
        logger.info("  âœ… ä¸Šä¸‹æ–‡æ£€ç´¢å‡†ç¡®")
        logger.info("  âœ… åˆ—éªŒè¯å·¥å…·æ­£å¸¸")
        logger.info("  âœ… åˆ—è‡ªåŠ¨ä¿®å¤å·¥å…·æ­£å¸¸")
        logger.info("  âœ… æ—§å·¥å…·å·²ç§»é™¤")
        logger.info("  âœ… æ–‡æ¡£å·²æ›´æ–°")
        logger.info("\n")
        logger.info("ä¸‹ä¸€æ­¥ï¼š")
        logger.info("  1. åœ¨å¼€å‘ç¯å¢ƒè¿è¡Œé›†æˆæµ‹è¯•")
        logger.info("  2. ç›‘æ§ LLM è°ƒç”¨æ¬¡æ•°å’Œæ‰§è¡Œæ—¶é—´")
        logger.info("  3. éªŒè¯ SQL å‡†ç¡®ç‡æ˜¯å¦æå‡è‡³ 95%+")
        logger.info("  4. å‡†å¤‡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²")
        logger.info("\n")

    except Exception as e:
        logger.error("\n")
        logger.error("=" * 60)
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error("=" * 60)
        logger.error("\n")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
