"""
ä¸“é—¨æµ‹è¯•192.168.61.30æ•°æ®æºçš„AutoReportAI AgentåŠŸèƒ½
è§£å†³LLMå“åº”ä¸ºç©ºçš„é—®é¢˜ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„æ•°æ®æºè¿›è¡Œæµ‹è¯•
"""

import asyncio
import sys
import os
import logging
from datetime import datetime
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from app.core.config import settings
from app.db.session import get_db
from app.models.data_source import DataSource
from app.models.template import Template
from app.models.llm_server import LLMServer
from app.models.user import User
from app.services.infrastructure.ai.agents.autoreport_ai_agent import (
    create_autoreport_ai_agent,
    AgentRequest,
    WorkflowType
)


class DataSource192168Testing:
    """ä¸“é—¨é’ˆå¯¹192.168.61.30æ•°æ®æºçš„æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
        self.target_datasource_id = "9cb48092-1bb8-4a7f-993f-8b355d984656"  # 192.168.61.30æ•°æ®æº
        
    async def run_targeted_test(self):
        """è¿è¡Œé’ˆå¯¹192.168.61.30æ•°æ®æºçš„æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹192.168.61.30æ•°æ®æºä¸“é¡¹æµ‹è¯•")
        
        try:
            # 1. è·å–æŒ‡å®šæ•°æ®æºé…ç½®
            datasource_config = await self.get_target_datasource_config()
            
            if not datasource_config:
                logger.error("æ— æ³•è·å–192.168.61.30æ•°æ®æºé…ç½®")
                return
                
            # 2. è·å–ç”¨æˆ·å’ŒLLMé…ç½®
            user_config = await self.get_user_and_llm_config()
            
            if not user_config:
                logger.error("æ— æ³•è·å–ç”¨æˆ·å’ŒLLMé…ç½®")
                return
                
            # 3. åˆ›å»ºAgentå¹¶æµ‹è¯•
            agent = create_autoreport_ai_agent(user_config["user_id"])
            
            # 4. æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
            await self.test_placeholder_to_sql_with_target_datasource(agent, datasource_config, user_config)
            
            # 5. æµ‹è¯•å¤šä¸Šä¸‹æ–‡é›†æˆ
            await self.test_context_integration_with_target_datasource(agent, datasource_config, user_config)
            
            # 6. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_targeted_test_report()
            
        except Exception as e:
            logger.error(f"192.168.61.30æ•°æ®æºæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
        logger.info("âœ… 192.168.61.30æ•°æ®æºä¸“é¡¹æµ‹è¯•å®Œæˆ")
    
    async def get_target_datasource_config(self):
        """è·å–ç›®æ ‡æ•°æ®æºé…ç½®"""
        try:
            db = next(get_db())
            
            # æŸ¥è¯¢æŒ‡å®šçš„æ•°æ®æº
            datasource = db.query(DataSource).filter(
                DataSource.id == self.target_datasource_id
            ).first()
            
            if not datasource:
                logger.error(f"æœªæ‰¾åˆ°æ•°æ®æºID: {self.target_datasource_id}")
                db.close()
                return None
            
            config = {
                "id": str(datasource.id),
                "name": datasource.name,
                "source_type": datasource.source_type.value if hasattr(datasource.source_type, 'value') else str(datasource.source_type),
                "doris_fe_hosts": datasource.doris_fe_hosts,
                "doris_query_port": datasource.doris_query_port,
                "doris_database": datasource.doris_database or "default_db",
                "doris_username": datasource.doris_username,
                "is_active": datasource.is_active
            }
            
            db.close()
            
            logger.info(f"âœ… è·å–ç›®æ ‡æ•°æ®æºé…ç½®æˆåŠŸ:")
            logger.info(f"   æ•°æ®æºåç§°: {config['name']}")
            logger.info(f"   Doris FE Hosts: {config['doris_fe_hosts']}")
            logger.info(f"   Query Port: {config['doris_query_port']}")
            logger.info(f"   æ•°æ®åº“: {config['doris_database']}")
            
            return config
            
        except Exception as e:
            logger.error(f"è·å–ç›®æ ‡æ•°æ®æºé…ç½®å¤±è´¥: {e}")
            return None
    
    async def get_user_and_llm_config(self):
        """è·å–ç”¨æˆ·å’ŒLLMé…ç½®"""
        try:
            db = next(get_db())
            
            # è·å–ç¬¬ä¸€ä¸ªç”¨æˆ·
            user = db.query(User).first()
            if not user:
                logger.error("æœªæ‰¾åˆ°ç”¨æˆ·")
                db.close()
                return None
            
            # è·å–æ¿€æ´»çš„LLMæœåŠ¡å™¨
            llm_server = db.query(LLMServer).filter(
                LLMServer.user_id == user.id,
                LLMServer.is_active == True
            ).first()
            
            if not llm_server:
                logger.warning("æœªæ‰¾åˆ°æ¿€æ´»çš„LLMæœåŠ¡å™¨")
            
            config = {
                "user_id": str(user.id),
                "username": user.username,
                "email": user.email,
                "llm_server": {
                    "id": str(llm_server.id) if llm_server else None,
                    "name": llm_server.name if llm_server else None,
                    "base_url": llm_server.base_url if llm_server else None,
                    "provider_type": llm_server.provider_type if llm_server else None
                } if llm_server else None
            }
            
            db.close()
            
            logger.info(f"âœ… è·å–ç”¨æˆ·å’ŒLLMé…ç½®æˆåŠŸ:")
            logger.info(f"   ç”¨æˆ·: {config['username']}")
            logger.info(f"   LLMæœåŠ¡å™¨: {config['llm_server']['name'] if config['llm_server'] else 'None'}")
            
            return config
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å’ŒLLMé…ç½®å¤±è´¥: {e}")
            return None
    
    async def test_placeholder_to_sql_with_target_datasource(self, agent, datasource_config, user_config):
        """ä½¿ç”¨ç›®æ ‡æ•°æ®æºæµ‹è¯•å ä½ç¬¦â†’SQLè½¬æ¢"""
        logger.info("ğŸ”§ æµ‹è¯•å ä½ç¬¦â†’SQLè½¬æ¢ (ä½¿ç”¨192.168.61.30æ•°æ®æº)")
        
        try:
            # æ„å»ºçœŸå®çš„æ•°æ®æºä¸Šä¸‹æ–‡
            data_source_context = {
                "source_id": datasource_config["id"],
                "source_type": datasource_config["source_type"],
                "database_name": datasource_config["doris_database"],
                "available_tables": ["customer", "orders", "products", "sales"], # å‡è®¾çš„è¡¨
                "table_schemas": {
                    "customer": [
                        {"name": "customer_id", "type": "bigint", "comment": "å®¢æˆ·ID"},
                        {"name": "customer_name", "type": "varchar", "comment": "å®¢æˆ·åç§°"},
                        {"name": "created_date", "type": "date", "comment": "åˆ›å»ºæ—¥æœŸ"}
                    ],
                    "orders": [
                        {"name": "order_id", "type": "bigint", "comment": "è®¢å•ID"},
                        {"name": "customer_id", "type": "bigint", "comment": "å®¢æˆ·ID"},
                        {"name": "order_amount", "type": "decimal", "comment": "è®¢å•é‡‘é¢"},
                        {"name": "order_date", "type": "date", "comment": "ä¸‹å•æ—¥æœŸ"}
                    ]
                },
                "connection_info": {
                    "host": datasource_config["doris_fe_hosts"][0] if datasource_config["doris_fe_hosts"] else "192.168.61.30",
                    "port": datasource_config["doris_query_port"],
                    "database": datasource_config["doris_database"],
                    "username": datasource_config["doris_username"]
                }
            }
            
            # æ„å»ºä»»åŠ¡ä¸Šä¸‹æ–‡
            task_context = {
                "task_id": "doris_192_168_61_30_test",
                "task_name": "Dorisæ•°æ®æºé”€å”®åˆ†æ",
                "task_description": f"åŸºäº{datasource_config['name']}æ•°æ®æºè¿›è¡Œé”€å”®æ•°æ®åˆ†æ",
                "business_domain": "sales_analytics",
                "report_type": "dashboard",
                "priority": "high"
            }
            
            # æµ‹è¯•å ä½ç¬¦ï¼šå®¢æˆ·æ€»æ•°ç»Ÿè®¡
            request = AgentRequest(
                request_id="doris_customer_count_test",
                workflow_type=WorkflowType.PLACEHOLDER_TO_SQL,
                parameters={
                    "placeholder_name": "total_customer_count",
                    "placeholder_description": f"åŸºäº{datasource_config['name']}(192.168.61.30)çš„å®¢æˆ·æ€»æ•°ç»Ÿè®¡",
                    "placeholder_type": "metric",
                    "expected_data_type": "number",
                    "task_context": task_context,
                    "data_source_context": data_source_context
                }
            )
            
            response = await agent.execute_request(request)
            
            self.test_results["doris_placeholder_to_sql"] = {
                "success": response.status.value == "completed",
                "status": response.status.value,
                "confidence_score": response.confidence_score,
                "execution_time": response.execution_time_seconds,
                "datasource_name": datasource_config["name"],
                "datasource_host": datasource_config["doris_fe_hosts"][0] if datasource_config["doris_fe_hosts"] else "192.168.61.30",
                "has_sql_query": bool(response.result and response.result.get("sql_query")) if response.result else False,
                "sql_query": response.result.get("sql_query", "") if response.result else "",
                "validation_errors": response.result.get("validation_errors", []) if response.result else [],
                "error_message": response.error_message if hasattr(response, 'error_message') else None
            }
            
            if response.status.value == "completed":
                logger.info(f"âœ… Dorisæ•°æ®æºå ä½ç¬¦â†’SQLè½¬æ¢æˆåŠŸ")
                logger.info(f"   æ•°æ®æº: {datasource_config['name']} (192.168.61.30)")
                logger.info(f"   ä¿¡å¿ƒåº¦: {response.confidence_score:.2f}")
                if response.result and response.result.get("sql_query"):
                    logger.info(f"   ç”Ÿæˆçš„SQL: {response.result['sql_query'][:150]}...")
            else:
                logger.warning(f"âš ï¸ Dorisæ•°æ®æºå ä½ç¬¦â†’SQLè½¬æ¢éƒ¨åˆ†æˆåŠŸ")
                logger.warning(f"   çŠ¶æ€: {response.status.value}")
                if hasattr(response, 'error_message') and response.error_message:
                    logger.warning(f"   é”™è¯¯: {response.error_message}")
                
        except Exception as e:
            logger.error(f"âŒ Dorisæ•°æ®æºå ä½ç¬¦â†’SQLè½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["doris_placeholder_to_sql"] = {
                "success": False,
                "error": str(e),
                "datasource_name": datasource_config["name"]
            }
    
    async def test_context_integration_with_target_datasource(self, agent, datasource_config, user_config):
        """ä½¿ç”¨ç›®æ ‡æ•°æ®æºæµ‹è¯•ä¸Šä¸‹æ–‡é›†æˆ"""
        logger.info("ğŸ§  æµ‹è¯•å¤šä¸Šä¸‹æ–‡é›†æˆ (ä½¿ç”¨192.168.61.30æ•°æ®æº)")
        
        try:
            contexts = [
                {
                    "context_id": "doris_192_168_61_30",
                    "context_type": "data_source",
                    "priority": "critical",
                    "content": {
                        "data_source_id": datasource_config["id"],
                        "data_source_name": datasource_config["name"],
                        "doris_host": datasource_config["doris_fe_hosts"][0] if datasource_config["doris_fe_hosts"] else "192.168.61.30",
                        "doris_port": datasource_config["doris_query_port"],
                        "database_name": datasource_config["doris_database"],
                        "source_type": datasource_config["source_type"]
                    }
                },
                {
                    "context_id": "user_context",
                    "context_type": "user",
                    "priority": "high",
                    "content": {
                        "user_id": user_config["user_id"],
                        "username": user_config["username"],
                        "has_llm_server": bool(user_config["llm_server"])
                    }
                },
                {
                    "context_id": "business_context",
                    "context_type": "business",
                    "priority": "medium",
                    "content": {
                        "domain": "sales_analytics",
                        "target_datasource": "doris_192_168_61_30",
                        "analysis_type": "customer_behavior"
                    }
                }
            ]
            
            request = AgentRequest(
                request_id="doris_context_integration",
                workflow_type=WorkflowType.MULTI_CONTEXT_INTEGRATION,
                parameters={
                    "contexts": contexts,
                    "target_task": f"åŸºäº192.168.61.30 Dorisæ•°æ®æºçš„é”€å”®æ•°æ®åˆ†æä¸Šä¸‹æ–‡é›†æˆ",
                    "required_context_types": ["data_source", "user"],
                    "custom_weights": {
                        "data_source": 0.5,
                        "user": 0.3,
                        "business": 0.2
                    }
                }
            )
            
            response = await agent.execute_request(request)
            
            self.test_results["doris_context_integration"] = {
                "success": response.status.value == "completed",
                "status": response.status.value,
                "execution_time": response.execution_time_seconds,
                "contexts_processed": len(contexts),
                "datasource_name": datasource_config["name"],
                "integration_result": response.result if response.result else {},
                "error_message": response.error_message if hasattr(response, 'error_message') else None
            }
            
            if response.status.value == "completed":
                logger.info(f"âœ… Dorisæ•°æ®æºå¤šä¸Šä¸‹æ–‡é›†æˆæˆåŠŸ")
                logger.info(f"   æ•°æ®æº: {datasource_config['name']} (192.168.61.30)")
                logger.info(f"   å¤„ç†çš„ä¸Šä¸‹æ–‡æ•°: {len(contexts)}")
            else:
                logger.warning(f"âš ï¸ Dorisæ•°æ®æºå¤šä¸Šä¸‹æ–‡é›†æˆéƒ¨åˆ†æˆåŠŸ")
                logger.warning(f"   çŠ¶æ€: {response.status.value}")
                
        except Exception as e:
            logger.error(f"âŒ Dorisæ•°æ®æºå¤šä¸Šä¸‹æ–‡é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["doris_context_integration"] = {
                "success": False,
                "error": str(e),
                "datasource_name": datasource_config["name"]
            }
    
    def generate_targeted_test_report(self):
        """ç”Ÿæˆä¸“é¡¹æµ‹è¯•æŠ¥å‘Š"""
        logger.info("ğŸ“Š === 192.168.61.30æ•°æ®æºä¸“é¡¹æµ‹è¯•æŠ¥å‘Š ===")
        
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results.values() if result.get("success", False))
        
        logger.info(f"ğŸ“ˆ æ€»ä½“ç»“æœ:")
        logger.info(f"   ç›®æ ‡æ•°æ®æº: æµ‹è¯•-å…¬å¸ (192.168.61.30)")
        logger.info(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"   æˆåŠŸæµ‹è¯•æ•°: {successful_tests}")
        logger.info(f"   æˆåŠŸç‡: {successful_tests/total_tests:.2%}" if total_tests > 0 else "   æˆåŠŸç‡: 0%")
        logger.info("")
        
        logger.info(f"ğŸ” è¯¦ç»†ç»“æœ:")
        test_emojis = {
            "doris_placeholder_to_sql": "ğŸ”§",
            "doris_context_integration": "ğŸ§ "
        }
        
        for test_name, result in self.test_results.items():
            emoji = test_emojis.get(test_name, "ğŸ§ª")
            status = "âœ… PASS" if result.get("success", False) else "âŒ FAIL"
            logger.info(f"   {emoji} {test_name}: {status}")
            
            # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
            if result.get("datasource_name"):
                logger.info(f"      æ•°æ®æº: {result['datasource_name']}")
            if result.get("datasource_host"):
                logger.info(f"      ä¸»æœº: {result['datasource_host']}")
            if result.get("success", False):
                if "confidence_score" in result:
                    logger.info(f"      ä¿¡å¿ƒåº¦: {result['confidence_score']:.2f}")
                if "execution_time" in result:
                    logger.info(f"      æ‰§è¡Œæ—¶é—´: {result['execution_time']:.3f}s")
                if result.get("has_sql_query"):
                    logger.info(f"      SQLç”Ÿæˆ: âœ…")
                if result.get("sql_query"):
                    logger.info(f"      SQLé¢„è§ˆ: {result['sql_query'][:100]}...")
            else:
                if result.get("error"):
                    logger.info(f"      é”™è¯¯: {result['error']}")
                if result.get("error_message"):
                    logger.info(f"      é”™è¯¯ä¿¡æ¯: {result['error_message']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = f"doris_192_168_61_30_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                "test_summary": {
                    "target_datasource": "æµ‹è¯•-å…¬å¸ (192.168.61.30)",
                    "total_tests": total_tests,
                    "successful_tests": successful_tests,
                    "success_rate": successful_tests/total_tests if total_tests > 0 else 0,
                    "test_time": datetime.now().isoformat(),
                    "environment": "doris_192_168_61_30_targeted"
                },
                "detailed_results": self.test_results
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“„ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # è®¾ç½®æ•°æ®åº“è¿æ¥ï¼ˆä»autorport-devçš„docker-compose.ymlè·å–æ­£ç¡®é…ç½®ï¼‰
        os.environ["DATABASE_URL"] = "postgresql://postgres:postgres123@localhost:5432/autoreport"
        os.environ["POSTGRES_PASSWORD"] = "postgres123"
        os.environ["POSTGRES_USER"] = "postgres"
        os.environ["POSTGRES_DB"] = "autoreport"
        
        logger.info("ğŸ¯ å¼€å§‹192.168.61.30æ•°æ®æºä¸“é¡¹æµ‹è¯•")
        logger.info(f"æ•°æ®åº“URL: postgresql://postgres:***@localhost:5432/autoreport")
        
        # å…ˆæµ‹è¯•æ•°æ®åº“è¿æ¥
        try:
            from app.db.session import get_db
            from sqlalchemy import text
            db = next(get_db())
            result = db.execute(text("SELECT 1 as test")).fetchone()
            logger.info(f"âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ: {result[0]}")
            db.close()
        except Exception as db_error:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {db_error}")
            return
        
        tester = DataSource192168Testing()
        await tester.run_targeted_test()
        
    except Exception as e:
        logger.error(f"ä¸»æµ‹è¯•å‡½æ•°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œ192.168.61.30æ•°æ®æºä¸“é¡¹æµ‹è¯•
    asyncio.run(main())