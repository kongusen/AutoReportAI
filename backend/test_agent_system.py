#!/usr/bin/env python3
"""
Agentç³»ç»Ÿé›†æˆæµ‹è¯•
==================

æµ‹è¯•æ–°çš„Agentç³»ç»Ÿæ¶æ„çš„æ ¸å¿ƒåŠŸèƒ½å’Œç»„ä»¶é›†æˆã€‚
"""

import asyncio
import json
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.services.infrastructure.agents.core.universal_agent_coordinator import (
    UniversalAgentCoordinator, CoordinationMode, execute_intelligent_task
)
from app.services.infrastructure.agents.core.smart_context_processor import (
    SmartContextProcessor, TaskComplexity
)
from app.services.infrastructure.agents.core.intelligent_prompt_orchestrator import (
    IntelligentPromptOrchestrator, create_smart_context
)
from app.services.infrastructure.agents.core.unified_tool_ecosystem import (
    UnifiedToolEcosystem, create_tool_definition, ToolCategory
)


async def test_smart_context_processor():
    """æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡å¤„ç†å™¨"""
    print("\nğŸ¨ æµ‹è¯• SmartContextProcessor")
    print("=" * 50)
    
    processor = SmartContextProcessor()
    
    # æµ‹è¯•å ä½ç¬¦åˆ†æåœºæ™¯
    test_cases = [
        {
            "description": "åˆ†ææ¨¡æ¿ä¸­çš„å ä½ç¬¦ {{ç”¨æˆ·å}} å’Œ {{æ—¥æœŸ}}",
            "context": {
                "template_info": {"content": "Hello {{ç”¨æˆ·å}}, ä»Šå¤©æ˜¯ {{æ—¥æœŸ}}"},
                "placeholder_text": "{{ç”¨æˆ·å}}, {{æ—¥æœŸ}}"
            }
        },
        {
            "description": "ç”Ÿæˆç”¨æˆ·æ´»è·ƒåº¦çš„SQLæŸ¥è¯¢è¯­å¥",
            "context": {
                "data_source_info": {
                    "table_details": [{"table_name": "users", "columns": ["id", "name", "login_time"]}]
                }
            }
        },
        {
            "description": "åˆ›å»ºé”€å”®æ•°æ®åˆ†ææŠ¥å‘Š",
            "context": {
                "report_template": {"type": "dashboard"},
                "data_sensitivity": "medium"
            }
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['description']}")
        
        try:
            context = await processor.build_intelligent_context(
                task_description=test_case["description"],
                context_data=test_case["context"],
                user_id="test_user"
            )
            
            print(f"  âœ… åœºæ™¯è¯†åˆ«: {context.scenario}")
            print(f"  âœ… å¤æ‚åº¦ç­‰çº§: {context.complexity_level.value}")
            print(f"  âœ… æ¨èAgent: {context.optimal_agent_type}")
            print(f"  âœ… å·¥ä½œæµç±»å‹: {context.workflow_type.value}")
            print(f"  âœ… å¯ç”¨å·¥å…·: {', '.join(context.available_tools[:3])}...")
            
        except Exception as e:
            print(f"  âŒ é”™è¯¯: {e}")


async def test_intelligent_prompt_orchestrator():
    """æµ‹è¯•æ™ºèƒ½Promptç¼–æ’å™¨"""
    print("\nğŸ§  æµ‹è¯• IntelligentPromptOrchestrator")
    print("=" * 50)
    
    orchestrator = IntelligentPromptOrchestrator()
    
    # åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡
    smart_context = create_smart_context(
        task_description="åˆ†æå ä½ç¬¦ {{å‘¨æœŸ:ç»Ÿè®¡å¼€å§‹æ—¥æœŸ}} çš„å«ä¹‰",
        context_data={
            "suggested_date_filter": "DATE(create_time) = '2025-09-14'",
            "template_info": {"placeholder_count": 3}
        },
        user_id="test_user",
        scenario="placeholder_analysis",
        complexity_level=TaskComplexity.MEDIUM
    )
    
    try:
        print("ğŸ“‹ ç”Ÿæˆæ‰§è¡Œç­–ç•¥...")
        strategy = await orchestrator.generate_execution_strategy(smart_context)
        
        print(f"  âœ… ç­–ç•¥ID: {strategy.strategy_id}")
        print(f"  âœ… ç½®ä¿¡åº¦: {strategy.confidence_score}")
        print(f"  âœ… å·¥å…·é€‰æ‹©: {', '.join(strategy.tool_selection[:3])}")
        print(f"  âœ… ä¼˜åŒ–æç¤º: {len(strategy.optimization_hints)} æ¡")
        
        # æµ‹è¯•ç¼“å­˜
        print("\nğŸ”„ æµ‹è¯•ç­–ç•¥ç¼“å­˜...")
        cached_strategy = await orchestrator.generate_execution_strategy(smart_context)
        print(f"  âœ… ç¼“å­˜å‘½ä¸­: {strategy.strategy_id == cached_strategy.strategy_id}")
        
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")


async def test_unified_tool_ecosystem():
    """æµ‹è¯•ç»Ÿä¸€å·¥å…·ç”Ÿæ€ç³»ç»Ÿ"""
    print("\nğŸ› ï¸  æµ‹è¯• UnifiedToolEcosystem")
    print("=" * 50)
    
    ecosystem = UnifiedToolEcosystem()
    
    # æ³¨å†Œæµ‹è¯•å·¥å…·
    test_tool = create_tool_definition(
        name="test_placeholder_analyzer",
        category=ToolCategory.ANALYSIS,
        description="æµ‹è¯•å ä½ç¬¦åˆ†æå·¥å…·",
        capabilities=["placeholder_analysis", "context_extraction"],
        performance_score=0.9,
        reliability_score=0.85
    )
    
    try:
        print("ğŸ”§ æ³¨å†Œæµ‹è¯•å·¥å…·...")
        success = ecosystem.register_custom_tool(test_tool)
        print(f"  âœ… å·¥å…·æ³¨å†Œ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡
        from app.services.infrastructure.agents.core.intelligent_prompt_orchestrator import ExecutionStrategy
        
        test_context = create_smart_context(
            task_description="åˆ†æå ä½ç¬¦",
            scenario="placeholder_analysis"
        )
        
        test_strategy = ExecutionStrategy(
            tool_selection=["placeholder_analyzer", "reasoning_tool"],
            optimization_hints=["Check context first"]
        )
        
        print("\nğŸ¯ æµ‹è¯•å·¥å…·é€‰æ‹©...")
        selected_tools = await ecosystem.discover_and_select_tools(test_context, test_strategy)
        print(f"  âœ… é€‰æ‹©äº† {len(selected_tools)} ä¸ªå·¥å…·")
        
        for tool in selected_tools:
            print(f"    - {tool.definition.name} (ç½®ä¿¡åº¦: {tool.confidence_score:.2f})")
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = ecosystem.get_performance_stats()
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"  âœ… æ³¨å†Œå·¥å…·æ•°: {stats['registered_tools']}")
        print(f"  âœ… å·¥å…·åˆ†ç±»: {list(stats['category_distribution'].keys())}")
        
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")


async def test_universal_agent_coordinator():
    """æµ‹è¯•é€šç”¨Agentåè°ƒå™¨"""
    print("\nğŸ¯ æµ‹è¯• UniversalAgentCoordinator")
    print("=" * 50)
    
    # æµ‹è¯•ä¸åŒåè°ƒæ¨¡å¼
    modes = [
        (CoordinationMode.SIMPLE, "ç®€å•æ¨¡å¼"),
        (CoordinationMode.STANDARD, "æ ‡å‡†æ¨¡å¼"), 
        (CoordinationMode.INTELLIGENT, "æ™ºèƒ½æ¨¡å¼")
    ]
    
    for mode, mode_name in modes:
        print(f"\nğŸš€ æµ‹è¯• {mode_name}")
        print("-" * 30)
        
        coordinator = UniversalAgentCoordinator(coordination_mode=mode)
        
        try:
            # æµ‹è¯•å ä½ç¬¦åˆ†æä»»åŠ¡
            result = await coordinator.execute_intelligent_task(
                task_description="åˆ†æå ä½ç¬¦ {{å‘¨æœŸ:ç»Ÿè®¡å¼€å§‹æ—¥æœŸ}}ï¼Œä¸Šä¸‹æ–‡å·²æä¾› suggested_date_filter: \"DATE(create_time) = '2025-09-14'\"",
                context_data={
                    "suggested_date_filter": "DATE(create_time) = '2025-09-14'",
                    "template_info": {
                        "placeholder_text": "{{å‘¨æœŸ:ç»Ÿè®¡å¼€å§‹æ—¥æœŸ}}",
                        "context_available": True
                    }
                },
                user_id="test_user"
            )
            
            print(f"  âœ… æ‰§è¡ŒæˆåŠŸ: {result.success}")
            print(f"  âœ… ä»»åŠ¡ID: {result.task_id}")
            print(f"  âœ… æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}s")
            print(f"  âœ… å®Œæˆé˜¶æ®µ: {len(result.phases_completed)} ä¸ª")
            
            if result.metadata:
                print(f"  âœ… æ‰§è¡Œæ¨¡å¼: {result.metadata.get('mode', 'unknown')}")
                if 'scenario' in result.metadata:
                    print(f"  âœ… åœºæ™¯è¯†åˆ«: {result.metadata['scenario']}")
                
        except Exception as e:
            print(f"  âŒ {mode_name} æ‰§è¡Œå¤±è´¥: {e}")
        
        # è·å–åè°ƒå™¨çŠ¶æ€
        status = coordinator.get_coordination_status()
        print(f"  ğŸ“Š æ´»è·ƒä»»åŠ¡: {status['active_tasks']}")
        print(f"  ğŸ“Š å®Œæˆä»»åŠ¡: {status['completed_tasks']}")


async def test_integration_scenario():
    """æµ‹è¯•é›†æˆåœºæ™¯ - è§£å†³åŸå§‹é—®é¢˜"""
    print("\nğŸ” é›†æˆæµ‹è¯• - åŸå§‹é—®é¢˜åœºæ™¯")  
    print("=" * 50)
    
    # æ¨¡æ‹ŸåŸå§‹é—®é¢˜åœºæ™¯
    task_description = "åˆ†æå ä½ç¬¦ {{å‘¨æœŸ:ç»Ÿè®¡å¼€å§‹æ—¥æœŸ}}"
    context_data = {
        # ä¸Šä¸‹æ–‡å·²ç»æä¾›äº†è¶³å¤Ÿä¿¡æ¯
        "suggested_date_filter": "DATE(create_time) = '2025-09-14'",
        "analysis_context": {
            "date_provided": True,
            "filter_ready": True,
            "needs_db_query": False
        },
        "template_info": {
            "placeholder_text": "{{å‘¨æœŸ:ç»Ÿè®¡å¼€å§‹æ—¥æœŸ}}",
            "expected_value": "2025-09-14"
        }
    }
    
    print("ğŸ“ ä»»åŠ¡æè¿°:", task_description)
    print("ğŸ“Š ä¸Šä¸‹æ–‡ä¿¡æ¯: å·²æä¾›æ—¥æœŸè¿‡æ»¤å™¨å’Œåˆ†æä¸Šä¸‹æ–‡")
    
    try:
        # ä½¿ç”¨å¿«æ·å‡½æ•°æµ‹è¯•
        result = await execute_intelligent_task(
            task_description=task_description,
            context_data=context_data,
            user_id="integration_test",
            mode=CoordinationMode.INTELLIGENT
        )
        
        print(f"\nâœ… é›†æˆæµ‹è¯•ç»“æœ:")
        print(f"  ğŸ¯ æ‰§è¡ŒæˆåŠŸ: {result.success}")
        print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}s")
        print(f"  ğŸ“‹ å®Œæˆé˜¶æ®µ: {[p.value for p in result.phases_completed]}")
        
        if result.success and result.metadata:
            print(f"  ğŸ¨ è¯†åˆ«åœºæ™¯: {result.metadata.get('scenario', 'N/A')}")
            print(f"  ğŸ§  å¤æ‚åº¦: {result.metadata.get('complexity', 'N/A')}")
            print(f"  ğŸ¤– Agentç±»å‹: {result.metadata.get('agent_type', 'N/A')}")
            print(f"  ğŸ› ï¸  ä½¿ç”¨å·¥å…·: {result.metadata.get('tools_used', 0)} ä¸ª")
            print(f"  ğŸ“ˆ ç­–ç•¥ç½®ä¿¡åº¦: {result.metadata.get('strategy_confidence', 'N/A')}")
        
        # æ£€æŸ¥æ˜¯å¦é¿å…äº†ä¸å¿…è¦çš„æ•°æ®åº“æŸ¥è¯¢
        if result.result and isinstance(result.result, dict):
            synthesis = result.result
            print(f"\nğŸ” ç»“æœåˆ†æ:")
            if "execution_summary" in synthesis:
                summary = synthesis["execution_summary"]
                print(f"  âœ… åœºæ™¯æ­£ç¡®è¯†åˆ«: {summary.get('scenario') == 'placeholder_analysis'}")
                print(f"  âœ… æ™ºèƒ½å¤„ç†: åº”è¯¥é¿å…ä¸å¿…è¦çš„æ•°æ®åº“æŸ¥è¯¢")
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Agentç³»ç»Ÿæ¶æ„æµ‹è¯•")
    print("=" * 60)
    print("æµ‹è¯•æ–°çš„ Prompt + TTæ§åˆ¶å¾ªç¯ + å·¥å…·ç”Ÿæ€ æ¶æ„")
    
    try:
        # 1. æµ‹è¯•æ™ºèƒ½ä¸Šä¸‹æ–‡å¤„ç†å™¨
        await test_smart_context_processor()
        
        # 2. æµ‹è¯•æ™ºèƒ½Promptç¼–æ’å™¨  
        await test_intelligent_prompt_orchestrator()
        
        # 3. æµ‹è¯•ç»Ÿä¸€å·¥å…·ç”Ÿæ€ç³»ç»Ÿ
        await test_unified_tool_ecosystem()
        
        # 4. æµ‹è¯•é€šç”¨Agentåè°ƒå™¨
        await test_universal_agent_coordinator()
        
        # 5. é›†æˆæµ‹è¯•
        await test_integration_scenario()
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        print("âœ… æ–°Agentç³»ç»Ÿæ¶æ„æµ‹è¯•é€šè¿‡")
        print("âœ… Prompt + TTæ§åˆ¶å¾ªç¯ + å·¥å…·ç”Ÿæ€ é›†æˆæ­£å¸¸")
        print("âœ… æ™ºèƒ½é€‚é…å¤šç§æƒ…å†µçš„èƒ½åŠ›éªŒè¯æˆåŠŸ")
        
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())