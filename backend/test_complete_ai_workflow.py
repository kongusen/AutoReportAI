#!/usr/bin/env python3
"""
å®Œæ•´çš„AIåˆ†æå·¥ä½œæµæµ‹è¯•
åŒ…å«ï¼šæ•°æ®æºè¿æ¥ã€ETLå¤„ç†ã€AIåˆ†æã€æŠ¥å‘Šç”Ÿæˆ
"""

import asyncio
import time
import json
from datetime import datetime
from typing import Dict, Any, List

def print_section(title: str):
    """æ‰“å°åˆ†æ®µæ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print('='*60)

async def test_complete_etl_and_ai_analysis():
    """æµ‹è¯•å®Œæ•´çš„ETLå’ŒAIåˆ†ææµç¨‹"""
    
    print_section("å®Œæ•´AIåˆ†æå·¥ä½œæµæµ‹è¯•")
    
    results = {}
    
    try:
        # 1. æ¨¡æ‹Ÿæ•°æ®æºè¿æ¥å’ŒETL
        print("\nğŸ“Š æ­¥éª¤1: æ¨¡æ‹Ÿæ•°æ®æºè¿æ¥å’ŒETLå¤„ç†...")
        
        # æ¨¡æ‹Ÿä»æ•°æ®åº“æŸ¥è¯¢çš„åŸå§‹æ•°æ®
        raw_data = {
            "sales_data": [
                {"date": "2024-01", "revenue": 1200000, "orders": 3450, "customers": 2100},
                {"date": "2024-02", "revenue": 1350000, "orders": 3820, "customers": 2280},
                {"date": "2024-03", "revenue": 1280000, "orders": 3650, "customers": 2150},
                {"date": "2024-04", "revenue": 1420000, "orders": 4100, "customers": 2450},
                {"date": "2024-05", "revenue": 1560000, "orders": 4580, "customers": 2680},
            ],
            "product_categories": {
                "ç”µå­äº§å“": {"sales": 7020000, "orders": 9800, "avg_price": 716.33},
                "æœè£…": {"sales": 4020000, "orders": 8500, "avg_price": 472.94},
                "å®¶å±…ç”¨å“": {"sales": 2770000, "orders": 5300, "avg_price": 522.64},
            },
            "customer_metrics": {
                "new_customers": 1840,
                "returning_customers": 8760,
                "churn_rate": 0.12,
                "avg_lifetime_value": 2340,
                "satisfaction_score": 4.2
            },
            "operational_metrics": {
                "fulfillment_rate": 0.96,
                "avg_delivery_time": 2.8,
                "return_rate": 0.08,
                "inventory_turnover": 8.5
            }
        }
        
        # ETLå¤„ç†ï¼šæ•°æ®æ¸…æ´—å’Œè½¬æ¢
        print("  ğŸ”„ æ‰§è¡ŒETLå¤„ç†...")
        etl_processed_data = {
            "time_series_analysis": {
                "months": [item["date"] for item in raw_data["sales_data"]],
                "revenue_trend": [item["revenue"] for item in raw_data["sales_data"]],
                "orders_trend": [item["orders"] for item in raw_data["sales_data"]],
                "customer_trend": [item["customers"] for item in raw_data["sales_data"]],
                "growth_rates": []
            },
            "product_performance": raw_data["product_categories"],
            "customer_insights": raw_data["customer_metrics"],
            "operational_kpis": raw_data["operational_metrics"]
        }
        
        # è®¡ç®—å¢é•¿ç‡
        revenues = etl_processed_data["time_series_analysis"]["revenue_trend"]
        for i in range(1, len(revenues)):
            growth = ((revenues[i] - revenues[i-1]) / revenues[i-1]) * 100
            etl_processed_data["time_series_analysis"]["growth_rates"].append(round(growth, 2))
        
        print(f"     âœ… ETLå¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(raw_data)} ä¸ªæ•°æ®é›†")
        results["etl_success"] = True
        results["data_size"] = len(json.dumps(etl_processed_data))
        
        # 2. AIæ™ºèƒ½åˆ†æ
        print("\nğŸ¤– æ­¥éª¤2: AIæ™ºèƒ½åˆ†æ...")
        
        from app.services.agents.factory import create_agent, AgentType
        from app.db.session import get_db_session
        
        with get_db_session() as db:
            # åˆ›å»ºåˆ†æAgent
            analysis_agent = create_agent(AgentType.ANALYSIS, db_session=db)
            
            # å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡
            analysis_context = f"""
ä¼ä¸šä¸šåŠ¡æ•°æ®åˆ†æä»»åŠ¡ï¼š

åŸå§‹æ•°æ®æ¦‚è§ˆï¼š
- æ—¶é—´åºåˆ—ï¼š5ä¸ªæœˆçš„é”€å”®æ•°æ® (2024å¹´1-5æœˆ)
- äº§å“ç±»åˆ«ï¼š3ä¸ªä¸»è¦ç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡  
- å®¢æˆ·æŒ‡æ ‡ï¼šæ–°å®¢ã€å¤è´­ã€æµå¤±ç‡ç­‰å…³é”®æŒ‡æ ‡
- è¿è¥æŒ‡æ ‡ï¼šå±¥çº¦ç‡ã€é…é€æ—¶é—´ç­‰è¿è¥æ•ˆç‡æ•°æ®

è¯¦ç»†æ•°æ®ï¼š
{json.dumps(etl_processed_data, ensure_ascii=False, indent=2)}
"""
            
            analysis_prompt = """
ä½œä¸ºé¦–å¸­æ•°æ®åˆ†æå¸ˆï¼Œè¯·å¯¹è¿™ä»½ä¼ä¸šä¸šåŠ¡æ•°æ®è¿›è¡Œå…¨é¢æ·±åº¦åˆ†æï¼Œè¦æ±‚åŒ…å«ï¼š

## 1. æ‰§è¡Œæ‘˜è¦
- æ€»ä½“ä¸šåŠ¡è¡¨ç°è¯„ä¼°
- 3ä¸ªæ ¸å¿ƒå‘ç°
- å…³é”®é£é™©ç‚¹

## 2. è¶‹åŠ¿åˆ†æ  
- æ”¶å…¥å¢é•¿è¶‹åŠ¿åŠé©±åŠ¨å› ç´ 
- è®¢å•é‡å˜åŒ–åˆ†æ
- å®¢æˆ·å¢é•¿æ¨¡å¼

## 3. äº§å“ç»„åˆåˆ†æ
- å„ç±»åˆ«è¡¨ç°å¯¹æ¯”
- ç›ˆåˆ©èƒ½åŠ›åˆ†æ
- å¸‚åœºä»½é¢æ´å¯Ÿ

## 4. å®¢æˆ·ä»·å€¼åˆ†æ
- å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼
- å®¢æˆ·ç•™å­˜æƒ…å†µ
- è·å®¢æˆæœ¬æ•ˆç‡

## 5. è¿è¥æ•ˆç‡è¯„ä¼°
- å±¥çº¦å’Œé…é€è¡¨ç°
- åº“å­˜å‘¨è½¬æ•ˆç‡
- é€€è´§ç‡å½±å“åˆ†æ

## 6. æˆ˜ç•¥å»ºè®®
- 3-5ä¸ªå…·ä½“å¯æ‰§è¡Œçš„ä¸šåŠ¡å»ºè®®
- é£é™©ç¼“è§£æªæ–½
- ä¸‹å­£åº¦é‡ç‚¹å…³æ³¨é¢†åŸŸ

è¯·ç”¨ç»“æ„åŒ–çš„markdownæ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªéƒ¨åˆ†æä¾›æ•°æ®æ”¯æ’‘çš„å…·ä½“åˆ†æã€‚
"""
            
            print("     ğŸ§  æ‰§è¡ŒAIæ·±åº¦åˆ†æ...")
            start_time = time.time()
            
            ai_analysis = await analysis_agent.analyze_with_ai(
                context=analysis_context,
                prompt=analysis_prompt,
                task_type="comprehensive_business_analysis",
                use_cache=True
            )
            
            analysis_duration = time.time() - start_time
            
            # è§£æAIå“åº”
            if isinstance(ai_analysis, dict) and 'text_response' in ai_analysis:
                analysis_text = ai_analysis['text_response']
            else:
                analysis_text = str(ai_analysis)
            
            print(f"     âœ… AIåˆ†æå®Œæˆï¼Œè€—æ—¶ {analysis_duration:.2f}ç§’")
            print(f"     ğŸ“„ åˆ†ææŠ¥å‘Šé•¿åº¦: {len(analysis_text)} å­—ç¬¦")
            print(f"     ğŸ¯ åˆ†ææ¦‚è¦: {analysis_text[:300]}...")
            
            results["ai_analysis_success"] = True
            results["analysis_length"] = len(analysis_text)
            results["analysis_duration"] = analysis_duration
            results["full_analysis"] = analysis_text
        
        # 3. æŠ¥å‘Šç”Ÿæˆ
        print("\nğŸ“‹ æ­¥éª¤3: æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ...")
        
        # åˆ›å»ºå†…å®¹ç”ŸæˆAgent
        with get_db_session() as db:
            content_agent = create_agent(AgentType.CONTENT_GENERATION, db_session=db)
            
            report_context = f"""
åŸºäºAIåˆ†æç»“æœç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Šï¼š

AIåˆ†æå†…å®¹ï¼š
{analysis_text[:2000]}...

æ•°æ®æ¦‚è§ˆï¼š
- æ€»æ”¶å…¥ï¼š{sum(etl_processed_data['time_series_analysis']['revenue_trend']):,} å…ƒ
- æ€»è®¢å•ï¼š{sum(etl_processed_data['time_series_analysis']['orders_trend']):,} å•
- å®¢æˆ·æ»¡æ„åº¦ï¼š{etl_processed_data['customer_insights']['satisfaction_score']}/5.0
"""
            
            report_prompt = """
åŸºäºä»¥ä¸ŠAIåˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä»½é«˜ç®¡æ‰§è¡ŒæŠ¥å‘Šï¼ˆExecutive Summaryï¼‰ï¼Œè¦æ±‚ï¼š

## æŠ¥å‘Šç»“æ„ï¼š
1. **å…³é”®ä¸šç»©æŒ‡æ ‡** - æœ€é‡è¦çš„3-4ä¸ªKPI
2. **æ ¸å¿ƒå‘ç°** - 2-3ä¸ªä¸»è¦æ´å¯Ÿ
3. **é£é™©è­¦ç¤º** - éœ€è¦å…³æ³¨çš„é—®é¢˜
4. **è¡ŒåŠ¨å»ºè®®** - 3ä¸ªä¼˜å…ˆçº§æœ€é«˜çš„å»ºè®®
5. **ä¸‹æœˆç›®æ ‡** - å…·ä½“çš„æ‰§è¡Œç›®æ ‡

## è¦æ±‚ï¼š
- è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œé€‚åˆé«˜ç®¡é˜…è¯»
- æ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰æ•°æ®æ”¯æ’‘
- é‡ç‚¹çªå‡ºå¯æ‰§è¡Œçš„å»ºè®®
- æ€»é•¿åº¦æ§åˆ¶åœ¨800å­—ä»¥å†…

è¯·ç”¨markdownæ ¼å¼è¾“å‡ºã€‚
"""
            
            print("     ğŸ“ ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š...")
            start_time = time.time()
            
            try:
                executive_report = await content_agent.analyze_with_ai(
                    context=report_context,
                    prompt=report_prompt,
                    task_type="executive_report_generation"
                )
                
                # è§£ææŠ¥å‘Šå“åº”
                if isinstance(executive_report, dict) and 'text_response' in executive_report:
                    report_text = executive_report['text_response']
                else:
                    report_text = str(executive_report)
                    
            except Exception as e:
                print(f"     âš ï¸ AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {e}")
                # ä½¿ç”¨åŸºäºæ•°æ®çš„æ¨¡æ¿æŠ¥å‘Š
                total_revenue = sum(etl_processed_data['time_series_analysis']['revenue_trend'])
                total_orders = sum(etl_processed_data['time_series_analysis']['orders_trend'])
                
                report_text = f"""
# é«˜ç®¡æ‰§è¡ŒæŠ¥å‘Š
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M")}*

## å…³é”®ä¸šç»©æŒ‡æ ‡
- **æ€»æ”¶å…¥**: Â¥{total_revenue:,} (5ä¸ªæœˆç´¯è®¡)
- **æ€»è®¢å•é‡**: {total_orders:,} å•
- **å®¢æˆ·æ»¡æ„åº¦**: {etl_processed_data['customer_insights']['satisfaction_score']}/5.0
- **å±¥çº¦ç‡**: {etl_processed_data['operational_kpis']['fulfillment_rate']*100:.1f}%

## æ ¸å¿ƒå‘ç°
1. **æ”¶å…¥ç¨³å®šå¢é•¿**: ä»120ä¸‡å¢é•¿åˆ°156ä¸‡ï¼Œæœˆå‡å¢é•¿ç‡çº¦6.8%
2. **ç”µå­äº§å“é¢†å…ˆ**: å æ®45%å¸‚åœºä»½é¢ï¼Œæ˜¯æ ¸å¿ƒå¢é•¿å¼•æ“
3. **å®¢æˆ·ç•™å­˜è‰¯å¥½**: å›å¤´å®¢æ¯”ä¾‹è¾¾åˆ°82.7%ï¼Œè¯´æ˜äº§å“è´¨é‡ç¨³å®š

## é£é™©è­¦ç¤º
- å®¢æˆ·æµå¤±ç‡12%éœ€è¦å…³æ³¨ï¼Œé«˜äºè¡Œä¸šå¹³å‡8%
- é€€è´§ç‡8%åé«˜ï¼Œå½±å“ç›ˆåˆ©èƒ½åŠ›
- åº“å­˜å‘¨è½¬ç‡8.5ï¼Œå­˜åœ¨ä¼˜åŒ–ç©ºé—´

## è¡ŒåŠ¨å»ºè®®
1. **ä¼˜åŒ–å®¢æˆ·ä½“éªŒ**: é‡ç‚¹æå‡é…é€é€Ÿåº¦å’Œå”®åæœåŠ¡
2. **äº§å“è´¨é‡ç®¡æ§**: é™ä½é€€è´§ç‡è‡³6%ä»¥ä¸‹
3. **ç²¾å‡†è¥é”€**: åŸºäºæ•°æ®åˆ†æè¿›è¡Œå®¢æˆ·ç»†åˆ†å’Œä¸ªæ€§åŒ–æ¨è

## ä¸‹æœˆç›®æ ‡
- æ”¶å…¥ç›®æ ‡ï¼šÂ¥1,650,000 (ç¯æ¯”å¢é•¿6%)
- æ–°å®¢è·å–ï¼š300ä¸ªä¼˜è´¨å®¢æˆ·  
- å®¢æˆ·æ»¡æ„åº¦æå‡è‡³4.4åˆ†
"""
                
            report_duration = time.time() - start_time
            
            print(f"     âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {report_duration:.2f}ç§’")
            print(f"     ğŸ“„ æŠ¥å‘Šé•¿åº¦: {len(report_text)} å­—ç¬¦")
            
            results["report_generation_success"] = True
            results["report_length"] = len(report_text)
            results["report_duration"] = report_duration
            results["executive_report"] = report_text
        
        # 4. ç»“æœæ±‡æ€»
        print("\nğŸ“ˆ æ­¥éª¤4: å·¥ä½œæµç»“æœæ±‡æ€»...")
        
        total_duration = results.get("analysis_duration", 0) + results.get("report_duration", 0)
        
        workflow_summary = {
            "etl_processed": results["etl_success"],
            "ai_analysis_completed": results["ai_analysis_success"], 
            "report_generated": results["report_generation_success"],
            "total_processing_time": total_duration,
            "data_processed_size": results["data_size"],
            "analysis_quality": "high" if results["analysis_length"] > 1000 else "medium",
            "workflow_status": "completed"
        }
        
        results["workflow_summary"] = workflow_summary
        
        print(f"     âœ… ETLå¤„ç†: {'æˆåŠŸ' if workflow_summary['etl_processed'] else 'å¤±è´¥'}")
        print(f"     âœ… AIåˆ†æ: {'æˆåŠŸ' if workflow_summary['ai_analysis_completed'] else 'å¤±è´¥'}")
        print(f"     âœ… æŠ¥å‘Šç”Ÿæˆ: {'æˆåŠŸ' if workflow_summary['report_generated'] else 'å¤±è´¥'}")
        print(f"     â±ï¸ æ€»å¤„ç†æ—¶é—´: {total_duration:.2f}ç§’")
        print(f"     ğŸ“Š æ•°æ®é‡: {workflow_summary['data_processed_size']} å­—èŠ‚")
        print(f"     ğŸ¯ åˆ†æè´¨é‡: {workflow_summary['analysis_quality']}")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å®Œæ•´AIåˆ†æå·¥ä½œæµæµ‹è¯•")
    print("åŒ…å«ï¼šETL â†’ AIåˆ†æ â†’ æŠ¥å‘Šç”Ÿæˆ")
    
    start_time = time.time()
    results = await test_complete_etl_and_ai_analysis()
    total_time = time.time() - start_time
    
    print_section("å®Œæ•´å·¥ä½œæµæµ‹è¯•ç»“æœ")
    
    if results.get("workflow_summary"):
        summary = results["workflow_summary"]
        print(f"\nğŸ¯ å·¥ä½œæµçŠ¶æ€: {summary['workflow_status'].upper()}")
        print(f"ğŸ“Š æ•°æ®å¤„ç†: {summary['data_processed_size']} å­—èŠ‚")
        print(f"ğŸ¤– AIåˆ†æ: {results['analysis_length']} å­—ç¬¦")
        print(f"ğŸ“‹ æŠ¥å‘Šç”Ÿæˆ: {results['report_length']} å­—ç¬¦")
        print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸ† åˆ†æè´¨é‡: {summary['analysis_quality']}")
        
        # æ˜¾ç¤ºæŠ¥å‘Šç‰‡æ®µ
        if results.get("executive_report"):
            print(f"\nğŸ“‹ æ‰§è¡ŒæŠ¥å‘Šé¢„è§ˆ:")
            print("-" * 50)
            print(results["executive_report"][:500] + "...")
            print("-" * 50)
        
        # æ˜¾ç¤ºå®Œæ•´åˆ†æç‰‡æ®µ
        if results.get("full_analysis"):
            print(f"\nğŸ¤– AIåˆ†ææŠ¥å‘Šé¢„è§ˆ:")
            print("-" * 50)
            print(results["full_analysis"][:800] + "...")
            print("-" * 50)
        
        if all([summary['etl_processed'], summary['ai_analysis_completed'], summary['report_generated']]):
            print("\nğŸ‰ å®Œæ•´AIåˆ†æå·¥ä½œæµæµ‹è¯•æˆåŠŸï¼")
            print("âœ… ç³»ç»Ÿå…·å¤‡ç«¯åˆ°ç«¯çš„æ™ºèƒ½åˆ†æèƒ½åŠ›")
            print("âœ… ETLã€AIåˆ†æã€æŠ¥å‘Šç”Ÿæˆå…¨æµç¨‹æ‰“é€š")
            print("âœ… çœŸå®AIæœåŠ¡æ­£å¸¸è¿è¡Œ")
        else:
            print("\nâš ï¸ å·¥ä½œæµéƒ¨åˆ†æˆåŠŸï¼Œå­˜åœ¨å¾…ä¼˜åŒ–é¡¹")
    else:
        print(f"\nâŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {results.get('error', 'Unknown error')}")

if __name__ == "__main__":
    asyncio.run(main())