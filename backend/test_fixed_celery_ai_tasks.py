#!/usr/bin/env python3
"""
ä¿®å¤åçš„Celery AIä»»åŠ¡æµ‹è¯•
ä½¿ç”¨æ­£ç¡®æ³¨å†Œçš„ä»»åŠ¡è¿›è¡Œæµ‹è¯•
"""

import time
import json
from datetime import datetime

def test_registered_ai_tasks():
    """æµ‹è¯•å·²æ³¨å†Œçš„AIä»»åŠ¡"""
    print("ğŸ¤– æµ‹è¯•å·²æ³¨å†Œçš„Celery AIä»»åŠ¡")
    print("=" * 50)
    
    try:
        # å¯¼å…¥å·²æ³¨å†Œçš„AIä»»åŠ¡
        from app.services.task.core.worker.tasks.ai_analysis_tasks import (
            custom_ai_analysis_task,
            ai_pipeline_task,
            batch_ai_analysis_task
        )
        from app.services.task.core.worker.config.celery_app import celery_app
        
        # 1. æ£€æŸ¥ä»»åŠ¡æ³¨å†Œ
        print("\nğŸ” æ­¥éª¤1: æ£€æŸ¥ä»»åŠ¡æ³¨å†Œ...")
        
        inspect = celery_app.control.inspect()
        registered_tasks = inspect.registered()
        
        if registered_tasks:
            all_tasks = []
            for worker, tasks in registered_tasks.items():
                all_tasks.extend(tasks)
            
            ai_tasks = [task for task in all_tasks if 'ai_analysis_tasks' in task]
            print(f"     âœ… å‘ç° {len(ai_tasks)} ä¸ªAIåˆ†æä»»åŠ¡:")
            for task in ai_tasks:
                print(f"       - {task.split('.')[-1]}")
        else:
            print("     âš ï¸ æ— æ³•è·å–æ³¨å†Œä»»åŠ¡åˆ—è¡¨")
        
        # 2. æµ‹è¯•å•ä¸ªAIåˆ†æä»»åŠ¡
        print("\nğŸ§  æ­¥éª¤2: æµ‹è¯•å•ä¸ªAIåˆ†æä»»åŠ¡...")
        
        test_data = {
            "business_metrics": {
                "revenue": [150000, 165000, 142000, 178000, 195000],
                "orders": [1250, 1380, 1190, 1520, 1680],
                "customers": [850, 920, 810, 1050, 1150],
                "months": ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ"]
            },
            "performance_kpis": {
                "conversion_rate": 3.8,
                "customer_satisfaction": 4.3,
                "retention_rate": 0.78,
                "churn_rate": 0.22
            }
        }
        
        analysis_prompt = """
è¯·ä½œä¸ºèµ„æ·±æ•°æ®åˆ†æå¸ˆï¼Œåˆ†æä»¥ä¸‹ä¸šåŠ¡æ•°æ®å¹¶æä¾›ä¸“ä¸šæ´å¯Ÿï¼š

1. **è¶‹åŠ¿åˆ†æ**ï¼šåˆ†æ5ä¸ªæœˆçš„ä¸šåŠ¡æ•°æ®è¶‹åŠ¿
2. **å…³é”®æŒ‡æ ‡è¯„ä¼°**ï¼šè¯„ä¼°è½¬åŒ–ç‡ã€æ»¡æ„åº¦ã€ç•™å­˜ç‡ç­‰KPI  
3. **ä¸šåŠ¡å»ºè®®**ï¼šæä¾›3ä¸ªå…·ä½“çš„æ”¹è¿›å»ºè®®

è¯·ç”¨ç®€æ´çš„markdownæ ¼å¼è¾“å‡ºã€‚
"""
        
        start_time = time.time()
        
        # ä½¿ç”¨apply_asyncæ¥é¿å…ä»»åŠ¡æ³¨å†Œé—®é¢˜
        ai_task_result = custom_ai_analysis_task.apply_async([
            json.dumps(test_data, ensure_ascii=False),
            analysis_prompt
        ])
        
        print("     â³ ç­‰å¾…AIåˆ†æå®Œæˆ...")
        ai_result = ai_task_result.get(timeout=60)
        execution_time = time.time() - start_time
        
        print(f"     âœ… AIåˆ†æä»»åŠ¡å®Œæˆï¼")
        print(f"     â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"     ğŸ“Š ä»»åŠ¡çŠ¶æ€: {ai_result.get('status')}")
        
        if ai_result.get('status') == 'success':
            analysis = ai_result.get('analysis', '')
            if isinstance(analysis, dict) and 'text_response' in analysis:
                analysis_text = analysis['text_response']
            else:
                analysis_text = str(analysis)
            
            print(f"     ğŸ“„ åˆ†æé•¿åº¦: {len(analysis_text)} å­—ç¬¦")
            print(f"     ğŸ¯ åˆ†æé¢„è§ˆ:")
            print("     " + "-" * 40)
            preview = analysis_text[:300].replace('\n', '\n     ')
            print("     " + preview + "...")
            print("     " + "-" * 40)
            
            single_task_result = {
                "success": True,
                "execution_time": execution_time,
                "analysis_length": len(analysis_text),
                "full_analysis": analysis_text
            }
        else:
            print(f"     âŒ AIåˆ†æå¤±è´¥: {ai_result.get('error')}")
            single_task_result = {"success": False, "error": ai_result.get('error')}
        
        # 3. æµ‹è¯•Pipelineä»»åŠ¡
        print("\nğŸ”§ æ­¥éª¤3: æµ‹è¯•Pipelineä»»åŠ¡...")
        
        pipeline_config = {
            "data": "é”€å”®æ•°æ®: æœˆåº¦å¢é•¿12%, å®¢æˆ·æ»¡æ„åº¦4.5/5.0, å¸‚åœºä»½é¢æå‡2%",
            "summary": "ä¸šåŠ¡è¡¨ç°è‰¯å¥½ï¼Œå¤šé¡¹æŒ‡æ ‡ä¸Šå‡",
            "processing_time": "2.3ç§’"
        }
        
        start_time = time.time()
        pipeline_task_result = ai_pipeline_task.apply_async([pipeline_config])
        pipeline_result = pipeline_task_result.get(timeout=45)
        pipeline_time = time.time() - start_time
        
        print(f"     âœ… Pipelineä»»åŠ¡å®Œæˆï¼")
        print(f"     â±ï¸ æ‰§è¡Œæ—¶é—´: {pipeline_time:.2f}ç§’")
        print(f"     ğŸ“Š ä»»åŠ¡çŠ¶æ€: {pipeline_result.get('status')}")
        print(f"     ğŸ“‹ å®Œæˆé˜¶æ®µ: {pipeline_result.get('completed_stages')}")
        
        # 4. æµ‹è¯•æ‰¹é‡ä»»åŠ¡
        print("\nğŸ”„ æ­¥éª¤4: æµ‹è¯•æ‰¹é‡ä»»åŠ¡...")
        
        batch_data = [
            {"context": "Q1é”€å”®é¢å¢é•¿15%", "prompt": "åˆ†æé”€å”®å¢é•¿çš„ä¸»è¦é©±åŠ¨å› ç´ "},
            {"context": "å®¢æˆ·è½¬åŒ–ç‡æå‡åˆ°4.2%", "prompt": "è¯„ä¼°è½¬åŒ–ç‡æ”¹å–„çš„ä¸šåŠ¡å½±å“"},
            {"context": "äº§å“Aå æ”¶å…¥65%", "prompt": "åˆ†æäº§å“é›†ä¸­åº¦é£é™©"}
        ]
        
        start_time = time.time()
        batch_task_result = batch_ai_analysis_task.apply_async([batch_data])
        batch_result = batch_task_result.get(timeout=60)
        batch_time = time.time() - start_time
        
        print(f"     âœ… æ‰¹é‡ä»»åŠ¡å®Œæˆï¼")
        print(f"     â±ï¸ æ‰§è¡Œæ—¶é—´: {batch_time:.2f}ç§’")
        print(f"     ğŸ“Š ä»»åŠ¡çŠ¶æ€: {batch_result.get('status')}")
        
        if batch_result.get('status') == 'completed':
            success_rate = batch_result.get('successful_tasks', 0) / batch_result.get('total_tasks', 1)
            print(f"     ğŸ“ˆ æˆåŠŸç‡: {success_rate*100:.1f}% ({batch_result.get('successful_tasks')}/{batch_result.get('total_tasks')})")
        
        return {
            "single_task": single_task_result,
            "pipeline_success": pipeline_result.get('status') == 'success',
            "batch_success": batch_result.get('status') == 'completed',
            "total_time": execution_time + pipeline_time + batch_time
        }
        
    except Exception as e:
        print(f"\nâŒ æ³¨å†Œä»»åŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

def test_basic_tasks_integration():
    """æµ‹è¯•ä¸åŸºç¡€ä»»åŠ¡çš„é›†æˆ"""
    print("\nğŸ”— æµ‹è¯•ä¸åŸºç¡€ä»»åŠ¡çš„é›†æˆ")
    print("=" * 50)
    
    try:
        from app.services.task.core.worker.tasks.basic_tasks import test_celery_task
        from app.services.task.core.worker.tasks.ai_analysis_tasks import custom_ai_analysis_task
        
        # 1. åŸºç¡€ä»»åŠ¡
        print("\nğŸ“ æ‰§è¡ŒåŸºç¡€ä»»åŠ¡...")
        basic_result = test_celery_task.apply_async(["é›†æˆæµ‹è¯•æ¶ˆæ¯"])
        basic_output = basic_result.get(timeout=10)
        print(f"     âœ… åŸºç¡€ä»»åŠ¡: {basic_output}")
        
        # 2. AIä»»åŠ¡
        print("\nğŸ¤– æ‰§è¡ŒAIä»»åŠ¡...")
        ai_context = "æµ‹è¯•æ•°æ®ï¼šç”¨æˆ·æ´»è·ƒåº¦85%ï¼Œæ”¶å…¥å¢é•¿18%"
        ai_prompt = "è¯·ç®€è¦åˆ†æè¿™äº›æŒ‡æ ‡çš„è¡¨ç°"
        
        ai_result = custom_ai_analysis_task.apply_async([ai_context, ai_prompt])
        ai_output = ai_result.get(timeout=30)
        
        print(f"     âœ… AIä»»åŠ¡çŠ¶æ€: {ai_output.get('status')}")
        
        return {
            "integration_success": True,
            "basic_task_works": True,
            "ai_task_works": ai_output.get('status') == 'success'
        }
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return {"integration_success": False, "error": str(e)}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¿®å¤åçš„Celery AIä»»åŠ¡æµ‹è¯•")
    print("é‡ç‚¹æµ‹è¯•ï¼šå·²æ³¨å†Œä»»åŠ¡ + çœŸå®AIåŠŸèƒ½ + é›†æˆæµ‹è¯•")
    
    total_start_time = time.time()
    
    # 1. æµ‹è¯•å·²æ³¨å†Œçš„AIä»»åŠ¡
    ai_test_result = test_registered_ai_tasks()
    
    # 2. æµ‹è¯•ä»»åŠ¡é›†æˆ
    integration_result = test_basic_tasks_integration()
    
    total_time = time.time() - total_start_time
    
    # ç»“æœæ±‡æ€»
    print("\n" + "=" * 60)
    print("ğŸ¯ ä¿®å¤åCelery AIä»»åŠ¡æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    
    if ai_test_result.get('single_task', {}).get('success'):
        print(f"   âœ… å•ä¸ªAIä»»åŠ¡: æˆåŠŸ")
        print(f"      â±ï¸ æ‰§è¡Œæ—¶é—´: {ai_test_result['single_task']['execution_time']:.2f}ç§’")
        print(f"      ğŸ“„ åˆ†æé•¿åº¦: {ai_test_result['single_task']['analysis_length']} å­—ç¬¦")
    else:
        print(f"   âŒ å•ä¸ªAIä»»åŠ¡: å¤±è´¥")
    
    print(f"   âœ… Pipelineä»»åŠ¡: {'æˆåŠŸ' if ai_test_result.get('pipeline_success') else 'å¤±è´¥'}")
    print(f"   âœ… æ‰¹é‡ä»»åŠ¡: {'æˆåŠŸ' if ai_test_result.get('batch_success') else 'å¤±è´¥'}")
    print(f"   âœ… ä»»åŠ¡é›†æˆ: {'æˆåŠŸ' if integration_result.get('integration_success') else 'å¤±è´¥'}")
    
    success_count = sum([
        ai_test_result.get('single_task', {}).get('success', False),
        ai_test_result.get('pipeline_success', False),
        ai_test_result.get('batch_success', False),
        integration_result.get('integration_success', False)
    ])
    
    print(f"\nğŸ“ˆ æ•´ä½“æˆåŠŸç‡: {success_count}/4 ({success_count*25}%)")
    print(f"â±ï¸ æ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
    
    if success_count >= 3:
        print("\nğŸ‰ Celery AIä»»åŠ¡ç³»ç»Ÿä¿®å¤æˆåŠŸï¼")
        print("âœ… AIåˆ†æä»»åŠ¡æ­£ç¡®æ³¨å†Œå¹¶å¯æ‰§è¡Œ")
        print("âœ… çœŸå®AIæœåŠ¡é›†æˆå®Œæ•´")
        print("âœ… å¼‚æ­¥ä»»åŠ¡å¤„ç†æ­£å¸¸")
        print("âœ… æ‰¹é‡å’ŒPipelineåŠŸèƒ½å¯ç”¨")
        
        # æ˜¾ç¤ºå®Œæ•´åˆ†æç¤ºä¾‹
        if ai_test_result.get('single_task', {}).get('full_analysis'):
            print("\nğŸ“‹ AIåˆ†ææŠ¥å‘Šç¤ºä¾‹:")
            print("-" * 50)
            analysis_text = ai_test_result['single_task']['full_analysis']
            if isinstance(analysis_text, dict) and 'text_response' in analysis_text:
                display_text = analysis_text['text_response']
            else:
                display_text = str(analysis_text)
            print(display_text[:600] + "..." if len(display_text) > 600 else display_text)
            print("-" * 50)
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½ä»æœ‰é—®é¢˜")
        if not ai_test_result.get('single_task', {}).get('success'):
            error = ai_test_result.get('single_task', {}).get('error', 'Unknown')
            print(f"   âŒ AIä»»åŠ¡é—®é¢˜: {error}")
        if not integration_result.get('integration_success'):
            error = integration_result.get('error', 'Unknown')
            print(f"   âŒ é›†æˆé—®é¢˜: {error}")

if __name__ == "__main__":
    main()