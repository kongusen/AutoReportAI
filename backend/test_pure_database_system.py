#!/usr/bin/env python3
"""
çº¯æ•°æ®åº“é©±åŠ¨ç³»ç»Ÿå®Œæ•´æµ‹è¯•

æµ‹è¯•å®Œå…¨ç§»é™¤å‘åå…¼å®¹ä»£ç åçš„çº¯æ•°æ®åº“é©±åŠ¨æ™ºèƒ½é€‰æ‹©ç³»ç»Ÿ
éªŒè¯ç”¨æˆ·å¿…é¡»æä¾›user_idæ‰èƒ½ä½¿ç”¨æ‰€æœ‰LLMæœåŠ¡
"""

import asyncio
import logging
from datetime import datetime
from uuid import uuid4

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_pure_database_llm_manager():
    """æµ‹è¯•çº¯æ•°æ®åº“é©±åŠ¨çš„LLMç®¡ç†å™¨"""
    print("ğŸ§  æµ‹è¯•çº¯æ•°æ®åº“é©±åŠ¨LLMç®¡ç†å™¨")
    print("=" * 50)
    
    try:
        # æµ‹è¯•æ— user_idçš„æƒ…å†µï¼ˆåº”è¯¥å¤±è´¥æˆ–æç¤ºéœ€è¦ç”¨æˆ·IDï¼‰
        print("\nâŒ æµ‹è¯•1: å°è¯•ä¸æä¾›user_idä½¿ç”¨æœåŠ¡")
        
        from app.services.infrastructure.ai.llm import get_llm_manager
        
        manager = await get_llm_manager()
        service_info = manager.get_service_info()
        
        print(f"âœ… æœåŠ¡åç§°: {service_info['service_name']}")
        print(f"ğŸ“Š æ¶æ„ç±»å‹: {service_info['architecture']}")
        print(f"ğŸ¯ æ•°æ®æº: {', '.join(service_info['data_sources'])}")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await manager.health_check()
        print(f"ğŸ’š å¥åº·çŠ¶æ€: {health['status']} ({'âœ…' if health['healthy'] else 'âŒ'})")
        print(f"ğŸ“ˆ æœåŠ¡å™¨: {health['servers']['healthy']}/{health['servers']['total']} å¥åº·")
        print(f"ğŸ¤– æ¨¡å‹: {health['models']['healthy']}/{health['models']['total']} å¥åº·")
        
        return {
            "status": "success",
            "manager_type": service_info.get("architecture", "unknown"),
            "health": health
        }
        
    except Exception as e:
        logger.error(f"LLMç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "error": str(e)}


async def test_user_specific_model_selection():
    """æµ‹è¯•ç”¨æˆ·ä¸“å±çš„æ¨¡å‹é€‰æ‹©"""
    print("\nğŸ¯ æµ‹è¯•ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©")
    print("=" * 40)
    
    # æ¨¡æ‹Ÿç”¨æˆ·IDï¼ˆå®é™…ç¯å¢ƒä¸­åº”è¯¥ä»æ•°æ®åº“è·å–çœŸå®ç”¨æˆ·ï¼‰
    test_user_id = str(uuid4())
    
    try:
        from app.services.infrastructure.ai.llm import select_best_model_for_user
        
        # æµ‹è¯•ä¸åŒåœºæ™¯çš„æ¨¡å‹é€‰æ‹©
        scenarios = [
            {
                "name": "æ¨ç†ä»»åŠ¡",
                "task_type": "reasoning",
                "complexity": "complex",
                "constraints": {"accuracy_critical": True}
            },
            {
                "name": "ç¼–ç¨‹ä»»åŠ¡",
                "task_type": "coding", 
                "complexity": "medium",
                "constraints": {"preferred_providers": ["anthropic", "openai"]}
            },
            {
                "name": "æˆæœ¬æ•æ„Ÿä»»åŠ¡",
                "task_type": "qa",
                "complexity": "simple",
                "constraints": {"cost_sensitive": True, "max_cost": 0.01}
            }
        ]
        
        results = []
        
        for scenario in scenarios:
            print(f"\nğŸ“‹ åœºæ™¯: {scenario['name']}")
            
            try:
                selection = await select_best_model_for_user(
                    user_id=test_user_id,
                    task_type=scenario["task_type"],
                    complexity=scenario["complexity"],
                    constraints=scenario["constraints"],
                    agent_id=f"{scenario['task_type']}_agent"
                )
                
                print(f"   ğŸ¯ é€‰æ‹©: {selection['provider']}:{selection['model']}")
                print(f"   ğŸ“Š ç½®ä¿¡åº¦: {selection['confidence']:.1%}")
                print(f"   ğŸ’­ ç†ç”±: {selection['reasoning']}")
                print(f"   ğŸ’° æˆæœ¬: ${selection['expected_cost']:.4f}")
                print(f"   ğŸ”§ æ¥æº: {selection['source']}")
                
                results.append({
                    "scenario": scenario['name'],
                    "status": "success",
                    "selection": selection
                })
                
            except Exception as e:
                print(f"   âŒ å¤±è´¥: {e}")
                results.append({
                    "scenario": scenario['name'],
                    "status": "error",
                    "error": str(e)
                })
        
        success_count = sum(1 for r in results if r["status"] == "success")
        
        return {
            "status": "success",
            "test_user_id": test_user_id,
            "scenarios_tested": len(scenarios),
            "successful_selections": success_count,
            "results": results
        }
        
    except Exception as e:
        logger.error(f"ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "error": str(e)}


async def test_pure_database_react_agent():
    """æµ‹è¯•çº¯æ•°æ®åº“é©±åŠ¨çš„React Agent"""
    print("\nğŸ¤– æµ‹è¯•çº¯æ•°æ®åº“é©±åŠ¨React Agent")
    print("=" * 45)
    
    test_user_id = str(uuid4())
    
    try:
        from app.services.infrastructure.ai.agents import create_pure_database_react_agent
        
        print(f"ğŸ‘¤ ä¸ºç”¨æˆ· {test_user_id} åˆ›å»ºReact Agent")
        
        # åˆ›å»ºç”¨æˆ·ä¸“å±çš„React Agent
        agent = create_pure_database_react_agent(user_id=test_user_id)
        
        service_info = agent.get_service_info()
        print(f"âœ… AgentæœåŠ¡: {service_info['service_name']}")
        print(f"ğŸ‘¤ å…³è”ç”¨æˆ·: {service_info['user_id']}")
        print(f"ğŸ¯ æ¶æ„ç±»å‹: {service_info['architecture']}")
        
        # æµ‹è¯•å¯¹è¯
        test_messages = [
            "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½",
            "å¸®æˆ‘åˆ†æä¸€ä¸‹å¸‚åœºè¶‹åŠ¿",
            "æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆšæ‰çš„å¯¹è¯"
        ]
        
        conversation_results = []
        
        for i, message in enumerate(test_messages, 1):
            print(f"\nğŸ’¬ å¯¹è¯ {i}: {message}")
            
            try:
                result = await agent.chat(message)
                
                print(f"   âœ… çŠ¶æ€: {result['status']}")
                print(f"   â±ï¸ ç”¨æ—¶: {result['conversation_time']:.2f}s")
                print(f"   ğŸ¤– æ¨¡å‹: {result['metadata'].get('model_used', 'unknown')}")
                print(f"   ğŸ§  æ¨ç†æ­¥éª¤: {len(result['reasoning_steps'])}")
                print(f"   ğŸ“„ å“åº”: {result['response'][:100]}...")
                
                conversation_results.append({
                    "message": message,
                    "status": "success",
                    "response_time": result['conversation_time'],
                    "model_used": result['metadata'].get('model_used')
                })
                
            except Exception as e:
                print(f"   âŒ å¯¹è¯å¤±è´¥: {e}")
                conversation_results.append({
                    "message": message,
                    "status": "error",
                    "error": str(e)
                })
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_conversation_stats()
        print(f"\nğŸ“Š Agentç»Ÿè®¡:")
        print(f"   æ€»å¯¹è¯: {stats['total_conversations']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1%}")
        print(f"   é€‰æ‹©æ¨¡å‹: {stats['selected_model']}")
        
        return {
            "status": "success",
            "user_id": test_user_id,
            "agent_info": service_info,
            "conversations": len(test_messages),
            "successful_conversations": len([r for r in conversation_results if r["status"] == "success"]),
            "statistics": stats
        }
        
    except Exception as e:
        logger.error(f"Pure Database React Agentæµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "error": str(e)}


async def test_user_feedback_and_learning():
    """æµ‹è¯•ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ ç³»ç»Ÿ"""
    print("\nğŸ“ˆ æµ‹è¯•ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ ç³»ç»Ÿ")
    print("=" * 40)
    
    test_user_id = str(uuid4())
    
    try:
        from app.services.infrastructure.ai.llm import record_usage_feedback
        
        # æ¨¡æ‹Ÿå¤šæ¬¡ä½¿ç”¨åé¦ˆ
        feedback_scenarios = [
            {
                "model": "gpt-4o-mini",
                "provider": "xiaoai",
                "success": True,
                "satisfaction": 0.9,
                "agent_id": "react_agent",
                "task_type": "reasoning"
            },
            {
                "model": "claude-sonnet-4-20250514",
                "provider": "xiaoai", 
                "success": True,
                "satisfaction": 0.95,
                "agent_id": "analysis_agent",
                "task_type": "analysis"
            },
            {
                "model": "gpt-4o-mini",
                "provider": "xiaoai",
                "success": False,
                "satisfaction": 0.4,
                "agent_id": "coding_agent",
                "task_type": "coding"
            }
        ]
        
        print(f"ğŸ‘¤ ä¸ºç”¨æˆ· {test_user_id} è®°å½•ä½¿ç”¨åé¦ˆ")
        
        for i, feedback in enumerate(feedback_scenarios, 1):
            print(f"   ğŸ“Š åé¦ˆ {i}: {feedback['provider']}:{feedback['model']} - æˆåŠŸ: {feedback['success']}, æ»¡æ„åº¦: {feedback['satisfaction']}")
            
            record_usage_feedback(
                user_id=test_user_id,
                model=feedback["model"],
                provider=feedback["provider"],
                success=feedback["success"],
                satisfaction_score=feedback["satisfaction"],
                actual_cost=0.01,
                actual_latency=1500,
                agent_id=feedback["agent_id"],
                task_type=feedback["task_type"]
            )
        
        print("âœ… åé¦ˆè®°å½•å®Œæˆï¼Œç³»ç»Ÿå°†åŸºäºåé¦ˆä¼˜åŒ–æœªæ¥é€‰æ‹©")
        
        return {
            "status": "success",
            "user_id": test_user_id,
            "feedback_records": len(feedback_scenarios),
            "learning_enabled": True
        }
        
    except Exception as e:
        logger.error(f"ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ æµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "error": str(e)}


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª çº¯æ•°æ®åº“é©±åŠ¨ç³»ç»Ÿå®Œæ•´æµ‹è¯•")
    print("=" * 70)
    print("å®Œå…¨ç§»é™¤å‘åå…¼å®¹ä»£ç ï¼Œæµ‹è¯•çº¯æ•°æ®åº“é©±åŠ¨çš„æ™ºèƒ½é€‰æ‹©ç³»ç»Ÿ")
    print("æ‰€æœ‰LLMæœåŠ¡éƒ½éœ€è¦ç”¨æˆ·IDæ‰èƒ½ä½¿ç”¨")
    print("=" * 70)
    
    try:
        # 1. æµ‹è¯•çº¯æ•°æ®åº“LLMç®¡ç†å™¨
        result1 = await test_pure_database_llm_manager()
        
        # 2. æµ‹è¯•ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©
        result2 = await test_user_specific_model_selection()
        
        # 3. æµ‹è¯•çº¯æ•°æ®åº“React Agent
        result3 = await test_pure_database_react_agent()
        
        # 4. æµ‹è¯•ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ 
        result4 = await test_user_feedback_and_learning()
        
        # æ€»ç»“æŠ¥å‘Š
        print(f"\nğŸ† å®Œæ•´æµ‹è¯•æ€»ç»“")
        print("=" * 50)
        
        # LLMç®¡ç†å™¨æµ‹è¯•ç»“æœ
        if result1.get("status") == "success":
            print("âœ… çº¯æ•°æ®åº“LLMç®¡ç†å™¨: æµ‹è¯•æˆåŠŸ")
            print(f"   - æ¶æ„: {result1['manager_type']}")
            print(f"   - å¥åº·: {result1['health']['status']}")
        else:
            print("âŒ çº¯æ•°æ®åº“LLMç®¡ç†å™¨: æµ‹è¯•å¤±è´¥")
        
        # æ¨¡å‹é€‰æ‹©æµ‹è¯•ç»“æœ
        if result2.get("status") == "success":
            print("âœ… ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©: æµ‹è¯•æˆåŠŸ")
            print(f"   - æµ‹è¯•ç”¨æˆ·: {result2['test_user_id']}")
            print(f"   - æˆåŠŸé€‰æ‹©: {result2['successful_selections']}/{result2['scenarios_tested']}")
        else:
            print("âŒ ç”¨æˆ·ä¸“å±æ¨¡å‹é€‰æ‹©: æµ‹è¯•å¤±è´¥")
        
        # React Agentæµ‹è¯•ç»“æœ
        if result3.get("status") == "success":
            print("âœ… çº¯æ•°æ®åº“React Agent: æµ‹è¯•æˆåŠŸ")
            print(f"   - ç”¨æˆ·Agent: {result3['user_id']}")
            print(f"   - æˆåŠŸå¯¹è¯: {result3['successful_conversations']}/{result3['conversations']}")
        else:
            print("âŒ çº¯æ•°æ®åº“React Agent: æµ‹è¯•å¤±è´¥")
        
        # åé¦ˆå­¦ä¹ æµ‹è¯•ç»“æœ
        if result4.get("status") == "success":
            print("âœ… ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ : æµ‹è¯•æˆåŠŸ")
            print(f"   - åé¦ˆè®°å½•: {result4['feedback_records']}")
            print(f"   - å­¦ä¹ åŠŸèƒ½: {'å¯ç”¨' if result4['learning_enabled'] else 'ç¦ç”¨'}")
        else:
            print("âŒ ç”¨æˆ·åé¦ˆå’Œå­¦ä¹ : æµ‹è¯•å¤±è´¥")
        
        print(f"\nğŸ’¡ æ ¸å¿ƒç‰¹æ€§éªŒè¯:")
        print("ğŸ¯ å®Œå…¨æ•°æ®åº“é©±åŠ¨ - æ— é…ç½®æ–‡ä»¶ä¾èµ–")
        print("ğŸ‘¤ ç”¨æˆ·ä¸“å±æœåŠ¡ - æ‰€æœ‰æœåŠ¡éƒ½éœ€è¦user_id")
        print("ğŸ§  æ™ºèƒ½æ¨¡å‹é€‰æ‹© - åŸºäºç”¨æˆ·é…ç½®å’Œåå¥½")
        print("ğŸ¤– ä¸ªæ€§åŒ–Agent - æ¯ä¸ªç”¨æˆ·æœ‰ä¸“å±Agentå®ä¾‹")
        print("ğŸ“ˆ æŒç»­å­¦ä¹ ä¼˜åŒ– - åŸºäºç”¨æˆ·åé¦ˆæ”¹è¿›é€‰æ‹©")
        print("ğŸ”’ ç”¨æˆ·éš”ç¦» - ä¸åŒç”¨æˆ·çš„é…ç½®å’Œæ•°æ®å®Œå…¨éš”ç¦»")
        
        print(f"\nâœ¨ æ¶æ„ä¼˜åŠ¿:")
        print("ğŸ—ï¸ çº¯å‡€æ¶æ„ - ç§»é™¤æ‰€æœ‰å‘åå…¼å®¹å’Œé…ç½®æ–‡ä»¶ä»£ç ")
        print("ğŸ“Š æ•°æ®é©±åŠ¨ - æ‰€æœ‰é…ç½®æ¥æºäºæ•°æ®åº“")
        print("ğŸ›ï¸ ç”¨æˆ·æ§åˆ¶ - å‰ç«¯é…ç½®é¡µé¢ç›´æ¥æ§åˆ¶åç«¯è¡Œä¸º")
        print("ğŸ”„ å®æ—¶æ›´æ–° - ç”¨æˆ·é…ç½®å˜æ›´ç«‹å³ç”Ÿæ•ˆ")
        print("ğŸ“ˆ å¯æ‰©å±•æ€§ - æ”¯æŒæ— é™ç”¨æˆ·å’Œæ¨¡å‹é…ç½®")
        
        print(f"\nğŸ‰ çº¯æ•°æ®åº“é©±åŠ¨ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ä¸»æµ‹è¯•å‡½æ•°å¤±è´¥: {e}")
        print(f"âŒ ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())