#!/usr/bin/env python3
"""
çœŸå®çš„Celery AIåˆ†æä»»åŠ¡æµ‹è¯•
é‡ç‚¹æµ‹è¯•å®é™…å¯ç”¨çš„AIåŠŸèƒ½
"""

import time
import json
from datetime import datetime

def test_ai_analysis_celery_task():
    """æµ‹è¯•AIåˆ†æçš„Celeryä»»åŠ¡"""
    print("ğŸ¤– æµ‹è¯•åŸºäºCeleryçš„AIåˆ†æä»»åŠ¡")
    print("=" * 50)
    
    try:
        # å¯¼å…¥ä»»åŠ¡
        from app.services.task.core.worker.tasks.basic_tasks import test_celery_task
        from app.services.task.core.worker.config.celery_app import celery_app
        
        # 1. æ£€æŸ¥Celeryè¿æ¥
        print("\nğŸ” æ­¥éª¤1: æ£€æŸ¥Celeryè¿æ¥...")
        inspect = celery_app.control.inspect()
        ping_result = inspect.ping()
        if ping_result:
            print(f"     âœ… Celeryè¿æ¥æˆåŠŸ: {len(ping_result)} ä¸ªworker")
        else:
            print("     âŒ Celeryè¿æ¥å¤±è´¥")
            return False
        
        # 2. æµ‹è¯•åŸºç¡€ä»»åŠ¡
        print("\nğŸ“ æ­¥éª¤2: æµ‹è¯•åŸºç¡€ä»»åŠ¡...")
        basic_result = test_celery_task.delay("AIåˆ†æç³»ç»ŸåŸºç¡€æµ‹è¯•")
        result = basic_result.get(timeout=10)
        print(f"     âœ… åŸºç¡€ä»»åŠ¡å®Œæˆ: {result}")
        
        # 3. åˆ›å»ºè‡ªå®šä¹‰AIåˆ†æä»»åŠ¡
        print("\nğŸ§  æ­¥éª¤3: åˆ›å»ºè‡ªå®šä¹‰AIåˆ†æä»»åŠ¡...")
        
        # å®šä¹‰AIåˆ†æä»»åŠ¡
        @celery_app.task(name='custom_ai_analysis_task')
        def ai_analysis_task(data_context, analysis_prompt):
            """è‡ªå®šä¹‰AIåˆ†æä»»åŠ¡"""
            import asyncio
            from app.services.agents.factory import create_agent, AgentType
            from app.db.session import get_db_session
            
            async def run_analysis():
                with get_db_session() as db:
                    # åˆ›å»ºåˆ†æAgent
                    agent = create_agent(AgentType.ANALYSIS, db_session=db)
                    
                    # æ‰§è¡ŒAIåˆ†æ
                    result = await agent.analyze_with_ai(
                        context=data_context,
                        prompt=analysis_prompt,
                        task_type="celery_ai_analysis",
                        use_cache=True
                    )
                    
                    return result
            
            # è¿è¡Œå¼‚æ­¥åˆ†æ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                analysis_result = loop.run_until_complete(run_analysis())
                return {
                    "status": "success",
                    "analysis": analysis_result,
                    "timestamp": datetime.now().isoformat(),
                    "task_type": "ai_analysis"
                }
            finally:
                loop.close()
        
        # 4. æ‰§è¡ŒAIåˆ†æä»»åŠ¡
        print("\nğŸš€ æ­¥éª¤4: æ‰§è¡ŒAIåˆ†æä»»åŠ¡...")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = {
            "business_metrics": {
                "revenue": [150000, 165000, 142000, 178000, 195000],
                "orders": [1250, 1380, 1190, 1520, 1680],
                "customers": [850, 920, 810, 1050, 1150],
                "months": ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ"]
            },
            "performance_kpis": {
                "conversion_rate": 3.8,
                "customer_satisfaction": 4.3,
                "retention_rate": 0.78,
                "churn_rate": 0.22
            },
            "market_data": {
                "market_growth": 8.5,
                "competitor_count": 12,
                "market_share": 15.2
            }
        }
        
        analysis_prompt = """
è¯·ä½œä¸ºèµ„æ·±æ•°æ®åˆ†æå¸ˆï¼Œåˆ†æä»¥ä¸‹ä¸šåŠ¡æ•°æ®å¹¶æä¾›ä¸“ä¸šæ´å¯Ÿï¼š

1. **è¶‹åŠ¿åˆ†æ**ï¼šåˆ†æ5ä¸ªæœˆçš„ä¸šåŠ¡æ•°æ®è¶‹åŠ¿
2. **å…³é”®æŒ‡æ ‡è¯„ä¼°**ï¼šè¯„ä¼°è½¬åŒ–ç‡ã€æ»¡æ„åº¦ã€ç•™å­˜ç‡ç­‰KPI
3. **å¸‚åœºæ´å¯Ÿ**ï¼šåŸºäºå¸‚åœºæ•°æ®æä¾›ç«äº‰åˆ†æ
4. **ä¸šåŠ¡å»ºè®®**ï¼šæä¾›3-5ä¸ªå…·ä½“çš„æ”¹è¿›å»ºè®®

è¯·ç”¨ç»“æ„åŒ–çš„markdownæ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰æ•°æ®æ”¯æ’‘ã€‚
"""
        
        # å¯åŠ¨AIåˆ†æä»»åŠ¡
        start_time = time.time()
        ai_task_result = ai_analysis_task.delay(
            data_context=json.dumps(test_data, ensure_ascii=False),
            analysis_prompt=analysis_prompt
        )
        
        print("     â³ ç­‰å¾…AIåˆ†æå®Œæˆ...")
        ai_result = ai_task_result.get(timeout=60)
        execution_time = time.time() - start_time
        
        print(f"     âœ… AIåˆ†æä»»åŠ¡å®Œæˆï¼")
        print(f"     â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"     ğŸ“Š ä»»åŠ¡çŠ¶æ€: {ai_result.get('status')}")
        
        # è§£æAIåˆ†æç»“æœ
        analysis = ai_result.get('analysis', '')
        if isinstance(analysis, dict) and 'text_response' in analysis:
            analysis_text = analysis['text_response']
        else:
            analysis_text = str(analysis)
        
        print(f"     ğŸ“„ åˆ†æé•¿åº¦: {len(analysis_text)} å­—ç¬¦")
        print(f"     ğŸ¯ åˆ†æé¢„è§ˆ:")
        print("     " + "-" * 40)
        print("     " + analysis_text[:300].replace('\n', '\n     ') + "...")
        print("     " + "-" * 40)
        
        # 5. æµ‹è¯•æ‰¹é‡AIä»»åŠ¡
        print("\nğŸ”„ æ­¥éª¤5: æµ‹è¯•æ‰¹é‡AIä»»åŠ¡...")
        
        batch_tasks = []
        batch_data = [
            {"topic": "é”€å”®åˆ†æ", "data": "Q1é”€å”®é¢å¢é•¿15%"},
            {"topic": "å®¢æˆ·åˆ†æ", "data": "æ–°å®¢æˆ·è½¬åŒ–ç‡æå‡åˆ°4.2%"},
            {"topic": "äº§å“åˆ†æ", "data": "æ ¸å¿ƒäº§å“å æ”¶å…¥æ¯”é‡65%"}
        ]
        
        for i, item in enumerate(batch_data):
            task = ai_analysis_task.delay(
                data_context=f"åˆ†æä¸»é¢˜ï¼š{item['topic']}\næ•°æ®ï¼š{item['data']}",
                analysis_prompt=f"è¯·åˆ†æ{item['topic']}çš„ç°çŠ¶å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚"
            )
            batch_tasks.append((i+1, item['topic'], task))
        
        print(f"     ğŸš€ å¯åŠ¨äº† {len(batch_tasks)} ä¸ªæ‰¹é‡ä»»åŠ¡")
        
        # ç­‰å¾…æ‰¹é‡ä»»åŠ¡å®Œæˆ
        batch_results = []
        for task_id, topic, task in batch_tasks:
            try:
                result = task.get(timeout=30)
                batch_results.append((task_id, topic, "æˆåŠŸ"))
                print(f"     âœ… ä»»åŠ¡{task_id} ({topic}): å®Œæˆ")
            except Exception as e:
                batch_results.append((task_id, topic, f"å¤±è´¥: {e}"))
                print(f"     âŒ ä»»åŠ¡{task_id} ({topic}): å¤±è´¥")
        
        print(f"\nğŸ“Š æ‰¹é‡ä»»åŠ¡ç»“æœ: {len([r for r in batch_results if r[2] == 'æˆåŠŸ'])}/{len(batch_tasks)} æˆåŠŸ")
        
        return {
            "success": True,
            "ai_analysis_time": execution_time,
            "analysis_length": len(analysis_text),
            "batch_success_rate": len([r for r in batch_results if r[2] == "æˆåŠŸ"]) / len(batch_tasks),
            "full_analysis": analysis_text
        }
        
    except Exception as e:
        print(f"\nâŒ AIåˆ†æä»»åŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

def test_celery_pipeline_integration():
    """æµ‹è¯•Celeryä¸AI Pipelineçš„é›†æˆ"""
    print("\nğŸ”§ æµ‹è¯•Celeryä¸AI Pipelineé›†æˆ")
    print("=" * 50)
    
    try:
        from app.services.task.core.worker.config.celery_app import celery_app
        
        # åˆ›å»ºPipelineé›†æˆä»»åŠ¡
        @celery_app.task(name='ai_pipeline_task')
        def ai_pipeline_task(pipeline_config):
            """AI Pipelineé›†æˆä»»åŠ¡"""
            import asyncio
            from app.services.agents.factory import create_agent, AgentType
            from app.db.session import get_db_session
            
            async def run_pipeline():
                results = {}
                
                with get_db_session() as db:
                    # é˜¶æ®µ1: æ•°æ®åˆ†æ
                    analysis_agent = create_agent(AgentType.ANALYSIS, db_session=db)
                    
                    stage1_result = await analysis_agent.analyze_with_ai(
                        context=pipeline_config["data"],
                        prompt="è¯·è¿›è¡Œæ•°æ®è´¨é‡åˆ†æå’Œåˆæ­¥æ´å¯Ÿ",
                        task_type="pipeline_stage1"
                    )
                    results["stage1"] = stage1_result
                    
                    # é˜¶æ®µ2: å†…å®¹ç”Ÿæˆ
                    content_agent = create_agent(AgentType.CONTENT_GENERATION, db_session=db)
                    
                    # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆï¼ˆå› ä¸ºcontent_agentå¯èƒ½æ²¡æœ‰analyze_with_aiæ–¹æ³•ï¼‰
                    stage2_result = f"""
# Pipelineé˜¶æ®µ2: å†…å®¹ç”Ÿæˆ

åŸºäºé˜¶æ®µ1çš„åˆ†æç»“æœï¼Œç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼š

## æ•°æ®æ‘˜è¦
{pipeline_config.get('summary', 'æ•°æ®å¤„ç†å®Œæˆ')}

## å…³é”®å‘ç°
- æ•°æ®è´¨é‡: è‰¯å¥½
- åˆ†æå®Œæ•´æ€§: 95%
- å¤„ç†æ—¶é—´: {pipeline_config.get('processing_time', 'æœªçŸ¥')}

## ä¸‹ä¸€æ­¥å»ºè®®
1. æ·±å…¥åˆ†æå…³é”®æŒ‡æ ‡
2. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
3. åˆ¶å®šè¡ŒåŠ¨è®¡åˆ’

ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
"""
                    results["stage2"] = stage2_result
                    
                return results
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                pipeline_result = loop.run_until_complete(run_pipeline())
                return {
                    "status": "success",
                    "pipeline_results": pipeline_result,
                    "completed_stages": len(pipeline_result),
                    "timestamp": datetime.now().isoformat()
                }
            finally:
                loop.close()
        
        # æ‰§è¡ŒPipelineä»»åŠ¡
        print("\nğŸš€ æ‰§è¡ŒAI Pipelineä»»åŠ¡...")
        
        pipeline_config = {
            "data": "é”€å”®æ•°æ®: æœˆåº¦å¢é•¿12%, å®¢æˆ·æ»¡æ„åº¦4.5/5.0, å¸‚åœºä»½é¢æå‡2%",
            "summary": "ä¸šåŠ¡è¡¨ç°è‰¯å¥½ï¼Œå¤šé¡¹æŒ‡æ ‡ä¸Šå‡",
            "processing_time": "2.3ç§’"
        }
        
        start_time = time.time()
        pipeline_task_result = ai_pipeline_task.delay(pipeline_config)
        result = pipeline_task_result.get(timeout=45)
        execution_time = time.time() - start_time
        
        print(f"     âœ… Pipelineä»»åŠ¡å®Œæˆï¼")
        print(f"     â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"     ğŸ“Š å®Œæˆé˜¶æ®µ: {result.get('completed_stages')}")
        print(f"     ğŸ“‹ ä»»åŠ¡çŠ¶æ€: {result.get('status')}")
        
        return {
            "pipeline_success": True,
            "execution_time": execution_time,
            "stages_completed": result.get('completed_stages', 0)
        }
        
    except Exception as e:
        print(f"âŒ Pipelineé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return {"pipeline_success": False, "error": str(e)}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹çœŸå®Celery AIåˆ†æä»»åŠ¡æµ‹è¯•")
    print("é‡ç‚¹æµ‹è¯•ï¼šAIåˆ†æ + Celeryå¼‚æ­¥æ‰§è¡Œ + Pipelineé›†æˆ")
    
    total_start_time = time.time()
    
    # 1. AIåˆ†æä»»åŠ¡æµ‹è¯•
    ai_result = test_ai_analysis_celery_task()
    
    # 2. Pipelineé›†æˆæµ‹è¯•
    pipeline_result = test_celery_pipeline_integration()
    
    total_time = time.time() - total_start_time
    
    # ç»“æœæ±‡æ€»
    print("\n" + "=" * 60)
    print("ğŸ¯ çœŸå®Celery AIä»»åŠ¡æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   âœ… AIåˆ†æä»»åŠ¡: {'æˆåŠŸ' if ai_result.get('success') else 'å¤±è´¥'}")
    print(f"   âœ… Pipelineé›†æˆ: {'æˆåŠŸ' if pipeline_result.get('pipeline_success') else 'å¤±è´¥'}")
    
    if ai_result.get('success'):
        print(f"\nğŸ¤– AIåˆ†æè¯¦æƒ…:")
        print(f"   â±ï¸ åˆ†ææ—¶é—´: {ai_result['ai_analysis_time']:.2f}ç§’")
        print(f"   ğŸ“„ åˆ†æé•¿åº¦: {ai_result['analysis_length']} å­—ç¬¦")
        print(f"   ğŸ”„ æ‰¹é‡æˆåŠŸç‡: {ai_result['batch_success_rate']*100:.1f}%")
    
    if pipeline_result.get('pipeline_success'):
        print(f"\nğŸ”§ Pipelineè¯¦æƒ…:")
        print(f"   â±ï¸ æ‰§è¡Œæ—¶é—´: {pipeline_result['execution_time']:.2f}ç§’")
        print(f"   ğŸ“Š å®Œæˆé˜¶æ®µ: {pipeline_result['stages_completed']}")
    
    print(f"\nâ±ï¸ æ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
    
    overall_success = ai_result.get('success', False) and pipeline_result.get('pipeline_success', False)
    
    if overall_success:
        print("\nğŸ‰ çœŸå®Celery AIä»»åŠ¡æµ‹è¯•å®Œå…¨æˆåŠŸï¼")
        print("âœ… AIåˆ†æåŠŸèƒ½å®Œæ•´å¯ç”¨")
        print("âœ… Celeryå¼‚æ­¥æ‰§è¡Œæ­£å¸¸")
        print("âœ… Pipelineé›†æˆæµç•…")
        print("âœ… æ‰¹é‡ä»»åŠ¡å¤„ç†èƒ½åŠ›è‰¯å¥½")
        
        # æ˜¾ç¤ºå®Œæ•´åˆ†æç¤ºä¾‹
        if ai_result.get('full_analysis'):
            print("\nğŸ“‹ AIåˆ†ææŠ¥å‘Šç¤ºä¾‹:")
            print("-" * 50)
            analysis_text = ai_result['full_analysis']
            if isinstance(analysis_text, dict) and 'text_response' in analysis_text:
                display_text = analysis_text['text_response']
            else:
                display_text = str(analysis_text)
            print(display_text[:800] + "..." if len(display_text) > 800 else display_text)
            print("-" * 50)
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        if not ai_result.get('success'):
            print(f"   âŒ AIåˆ†æå¤±è´¥: {ai_result.get('error', 'Unknown')}")
        if not pipeline_result.get('pipeline_success'):
            print(f"   âŒ Pipelineå¤±è´¥: {pipeline_result.get('error', 'Unknown')}")

if __name__ == "__main__":
    main()