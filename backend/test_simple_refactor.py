"""
ç®€å•çš„é‡æ„éªŒè¯æµ‹è¯• - ç›´æ¥æµ‹è¯•é‡æ„çš„æ ¸å¿ƒç±»
"""

import sys
import os
import asyncio
import json

# ç›´æ¥æ·»åŠ è·¯å¾„é¿å…å¤æ‚çš„å¯¼å…¥é—®é¢˜
sys.path.append('/Users/shan/work/uploads/AutoReportAI/backend')


def test_api_message():
    """æµ‹è¯•APIæ¶ˆæ¯ç±»"""
    print("ğŸ§ª æµ‹è¯•APIæ¶ˆæ¯ç±»")
    
    # ç›´æ¥å¯¼å…¥å¹¶æµ‹è¯•
    from app.services.infrastructure.ai.core.api_messages import APIMessage
    
    # åˆ›å»ºæ¶ˆæ¯
    msg = APIMessage.user_message("æµ‹è¯•æ¶ˆæ¯å†…å®¹")
    assert msg.role == "user"
    assert msg.content == "æµ‹è¯•æ¶ˆæ¯å†…å®¹"
    
    # è½¬æ¢ä¸ºå­—å…¸
    msg_dict = msg.to_dict()
    assert msg_dict["role"] == "user"
    assert msg_dict["content"] == "æµ‹è¯•æ¶ˆæ¯å†…å®¹"
    
    print("âœ… APIæ¶ˆæ¯ç±»æµ‹è¯•é€šè¿‡")
    return True


def test_streaming_parser():
    """æµ‹è¯•æµå¼è§£æå™¨"""
    print("ğŸ§ª æµ‹è¯•æµå¼JSONè§£æå™¨")
    
    from app.services.infrastructure.ai.core.api_messages import StreamingJSONParser
    
    parser = StreamingJSONParser()
    
    # æµ‹è¯•å®Œæ•´JSONè§£æ
    json_text = '{"tool": "test_tool", "params": {"key": "value"}}'
    results = parser.process_chunk(json_text)
    
    assert len(results) == 1
    result = results[0]
    assert result["tool"] == "test_tool"
    assert result["params"]["key"] == "value"
    
    print("âœ… æµå¼JSONè§£æå™¨æµ‹è¯•é€šè¿‡")
    return True


async def test_security_basic():
    """æµ‹è¯•åŸºç¡€å®‰å…¨æ£€æŸ¥"""
    print("ğŸ§ª æµ‹è¯•åŸºç¡€å®‰å…¨æ£€æŸ¥")
    
    from app.services.infrastructure.ai.core.security import SecurityChecker, SecurityLevel
    
    checker = SecurityChecker()
    
    # æµ‹è¯•å®‰å…¨æ“ä½œ
    result = await checker.check_tool_execution(
        "safe_tool",
        {"safe_param": "safe_value"}
    )
    
    assert result.allowed == True
    print(f"å®‰å…¨æ£€æŸ¥ç»“æœ: {result.level.value}")
    
    print("âœ… åŸºç¡€å®‰å…¨æ£€æŸ¥æµ‹è¯•é€šè¿‡")
    return True


def test_enhanced_prompts():
    """æµ‹è¯•å¢å¼ºæç¤ºç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºæç¤ºç³»ç»Ÿ")
    
    from app.services.infrastructure.ai.core.enhanced_prompts import SimplifiedPromptManager
    
    manager = SimplifiedPromptManager()
    
    # ç”Ÿæˆç¼–æ’æç¤º
    prompt = manager.get_orchestration_prompt(
        goal="æµ‹è¯•ç›®æ ‡",
        available_tools=["tool1", "tool2"]
    )
    
    assert len(prompt) > 0
    assert "æµ‹è¯•ç›®æ ‡" in prompt
    assert "tool1" in prompt
    assert "<task_analysis>" in prompt
    
    print(f"ç”Ÿæˆçš„æç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦")
    print("âœ… å¢å¼ºæç¤ºç³»ç»Ÿæµ‹è¯•é€šè¿‡")
    return True


def test_tool_context():
    """æµ‹è¯•å·¥å…·ä¸Šä¸‹æ–‡"""
    print("ğŸ§ª æµ‹è¯•å·¥å…·ä¸Šä¸‹æ–‡")
    
    from app.services.infrastructure.ai.core.tools import ToolContext
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    context = ToolContext(
        user_id="test_user",
        task_id="test_task", 
        session_id="test_session"
    )
    
    # æµ‹è¯•åŸºç¡€å±æ€§
    assert context.user_id == "test_user"
    assert context.task_id == "test_task"
    
    # æµ‹è¯•é”™è¯¯è®°å½•
    context.add_error("test_error", "æµ‹è¯•é”™è¯¯")
    errors = context.get_recent_errors()
    assert len(errors) == 1
    assert errors[0]["type"] == "test_error"
    
    # æµ‹è¯•æ´å¯Ÿè®°å½•
    context.add_insight("æµ‹è¯•æ´å¯Ÿ")
    assert "æµ‹è¯•æ´å¯Ÿ" in context.learned_insights
    
    print("âœ… å·¥å…·ä¸Šä¸‹æ–‡æµ‹è¯•é€šè¿‡")
    return True


async def run_simple_tests():
    """è¿è¡Œç®€å•çš„æµ‹è¯•å¥—ä»¶"""
    print("ğŸš€ å¼€å§‹ç®€åŒ–é‡æ„éªŒè¯æµ‹è¯•\n")
    
    tests = [
        ("APIæ¶ˆæ¯ç±»", test_api_message),
        ("æµå¼è§£æå™¨", test_streaming_parser), 
        ("åŸºç¡€å®‰å…¨æ£€æŸ¥", test_security_basic),
        ("å¢å¼ºæç¤ºç³»ç»Ÿ", test_enhanced_prompts),
        ("å·¥å…·ä¸Šä¸‹æ–‡", test_tool_context)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                passed += 1
                print(f"âœ… {test_name} é€šè¿‡\n")
            else:
                print(f"âŒ {test_name} å¤±è´¥\n")
                
        except Exception as e:
            print(f"ğŸ’¥ {test_name} å¼‚å¸¸: {e}\n")
    
    # è¾“å‡ºç»“æœ
    success_rate = passed / total * 100
    print("=" * 50)
    print("ğŸ† é‡æ„éªŒè¯ç»“æœ")
    print("=" * 50)
    print(f"æµ‹è¯•æ€»æ•°: {total}")
    print(f"é€šè¿‡æ•°é‡: {passed}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    
    if success_rate >= 80:
        print("ğŸ‰ é‡æ„éªŒè¯æˆåŠŸï¼æ ¸å¿ƒç»„ä»¶è¿è¡Œè‰¯å¥½ã€‚")
    elif success_rate >= 60:
        print("âš ï¸ é‡æ„éƒ¨åˆ†æˆåŠŸï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")
    else:
        print("âŒ é‡æ„å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤ã€‚")
    
    print("=" * 50)
    
    return passed, total


if __name__ == "__main__":
    try:
        passed, total = asyncio.run(run_simple_tests())
        print(f"\nğŸ“Š æœ€ç»ˆç»“æœ: {passed}/{total} é€šè¿‡")
    except Exception as e:
        print(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()