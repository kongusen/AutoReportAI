"""
æµ‹è¯•æµå¼LLM APIè°ƒç”¨å’ŒåŠ¨æ€è¶…æ—¶æœºåˆ¶
"""

import asyncio
import sys
import os
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from app.services.infrastructure.ai.llm.pure_database_manager import (
    ask_agent,
    get_user_llm_config,
    call_llm_api
)


async def test_streaming_api():
    """æµ‹è¯•æµå¼APIè°ƒç”¨"""
    logger.info("ğŸ”„ æµ‹è¯•æµå¼LLM APIè°ƒç”¨")
    
    try:
        # è®¾ç½®æ•°æ®åº“è¿æ¥
        os.environ["DATABASE_URL"] = "postgresql://postgres:postgres123@localhost:5432/autoreport"
        os.environ["POSTGRES_PASSWORD"] = "postgres123"
        
        # è·å–ç”¨æˆ·LLMé…ç½®
        user_id = "c9244981-d32d-4ff7-9e92-b50bfd7e4502"  # adminç”¨æˆ·ID
        llm_config = await get_user_llm_config(user_id)
        
        if not llm_config:
            logger.error("æœªæ‰¾åˆ°ç”¨æˆ·LLMé…ç½®")
            return
            
        logger.info(f"æ‰¾åˆ°LLMé…ç½®: {llm_config['model_name']} @ {llm_config['base_url']}")
        
        # æµ‹è¯•1: æ ‡å‡†æ¨¡å‹è°ƒç”¨
        logger.info("\n=== æµ‹è¯•1: æ ‡å‡†æ¨¡å‹è°ƒç”¨ ===")
        standard_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹"},
            {"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯SQLï¼Œç®€çŸ­å›ç­”"}
        ]
        
        # ä¸´æ—¶ä¿®æ”¹æ¨¡å‹åç§°ä¸ºæ ‡å‡†æ¨¡å‹
        standard_config = llm_config.copy()
        standard_config["model_name"] = "gpt-3.5-turbo"  # æ ‡å‡†æ¨¡å‹
        
        standard_result = await call_llm_api(standard_config, standard_messages)
        logger.info(f"æ ‡å‡†æ¨¡å‹å“åº”: {standard_result[:100]}...")
        
        # æµ‹è¯•2: Thinkæ¨¡å‹è°ƒç”¨ï¼ˆæµå¼ï¼‰
        logger.info("\n=== æµ‹è¯•2: Thinkæ¨¡å‹è°ƒç”¨ï¼ˆæµå¼ï¼‰ ===")
        think_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé«˜çº§æ•°æ®åˆ†æä¸“å®¶ï¼Œéœ€è¦æ·±åº¦æ€è€ƒ"},
            {"role": "user", "content": "è¯·è¯¦ç»†åˆ†æä¸€ä¸ªç”µå•†å¹³å°çš„ç”¨æˆ·ç•™å­˜ç‡è®¡ç®—æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸åŒæ—¶é—´çª—å£çš„è®¡ç®—é€»è¾‘ï¼Œå¹¶ç»™å‡ºSQLç¤ºä¾‹ã€‚è¯·ä»”ç»†æ€è€ƒå¹¶ç»™å‡ºå®Œæ•´çš„åˆ†æã€‚"}
        ]
        
        # ä½¿ç”¨thinkæ¨¡å‹
        think_config = llm_config.copy()
        think_config["model_name"] = "deepseek-v3.1-think-250821"  # thinkæ¨¡å‹
        
        think_result = await call_llm_api(think_config, think_messages)
        logger.info(f"Thinkæ¨¡å‹å“åº”é•¿åº¦: {len(think_result)}")
        logger.info(f"Thinkæ¨¡å‹å“åº”é¢„è§ˆ: {think_result[:200]}...")
        
        # æµ‹è¯•3: ä½¿ç”¨ask_agentæ¥å£
        logger.info("\n=== æµ‹è¯•3: ä½¿ç”¨ask_agentæ¥å£ ===")
        agent_result = await ask_agent(
            user_id=user_id,
            question="åŸºäºDorisæ•°æ®åº“ï¼Œå¦‚ä½•è®¡ç®—å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼ˆCLVï¼‰ï¼Ÿ",
            agent_type="data_analyst",
            task_type="reasoning",
            complexity="complex"
        )
        logger.info(f"Agentå“åº”: {agent_result[:200]}...")
        
        logger.info("âœ… æµå¼APIæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æµå¼APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def test_timeout_scenarios():
    """æµ‹è¯•å„ç§è¶…æ—¶åœºæ™¯"""
    logger.info("â±ï¸ æµ‹è¯•è¶…æ—¶åœºæ™¯")
    
    try:
        os.environ["DATABASE_URL"] = "postgresql://postgres:postgres123@localhost:5432/autoreport"
        
        # è·å–LLMé…ç½®
        user_id = "c9244981-d32d-4ff7-9e92-b50bfd7e4502"
        llm_config = await get_user_llm_config(user_id)
        
        if not llm_config:
            logger.error("æœªæ‰¾åˆ°ç”¨æˆ·LLMé…ç½®")
            return
        
        # æµ‹è¯•é•¿æ—¶é—´æ€è€ƒä»»åŠ¡
        logger.info("\n=== æµ‹è¯•é•¿æ—¶é—´æ€è€ƒä»»åŠ¡ ===")
        long_think_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå“²å­¦å®¶å’Œæ•°å­¦å®¶ï¼Œéœ€è¦æ·±åº¦æ€è€ƒå¤æ‚é—®é¢˜"},
            {"role": "user", "content": """
            è¯·æ·±å…¥åˆ†æä»¥ä¸‹å¤æ‚çš„æ•°æ®ç§‘å­¦é—®é¢˜ï¼š
            
            1. å¦‚ä½•è®¾è®¡ä¸€ä¸ªå¤šç»´åº¦çš„ç”¨æˆ·è¡Œä¸ºåˆ†ææ¨¡å‹ï¼Ÿ
            2. åœ¨å¤§æ•°æ®ç¯å¢ƒä¸‹å¦‚ä½•å¹³è¡¡å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Ÿ
            3. æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸é¢„æµ‹å‡†ç¡®æ€§çš„æƒè¡¡ç­–ç•¥ï¼Ÿ
            4. å®æ—¶æ•°æ®æµå¤„ç†ä¸­çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•è®¾è®¡ï¼Ÿ
            5. åˆ†å¸ƒå¼è®¡ç®—ç¯å¢ƒä¸‹çš„æ•°æ®ä¸€è‡´æ€§ä¿è¯æœºåˆ¶ï¼Ÿ
            
            è¯·å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œè¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ç†è®ºåŸºç¡€ã€å®ç°æ–¹æ³•ã€ä¼˜ç¼ºç‚¹å¯¹æ¯”ã€å®é™…åº”ç”¨æ¡ˆä¾‹ç­‰ã€‚
            """}
        ]
        
        think_config = llm_config.copy()
        think_config["model_name"] = "deepseek-v3.1-think-250821"
        
        result = await call_llm_api(think_config, long_think_messages)
        logger.info(f"é•¿æ—¶é—´æ€è€ƒä»»åŠ¡å®Œæˆï¼Œå“åº”é•¿åº¦: {len(result)}")
        
        logger.info("âœ… è¶…æ—¶æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"è¶…æ—¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        logger.info("ğŸš€ å¼€å§‹æµå¼LLM APIæµ‹è¯•")
        
        # åŸºç¡€æµå¼APIæµ‹è¯•
        await test_streaming_api()
        
        # è¶…æ—¶åœºæ™¯æµ‹è¯•
        await test_timeout_scenarios()
        
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"ä¸»æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())